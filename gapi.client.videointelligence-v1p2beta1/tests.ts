/* This is stub file for gapi.client.videointelligence-v1p2beta1 definition tests */
// IMPORTANT
// This file was generated by https://github.com/Maxim-Mazurok/google-api-typings-generator. Please do not edit it manually.
// In case of any problems please post issue to https://github.com/Maxim-Mazurok/google-api-typings-generator

// Revision: 20240325

gapi.load('client', async () => {
  /** now we can use gapi.client */

  await gapi.client.load(
    'https://videointelligence.googleapis.com/$discovery/rest?version=v1p2beta1'
  );
  /** now we can use gapi.client.videointelligence */

  /** don't forget to authenticate your client before sending any request to resources: */
  /** declare client_id registered in Google Developers Console */
  const client_id = '<<PUT YOUR CLIENT ID HERE>>';
  const scope = [
    /** See, edit, configure, and delete your Google Cloud data and see the email address for your Google Account. */
    'https://www.googleapis.com/auth/cloud-platform',
  ];
  const immediate = false;
  gapi.auth.authorize({client_id, scope, immediate}, authResult => {
    if (authResult && !authResult.error) {
      /** handle successful authorization */
      void run();
    } else {
      /** handle authorization error */
    }
  });

  async function run() {
    /** Performs asynchronous video annotation. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `AnnotateVideoProgress` (progress). `Operation.response` contains `AnnotateVideoResponse` (results). */
    await gapi.client.videointelligence.videos.annotate(
      {},
      {
        features: ['Test string'],
        inputContent: 'Test string',
        inputUri: 'Test string',
        locationId: 'Test string',
        outputUri: 'Test string',
        videoContext: {
          explicitContentDetectionConfig: {
            model: 'Test string',
          },
          faceDetectionConfig: {
            includeAttributes: true,
            includeBoundingBoxes: true,
            model: 'Test string',
          },
          labelDetectionConfig: {
            frameConfidenceThreshold: 42,
            labelDetectionMode: 'Test string',
            model: 'Test string',
            stationaryCamera: true,
            videoConfidenceThreshold: 42,
          },
          objectTrackingConfig: {
            model: 'Test string',
          },
          personDetectionConfig: {
            includeAttributes: true,
            includeBoundingBoxes: true,
            includePoseLandmarks: true,
          },
          segments: [
            {
              endTimeOffset: 'Test string',
              startTimeOffset: 'Test string',
            },
          ],
          shotChangeDetectionConfig: {
            model: 'Test string',
          },
          speechTranscriptionConfig: {
            audioTracks: [42],
            diarizationSpeakerCount: 42,
            enableAutomaticPunctuation: true,
            enableSpeakerDiarization: true,
            enableWordConfidence: true,
            filterProfanity: true,
            languageCode: 'Test string',
            maxAlternatives: 42,
            speechContexts: [
              {
                phrases: ['Test string'],
              },
            ],
          },
          textDetectionConfig: {
            languageHints: ['Test string'],
            model: 'Test string',
          },
        },
      }
    );
  }
});
