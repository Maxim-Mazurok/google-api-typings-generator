/* This is stub file for gapi.client.speech-v1 definition tests */
// IMPORTANT
// This file was generated by https://github.com/Maxim-Mazurok/google-api-typings-generator. Please do not edit it manually.
// In case of any problems please post issue to https://github.com/Maxim-Mazurok/google-api-typings-generator

// Revision: 20220808

gapi.load('client', async () => {
    /** now we can use gapi.client */

    await gapi.client.load('https://speech.googleapis.com/$discovery/rest?version=v1');
    /** now we can use gapi.client.speech */

    /** don't forget to authenticate your client before sending any request to resources: */
    /** declare client_id registered in Google Developers Console */
    const client_id = '<<PUT YOUR CLIENT ID HERE>>';
    const scope = [
        /** See, edit, configure, and delete your Google Cloud data and see the email address for your Google Account. */
        'https://www.googleapis.com/auth/cloud-platform',
    ];
    const immediate = false;
    gapi.auth.authorize({ client_id, scope, immediate }, authResult => {
        if (authResult && !authResult.error) {
            /** handle successful authorization */
            run();
        } else {
            /** handle authorization error */
        }
    });

    async function run() {
        /** Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service. */
        await gapi.client.speech.operations.get({
            name: "Test string",
        });
        /**
         * Lists operations that match the specified filter in the request. If the server doesn't support this method, it returns `UNIMPLEMENTED`. NOTE: the `name` binding allows API services to
         * override the binding to use different resource name schemes, such as `users/*‚Äç/operations`. To override the binding, API services can add a binding such as
         * `"/v1/{name=users/*}/operations"` to their service configuration. For backwards compatibility, the default name includes the operations collection id, however overriding users must
         * ensure the name binding is the parent resource, without the operations collection id.
         */
        await gapi.client.speech.operations.list({
            filter: "Test string",
            name: "Test string",
            pageSize: 42,
            pageToken: "Test string",
        });
        /** Create a custom class. */
        await gapi.client.speech.projects.locations.customClasses.create({
            parent: "Test string",
        }, {
            customClass: {
                customClassId: "Test string",
                items: [
                    {
                        value: "Test string",
                    }
                ],
                name: "Test string",
            },
            customClassId: "Test string",
        });
        /** Delete a custom class. */
        await gapi.client.speech.projects.locations.customClasses.delete({
            name: "Test string",
        });
        /** Get a custom class. */
        await gapi.client.speech.projects.locations.customClasses.get({
            name: "Test string",
        });
        /** List custom classes. */
        await gapi.client.speech.projects.locations.customClasses.list({
            pageSize: 42,
            pageToken: "Test string",
            parent: "Test string",
        });
        /** Update a custom class. */
        await gapi.client.speech.projects.locations.customClasses.patch({
            name: "Test string",
            updateMask: "Test string",
        }, {
            customClassId: "Test string",
            items: [
                {
                    value: "Test string",
                }
            ],
            name: "Test string",
        });
        /**
         * Create a set of phrase hints. Each item in the set can be a single word or a multi-word phrase. The items in the PhraseSet are favored by the recognition model when you send a call that
         * includes the PhraseSet.
         */
        await gapi.client.speech.projects.locations.phraseSets.create({
            parent: "Test string",
        }, {
            phraseSet: {
                boost: 42,
                name: "Test string",
                phrases: [
                    {
                        boost: 42,
                        value: "Test string",
                    }
                ],
            },
            phraseSetId: "Test string",
        });
        /** Delete a phrase set. */
        await gapi.client.speech.projects.locations.phraseSets.delete({
            name: "Test string",
        });
        /** Get a phrase set. */
        await gapi.client.speech.projects.locations.phraseSets.get({
            name: "Test string",
        });
        /** List phrase sets. */
        await gapi.client.speech.projects.locations.phraseSets.list({
            pageSize: 42,
            pageToken: "Test string",
            parent: "Test string",
        });
        /** Update a phrase set. */
        await gapi.client.speech.projects.locations.phraseSets.patch({
            name: "Test string",
            updateMask: "Test string",
        }, {
            boost: 42,
            name: "Test string",
            phrases: [
                {
                    boost: 42,
                    value: "Test string",
                }
            ],
        });
        /**
         * Performs asynchronous speech recognition: receive results via the google.longrunning.Operations interface. Returns either an `Operation.error` or an `Operation.response` which contains
         * a `LongRunningRecognizeResponse` message. For more information on asynchronous speech recognition, see the [how-to](https://cloud.google.com/speech-to-text/docs/async-recognize).
         */
        await gapi.client.speech.speech.longrunningrecognize({
        }, {
            audio: {
                content: "Test string",
                uri: "Test string",
            },
            config: {
                adaptation: {
                    customClasses: [
                        {
                            customClassId: "Test string",
                            items: [
                                {
                                    value: "Test string",
                                }
                            ],
                            name: "Test string",
                        }
                    ],
                    phraseSetReferences: [
                        "Test string"
                    ],
                    phraseSets: [
                        {
                            boost: 42,
                            name: "Test string",
                            phrases: [
                                {
                                    boost: 42,
                                    value: "Test string",
                                }
                            ],
                        }
                    ],
                },
                alternativeLanguageCodes: [
                    "Test string"
                ],
                audioChannelCount: 42,
                diarizationConfig: {
                    enableSpeakerDiarization: true,
                    maxSpeakerCount: 42,
                    minSpeakerCount: 42,
                    speakerTag: 42,
                },
                enableAutomaticPunctuation: true,
                enableSeparateRecognitionPerChannel: true,
                enableSpokenEmojis: true,
                enableSpokenPunctuation: true,
                enableWordConfidence: true,
                enableWordTimeOffsets: true,
                encoding: "Test string",
                languageCode: "Test string",
                maxAlternatives: 42,
                metadata: {
                    audioTopic: "Test string",
                    industryNaicsCodeOfAudio: 42,
                    interactionType: "Test string",
                    microphoneDistance: "Test string",
                    originalMediaType: "Test string",
                    originalMimeType: "Test string",
                    recordingDeviceName: "Test string",
                    recordingDeviceType: "Test string",
                },
                model: "Test string",
                profanityFilter: true,
                sampleRateHertz: 42,
                speechContexts: [
                    {
                        boost: 42,
                        phrases: [
                            "Test string"
                        ],
                    }
                ],
                useEnhanced: true,
            },
            outputConfig: {
                gcsUri: "Test string",
            },
        });
        /** Performs synchronous speech recognition: receive results after all audio has been sent and processed. */
        await gapi.client.speech.speech.recognize({
        }, {
            audio: {
                content: "Test string",
                uri: "Test string",
            },
            config: {
                adaptation: {
                    customClasses: [
                        {
                            customClassId: "Test string",
                            items: [
                                {
                                    value: "Test string",
                                }
                            ],
                            name: "Test string",
                        }
                    ],
                    phraseSetReferences: [
                        "Test string"
                    ],
                    phraseSets: [
                        {
                            boost: 42,
                            name: "Test string",
                            phrases: [
                                {
                                    boost: 42,
                                    value: "Test string",
                                }
                            ],
                        }
                    ],
                },
                alternativeLanguageCodes: [
                    "Test string"
                ],
                audioChannelCount: 42,
                diarizationConfig: {
                    enableSpeakerDiarization: true,
                    maxSpeakerCount: 42,
                    minSpeakerCount: 42,
                    speakerTag: 42,
                },
                enableAutomaticPunctuation: true,
                enableSeparateRecognitionPerChannel: true,
                enableSpokenEmojis: true,
                enableSpokenPunctuation: true,
                enableWordConfidence: true,
                enableWordTimeOffsets: true,
                encoding: "Test string",
                languageCode: "Test string",
                maxAlternatives: 42,
                metadata: {
                    audioTopic: "Test string",
                    industryNaicsCodeOfAudio: 42,
                    interactionType: "Test string",
                    microphoneDistance: "Test string",
                    originalMediaType: "Test string",
                    originalMimeType: "Test string",
                    recordingDeviceName: "Test string",
                    recordingDeviceType: "Test string",
                },
                model: "Test string",
                profanityFilter: true,
                sampleRateHertz: 42,
                speechContexts: [
                    {
                        boost: 42,
                        phrases: [
                            "Test string"
                        ],
                    }
                ],
                useEnhanced: true,
            },
        });
    }
});
