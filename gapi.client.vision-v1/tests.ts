/* This is stub file for gapi.client.vision-v1 definition tests */
// IMPORTANT
// This file was generated by https://github.com/Maxim-Mazurok/google-api-typings-generator. Please do not edit it manually.
// In case of any problems please post issue to https://github.com/Maxim-Mazurok/google-api-typings-generator

// Revision: 20240509

gapi.load('client', async () => {
  /** now we can use gapi.client */

  await gapi.client.load(
    'https://vision.googleapis.com/$discovery/rest?version=v1'
  );
  /** now we can use gapi.client.vision */

  /** don't forget to authenticate your client before sending any request to resources: */
  /** declare client_id registered in Google Developers Console */
  const client_id = '<<PUT YOUR CLIENT ID HERE>>';
  const scope = [
    /** See, edit, configure, and delete your Google Cloud data and see the email address for your Google Account. */
    'https://www.googleapis.com/auth/cloud-platform',
    /** Apply machine learning models to understand and label images */
    'https://www.googleapis.com/auth/cloud-vision',
  ];
  const immediate = false;
  gapi.auth.authorize({client_id, scope, immediate}, authResult => {
    if (authResult && !authResult.error) {
      /** handle successful authorization */
      void run();
    } else {
      /** handle authorization error */
    }
  });

  async function run() {
    /** Service that performs image detection and annotation for a batch of files. Now only "application/pdf", "image/tiff" and "image/gif" are supported. This service will extract at most 5 (customers can specify which 5 in AnnotateFileRequest.pages) frames (gif) or pages (pdf or tiff) from each file provided and perform detection and annotation for each image extracted. */
    await gapi.client.vision.files.annotate(
      {},
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
            inputConfig: {
              content: 'Test string',
              gcsSource: {
                uri: 'Test string',
              },
              mimeType: 'Test string',
            },
            pages: [42],
          },
        ],
      }
    );
    /** Run asynchronous image detection and annotation for a list of generic files, such as PDF files, which may contain multiple pages and multiple images per page. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateFilesResponse` (results). */
    await gapi.client.vision.files.asyncBatchAnnotate(
      {},
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
            inputConfig: {
              content: 'Test string',
              gcsSource: {
                uri: 'Test string',
              },
              mimeType: 'Test string',
            },
            outputConfig: {
              batchSize: 42,
              gcsDestination: {
                uri: 'Test string',
              },
            },
          },
        ],
      }
    );
    /** Run image detection and annotation for a batch of images. */
    await gapi.client.vision.images.annotate(
      {},
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            image: {
              content: 'Test string',
              source: {
                gcsImageUri: 'Test string',
                imageUri: 'Test string',
              },
            },
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
          },
        ],
      }
    );
    /** Run asynchronous image detection and annotation for a list of images. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateImagesResponse` (results). This service will write image annotation outputs to json files in customer GCS bucket, each json file containing BatchAnnotateImagesResponse proto. */
    await gapi.client.vision.images.asyncBatchAnnotate(
      {},
      {
        labels: {
          A: 'Test string',
        },
        outputConfig: {
          batchSize: 42,
          gcsDestination: {
            uri: 'Test string',
          },
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            image: {
              content: 'Test string',
              source: {
                gcsImageUri: 'Test string',
                imageUri: 'Test string',
              },
            },
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
          },
        ],
      }
    );
    /** Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service. */
    await gapi.client.vision.locations.operations.get({
      name: 'Test string',
    });
    /** Starts asynchronous cancellation on a long-running operation. The server makes a best effort to cancel the operation, but success is not guaranteed. If the server doesn't support this method, it returns `google.rpc.Code.UNIMPLEMENTED`. Clients can use Operations.GetOperation or other methods to check whether the cancellation succeeded or whether the operation completed despite cancellation. On successful cancellation, the operation is not deleted; instead, it becomes an operation with an Operation.error value with a google.rpc.Status.code of 1, corresponding to `Code.CANCELLED`. */
    await gapi.client.vision.operations.cancel(
      {
        name: 'Test string',
      },
      {}
    );
    /** Deletes a long-running operation. This method indicates that the client is no longer interested in the operation result. It does not cancel the operation. If the server doesn't support this method, it returns `google.rpc.Code.UNIMPLEMENTED`. */
    await gapi.client.vision.operations.delete({
      name: 'Test string',
    });
    /** Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service. */
    await gapi.client.vision.operations.get({
      name: 'Test string',
    });
    /** Lists operations that match the specified filter in the request. If the server doesn't support this method, it returns `UNIMPLEMENTED`. */
    await gapi.client.vision.operations.list({
      filter: 'Test string',
      name: 'Test string',
      pageSize: 42,
      pageToken: 'Test string',
    });
    /** Service that performs image detection and annotation for a batch of files. Now only "application/pdf", "image/tiff" and "image/gif" are supported. This service will extract at most 5 (customers can specify which 5 in AnnotateFileRequest.pages) frames (gif) or pages (pdf or tiff) from each file provided and perform detection and annotation for each image extracted. */
    await gapi.client.vision.projects.files.annotate(
      {
        parent: 'Test string',
      },
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
            inputConfig: {
              content: 'Test string',
              gcsSource: {
                uri: 'Test string',
              },
              mimeType: 'Test string',
            },
            pages: [42],
          },
        ],
      }
    );
    /** Run asynchronous image detection and annotation for a list of generic files, such as PDF files, which may contain multiple pages and multiple images per page. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateFilesResponse` (results). */
    await gapi.client.vision.projects.files.asyncBatchAnnotate(
      {
        parent: 'Test string',
      },
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
            inputConfig: {
              content: 'Test string',
              gcsSource: {
                uri: 'Test string',
              },
              mimeType: 'Test string',
            },
            outputConfig: {
              batchSize: 42,
              gcsDestination: {
                uri: 'Test string',
              },
            },
          },
        ],
      }
    );
    /** Run image detection and annotation for a batch of images. */
    await gapi.client.vision.projects.images.annotate(
      {
        parent: 'Test string',
      },
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            image: {
              content: 'Test string',
              source: {
                gcsImageUri: 'Test string',
                imageUri: 'Test string',
              },
            },
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
          },
        ],
      }
    );
    /** Run asynchronous image detection and annotation for a list of images. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateImagesResponse` (results). This service will write image annotation outputs to json files in customer GCS bucket, each json file containing BatchAnnotateImagesResponse proto. */
    await gapi.client.vision.projects.images.asyncBatchAnnotate(
      {
        parent: 'Test string',
      },
      {
        labels: {
          A: 'Test string',
        },
        outputConfig: {
          batchSize: 42,
          gcsDestination: {
            uri: 'Test string',
          },
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            image: {
              content: 'Test string',
              source: {
                gcsImageUri: 'Test string',
                imageUri: 'Test string',
              },
            },
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
          },
        ],
      }
    );
    /** Service that performs image detection and annotation for a batch of files. Now only "application/pdf", "image/tiff" and "image/gif" are supported. This service will extract at most 5 (customers can specify which 5 in AnnotateFileRequest.pages) frames (gif) or pages (pdf or tiff) from each file provided and perform detection and annotation for each image extracted. */
    await gapi.client.vision.projects.locations.files.annotate(
      {
        parent: 'Test string',
      },
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
            inputConfig: {
              content: 'Test string',
              gcsSource: {
                uri: 'Test string',
              },
              mimeType: 'Test string',
            },
            pages: [42],
          },
        ],
      }
    );
    /** Run asynchronous image detection and annotation for a list of generic files, such as PDF files, which may contain multiple pages and multiple images per page. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateFilesResponse` (results). */
    await gapi.client.vision.projects.locations.files.asyncBatchAnnotate(
      {
        parent: 'Test string',
      },
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
            inputConfig: {
              content: 'Test string',
              gcsSource: {
                uri: 'Test string',
              },
              mimeType: 'Test string',
            },
            outputConfig: {
              batchSize: 42,
              gcsDestination: {
                uri: 'Test string',
              },
            },
          },
        ],
      }
    );
    /** Run image detection and annotation for a batch of images. */
    await gapi.client.vision.projects.locations.images.annotate(
      {
        parent: 'Test string',
      },
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            image: {
              content: 'Test string',
              source: {
                gcsImageUri: 'Test string',
                imageUri: 'Test string',
              },
            },
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
          },
        ],
      }
    );
    /** Run asynchronous image detection and annotation for a list of images. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateImagesResponse` (results). This service will write image annotation outputs to json files in customer GCS bucket, each json file containing BatchAnnotateImagesResponse proto. */
    await gapi.client.vision.projects.locations.images.asyncBatchAnnotate(
      {
        parent: 'Test string',
      },
      {
        labels: {
          A: 'Test string',
        },
        outputConfig: {
          batchSize: 42,
          gcsDestination: {
            uri: 'Test string',
          },
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            image: {
              content: 'Test string',
              source: {
                gcsImageUri: 'Test string',
                imageUri: 'Test string',
              },
            },
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
          },
        ],
      }
    );
    /** Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service. */
    await gapi.client.vision.projects.locations.operations.get({
      name: 'Test string',
    });
    /** Creates and returns a new product resource. Possible errors: * Returns INVALID_ARGUMENT if display_name is missing or longer than 4096 characters. * Returns INVALID_ARGUMENT if description is longer than 4096 characters. * Returns INVALID_ARGUMENT if product_category is missing or invalid. */
    await gapi.client.vision.projects.locations.products.create(
      {
        parent: 'Test string',
        productId: 'Test string',
      },
      {
        description: 'Test string',
        displayName: 'Test string',
        name: 'Test string',
        productCategory: 'Test string',
        productLabels: [
          {
            key: 'Test string',
            value: 'Test string',
          },
        ],
      }
    );
    /** Permanently deletes a product and its reference images. Metadata of the product and all its images will be deleted right away, but search queries against ProductSets containing the product may still work until all related caches are refreshed. */
    await gapi.client.vision.projects.locations.products.delete({
      name: 'Test string',
    });
    /** Gets information associated with a Product. Possible errors: * Returns NOT_FOUND if the Product does not exist. */
    await gapi.client.vision.projects.locations.products.get({
      name: 'Test string',
    });
    /** Lists products in an unspecified order. Possible errors: * Returns INVALID_ARGUMENT if page_size is greater than 100 or less than 1. */
    await gapi.client.vision.projects.locations.products.list({
      pageSize: 42,
      pageToken: 'Test string',
      parent: 'Test string',
    });
    /** Makes changes to a Product resource. Only the `display_name`, `description`, and `labels` fields can be updated right now. If labels are updated, the change will not be reflected in queries until the next index time. Possible errors: * Returns NOT_FOUND if the Product does not exist. * Returns INVALID_ARGUMENT if display_name is present in update_mask but is missing from the request or longer than 4096 characters. * Returns INVALID_ARGUMENT if description is present in update_mask but is longer than 4096 characters. * Returns INVALID_ARGUMENT if product_category is present in update_mask. */
    await gapi.client.vision.projects.locations.products.patch(
      {
        name: 'Test string',
        updateMask: 'Test string',
      },
      {
        description: 'Test string',
        displayName: 'Test string',
        name: 'Test string',
        productCategory: 'Test string',
        productLabels: [
          {
            key: 'Test string',
            value: 'Test string',
          },
        ],
      }
    );
    /** Asynchronous API to delete all Products in a ProductSet or all Products that are in no ProductSet. If a Product is a member of the specified ProductSet in addition to other ProductSets, the Product will still be deleted. It is recommended to not delete the specified ProductSet until after this operation has completed. It is also recommended to not add any of the Products involved in the batch delete to a new ProductSet while this operation is running because those Products may still end up deleted. It's not possible to undo the PurgeProducts operation. Therefore, it is recommended to keep the csv files used in ImportProductSets (if that was how you originally built the Product Set) before starting PurgeProducts, in case you need to re-import the data after deletion. If the plan is to purge all of the Products from a ProductSet and then re-use the empty ProductSet to re-import new Products into the empty ProductSet, you must wait until the PurgeProducts operation has finished for that ProductSet. The google.longrunning.Operation API can be used to keep track of the progress and results of the request. `Operation.metadata` contains `BatchOperationMetadata`. (progress) */
    await gapi.client.vision.projects.locations.products.purge(
      {
        parent: 'Test string',
      },
      {
        deleteOrphanProducts: true,
        force: true,
        productSetPurgeConfig: {
          productSetId: 'Test string',
        },
      }
    );
    /** Creates and returns a new ReferenceImage resource. The `bounding_poly` field is optional. If `bounding_poly` is not specified, the system will try to detect regions of interest in the image that are compatible with the product_category on the parent product. If it is specified, detection is ALWAYS skipped. The system converts polygons into non-rotated rectangles. Note that the pipeline will resize the image if the image resolution is too large to process (above 50MP). Possible errors: * Returns INVALID_ARGUMENT if the image_uri is missing or longer than 4096 characters. * Returns INVALID_ARGUMENT if the product does not exist. * Returns INVALID_ARGUMENT if bounding_poly is not provided, and nothing compatible with the parent product's product_category is detected. * Returns INVALID_ARGUMENT if bounding_poly contains more than 10 polygons. */
    await gapi.client.vision.projects.locations.products.referenceImages.create(
      {
        parent: 'Test string',
        referenceImageId: 'Test string',
      },
      {
        boundingPolys: [
          {
            normalizedVertices: [
              {
                x: 42,
                y: 42,
              },
            ],
            vertices: [
              {
                x: 42,
                y: 42,
              },
            ],
          },
        ],
        name: 'Test string',
        uri: 'Test string',
      }
    );
    /** Permanently deletes a reference image. The image metadata will be deleted right away, but search queries against ProductSets containing the image may still work until all related caches are refreshed. The actual image files are not deleted from Google Cloud Storage. */
    await gapi.client.vision.projects.locations.products.referenceImages.delete(
      {
        name: 'Test string',
      }
    );
    /** Gets information associated with a ReferenceImage. Possible errors: * Returns NOT_FOUND if the specified image does not exist. */
    await gapi.client.vision.projects.locations.products.referenceImages.get({
      name: 'Test string',
    });
    /** Lists reference images. Possible errors: * Returns NOT_FOUND if the parent product does not exist. * Returns INVALID_ARGUMENT if the page_size is greater than 100, or less than 1. */
    await gapi.client.vision.projects.locations.products.referenceImages.list({
      pageSize: 42,
      pageToken: 'Test string',
      parent: 'Test string',
    });
    /** Adds a Product to the specified ProductSet. If the Product is already present, no change is made. One Product can be added to at most 100 ProductSets. Possible errors: * Returns NOT_FOUND if the Product or the ProductSet doesn't exist. */
    await gapi.client.vision.projects.locations.productSets.addProduct(
      {
        name: 'Test string',
      },
      {
        product: 'Test string',
      }
    );
    /** Creates and returns a new ProductSet resource. Possible errors: * Returns INVALID_ARGUMENT if display_name is missing, or is longer than 4096 characters. */
    await gapi.client.vision.projects.locations.productSets.create(
      {
        parent: 'Test string',
        productSetId: 'Test string',
      },
      {
        displayName: 'Test string',
        indexError: {
          code: 42,
          details: [
            {
              A: 42,
            },
          ],
          message: 'Test string',
        },
        indexTime: 'Test string',
        name: 'Test string',
      }
    );
    /** Permanently deletes a ProductSet. Products and ReferenceImages in the ProductSet are not deleted. The actual image files are not deleted from Google Cloud Storage. */
    await gapi.client.vision.projects.locations.productSets.delete({
      name: 'Test string',
    });
    /** Gets information associated with a ProductSet. Possible errors: * Returns NOT_FOUND if the ProductSet does not exist. */
    await gapi.client.vision.projects.locations.productSets.get({
      name: 'Test string',
    });
    /** Asynchronous API that imports a list of reference images to specified product sets based on a list of image information. The google.longrunning.Operation API can be used to keep track of the progress and results of the request. `Operation.metadata` contains `BatchOperationMetadata`. (progress) `Operation.response` contains `ImportProductSetsResponse`. (results) The input source of this method is a csv file on Google Cloud Storage. For the format of the csv file please see ImportProductSetsGcsSource.csv_file_uri. */
    await gapi.client.vision.projects.locations.productSets.import(
      {
        parent: 'Test string',
      },
      {
        inputConfig: {
          gcsSource: {
            csvFileUri: 'Test string',
          },
        },
      }
    );
    /** Lists ProductSets in an unspecified order. Possible errors: * Returns INVALID_ARGUMENT if page_size is greater than 100, or less than 1. */
    await gapi.client.vision.projects.locations.productSets.list({
      pageSize: 42,
      pageToken: 'Test string',
      parent: 'Test string',
    });
    /** Makes changes to a ProductSet resource. Only display_name can be updated currently. Possible errors: * Returns NOT_FOUND if the ProductSet does not exist. * Returns INVALID_ARGUMENT if display_name is present in update_mask but missing from the request or longer than 4096 characters. */
    await gapi.client.vision.projects.locations.productSets.patch(
      {
        name: 'Test string',
        updateMask: 'Test string',
      },
      {
        displayName: 'Test string',
        indexError: {
          code: 42,
          details: [
            {
              A: 42,
            },
          ],
          message: 'Test string',
        },
        indexTime: 'Test string',
        name: 'Test string',
      }
    );
    /** Removes a Product from the specified ProductSet. */
    await gapi.client.vision.projects.locations.productSets.removeProduct(
      {
        name: 'Test string',
      },
      {
        product: 'Test string',
      }
    );
    /** Lists the Products in a ProductSet, in an unspecified order. If the ProductSet does not exist, the products field of the response will be empty. Possible errors: * Returns INVALID_ARGUMENT if page_size is greater than 100 or less than 1. */
    await gapi.client.vision.projects.locations.productSets.products.list({
      name: 'Test string',
      pageSize: 42,
      pageToken: 'Test string',
    });
    /** Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service. */
    await gapi.client.vision.projects.operations.get({
      name: 'Test string',
    });
  }
});
