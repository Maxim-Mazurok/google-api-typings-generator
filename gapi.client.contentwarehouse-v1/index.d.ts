/* Type definitions for non-npm package Document AI Warehouse API v1 0.0 */
// Project: https://cloud.google.com/document-warehouse
// Definitions by: Maxim Mazurok <https://github.com/Maxim-Mazurok>
//                 Nick Amoscato <https://github.com/namoscato>
//                 Declan Vong <https://github.com/declanvong>
// Definitions: https://github.com/DefinitelyTyped/DefinitelyTyped

// IMPORTANT
// This file was generated by https://github.com/Maxim-Mazurok/google-api-typings-generator. Please do not edit it manually.
// In case of any problems please post issue to https://github.com/Maxim-Mazurok/google-api-typings-generator
// Generated from: https://contentwarehouse.googleapis.com/$discovery/rest?version=v1
// Revision: 20221219

/// <reference types="gapi.client" />

declare namespace gapi.client {
    /** Load Document AI Warehouse API v1 */
    function load(urlOrObject: "https://contentwarehouse.googleapis.com/$discovery/rest?version=v1"): Promise<void>;
    /** @deprecated Please load APIs with discovery documents. */
    function load(name: "contentwarehouse", version: "v1"): Promise<void>;
    /** @deprecated Please load APIs with discovery documents. */
    function load(name: "contentwarehouse", version: "v1", callback: () => any): void;

    namespace contentwarehouse {
        interface AbuseiamAbuseType {
            id?: string;
            /**
             * Optional client specific subtype of abuse that is too specific to belong in the above enumeration. For example, some client may want to differentiate nudity from graphic sex, but
             * both are PORNOGRAPHY.
             */
            subtype?: string;
        }
        interface AbuseiamAgeRestriction {
            /** This restriction applies if the user is between [min_age_years, age_years) years old. */
            ageYears?: number;
            minAgeYears?: number;
        }
        interface AbuseiamAndRestriction {
            /** This restriction applies if all of the children apply. */
            child?: AbuseiamUserRestriction[];
        }
        interface AbuseiamClient {
            id?: string;
            /**
             * The name of the subservice within a client. This subservice can be used to affect the flow of decision script, or selection of backend classifiers. For example, StreetView may want
             * to specify a panel is insufficiently blurred (maybe there is a lisense plate or public sex, etc), which requires manual review then the subservice might be "blurring".
             */
            subservice?: string;
        }
        interface AbuseiamClusterEvaluationContext {
            /** The family of the cluster where the case received the evaluation. */
            clusterFamily?: string;
            /** The AbuseIAm rowkey of the cluster where the case received an evaluation. */
            clusterRowkey?: string;
            /**
             * The gaia id of a mail box that ops can send inquiries to for appeals. Used only by user clusters to fill a required gatekeeper param. See gaia_disableserver.DisableSpec.escalate_to
             * field.
             */
            gaiaIdToEscalate?: string;
        }
        interface AbuseiamConstantRestriction {
            /** A constant of type TRUE always applies, and of type FALSE never applies. */
            type?: string;
        }
        interface AbuseiamContentRestriction {
            /** Takedowns specified by admins via AbuseIAm */
            adminVerdict?: AbuseiamVerdict[];
            /** User-specified takedowns */
            userVerdict?: AbuseiamVerdict[];
        }
        interface AbuseiamEvaluation {
            abuseType?: AbuseiamAbuseType;
            /** Who creates this Evaluation. This field is required. */
            backend?: string;
            /** Extra information regarding the cluster review context where the case received the evaluation. */
            clusterEvaluationContext?: AbuseiamClusterEvaluationContext;
            /** Backends can choose to put some debug info in addition to abuse_type, score, and status. */
            comment?: string;
            /**
             * A set of repeated features to allow adapters to return semi structured data. Please, prefer using feature instead of the old misc_data field since it supports richer and more
             * structured data to be passed back.
             */
            feature?: AbuseiamFeature[];
            /** Information about the manual review, for manual review evaluations. Do NOT expect this field to be set if `backend != MANUAL_REVIEW`. */
            manualReviewInfo?: AbuseiamManualReviewEvaluationInfo;
            /**
             * This field is used to store miscellaneous information that Backend might provide. If you find youself here considering to use this field, please prefer using the repeated feature
             * field below instead. It supports a richer structure for passing complex data back from the backend.
             */
            miscData?: AbuseiamNameValuePair[];
            /** When the evaluation was processed by the decision script. */
            processedMicros?: string;
            /** Time in milliseconds when the Backend processed this Evaluation. */
            processTimeMillisecs?: string;
            /** The list of regions where the evaluation applies. */
            region?: AbuseiamRegion[];
            score?: number;
            status?: string;
            target?: AbuseiamTarget;
            /** When the Evaluation was generated. */
            timestampMicros?: string;
            /**
             * A boolean expression tree used to define the restrictions where the verdict applies. Please use java/com/google/ccc/abuse/abuseiam/client/TakedownManager.java to evaluate this
             * proto.
             */
            userRestriction?: AbuseiamUserRestriction;
            /** Version of Backend. For rules, this string is the only way to differentiate between them. */
            version?: string;
            /** Information about the video review, for video review evaluations. Do NOT expect this field to be set if `backend != VIDEO_REVIEW`. */
            videoReviewData?: AbuseiamVideoReviewData;
        }
        interface AbuseiamFeature {
            /** Exactly one of the following should be filled in. */
            booleanValue?: boolean;
            doubleValue?: number;
            /** Useful for applications that need to know how many times a specific feature occurs */
            featureCount?: string;
            /** Useful for timestamps, or for numerical features where it is helpful for decision scripts to have exact values. */
            int64Value?: string;
            /**
             * integer value field is deprecated and shall only be used for passing the following features hardcoded in spamiam::SpamIAmMessage: spamiam::OrkutSenderId spamiam::OrkutPostnumReports
             * spamiam::BloggerNumComments spamiam::BloggerNumCommentsByOthers Another hard-coded spamiam feature is spamiam::BlogName, which can be specified via string value.
             */
            integerValue?: number;
            name?: string;
            stringValue?: string[];
            /** This field should only be used to store a sequence of timestamps associated with the feature. */
            timestampSequence?: string[];
        }
        interface AbuseiamGeoRestriction {
            locale?: AbuseiamGeoRestrictionLocale[];
        }
        interface AbuseiamGeoRestrictionLocale {
            /** The location where the restriction applies. Defaults to the "The world". See go/iii. */
            location?: string;
            /** The UserRestriction that applies to this location. If not specified evaluates to true. */
            restriction?: AbuseiamUserRestriction;
        }
        interface AbuseiamHash {
            /** 64 bit hash in the hex form. */
            hash?: string;
            type?: string;
        }
        interface AbuseiamManualReviewerInfo {
            credential?: string[];
            username?: string;
        }
        interface AbuseiamManualReviewEvaluationInfo {
            /** Reviewer performing the manual review. */
            reviewer?: AbuseiamManualReviewerInfo;
            /** Tool used to perform the manual review. */
            tool?: AbuseiamManualReviewTool;
        }
        interface AbuseiamManualReviewTool {
            experimentId?: string;
            name?: string;
        }
        interface AbuseiamNameValuePair {
            name?: string;
            nonUtf8Value?: string;
            value?: string;
        }
        interface AbuseiamNotRestriction {
            /** This restriction applies if the child does not apply. Only one is allowed. "repeated" is used to avoid breaking Sawzall (See b/6758277). */
            child?: AbuseiamUserRestriction[];
        }
        interface AbuseiamOrRestriction {
            /** This restriction applies if any of the children apply. */
            child?: AbuseiamUserRestriction[];
        }
        interface AbuseiamRegion {
            /** This is a CLDR Region Code: http://wiki/Main/IIIHowTo#using_region It is used to denote the region affected by a verdict. */
            region?: string;
        }
        interface AbuseiamSpecialRestriction {
            type?: string;
        }
        interface AbuseiamTarget {
            id?: string;
            type?: string;
        }
        interface AbuseiamUserNotification {
            channel?: string;
        }
        interface AbuseiamUserRestriction {
            ageRestriction?: AbuseiamAgeRestriction;
            /** Operators */
            andRestriction?: AbuseiamAndRestriction;
            /** Constant */
            constantRestriction?: AbuseiamConstantRestriction;
            /** Leaf Nodes */
            geoRestriction?: AbuseiamGeoRestriction;
            notRestriction?: AbuseiamNotRestriction;
            orRestriction?: AbuseiamOrRestriction;
            specialRestriction?: AbuseiamSpecialRestriction;
        }
        interface AbuseiamVerdict {
            /** Target client of the verdict. It can be used to differentiate verdicts from multiple clients when such verdicts are processed in one common place. */
            client?: AbuseiamClient;
            /** Additional info regarding the verdict. */
            comment?: string;
            decision?: string;
            /** Time duration (in minutes) of the verdict. */
            durationMins?: number;
            /** Evaluations relevant to this verdict. Every Verdict should contain at least one Evaluation. */
            evaluation?: AbuseiamEvaluation[];
            /** Details of all the hashes that can be computed on a message, such as simhash and attachment hash */
            hashes?: AbuseiamHash[];
            /** Is this verdict issued by legal? */
            isLegalIssued?: boolean;
            /** This field is used to pass relevant / necessary scores to our clients. For eg: ASBE propogates these scores to moonshine. */
            miscScores?: AbuseiamNameValuePair[];
            /** A short description of the reason why the verdict decision is made. */
            reasonCode?: string;
            /** The regions in which this verdict should be enforced. Absence of this field indicates that the verdict is applicable everywhere. */
            region?: AbuseiamRegion[];
            /** Restrictions on where this verdict applies. If any restriction is met, the verdict is applied there. If no restrictions are present, the verdict is considered global. */
            restriction?: AbuseiamVerdictRestriction[];
            /** Category of the strike if this is a strike verdict. */
            strikeCategory?: string;
            target?: AbuseiamTarget;
            /** The timestamp of the target. E.g., the time when the target was updated. */
            targetTimestampMicros?: string;
            /** When the verdict is generated */
            timestampMicros?: string;
            /** Extra notification(s) to be delivered to target user or message owner about the verdict. */
            userNotification?: AbuseiamUserNotification[];
            /** version of decision script */
            version?: string;
        }
        interface AbuseiamVerdictRestriction {
            /**
             * For a restriction to apply, all contexts must be satisfied. For example, if context[0] is COUNTRY/'GERMANY' and context[1] is DESTINATION_STREAM/'gplus:SQUARE:knitting_discussion',
             * then the verdict applies only when the 'knitting discussion' square is viewed from inside Germany. Please note that this is present for legacy reasons and users of this field would
             * be migrated to use the user_restriction field defined below.
             */
            context?: AbuseiamVerdictRestrictionContext[];
            /**
             * A boolean expression tree used to define the restrictions where the verdict applies. Please use java/com/google/ccc/abuse/abuseiam/client/TakedownManager.java to evaluate this
             * proto.
             */
            userRestriction?: AbuseiamUserRestriction;
        }
        interface AbuseiamVerdictRestrictionContext {
            /** String identifying the context. */
            id?: string;
            type?: string;
        }
        interface AbuseiamVideoReviewData {
            /** Serialized repeated youtube_admin.adminmatch.csai.ReferenceFragment */
            referenceFragment?: string[];
            /** Information about the video reviewer. */
            reviewer?: AbuseiamVideoReviewer;
            /** The Viper id of the video. */
            videoId?: string;
        }
        interface AbuseiamVideoReviewer {
            type?: string;
            /** The username of the person doing the video review. */
            username?: string;
        }
        interface AdsShoppingReportingOffersSerializedSoriId {
            highId?: string;
            lowId1?: string;
            lowId2?: string;
        }
        interface Anchors {
            anchor?: AnchorsAnchor[];
            /** The total # of local homepage anchors dropped in AnchorAccumulator. */
            homepageAnchorsDropped?: string;
            /**
             * The index tier from which the anchors were extracted. Note that this is only valid in the anchor record written by linkextractor. The value can be one of the enum values defined in
             * segindexer/types.h.
             */
            indexTier?: number;
            /** The total # of local non-homepage anchors dropped in AnchorAccumulator. */
            localAnchorsDropped?: string;
            /** The total # of non-local anchors dropped in AnchorAccumulator. */
            nonlocalAnchorsDropped?: string;
            redundantanchorinfo?: AnchorsRedundantAnchorInfo[];
            /** The *_anchors_dropped fields below are not populated by Alexandria, which uses cdoc.anchor_stats instead. The total # of redundant anchors dropped in linkextractor. */
            redundantAnchorsDropped?: string;
            /** The total # of supplemental anchors dropped in AnchorAccumulator. ## DEPRECATED. */
            supplementalAnchorsDropped?: string;
            /** may be implicit */
            targetDocid?: string;
            /** HOST_LEVEL site chunking. */
            targetSite?: string;
            /** This is produced during link extraction but not written out in the linklogs in order to save space. */
            targetUrl?: string;
        }
        interface AnchorsAnchor {
            bucket?: number;
            /** CATfish tags attached to a link. These are similar to link tags, except the values are created on the fly within Cookbook. See: http://sites/cookbook/exporting/indexing */
            catfishTags?: number[];
            /** If the anchor contained images, these image urls are stored here in compressed form. */
            compressedImageUrls?: string[];
            /** The anchor's original target url, compressed. Available only in Alexandria docjoins when the anchor is forwarded. */
            compressedOriginalTargetUrl?: string;
            context?: number;
            /** This is a hash of terms near the anchor. (This is a second-generation hash replacing the value stored in the 'context' field.) */
            context2?: number;
            /**
             * used for history - the first and last time we have seen this anchor. creation_date also used for Freshdocs Twitter indexing, a retweet is an anchor of the original tweet. This field
             * records the time when a retweet is created.
             */
            creationDate?: number;
            deleted?: boolean;
            deletionDate?: number;
            /** DEPRECATED */
            demotionreason?: number;
            /**
             * Encoded data containing information about newsiness of anchor. Populated only if anchor is classified as coming from a newsy, high quality site. Encoded data for anchor sources are
             * being stored in googledata/quality/freshness/news_anchors/encoded_news_anchors_data.txt Scores are being computed with quality/freshness/news_anchors/ routines.
             */
            encodedNewsAnchorData?: number;
            /** If true, the anchor is for experimental purposes and should not be used in serving. */
            experimental?: boolean;
            /** true iff exp domain */
            expired?: boolean;
            /**
             * # days past Dec 31, 1994, 23:00:00 UTC (Unix time @788914800) that this link was first seen. Should never occupy more than 15 bits. NOTE: this is NOT the same as creation_date;
             * firstseen_date is filled during link extraction
             */
            firstseenDate?: number;
            /** true if we think 'firstseen_date' is an accurate estimate of when the link was actually added to the source page. false if it may have existed for some time before we saw it. */
            firstseenNearCreation?: boolean;
            fontsize?: number;
            /**
             * How the anchor is forwarded to the canonical, available only for forwarded anchors (i.e., the field is set). The forwarding types are defined in URLForwardingUtil
             * (segindexer/segment-indexer-util.h). Always use URLForwardingUtil to access this field and use URLForwardingUtil::GetAnchorForwardingReason to get the explanation how the anchor is
             * forwarded to the canonical. NOTE: Use with caution as it is only set for docjoins generated using the urlmap from repository/updater.
             */
            forwardingTypes?: number;
            /** The URL fragment for this anchor (the foo in http://www.google.com#foo) */
            fragment?: string;
            /** The full context. These are not written out in the linklogs. */
            fullLeftContext?: string[];
            fullRightContext?: string[];
            /**
             * The bit ~roughly~ indicates whether an anchor's source and target pages are on the same domain. Note: this plays no role in determining whether an anchor is onsite, ondomain, or
             * offdomain in mustang (i.e., the bit above).
             */
            isLocal?: boolean;
            /** Used for history and freshness tracking - the timestamp this anchor is updated in indexing. */
            lastUpdateTimestamp?: number;
            /** Additional information related to the anchor, such as additional anchor text or scores. */
            linkAdditionalInfo?: any;
            /** Contains info on link type, source page, etc. */
            linkTags?: number[];
            /** For ranking purposes, the quality of an anchor is measured by its "locality" and "bucket". See quality/anchors/definitions.h for more information. */
            locality?: number;
            /**
             * This is the offset for the first term in the anchor - it can be used as a unique ID for the anchor within the document and compared against all per-tag data. This is measured in
             * bytes from the start of the document. We write this out to the linklogs to recover the original order of links after source/target forwarding. This is necessary for computing the
             * global related data.
             */
            offset?: number;
            /** The docid of the anchor's original target. This field is available if and only if the anchor is forwarded. */
            originalTargetDocid?: string;
            /** Original text, including capitalization and punctuation. Runs of whitespace are collapsed into a single space. */
            origText?: string;
            /** Weight to be stored in linkmaps for pageranker */
            pagerankWeight?: number;
            /** The number of additional links from the same source page to the same target domain. Not populated if is_local is true. */
            parallelLinks?: number;
            /**
             * DEPRECATED. It used to be set if firstseen_date is not set. It's to indicate that the anchor is possibly old, but we don't have enough information to tell until the linkage map is
             * updated. TODO(hxu) rename it to possibly_old_firstseen_date_DEPRECATED after clean up other dependencies.
             */
            possiblyOldFirstseenDate?: boolean;
            /** TEMPORARY */
            setiPagerankWeight?: number;
            source?: AnchorsAnchorSource;
            /**
             * is to record the quality of the anchor's source page and is correlated with but not identical to the index tier of the source page. In the docjoins built by the indexing pipeline
             * (Alexandria), - Anchors marked TYPE_HIGH_QUALITY are from base documents. - Anchors marked TYPE_MEDIUM_QUALITY are from documents of medium quality (roughly but not exactly
             * supplemental tier documents). - Anchors marked TYPE_LOW_QUALITY are from documents of low quality (roughly but not exactly blackhole documents). Note that the source_type can also
             * be used as an importance indicator of an anchor (a lower source_type value indicates a more important anchor), so it is important to enforce that TYPE_HIGH_QUALITY <
             * TYPE_MEDIUM_QUALITY < TYPE_LOW_QUALITY To add a new source type in future, please maintain the proper relationship among the types as well. TYPE_FRESHDOCS, only available in
             * freshdocs indexing, is a special case and is considered the same type as TYPE_HIGH_QUALITY for the purpose of anchor importance in duplicate anchor removal.
             */
            sourceType?: number;
            /**
             * A given target URL may be found in different encodings in different documents. We store the URL encoding with each source anchor so that we can count them later to find the encoding
             * most likely to be expected by the Web site. Around 0.7% of target URLs are expected to require a non-default value here. The default value 0 is referenced in C++ as
             * webutil::kDefaultUrlEncoding. See also webutil/urlencoding.
             */
            targetUrlEncoding?: number;
            /** Space-delimited anchor words. Text that needs segmentation (like CJK or Thai) is unsegmented, since we set FLAGS_segment_during_lexing to false in mr-linkextractor.cc . */
            text?: string;
            /** This field is DEPRECATED and no longer filled. For source page crawl timestamp, use Source.crawl_timestamp. Next tag id should be 62. */
            timestamp?: string;
            /** DEPRECATED: Now in link_tags */
            type?: number;
            /** weights are 0-127 */
            weight?: number;
        }
        interface AnchorsAnchorSource {
            /** Additional information related to the source, such as news hub info. */
            additionalInfo?: any;
            /** anchor++ cluster id */
            cluster?: number;
            /** compressed source url */
            compressedUrl?: string;
            /** Source page crawl timestamp. */
            crawlTimestamp?: string;
            /**
             * The docid field used to be "required", but it is now "optional" because it is not present when anchors are stored in webtable. When anchors are stored as part of docjoin files in
             * the segment indexer, however, docid should be considered required.
             */
            docid?: string;
            /** necessary for anything? */
            doclength?: number;
            /**
             * Information about if the source page is a home page. It can be one of the enum values defined in PerDocData::HomePageInfo (NOT_HOMEPAGE, NOT_TRUSTED, PARTIALLY_TRUSTED, and
             * FULLY_TRUSTED).
             */
            homePageInfo?: number;
            /** uint16 scale */
            indyrank?: number;
            /** DEPRECATED, use packed_ipaddress */
            ipaddr?: number;
            /** default -> English */
            language?: number;
            /** 0 -> no hash */
            linkhash?: string;
            /** Countries to which the source page is local/most relevant; stored as III identifiers for country/region codes (see http://go/iii). */
            localCountryCodes?: number[];
            /** This NSR value has range [0,1000] and is the original value [0.0,1.0] multiplied by 1000 rounded to an integer. */
            nsr?: number;
            outdegree?: number;
            /** approx num of pointed-to sites */
            outsites?: number;
            /** string in IPAddress::ToPackedString() format. */
            packedIpaddress?: string;
            /** uint16 scale */
            pagerank?: number;
            /** unit16 scale */
            pagerankNs?: number;
            /**
             * Page tags are described by enum PageTag in PerDocData. Page tags are used in anchors to identify properties of the linking page. These are DEPRECATED: in the future, use link_tags
             * instead. DEPRECATED
             */
            pageTags?: number[];
            /** DEPRECATED */
            seglanguage?: number;
            site?: string;
            /** uint16 scale */
            spamrank?: number;
            /** deprecated, to be removed after October 20. 0-127 scale */
            spamscore1?: number;
            /** 0-127 scale */
            spamscore2?: number;
            /** Webtable key of source */
            webtableKey?: string;
        }
        interface AnchorsRedundantAnchorInfo {
            anchorsDropped?: string;
            domain?: string;
            text?: string;
        }
        interface AppsDynamiteCustomerId {
            customerId?: string;
        }
        interface AppsDynamiteSharedOrganizationInfo {
            consumerInfo?: any;
            customerInfo?: AppsDynamiteSharedOrganizationInfoCustomerInfo;
        }
        // tslint:disable-next-line:no-empty-interface
        interface AppsDynamiteSharedOrganizationInfoConsumerInfo {
        }
        interface AppsDynamiteSharedOrganizationInfoCustomerInfo {
            customerId?: AppsDynamiteCustomerId;
        }
        interface AppsPeopleActivityBackendDestinationStream {
            /**
             * The hierarchy of IDs. Each individual ID is "flat" and the repeated list defines the hierarchy. Namespaces define the "validity" of this hierachy (depth, naming convention, etc) and
             * the server will reject invalid IDs.
             */
            id?: string[];
            namespace?: string;
        }
        interface AppsPeopleActivityStreamqualityDistillerEngagements {
            /** Corresponds on "This account might be compromised or hacked" reporting action. */
            reportCompromised?: string;
            /** Corresponds on "Harassment or bullying" reporting action. */
            reportHarassment?: string;
            /** Corresponds on "Hate speach or graphic violence" reporting action. */
            reportHate?: string;
            /** Corresponds on "Pornography or sexually explicit material" reporting action. */
            reportPorn?: string;
            /** Corresponds on "Unwanted commercial content or spam" reporting action. */
            reportSpam?: string;
            /** Number of times this activity was served out of asbe/stanza. */
            serveCount?: string;
            /** Timestamp in seconds for which time this record is valid. */
            timeSec?: string;
            /** Corresponds on Distiller comment thumbs down action. */
            ytThumbsDown?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiAbout {
            contentType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** Sanitized HTML value that is only populated when the SANITIZE_ABOUT_HTML extension is requested. */
            safeHtmlValue?: WebutilHtmlTypesSafeHtmlProto;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedData {
            nameDisplayOptions?: AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataNameDisplayOptions;
            photosCompareData?: AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataPhotosCompareData;
            profileEditability?: AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataProfileEditability;
            profileNameModificationHistory?: AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataProfileNameModificationHistory;
        }
        interface AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataNameDisplayOptions {
            nicknameOption?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataPhotosCompareData {
            diffData?: AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataPhotosCompareDataDiffData;
            highResUrl?: string;
            /**
             * True if photo diff is greater than 0.01 on any color band, or if the user has a low res photo but no high res photo. This field is primarily for use in About Me and for other uses
             * it's recommended to use the DiffData values directly instead. The cutoff is based on a heuristic determined in go/comparing-profile-photos
             */
            inconsistentPhoto?: boolean;
            /** Only present if the photo diff is greater than 0.01 on any color band. */
            lowResData?: string;
            lowResUrl?: string;
            monogramUrl?: string;
            /** True if the low-res photo has a private ACL set. */
            privateLowResAcl?: boolean;
        }
        interface AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataPhotosCompareDataDiffData {
            blueDiff?: number;
            greenDiff?: number;
            redDiff?: number;
        }
        interface AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataProfileEditability {
            /**
             * Read-only set of zero or more field paths that are locked for update on this person, such as "person.name", "person.email", etc. The set of fields is only populated for the
             * requester's profile. Fields in the set cannot be edited, added, or deleted from the profile. Attempting to update any of these fields will result in an exception.
             */
            lockedField?: string[];
        }
        interface AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedDataProfileNameModificationHistory {
            /**
             * The number of name changes remaining at RPC request time. This can be more than name_changes_remaining, if user hasn't changed name for some time and accrued quota since last
             * change.
             */
            computedNameChangesRemaining?: number;
            /**
             * The number of nickname changes remaining at RPC request time. This can be more than nickname_changes_remaining, if user hasn't changed nickname for some time and accrued quota since
             * last change.
             */
            computedNicknameChangesRemaining?: number;
            /** The number of name changes remaining at the time the name was last modified. */
            nameChangesRemaining?: number;
            /** The last time the profile name was modified in milliseconds UTC. */
            nameLastModified?: string;
            /** The number of nickname changes remaining at the time the nickname was last modified. */
            nicknameChangesRemaining?: number;
            /** The last time the profile nickname was modified in milliseconds UTC. */
            nicknameLastModified?: string;
            quotaEnforcementStatus?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiAccountEmail {
            email?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiAdditionalContainerInfo {
            /** When the container is a DEVICE_CONTACT, this list provides account information from the raw contact which is the source of this field. */
            rawDeviceContactInfo?: AppsPeopleOzExternalMergedpeopleapiRawDeviceContactInfo[];
        }
        interface AppsPeopleOzExternalMergedpeopleapiAddress {
            country?: string;
            countryCode?: string;
            /** FeatureId associated with the address. The format is the same as that used for ids in PLACE containers in SourceIdentity. */
            encodedPlaceId?: string;
            extendedAddress?: string;
            formatted?: string;
            /** The `type` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedType?: string;
            locality?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            poBox?: string;
            pointSpec?: AppsPeopleOzExternalMergedpeopleapiPointSpec;
            postalCode?: string;
            region?: string;
            streetAddress?: string;
            /** The type of the address. The type can be free form or one of these predefined values: * `home` * `work` * `other` */
            type?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiAffinity {
            /** Contains extra ranking information returned by DAS. */
            affinityMetadata?: SocialGraphWireProtoPeopleapiAffinityMetadata;
            affinityType?: string;
            /** The ID of the container */
            containerId?: string;
            /** The type of container to which this affinity applies */
            containerType?: string;
            /** Used to log events for this affinity value, for disco diagnostic-purposes. See go/disco-diagnostics. */
            loggingId?: string;
            /**
             * Affinity value. Frequently represented as an inverse ranking, sometimes with additional data encoded. If data_formats.affinity_formats.score_format is set to RAW_SCORE then the
             * value will be the score returned by DAS.
             */
            value?: number;
        }
        interface AppsPeopleOzExternalMergedpeopleapiAgeRangeType {
            /**
             * Please read go/people-api-howto:age on how to get age data. Age of the user. The field is set based on profile storage fields such as account birthday. If the source fields are not
             * present, `age_in_years` will be left unset.
             */
            ageInYears?: number;
            /**
             * Deprecated. Use go/supervised-accounts#capabilities-for-child-accounts instead. Denotes whether the user is under the region based Age of Consent. The user's region is based on
             * ClientUserInfo.GlobalTos.AgreedLocation The age is inferred from Birthday field or CertifiedBornBefore field. The region based AoC is specified at go/aoc.
             */
            ageOfConsentStatus?: string;
            /**
             * Deprecated. Please read go/people-api-howto:age on how to get age data. Age range is populated based on `account_birthday` and `certified_born_before`, which may not be set for
             * dasher users.
             */
            ageRange?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
        }
        interface AppsPeopleOzExternalMergedpeopleapiAppUniqueInfo {
            /** Store the app unique id endpoint. This will be passed over to app to fulfill the action. For example, app_unique_id for Whatsapp will be "11234567890@s.whatsapp.net" */
            appUniqueId?: string;
            /** Store third party endpoint that is displayed to users. For example, display_app_unique_id for Whatsapp will be "Message +11234567890". */
            displayAppUniqueId?: string;
            /** Store third party endpoint label. For example, "HOME", "WORK" */
            label?: string;
            /**
             * Store mimetype of this endpoint. We will use this as the differentiator for Assistant to know whether to use the RawContact for messaging, call or video call. For example, send
             * message mimetype for whatsapp: "vnd.android.cursor.item/vnd.com.whatsapp.profile" voice call mimetype for whatsapp: "vnd.android.cursor.item/vnd.com.whatsapp.voip.call"
             */
            mimetype?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiBestDisplayName {
            /** The container the suggested name was sourced from */
            containerType?: string;
            /**
             * The display name. This name is intended to be the best name to display for this Person. It may be built from a variety of fields, even if those fields are not explicitly requested
             * in the request mask. Generally, the display name is formatted in 'first last' format. If the name appears to be a CJK name (as determined by a heuristic), the 'last first' format
             * will be used. There may be other cases that the 'last first' format is used which are not documented here. See the code at:
             * http://google3/java/com/google/focus/backend/client/DisplayNameFormatter.java?l=659&rcl=351360938
             */
            displayName?: string;
            /** The display name, always in 'last first' format. This field does not depend on the format of `display_name` and will always be in 'last first' format. */
            displayNameLastFirst?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiBirthday {
            ageDisableGracePeriod?: AppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriod;
            /** Whether the user has opted in to display their birthday via photo decorations. */
            birthdayDecoration?: SocialGraphApiProtoBirthdayDecoration;
            birthdayResolution?: string;
            /**
             * Birthdays are more accurately represented as a calendar day that does not depend on a timestamp representation at all. When given a timestamp, there are lots of opportunities to
             * make mistakes, so a CalendarDay proto is replacing timestamps. Currently this is always returned by PeopleApi on reads that include birthday fields. New clients should write using
             * calendar_day. Clients that were already writing via date_ms are allowlisted such that writes use that field. Old callers should migrate to writing BOTH date_ms and calendar_day
             * values. If those are consistent, they may be removed from the 'legacy_timestamp_event_write_behavior_enabled' capability.
             */
            calendarDay?: GoogleTypeDate;
            /**
             * Birthdays are currently represented as timestamp values, although the interpretation of these timestamp values is a calendar date. Clients are recommended to read the calendar_day
             * field, which is easier to work with than date_ms. New clients writing to PeopleApi must set calendar_day instead of date_ms. There are a few important details about how this value
             * should be mapped to a calendar date that should be consistent among all clients. 1. Epoch - The epoch or calendar date equivalent to 0 ms is chosen to be 1970-01-01 UTC. 2. Timezone
             * - All of the conversions to calendars should occur in the UTC timezone. We don't typically think of someones birthday changing when they travel, so clients should not use local
             * times. 3. Calendar - The calendar used for the dates should be a Gregorian proleptic calendar. Proleptic means that the rules of the Gregorian calendar are retrofitted to before its
             * adoption. It is easy to get this wrong, particularly with the java GregorianCalendar class, which by default is a mixed Gregorian/Julian calendar. Joda Time makes this easy, but if
             * it's not an option, look into GregorianCalendar.setGregorianChange(). 4. Omitted years - Clients have chosen to represent birthdays or events without years as timestamps within the
             * year zero. When the computed date has a year of 0, it means the client did not specify a year. Note that a year 0 does not exist in a chronology like the familiar Anno Domini (A.D.
             * and B.C.); clients must agree on year numbering. 5. Year Numbering - The chronology used to map dates to the calendar should use Astronomical Year Numbering so that the year 0 is
             * defined and dates before it have a negative year. If libraries only provide Anno Domini, then the year of 1 BC corresponds to year zero and an omitted user provided year. Other BC
             * values are presumed rare, but clients should still not ignore the era and interpret the year as an A.D. value, especially if writing values back to PeopleApi.
             */
            dateMs?: string;
            /** date_ms_as_number contains the same data as date_ms, but has a different type in generated javascript bindings. Non javascript clients can ignore it. */
            dateMsAsNumber?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** People Prompts settings for contact birthday data. */
            prompt?: SocialGraphApiProtoPrompt;
            /** Actual value entered. Allows unstructured values. */
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriod {
            /** Provisional birthday <AoC the user provided, which made them enter the grace period. The main birthday fields were not altered yet while in the grace period. */
            calendarDay?: GoogleTypeDate;
            /** Timestamp which signifies the end of the grace period for this account. */
            gracePeriodEnd?: string;
            /** Timestamp which signifies the start of the grace period for this account. */
            gracePeriodStart?: string;
            gracePeriodType?: string;
            manualGracePeriodInfo?: AppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriodManualGracePeriodInfo;
        }
        interface AppsPeopleOzExternalMergedpeopleapiBirthdayAgeDisableGracePeriodManualGracePeriodInfo {
            /** The Gaia ID of an email that ops can send inquiries to for appeals. */
            escalateTo?: string;
            /** The Gaia ID of a Googler who initiated this disable. */
            executedBy?: string;
            /**
             * When setting a user into age grace period manually, the requester can additionally supply a short human-readable reason of why the account is put into manual grace period. The
             * description will be forwarded to Gaia when we disable the account when the grace period expires.
             */
            reason?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiBraggingRights {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiCalendar {
            /** The `type` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** The type of the calendar URL. The type can be free form or one of these predefined values: * `home` * `freeBusy` * `work` */
            type?: string;
            url?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiCallerIdExtendedData {
            /** Indicates which data source was used to populate the caller ID result */
            callerIdSource?: AppsPeopleOzExternalMergedpeopleapiCallerIdExtendedDataCallerIdSource;
        }
        interface AppsPeopleOzExternalMergedpeopleapiCallerIdExtendedDataCallerIdSource {
            sourceType?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiCertifiedBornBefore {
            /** Indicates that the user was born at or before this time. */
            bornBefore?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
        }
        interface AppsPeopleOzExternalMergedpeopleapiChannelData {
            /** Unique ID that corresponds to a Youtube channel. */
            channelId?: string;
            /** Number of comments for a given Youtube channel. */
            commentCount?: string;
            /** Description of the channel. */
            description?: string;
            playlistCount?: string;
            /**
             * A FIFE URL pointing to the channel's profile image (go/avatar-fife-urls) with default fife url options. Also refer to go/people-api-concepts:photos for People API's FIFE best
             * practices. The image could be up to a couple of days stale, though it is much fresher in practice. If a fresh image is required, contact the YouTubeAccountProfileService. The URL
             * itself expires ~30 days after generation.
             */
            profilePictureUrl?: string;
            /** URL of user's Youtube channel profile. */
            profileUrl?: string;
            /** Number of subscribers for a given Youtube channel. */
            subscriberCount?: string;
            /** Title of the YouTube channel */
            title?: string;
            /**
             * Whether or not the channel's profile has a title/avatar that is canonical in YouTube. Used to determine if the product profile card should be part of the core persona or have their
             * own persona.
             */
            usesYoutubeNames?: boolean;
            /** Number of videos uploaded in a given Youtube channel. */
            videoCount?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiCircleMembership {
            /** The circle that the person belongs to. */
            circleId?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
        }
        interface AppsPeopleOzExternalMergedpeopleapiClientData {
            key?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            namespace?: string;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiCommunicationEmail {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiConnectionReminder {
            /** Contains the Contact level settings that will affect all reminders. */
            contactPromptSettings?: SocialGraphApiProtoContactPromptSettings;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** Contact-level "reminder to connect" prompts for this contact. */
            prompt?: SocialGraphApiProtoPrompt[];
        }
        interface AppsPeopleOzExternalMergedpeopleapiContactCreateContextInfo {
            contactCreateContext?: SocialGraphApiProtoContactCreateContext;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
        }
        interface AppsPeopleOzExternalMergedpeopleapiContactEditContextInfo {
            contactEditContext?: SocialGraphApiProtoContactEditContext;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
        }
        interface AppsPeopleOzExternalMergedpeopleapiContactGroupMembership {
            /**
             * The contact-group that the person belong to. The id can be either a hex-formatted id or a camel-cased SystemContactGroup predefined group name. The id will be predefined group name
             * iff the system_contact_group_id has a value.
             */
            contactGroupId?: string;
            /** Information related to delegated group that this contact belongs to. */
            delegatedGroupInfo?: AppsPeopleOzExternalMergedpeopleapiDelegatedGroupInfo;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** This field will be populated when the membership is in a system-reserved contact-group. */
            systemContactGroupId?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiContactStateInfo {
            contactState?: SocialGraphApiProtoContactState;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
        }
        interface AppsPeopleOzExternalMergedpeopleapiCoverPhoto {
            imageHeight?: number;
            imageId?: string;
            imageUrl?: string;
            imageWidth?: number;
            isAnimated?: boolean;
            isDefault?: boolean;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
        }
        interface AppsPeopleOzExternalMergedpeopleapiCustomerInfo {
            /**
             * DEPRECATED. Use obfuscated_customer_id instead. If result has a GSuite Customer ID, this field will continue to be populated with -1 to indicate the presence of a value for
             * backwards compatibility with clients in the wild. See b/144596193.
             */
            customerId?: string;
            /** Customer organization name for dasher user. */
            customerName?: string;
            /** Obfuscated FlexOrgs customer ID for Dasher user. See cs/symbol:CustomerIdObfuscator. */
            obfuscatedCustomerId?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiCustomSchemaField {
            fieldDisplayName?: string;
            fieldId?: string;
            fieldType?: string;
            /** The `type` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            multiValued?: boolean;
            schemaDisplayName?: string;
            schemaId?: string;
            /** The type of the custom schema field. The type can be free form or one of these predefined values: * `home` * `other` * `work` */
            type?: string;
            /** String representation of the value, based on FieldType */
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiDedupedContainerInfo {
            /** See SourceIdentity.container_type */
            containerType?: string;
            /** See SourceIdentity.id */
            id?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiDelegatedGroupInfo {
            /** Required. The additional id specifically for a delegated group. */
            delegatedGroupId?: SocialGraphApiProtoDelegatedGroupId;
        }
        interface AppsPeopleOzExternalMergedpeopleapiDeviceContactExtraMetadata {
            /** Attributes for this device contact. */
            attributes?: string[];
            /** Usage info for this device contact. */
            usageInfo?: SocialGraphApiProtoUsageInfo[];
        }
        interface AppsPeopleOzExternalMergedpeopleapiDeviceContactId {
            /** Aggregated device contact id on the source device. */
            contactId?: string;
            /** Source device id (go/client-instance-id) of this device contact. */
            deviceId?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiDeviceContactInfo {
            /** Metadata for this device contact. */
            deviceContactMetadata?: AppsPeopleOzExternalMergedpeopleapiDeviceContactExtraMetadata;
            /**
             * Output only. True if any of the contact's phone, email or address fields can be used on devices other than the one it originated from. Note that there can be other fields, typically
             * name, and metadata such as some of the raw_contact_infos that can be used on other devices. Assigned by the server.
             */
            hasCrossDeviceData?: boolean;
            /** Id of the device contact. */
            id?: AppsPeopleOzExternalMergedpeopleapiDeviceContactId;
            /** Last time a device contact was updated on device. */
            lastClientUpdateTime?: string;
            /**
             * An opaque value used by the device to look up this contact if its row id changed as a result of a sync or aggregation. See:
             * https://developer.android.com/reference/android/provider/ContactsContract.ContactsColumns.html#LOOKUP_KEY
             */
            lookupKey?: string;
            /** Info about the raw device contacts that make up this device contact. */
            rawContactInfo?: AppsPeopleOzExternalMergedpeopleapiRawDeviceContactInfo[];
        }
        interface AppsPeopleOzExternalMergedpeopleapiEdgeKeyInfo {
            /** The container ID of the entity this field creates a join to. See `SourceIdentity.id`. */
            containerId?: string;
            /** The type of container that this edge points to. See `SourceIdentity.container_type`. */
            containerType?: string;
            /** Data that is added to the proto by peopleapi read extensions. */
            extendedData?: AppsPeopleOzExternalMergedpeopleapiEdgeKeyInfoExtensionData;
            /**
             * True indicates this edge links this source to a container represented by this person object. Note: Except for certain legacy clients, EdgeKeyInfo is only created for for edges to an
             * entity in this person and this will always be true.
             */
            materialized?: boolean;
        }
        interface AppsPeopleOzExternalMergedpeopleapiEdgeKeyInfoExtensionData {
            /** The GDataCompatibilityExtension will (temporarily) return mobile_owner_id for profile containers. */
            gdataCompatibilityExtensionId?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiEmail {
            certificate?: AppsPeopleOzExternalMergedpeopleapiEmailCertificate[];
            classification?: string;
            /** To read or update, use the CONTACT_GROUP_PREFERENCE mask field. */
            contactGroupPreference?: AppsPeopleOzExternalMergedpeopleapiEmailContactGroupPreference[];
            displayName?: string;
            extendedData?: AppsPeopleOzExternalMergedpeopleapiEmailExtendedData;
            /** The `type` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            signupEmailMetadata?: AppsPeopleOzExternalMergedpeopleapiEmailSignupEmailMetadata;
            /** The type of the email address. The type can be free form or one of these predefined values: * `home` * `work` * `other` */
            type?: string;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiEmailCertificate {
            /** The name of this certificate configuration. Examples could be "High security level" or "For domain emails only". */
            configurationName?: string;
            /** It is conceivable that certificates could be ACLed. We also need to indicate which certificate is the default. The PersonFieldMetadata can accomplish both of these. */
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            status?: AppsPeopleOzExternalMergedpeopleapiEmailCertificateCertificateStatus;
        }
        interface AppsPeopleOzExternalMergedpeopleapiEmailCertificateCertificateStatus {
            /** The certificate expiration timestamp in seconds. */
            notAfterSec?: string;
            /** Current status of the email's certificate chain. */
            statusCode?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiEmailContactGroupPreference {
            contactGroupId?: string;
            /** If the Preference was implicitly set by PeopleApi. A preference with this bit will not be saved. See go/contact-group-email-preference-papi-problem for more info. */
            isSynthetic?: boolean;
            type?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiEmailExtendedData {
            /** For use with the CUSTOMER_INFO_ADDITIONAL_DATA extension. This includes information on whether the given email is internal to or external to the requesting user's domain. */
            internalExternal?: PeoplestackFlexorgsProtoInternalExternal;
            /** For ListPeoplebyKnownId to indicate an email is sythesized from a lookup email. */
            isPlaceholder?: boolean;
            /** For use with the TLS extension. Whether the SMTP server that handles delivery for this email address supports TLS encryption. */
            smtpServerSupportsTls?: boolean;
            /**
             * For use with the Gmail Homograph Warning extension. Whether the email contains mixed character sets that could be used to decieve users. This field is populated by the
             * GMAIL_SECURITY_DATA extension.
             */
            usesConfusingCharacters?: boolean;
        }
        interface AppsPeopleOzExternalMergedpeopleapiEmailSignupEmailMetadata {
            /** This is considered to be the primary signup email. At most 1 signup email will have this set. */
            primary?: boolean;
        }
        interface AppsPeopleOzExternalMergedpeopleapiEmergencyInfo {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /**
             * Opaque id from Pomeroy (go/pomeroy). Non-empty pomeroy_id means that this contact has the potential to become trusted contact or it's already trusted contact. Trust is eventually
             * gaia<->gaia link, but when the trust link is initiated gaia might not be known. Until gaia is discovered, pomeroy_id is used to identify the contact uniquely. If trust_level is
             * missing or set to TRUST_LEVEL_UNSPECIFIED pomeroy_id must be empty.
             */
            pomeroyId?: string;
            trustLevel?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiEvent {
            /**
             * Event are more accurately represented as a calendar day that does not depend on a timestamp representation at all. When given a timestamp, there are lots of opportunities to make
             * mistakes, so a CalendarDay proto is replacing timestamps. PeopleApi will return these values on reads, and unless the client is a legacy caller in the
             * legacy_timestamp_event_write_behavior_enabled capability allowlist, this value is what is used for Person writes.
             */
            calendarDay?: GoogleTypeDate;
            /** The `type` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** People Prompts settings for contact event data. */
            prompt?: SocialGraphApiProtoPrompt;
            /**
             * Clients are recommended to read the calendar_day field instead of timestamp_millis. When writing events, new clients must set calendar_day instead of timestamp_millis. Events are
             * currently represented as timestamp values, although the interpretation of these timestamp values is a calendar date. There are a few important details about how this value should be
             * mapped to a calendar date that should be consistent among all clients. For detailed information, see Birthday.date_ms.
             */
            timestampMillis?: string;
            /** The type of the event. The type can be free form or one of these predefined values: * `anniversary` * `other` */
            type?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiExternalId {
            /** The `type` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** The type of the external ID. The type can be free form or one of these predefined values: * `account` * `customer` * `loginId` * `network` * `organization` */
            type?: string;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiFieldAcl {
            /** A custom type of field ACL entry. The set of all ACL entries includes those listed in acl_entry as well as predefined_acl_entry. */
            aclEntry?: AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntry[];
            /**
             * Set of users that will be authorized to view the field by this field ACL. If the ACL is public, this will only contain ALL_USERS. This field is synthesized, read-only, and currently
             * only used for profile photos. It's populated under "person.photo.metadata.field_acl" for the current photo ACL and "person.photo.metadata.acl_choices" for available photo ACL
             * choices. Note: The set of authorized viewers for a given FieldAcl may depend on the user's account type and domain configuration. For example, a PRIVATE_READ FieldAcl could have any
             * of the following authorized viewers: Consumer user: [IDENTITY_ACL_ESTABLISHED] Dasher user without domain contact sharing: [IDENTITY_ACL_ESTABLISHED] Unicorn user:
             * [SAME_UNICORN_FAMILY] Hafez user: []
             */
            authorizedViewers?: string[];
            /**
             * A common type of field ACL entry. A predefined ACL entry is a shortcut for a commonly occurring case of role and scope. For example, PUBLIC_READ is the same as an AclEntry with role
             * = READER and scope.all_users = true. The set of all ACL entries includes those listed in acl_entry as well as predefined_acl_entry.
             */
            predefinedAclEntry?: string[];
        }
        interface AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntry {
            role?: string;
            scope?: AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScope;
        }
        interface AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScope {
            /** Indicates that the field is accessible to all users including unauthenticated users. For some fields this means "to everyone except blocked users". */
            allUsers?: boolean;
            /** This is a "synthetic" field. In reality domains are treated as gaia- groups. This field will be 'true' when the field is ACLed to the gaia-group of the requester's domain. */
            domainUsers?: boolean;
            membership?: AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScopeMembershipAcl;
            /** Indicates that the field is accessible to a person. */
            person?: AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScopePersonAcl;
        }
        interface AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScopeMembershipAcl {
            circle?: AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScopeMembershipAclCircleAcl;
            contactGroup?: AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScopeMembershipAclContactGroupAcl;
        }
        interface AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScopeMembershipAclCircleAcl {
            circleId?: string;
            circleSet?: string;
            /** Equivalent to Circle.display_name for the circle_id. Included when FieldAclOption.FULL_ACL_WITH_DETAILS is requested. This field is read-only and ignored on update. */
            displayName?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScopeMembershipAclContactGroupAcl {
            /**
             * A contact group ID. This is either a user-defined contact group hex ID, or it is the string name of the enum constant in Group.PredefinedId in FBS backend.proto for predefined
             * groups. Common values for the predefined name include, but are not limited to: all, myContacts, starred, chatBuddies, friends, family, coworkers, and blocked.
             */
            contactGroupId?: string;
            /**
             * The localized display name for the predefined group, if known; or, the display name for the user-defined contact group. Included when FieldAclOption.FULL_ACL_WITH_DETAILS is
             * requested.
             */
            displayName?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiFieldAclAclEntryScopePersonAcl {
            /**
             * DEPRECATED. This is not different than reading from person.name for a self-read; ACLs to a circle or to a non-self person are no longer supported. Equivalent to Name.display_name
             * for the person_id profile. Included when the profile Name is ACLed to the requester and FieldAclOption.FULL_ACL_WITH_DETAILS is requested. This field is read-only and ignored on
             * update.
             */
            displayName?: string;
            personId?: string;
            /**
             * DEPRECATED. This is not different than reading from person.photo for a self-read; ACLs to a circle or to a non-self person are no longer supported. Equivalent to Photo.url for the
             * person_id profile. Included when the profile Photo is ACLed to the requester and FieldAclOption.FULL_ACL_WITH_DETAILS is requested. This field is read-only and ignored on update.
             */
            photoUrl?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiFieldEmergencyInfo {
            emergencyLevel?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiFileAs {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiGender {
            /**
             * Preferred pronoun choice. It's unclear whether this value is constrained to a finite domain by UIs. `address_me_as` may be populated regardless of whether `type` is "male",
             * "female", or "other", although most writers only set it if `type` is "other".
             */
            addressMeAs?: string;
            /**
             * A free-form string indicating what the user entered as their gender. `custom_type` may exist even if the type is "male" or "female", although most writers do not set it unless
             * `type` is "other".
             */
            customType?: string;
            /** The `type` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** The gender. "male", "female", or "other". If "other", typically, additional fields will have additional information. */
            type?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiGPayExtendedData {
            /** Failure type if there is an error when fetching product profile data. */
            failure?: AppsPeopleOzExternalMergedpeopleapiProductProfileFailure;
            /**
             * A number in international format including the country code that is made user readable by including formatting such as spaces. Example: "+41 44 668 1800" DEPRECATED: A user's phone
             * number should be masked and not in an international format
             */
            internationalNumber?: string;
            /** The masked string of a user's phone number The number will be obfucsated with * except the last 4 digits. Refer to: //java/com/google/nbu/paisa/common/PhoneNumberMasker.java */
            maskedNumber?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiGplusExtendedData {
            contentRestriction?: string;
            /** Equivalent to having the DASHER_POLICY bit in the REGISTERED state. */
            isEnterpriseUser?: boolean;
        }
        interface AppsPeopleOzExternalMergedpeopleapiHangoutsExtendedData {
            hadPastHangoutState?: string;
            /**
             * Populated for all contacts. Only set if had_past_hangout_state == HAD_PAST_HANGOUT. INVITATION_NEEDED is not a valid value because there already is a past hangout, which means
             * either the invitation is still pending or it’s been accepted.
             */
            invitationStatus?: string;
            /** True if this is a Hangouts bot. */
            isBot?: boolean;
            isDismissed?: boolean;
            isFavorite?: boolean;
            isPinned?: boolean;
            userType?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiIdentityInfo {
            /** Original lookup token from the request that resulted in this person or one of its containers. */
            originalLookupToken?: string[];
            /**
             * Any former IDs this person may have had, in the case that their ID may have changed. Populated only for sync requests. Examples of such changes include adding an edge to a contact
             * that links to a profile. The ID will change from being contact-oriented to being profile-oriented. To be used to clear out old versions of a person.
             */
            previousPersonId?: string[];
            /** A list of sources contributing to the merged person, including profiles (with gaia-id), contacts and synthetic-contacts. */
            sourceIds?: AppsPeopleOzExternalMergedpeopleapiSourceIdentity[];
        }
        interface AppsPeopleOzExternalMergedpeopleapiIm {
            /** The `protocol` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedProtocol?: string;
            /** The `type` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** The protocol of the IM. The protocol can be free form or one of these predefined values: * `aim` * `msn` * `yahoo` * `skype` * `qq` * `googleTalk` * `icq` * `jabber` * `netMeeting` */
            protocol?: string;
            /** The type of the IM. The type can be free form or one of these predefined values: * `home` * `work` * `other` */
            type?: string;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiInAppNotificationTarget {
            app?: string[];
            clientData?: AppsPeopleOzExternalMergedpeopleapiInAppNotificationTargetClientData[];
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** There may be more than one field from which this IANT originates, as in the case of Bob's public profile. */
            originatingField?: AppsPeopleOzExternalMergedpeopleapiInAppNotificationTargetOriginatingField[];
            type?: string;
            /** The value of the target, used for delivery. E.g., the obfuscated gaia ID for a visible profile. */
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiInAppNotificationTargetClientData {
            /** The app to which this client data applies. */
            app?: string;
            byteValue?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiInAppNotificationTargetOriginatingField {
            /** The index of the relevant field in the merged person */
            fieldIndex?: number;
            fieldType?: string;
            /** The value of the origin field */
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiInAppReachability {
            appType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            reachabilityKey?: AppsPeopleOzExternalMergedpeopleapiInAppReachabilityReachabilityKey;
            status?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiInAppReachabilityReachabilityKey {
            keyType?: string;
            /** The value of the key by which the user said they may be reachable. E.g., the phone number. */
            keyValue?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiInteractionSettings {
            allowed?: boolean;
            interaction?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
        }
        interface AppsPeopleOzExternalMergedpeopleapiInterest {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiLanguage {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiLatLng {
            lat?: number;
            lng?: number;
        }
        interface AppsPeopleOzExternalMergedpeopleapiLegacyFields {
            /** Mobile obfuscated gaia id. This is the same gaia id in metadata.owner_id, but obfuscated with the legacy mobile obfuscator. */
            mobileOwnerId?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiLimitedProfileSettingsField {
            limitedProfileSettings?: SocialGraphApiProtoLimitedProfileSettings;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
        }
        interface AppsPeopleOzExternalMergedpeopleapiLocation {
            buildingId?: string;
            /** The building_name field is only filled if the DESK_LOCATION_ADDITIONAL_DATA extension is active. */
            buildingName?: string;
            current?: boolean;
            /** Most specific textual description of individual desk location. */
            deskCode?: string;
            floorName?: string;
            floorSection?: string;
            /** Indicates the time this location was added or last edited. */
            lastUpdateTime?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** Value indicates the origin of this location information. */
            source?: string;
            /** Describes the type of location. For e.g. Grew_up, Desk. Corresponds to FBS backend.proto Location.StandardTag */
            type?: string;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiManagementUpchain {
            /**
             * List of managers in the chain. If user has manager email "abc@google.com" and manager's manager has email "xyz@google.com" then the list will be: [0]: { email: "abc@google.com" }
             * [1]: { email: "xyz@google.com" }
             */
            indirectManager?: AppsPeopleOzExternalMergedpeopleapiManagementUpchainIndirectManager[];
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            status?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiManagementUpchainIndirectManager {
            email?: string;
            personId?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiMapsExtendedData {
            /** Failure type if there is an error when fetching product profile data. */
            failure?: AppsPeopleOzExternalMergedpeopleapiProductProfileFailure;
            /** Number of people the user is following. */
            followeeCount?: string;
            /** Number of people who are following the user. */
            followerCount?: number;
            /** Sum of creators contributions i.e. reviews, rating, questions, etc. */
            numContributions?: string;
            /** The user's profile photo that might have a badge rendered at the corner if the user is eligible for a badge. */
            profilePhotoUrl?: string;
            /** A user's bio, or tagline. */
            tagline?: string;
            /** A topic that creator has expertise in. This will be in the format: emoji associated with the topic, display name of the topic, topic score */
            topicExpertise?: string[];
            /** A user's caption displayed under the user name on their profile page i.e. 'Local Guide Level 8' */
            userCaption?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiMapsProfile {
            fieldRestriction?: AppsPeopleOzExternalMergedpeopleapiMapsProfileFieldRestriction[];
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            tagline?: string;
            /** A link to the profile owner's website to be displayed in profile. */
            websiteLink?: AppsPeopleOzExternalMergedpeopleapiMapsProfileUrlLink;
        }
        interface AppsPeopleOzExternalMergedpeopleapiMapsProfileFieldRestriction {
            /** Opaque data associated with this restriction e.g. abuse status. */
            clientData?: string;
            type?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiMapsProfileUrlLink {
            /** Anchor text to be displayed as clickable link. If not present, the URL should be displayed directly. */
            anchorText?: string;
            /** The URL to be linked to. */
            url?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiMatchInfo {
            /** The list of matches ordered by most relevant matching for autocomplete coming first. */
            match?: AppsPeopleOzExternalMergedpeopleapiMatchInfoLookupTokenMatch[];
            /** The query token we are matching against. */
            query?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiMatchInfoLookupTokenMatch {
            /** Index right after the last character that matches the query. length = end-start, we have substring = [start, end). */
            endIndex?: number;
            /** Index of the first unicode character that matches the query. */
            startIndex?: number;
        }
        interface AppsPeopleOzExternalMergedpeopleapiMembership {
            /** A circle that the person belongs to. */
            circleId?: string;
            /**
             * A contact-group that the person belong to. The id can be either a hex-formatted id or a camel-cased SystemContactGroup predefined group name. The id will be predefined group name
             * iff the system_contact_group_id has a value.
             */
            contactGroupId?: string;
            /**
             * The metadata field can be used to determine which container generated the membership. For example, when the membership has a contact_group_id, the metadata.container will be CONTACT
             * and the container_id will be the contact Id.
             */
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** The membership has a contact_group_id, this field will be populated when the membership is in a system-reserved contact-group. */
            systemContactGroupId?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiMission {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiName {
            /**
             * Read-only. A name synthesized based on `unstructured_name` and the structured name fields. Example: "John Smith" If a language code is passed in the side channel using
             * http://cs/symbol:framework.rpc.DeprecatedPropagatedLanguageCode.value or http://cs/symbol:google.rpc.context.OriginContext.accept_language and the name does not have
             * `honorific_prefix`, `middle_name`, or `honorific_suffix` set, the language code will be used to format `display_name`. If `include_account_locale` is set on the
             * `MergePersonSourceOptions` and a language code is not passed in the side channel. The language code from go/uls will be used as the language code for formatting `display_name`.
             */
            displayName?: string;
            /** Read-only. A name synthesized based on `unstructured_name` and the structured name fields with the last name first. Example: "Smith, John" */
            displayNameLastFirst?: string;
            /** Read-only. The source of the display name. */
            displayNameSource?: SocialGraphApiProtoDisplayNameSource;
            familyName?: string;
            /** DEPRECATED(b/70571931). Use `unstructured_name` instead. */
            formattedName?: string;
            givenName?: string;
            honorificPrefix?: string;
            honorificSuffix?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            middleName?: string;
            /** This field is stored in contact annotations and merged at read-time. It is available with CONTACT_ANNOTATION container type at read time. */
            pronunciations?: SocialGraphApiProtoPronunciations;
            /**
             * Read-only. A possibly shorter version of the user's name. - The purpose of this field is to address the needs of UIs where a full display name might be too large to fit. Instead of
             * relying on `first_name`, which might not be present, `short_display_name` is preferred. - This is only available for PROFILE and DOMAIN_PROFILE container types. - About the actual
             * content in this field: will be the first name when it's visible to the requester, or the same as `display_name`, otherwise. A sample scenario where the first name may not be visible
             * is when the limited profile is returned. For more info, see: http://shortn/_9iV7TJ33la
             */
            shortDisplayName?: string;
            /** The free form name value. For contact mutates it is recommended for clients to set either the `unstructured_name` or the set of structured name fields, not both. */
            unstructuredName?: string;
            yomiFamilyName?: string;
            yomiFullName?: string;
            yomiGivenName?: string;
            yomiHonorificPrefix?: string;
            yomiHonorificSuffix?: string;
            yomiMiddleName?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiNickname {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            type?: string;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiOccupation {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiOpeningHours {
            /** Is this place open right now? Always present unless we lack time-of-day or timezone data for these opening hours. */
            openNow?: boolean;
            periods?: AppsPeopleOzExternalMergedpeopleapiOpeningHoursPeriod[];
            /**
             * Localized strings describing the opening hours of this place, one string for each day of the week. Will be empty if the hours are unknown or could not be converted to localized
             * text. Example: "Sun: 18:00-06:00"
             */
            weekdayTexts?: string[];
        }
        interface AppsPeopleOzExternalMergedpeopleapiOpeningHoursEndpoint {
            /** A day of the week, as an integer in the range 0-6. 0 is Sunday, 1 is Monday, etc. */
            day?: number;
            /** A time in 24-hour "hhmm" format (i.e. range is 0000 to 2359). */
            time?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiOpeningHoursPeriod {
            close?: AppsPeopleOzExternalMergedpeopleapiOpeningHoursEndpoint;
            open?: AppsPeopleOzExternalMergedpeopleapiOpeningHoursEndpoint;
        }
        interface AppsPeopleOzExternalMergedpeopleapiOrganization {
            assignment?: AppsPeopleOzExternalMergedpeopleapiOrganizationAssignment[];
            certification?: string;
            costCenter?: string;
            current?: boolean;
            department?: string;
            description?: string;
            domain?: string;
            /**
             * Start and End Dates are better represented as calendar entities. The intention is to replace timestamps. Not set if no value exists. Clients can choose whether to use has* semantics
             * or default value semantics. For writes, the default proto and an absent message are equivalent. Legacy callers in the legacy_timestamp_event_write_behavior_enabled capability
             * allowlist should write to PeopleApi via end_ms and migrate to setting both so they can be removed from the whitelist.
             */
            endCalendarDay?: GoogleTypeDate;
            /**
             * Clients are encouraged to read the end_calendar_day instead. PeopleApi writes will still use end_ms for legacy callers that are in the legacy_timestamp_event_write_behavior_enabled
             * capability allowlist. New writers must use the calendar_day fields.
             */
            endMs?: string;
            endMsAsNumber?: string;
            /** The `string_type` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedStringType?: string;
            fteMilliPercent?: number;
            importance?: number;
            location?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            name?: string;
            project?: AppsPeopleOzExternalMergedpeopleapiOrganizationProject[];
            /**
             * Start and End Dates are better represented as calendar entities. The intention is to replace timestamps. Not set if no value exists. Clients can choose whether to use has* semantics
             * or default value semantics. For writes, the default proto and an absent message are equivalent. Legacy callers in the legacy_timestamp_event_write_behavior_enabled capability
             * allowlist should write to PeopleApi via start_ms and migrate to setting both so they can be removed from the allowlist.
             */
            startCalendarDay?: GoogleTypeDate;
            /**
             * Clients are encouraged to read the start_calendar_day instead. PeopleApi writes will still use start_ms for legacy callers that are in the
             * legacy_timestamp_event_write_behavior_enabled capability allowlist. New writers must use the calendar_day fields.
             */
            startMs?: string;
            startMsAsNumber?: string;
            /** The type of the organization. The type can be free form or one of these predefined values: * `work` * `school` */
            stringType?: string;
            symbol?: string;
            title?: string;
            type?: string;
            yomiName?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiOrganizationAssignment {
            name?: string;
            url?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiOrganizationProject {
            description?: string;
            name?: string;
            role?: string;
            /** Mapped from StandardProjectTag / CustomProjectTag */
            type?: string;
            url?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiOtherKeyword {
            /** The `type` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            source?: string;
            /**
             * The type of the event. The type depends on the `OtherKeyword.source`. `OUTLOOK` source fields must be one of: * `billing_information` * `directory_server` * `keyword` * `mileage` *
             * `sensitivity` * `user` * `subject` All other fields are treated as a `CUSTOM` source field. The value can be free form or one of these predefined values: * `home` * `other` * `work`
             */
            type?: string;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPerson {
            about?: AppsPeopleOzExternalMergedpeopleapiAbout[];
            address?: AppsPeopleOzExternalMergedpeopleapiAddress[];
            /** Deprecated. If age is needed use `person.age_range_repeated` instead. Please see go/people-api-howto:age on how to correctly get age data. */
            ageRange?: string;
            /** Data on the person's age range, adult status, and age of consent. NOTE: Please read go/people-api-howto:age on how to correctly get age data. */
            ageRangeRepeated?: AppsPeopleOzExternalMergedpeopleapiAgeRangeType[];
            birthday?: AppsPeopleOzExternalMergedpeopleapiBirthday[];
            /** Used only by contacts, no data will be returned for profiles. */
            braggingRights?: AppsPeopleOzExternalMergedpeopleapiBraggingRights[];
            /** b/145671020: Deprecated for Profiles, but not for Contacts. */
            calendar?: AppsPeopleOzExternalMergedpeopleapiCalendar[];
            certifiedBornBefore?: AppsPeopleOzExternalMergedpeopleapiCertifiedBornBefore[];
            /** Circles that this person is a member of. */
            circleMembership?: AppsPeopleOzExternalMergedpeopleapiCircleMembership[];
            clientData?: AppsPeopleOzExternalMergedpeopleapiClientData[];
            communicationEmail?: AppsPeopleOzExternalMergedpeopleapiCommunicationEmail[];
            /**
             * Reminder to connect with a Contact (part of go/people-prompts). Also contains contact-level prompts settings. Each Contact can have a single `connection_reminder` (but can have
             * multiple Prompts inside of it). Field is repeated per PeopleAPI data model go/people-api-concepts#repeated. Only supported for CONTACT container.
             */
            connectionReminder?: AppsPeopleOzExternalMergedpeopleapiConnectionReminder[];
            contactCreateContextInfo?: AppsPeopleOzExternalMergedpeopleapiContactCreateContextInfo[];
            contactEditContextInfo?: AppsPeopleOzExternalMergedpeopleapiContactEditContextInfo[];
            /** Contact groups that this person is a member of. */
            contactGroupMembership?: AppsPeopleOzExternalMergedpeopleapiContactGroupMembership[];
            /**
             * Contact state and related metadata. See go/fbs-contacts-trash. If this field was requested but is not set on the Person then the contact is in the DEFAULT contact state. This field
             * is read-only, and should not be set on a mutate (e.g. UpdatePerson) call. Clients must call the explicit APIs (e.g. UntrashPerson) to change contact state.
             */
            contactStateInfo?: AppsPeopleOzExternalMergedpeopleapiContactStateInfo[];
            /** DEPRECATED. Now always returns a default cover photo. See go/sunset-cover-photo. */
            coverPhoto?: AppsPeopleOzExternalMergedpeopleapiCoverPhoto[];
            customSchemaField?: AppsPeopleOzExternalMergedpeopleapiCustomSchemaField[];
            email?: AppsPeopleOzExternalMergedpeopleapiEmail[];
            /** Emergency information. See go/emergency-trusted-contacts-papi. */
            emergencyInfo?: AppsPeopleOzExternalMergedpeopleapiEmergencyInfo[];
            /** Event is currently in use by contacts. */
            event?: AppsPeopleOzExternalMergedpeopleapiEvent[];
            /** Data added by extensions that are not specific to a particular field. */
            extendedData?: AppsPeopleOzExternalMergedpeopleapiPersonExtendedData;
            externalId?: AppsPeopleOzExternalMergedpeopleapiExternalId[];
            fileAs?: AppsPeopleOzExternalMergedpeopleapiFileAs[];
            /** A fingerprint that can be used to reliably determine if a resource has changed. Externally it is used as part of the etag. */
            fingerprint?: string;
            gender?: AppsPeopleOzExternalMergedpeopleapiGender[];
            im?: AppsPeopleOzExternalMergedpeopleapiIm[];
            /** Ways to send in-app notifications to this person. See go/reachability. This field is read-only and ignored for mutates. */
            inAppNotificationTarget?: AppsPeopleOzExternalMergedpeopleapiInAppNotificationTarget[];
            /** Used only by profile service, deprecated for PeopleAPI and Sharpen. If you aren't sure, contact people-api-users@ and profile-service-eng@. */
            inAppReachability?: AppsPeopleOzExternalMergedpeopleapiInAppReachability[];
            /** DEPRECATED. This field isn't populated in people.list. */
            interactionSettings?: AppsPeopleOzExternalMergedpeopleapiInteractionSettings[];
            interest?: AppsPeopleOzExternalMergedpeopleapiInterest[];
            language?: AppsPeopleOzExternalMergedpeopleapiLanguage[];
            /** DEPRECATED. This field was only for backwards compatibility with legacy GData callers, and should not be used by new clients. Legacy fields used for mobile clients. */
            legacyFields?: AppsPeopleOzExternalMergedpeopleapiLegacyFields;
            /** Settings for the limited profile. See go/limited-profiles-api. */
            limitedProfileSettings?: AppsPeopleOzExternalMergedpeopleapiLimitedProfileSettingsField[];
            /**
             * Other person resources linked indirectly by an edge. The full person or just the IDs may be populated depending on request parameters. We consider linked people distinct people, but
             * they share information. Example: A contact with two outgoing edges. The two edges are considered separate, but linked people.
             */
            linkedPerson?: AppsPeopleOzExternalMergedpeopleapiPerson[];
            location?: AppsPeopleOzExternalMergedpeopleapiLocation[];
            managementUpchain?: AppsPeopleOzExternalMergedpeopleapiManagementUpchain[];
            /** MapsProfile, see go/product-profiles-backend-api */
            mapsProfile?: AppsPeopleOzExternalMergedpeopleapiMapsProfile[];
            /** DEPRECATED. Please use `circle_membership` or `contact_group_membership` instead. Contact-groups and circles that this person is a member of. */
            membership?: AppsPeopleOzExternalMergedpeopleapiMembership[];
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonMetadata;
            mission?: AppsPeopleOzExternalMergedpeopleapiMission[];
            /** See go/people-api-howto:names for details about names in PeopleAPI. */
            name?: AppsPeopleOzExternalMergedpeopleapiName[];
            nickname?: AppsPeopleOzExternalMergedpeopleapiNickname[];
            occupation?: AppsPeopleOzExternalMergedpeopleapiOccupation[];
            organization?: AppsPeopleOzExternalMergedpeopleapiOrganization[];
            /** Legacy arbitrary key value fields */
            otherKeyword?: AppsPeopleOzExternalMergedpeopleapiOtherKeyword[];
            /** DEPRECATED. This feature was stubbed, but never implemented. This field will not be populated with any results. */
            peopleInCommon?: AppsPeopleOzExternalMergedpeopleapiPerson[];
            /**
             * In order to request this field, the client must set desired PersonAttributeKey in the dedicated RequestMask field `person_attribute`. Unlike other person fields, this field cannot
             * be requested in the `include_field` field mask.
             */
            personAttribute?: AppsPeopleOzExternalMergedpeopleapiPersonAttribute[];
            /**
             * The ID of the person. This is determined by the backend, is unstable, and may not be the same as a user_id. Internally referred as 'personKey' to distinguish from the common
             * PersonId pojo. See go/people-api-concepts#person-id
             */
            personId?: string;
            phone?: AppsPeopleOzExternalMergedpeopleapiPhone[];
            /** See go/people-api-concepts/photos for usage details */
            photo?: AppsPeopleOzExternalMergedpeopleapiPhoto[];
            /** Data specific to places. Data which also applies to contacts and profiles such as name, phone, photo, etc. are returned in the corresponding Person fields. */
            placeDetails?: AppsPeopleOzExternalMergedpeopleapiPlaceDetails[];
            /** DEPRECATED. Info about plus pages in the person. */
            plusPageInfo?: AppsPeopleOzExternalMergedpeopleapiPlusPageInfo[];
            posixAccount?: AppsPeopleOzExternalMergedpeopleapiPosixAccount[];
            /**
             * DEPRECATED. (go/people-api-concepts#repeated): Use person.profile_url_repeated instead. Access to this field is restricted to a set of legacy clients. This is a Google+-only field.
             * See go/fbs-g+-deprecation. NOTE: `Person.profile_url` is only populated for profile-centric person.
             */
            profileUrl?: string;
            /** This is a Google+-only field. See go/fbs-g+-deprecation. */
            profileUrlRepeated?: AppsPeopleOzExternalMergedpeopleapiProfileUrl[];
            pronoun?: AppsPeopleOzExternalMergedpeopleapiPronoun[];
            /** Information about the profiles that are a part of this Person. This is only applicable to PROFILE and DOMAIN_PROFILE containers. */
            readOnlyProfileInfo?: AppsPeopleOzExternalMergedpeopleapiReadOnlyProfileInfo[];
            /** See go/relation-vs-relationship for relation vs relationship explanation. */
            relation?: AppsPeopleOzExternalMergedpeopleapiRelation[];
            /** DEPRECATED. No data is returned for this field anymore. */
            relationshipInterest?: AppsPeopleOzExternalMergedpeopleapiRelationshipInterest[];
            /** DEPRECATED. No data is returned for this field anymore. */
            relationshipStatus?: AppsPeopleOzExternalMergedpeopleapiRelationshipStatus[];
            rightOfPublicityState?: AppsPeopleOzExternalMergedpeopleapiRightOfPublicityState[];
            /**
             * Data specific to rosters (such as Google Groups and Chat Rooms). Data which also applies to contacts and profiles such as name, email, and photo, etc are returned in the
             * corresponding Person fields.
             */
            rosterDetails?: AppsPeopleOzExternalMergedpeopleapiRosterDetails[];
            /** Profile for Janata and Search. go/janata-profile-in-sgbe */
            searchProfile?: AppsPeopleOzExternalMergedpeopleapiSearchProfile[];
            /** SipAddress is currently in use by contacts. */
            sipAddress?: AppsPeopleOzExternalMergedpeopleapiSipAddress[];
            skills?: AppsPeopleOzExternalMergedpeopleapiSkills[];
            /** NOTE: this is used by go/starlight, but not actually used or returned in PeopleAPI. See b/27281119 for context. Please reach out to people-api-eng@ if you have questions. */
            socialConnection?: AppsPeopleOzExternalMergedpeopleapiSocialConnection[];
            sortKeys?: AppsPeopleOzExternalMergedpeopleapiSortKeys;
            sshPublicKey?: AppsPeopleOzExternalMergedpeopleapiSshPublicKey[];
            /** Only supported for PLACE container results, no data will be returned for profiles. */
            tagline?: AppsPeopleOzExternalMergedpeopleapiTagline[];
            /** DEPRECATED. *UNSUPPORTED*. This field is never populated. */
            teamsExtendedData?: AppsPeopleOzExternalMergedpeopleapiTeamsExtendedData;
            /** UserDefined is currently in use by contacts. */
            userDefined?: AppsPeopleOzExternalMergedpeopleapiUserDefined[];
            /** Add annotation_id and metadata (product_source) for visible to guests contacts go/visible-to-guests. */
            visibleToGuests?: AppsPeopleOzExternalMergedpeopleapiVisibleToGuests[];
            website?: AppsPeopleOzExternalMergedpeopleapiWebsite[];
        }
        interface AppsPeopleOzExternalMergedpeopleapiPersonAttribute {
            attributeKey?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPersonExtendedData {
            /** For use by AboutMe and SmartProfile clients. */
            aboutMeExtendedData?: AppsPeopleOzExternalMergedpeopleapiAboutMeExtendedData;
            /** For use with Apps Waldo Availability Data extension */
            appsWaldoExtendedData?: SocialGraphWireProtoPeopleapiExtensionAppsWaldoExtendedData;
            /** For use with caller ID extension */
            callerIdExtendedData?: AppsPeopleOzExternalMergedpeopleapiCallerIdExtendedData;
            /** For use with Contacts extension. */
            contactsExtendedData?: AppsPeopleOzExternalMergedpeopleapiWebContactsExtendedData;
            /** Hosted domain this person is a member of. The domain_name is also returned as part of the person's ReadOnlyProfileInfo, so requesting it via this extension is no longer necessary. */
            domainName?: string[];
            /** For use with Dynamite extension. */
            dynamiteExtendedData?: SocialGraphWireProtoPeopleapiExtensionDynamiteExtendedData;
            /** For use with Google Pay extension. */
            gpayExtendedData?: AppsPeopleOzExternalMergedpeopleapiGPayExtendedData;
            /** For use with Google+ extension. */
            gplusExtendedData?: AppsPeopleOzExternalMergedpeopleapiGplusExtendedData;
            /** For use with Hangouts extension. */
            hangoutsExtendedData?: AppsPeopleOzExternalMergedpeopleapiHangoutsExtendedData;
            /**
             * For use with gmail extensions and lookup by email. If true, no person was actually found using the specified email address, but we want to return TLS info about the email address
             * regardless.
             */
            isPlaceholder?: boolean;
            /** For use with Maps extension. */
            mapsExtendedData?: AppsPeopleOzExternalMergedpeopleapiMapsExtendedData;
            /** For use with Paisa extension */
            paisaExtendedData?: SocialGraphWireProtoPeopleapiExtensionPaisaExtendedData;
            /** DEPRECATED: Use people_stack_person_extended_data instead. For use with PeopleStack extension. */
            peopleStackExtendedData?: SocialGraphWireProtoPeopleapiExtensionPeopleStackExtendedData;
            /** For use with PeopleStack extension. */
            peopleStackPersonExtendedData?: SocialGraphWireProtoPeopleapiExtensionPeopleStackPersonExtendedData;
            /** For use with Play Games Product Profile extension. See go/jam-games-profile. The play games profile will be returned only for profile-centric requests. */
            playGamesExtendedData?: AppsPeopleOzExternalMergedpeopleapiPlayGamesExtendedData;
            /**
             * For use with the TLS extension and lookup by email. If true, no person was actually found using the specified email address, but we want to return TLS info about the email address
             * regardless. DEPRECATED: Use is_placeholder instead.
             */
            tlsIsPlaceholder?: boolean;
            /** For use with Youtube extension. */
            youtubeExtendedData?: AppsPeopleOzExternalMergedpeopleapiYoutubeExtendedData;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata {
            /**
             * When the container is PROFILE/DOMAIN_PROFILE and the profile owner is the requester, this read-only, synthesized field indicates which ACLs the user is allowed to set on the profile
             * field. This is distinct from field_acl, which is the field's currently set ACL. field_acl will always be a valid ACL choice, except for the case of default synthesized profile
             * fields like monogram profile photos. For those, field_acl does not represent a user-set field ACL, so it may or may not be a valid choice. In all cases, default_acl_choice will
             * always be a valid choice. This is currently only populated on the photo field when the "person.photo.metadata.acl_choices" mask is set.
             */
            aclChoices?: AppsPeopleOzExternalMergedpeopleapiFieldAcl[];
            /** Additional information about the container of this field. */
            additionalContainerInfo?: AppsPeopleOzExternalMergedpeopleapiAdditionalContainerInfo;
            /** For field-level affinity scores. The affinity between the requester and this particular field in the Person (e.g., frequency of calling a particular phone number). */
            affinity?: AppsPeopleOzExternalMergedpeopleapiAffinity[];
            /** Each field can have different visibility settings Only returned when explicitly requested. */
            contactVisibility?: string[];
            /**
             * DEPRECATED. Use container_type instead. Having the Container be an enum at the PFM message level causes circular dependency when other types try to refer to it. It breaks javascript
             * build targets.
             */
            container?: string;
            /**
             * DEPRECATED. Use encoded_container_id instead. The numeric id of the data source. The id is only unique within a single container type. This is only set when the id of the container
             * is numeric, e.g. contact id.
             */
            containerId?: string;
            /** Indicates if this field is the primary field for the container and container_id. */
            containerPrimary?: boolean;
            /** The source for the data in the field. */
            containerType?: string;
            /** True if this field can be used on other devices than the one it originated from. Assigned by the server. Currently only used for device contacts. */
            crossDeviceAllowed?: boolean;
            /**
             * When the container is PROFILE/DOMAIN_PROFILE and the profile owner is the requester, this read-only, synthesized field contains the default ACL choice. This can be used to select a
             * preferred choice from acl_choices. Generally, default_acl_choice should only be preferred for default synthesized profile fields like monogram profile photos. Otherwise, the
             * existing field_acl should be preferred. This is currently only populated on the photo field when the "person.photo.metadata.acl_choices" mask is set.
             */
            defaultAclChoice?: AppsPeopleOzExternalMergedpeopleapiFieldAcl;
            /** DEPRECATED. Use container_id. Not populated or used at all. */
            deprecatedContactContainerId?: string;
            /** Field is an edge key for this person. Modifying it breaks the link between data sources. This is equivalent to edge_key_info having at least one entry with materialized = true. */
            edgeKey?: boolean;
            /** Edges that this field creates. This includes all edges and not necessarily just the edge relevant to the joined entities. */
            edgeKeyInfo?: AppsPeopleOzExternalMergedpeopleapiEdgeKeyInfo[];
            /**
             * The encoded id of the data source. The id is only unique within a single container type. This field correlates to person.metadata.identity_info.source_id.id. This field may not be
             * populated in some special cases, where the id is not visible to the querying user. e.g. ListAutocompletions with full phone number query.
             */
            encodedContainerId?: string;
            /** When the container is PROFILE and the profile owner is the requester, this field indicates how the profile field is accessible. */
            fieldAcl?: AppsPeopleOzExternalMergedpeopleapiFieldAcl;
            /**
             * Indicates the time that the field was added or last edited. Currently this is populated for: (1) person.birthday with ContainerType PROFILE, DOMAIN_PROFILE or ACCOUNT. (2)
             * person.name, person.address, person.relation, person.email and person.phone with ContainerType CONTACT_ANNOTATION;
             */
            lastUpdateTime?: string;
            /** The matching informations if there was a query against this field. */
            matchingInfo?: AppsPeopleOzExternalMergedpeopleapiMatchInfo[];
            /** When deduping fields by value, list of containers of the fields that where deduped. */
            otherDedupedContainers?: AppsPeopleOzExternalMergedpeopleapiDedupedContainerInfo[];
            /**
             * If true, indicates this field is the Person's primary field eg. Contact, and (Profile) Person could have different Name fields, and the Name represented by the Person is primary.
             * For selecting a primary field from RepeatedFields within a Person, use container_primary.
             */
            primary?: boolean;
            /** The product(s) that generated the data in this field. Empty is equivalent to DEFAULT. ST_USER_METADATA */
            productMetadata?: AppsPeopleOzExternalMergedpeopleapiProductMetadata[];
            /**
             * Indicates whether this is a verified field. It is synthesized from verification and is read-only. If there is at least one verification with status PASSED, the field is considered
             * verified. Currently this is applicable to address, email, name, and phone for PROFILE and DOMAIN_PROFILE. Use .metadata.verified in the request mask.
             */
            verified?: boolean;
            /** Currently, only people.get may set this value */
            visibility?: string;
            /** Whether the field is writeable to the requester. */
            writeable?: boolean;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPersonListWithTotalNumber {
            people?: AppsPeopleOzExternalMergedpeopleapiPerson[];
            /** The total number of people, which is aways no less than the size of the above list. */
            totalNumber?: number;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPersonMetadata {
            /** Affinities associated with the person, with respect to the requester. */
            affinity?: AppsPeopleOzExternalMergedpeopleapiAffinity[];
            /**
             * Populated when the data for the MergedPerson comes from a 3rd party provider or data source. Clients must display these attributions to the user if they are present. NOTE: This
             * field is only relevant when requesting the following containers: - PLACE (data read from Maps)
             */
            attribution?: string[];
            /**
             * The best name to use for this person for user-facing display. See go/people-api-howto:names for details about how this field is computed. In many cases this will simply be
             * Person.name[0]. However, Person.name returns only explicit Name fields, but other fields maybe usable as a name (for example: nicknames, file_as, ...). `best_display_name` will be
             * calculated from all fields in storage which are usable as a name, even fields which are not explicitly requested in the MergedPerson result. See
             * go/javagoog/apps/tacotown/socialgraph/entity/PersonNameFormatter.java
             */
            bestDisplayName?: AppsPeopleOzExternalMergedpeopleapiBestDisplayName;
            /** DEPRECATED. Indicates whether the profile owner has blocked this person. Please use `person.read_only_profile_info.block_type` instead. */
            blockType?: string[];
            /** DEPRECATED. The circles the person belongs to. */
            circleId?: string[];
            /** DEPRECATED. Please use `person.contact_group_memberships` instead. The contact groups the person belongs to. */
            contactGroupId?: string[];
            /** The IDs of all contacts contributing to this person. */
            contactId?: string[];
            /**
             * DEPRECATED. Customized masking of the response similar to the legacy People2RequestMask People2Params request message. NOTE: This param is inherently client-specific, limited to
             * specific legacy clients, and not open to new usage. NOTE: Effects may be applied to a subset of people in the response.
             */
            customResponseMaskingType?: string;
            /** For sync requests (i.e., changed since the provided sync_token), indicates the resource is a tombstone for a Person resource that has been entirely deleted. */
            deleted?: boolean;
            /** DEPRECATED. Please use `person.read_only_profile_info.block_type` instead. */
            deprecatedBlocked?: boolean;
            /** DEPRECATED. This field is no longer populated or read. */
            deprecatedMembershipCircleId?: string[];
            /** DEPRECATED. This field is no longer populated or read. */
            deprecatedMembershipContactGroupId?: string[];
            /**
             * Info about the aggregated device contacts. When the person contains RAW_DEVICE_CONTACT containers, each DeviceContactInfo represents a single aggregate device contact made up of one
             * or more raw device contacts.
             */
            deviceContactInfo?: AppsPeopleOzExternalMergedpeopleapiDeviceContactInfo[];
            /** Detailed metadata about the lookup IDs and data sources included in a MergedPerson result. */
            identityInfo?: AppsPeopleOzExternalMergedpeopleapiIdentityInfo;
            /** DEPRECATED. Indicates whether this person is blocking the profile owner. Please use `person.read_only_profile_info.incoming_block_type` instead. */
            incomingBlockType?: string[];
            /**
             * DEPRECATED. Indicates whether this person is in the same domain as the viewer. For proxying trust between two users based on organization membership, see: - go/flex-orgs-platform -
             * go/flex-orgs-compliance-handbook (especially http://shortn/_ChwfAY36Ys)
             */
            inViewerDomain?: boolean;
            /**
             * DEPRECATED. The last update timestamps for the constituent components of this person are available in `identity_info.source_ids`. The time of the most recent change to this person,
             * in !!!NANOS!!! (due to a bug). May be a change to any of the underlying parts of the person (profile, contact, etc.). Not guaranteed to be the timestamp of the most recent change,
             * due to limitations in the backend. This field is not fully deprecated for backend container-specific storage services like ProfileService which lack identity_info. The use is still
             * discouraged in such systems and they should prefer to use the `last_update_time` field of this message instead.
             */
            lastUpdateTimeMicros?: string;
            /** The person model that is used to construct this person. */
            model?: string;
            /** DEPRECATED. */
            objectType?: string;
            /** DEPRECATED. Please use `person.read_only_profile_info.owner_id` instead. */
            ownerId?: string;
            /** DEPRECATED. See `person.read_only_profile_info.owner_user_type` instead. */
            ownerUserType?: string[];
            /** DEPRECATED. Please use `Person.plus_page_info` instead. */
            plusPageType?: string;
            /** DEPRECATED. This field is no longer populated or read. */
            previousPersonId?: string[];
            /** DEPRECATED. Stats/counters pertaining to followers and incoming edges. Please use `person.read_only_profile_info.profile_owner_stats` instead. */
            profileOwnerStats?: AppsPeopleOzExternalMergedpeopleapiProfileOwnerStats;
            /** Contact people-directory-dev-team@ if you want to use this field. */
            scoringInfo?: AppsPeopleOzExternalMergedpeopleapiPersonMetadataScoringInfo;
            /** DEPRECATED. This field is no longer populated or read. */
            userVisibleStats?: AppsPeopleOzExternalMergedpeopleapiUserVisibleStats;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPersonMetadataScoringInfo {
            /** Only populated on a SearchDirectoryPeople call, when results are scored. Contact people-directory-dev-team@ if you want to use this field. */
            rawMatchQualityScore?: number;
            /**
             * Only populated on a SearchDirectoryPeople call that sends a request with StFieldSpecExpressions. - Used for linking indexed terms with query terms for go/better-name-matching - Name
             * should be alphanumeric or underscores - Value should be an st expression following the syntax at go/stsyntax Contact people-directory-dev-team@ if you want to use this field.
             */
            stExpressionResults?: AppsPeopleOzExternalMergedpeopleapiPersonMetadataScoringInfoStExpressionResult[];
        }
        interface AppsPeopleOzExternalMergedpeopleapiPersonMetadataScoringInfoStExpressionResult {
            name?: string;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPhone {
            /** Canonicalized form that follows ITU-T E.164 international public telecommunication numbering plan. */
            canonicalizedForm?: string;
            /** Emergency information. See go/emergency-trusted-contacts-papi. */
            emergencyInfo?: AppsPeopleOzExternalMergedpeopleapiFieldEmergencyInfo;
            /** Read-only. Field requested by specifying `HANGOUTS_PHONE_DATA` in `extension_set.extension_names`. */
            extendedData?: AppsPeopleOzExternalMergedpeopleapiPhoneExtendedData;
            /** The `type` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /**
             * The type of the phone number. The type can be free form or one of these predefined values: * `home` * `work` * `mobile` * `homeFax` * `workFax` * `otherFax` * `pager` * `workMobile`
             * * `workPager` * `main` * `googleVoice` * `other`
             */
            type?: string;
            uri?: string;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPhoneExtendedData {
            /** For use with Hangouts extension. */
            structuredPhone?: AppsPeopleOzExternalMergedpeopleapiStructuredPhone;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPhoto {
            /**
             * URL of an emoji avatar as an image. See go/emoji-cdn. PeopleAPI will return the SVG format so that it can be scaled client side and so that the images will not be animated. All
             * clients that use this field must also have fall-back handling for using the `Photo.url` field if this is empty. When we have FIFE-compatible emoji-image URLs we will drop this field
             * and return the Photo.url instead. Clients that have their own go/emoji-rendering integration may prefer to render the emoji-avatar from `Photo.glyph` field using their rendering
             * system so that the emoji version/style match the rest of the application. For further background, see go/chatroom-avatar-as-roster-metadata. This field will only be populated if all
             * of: - The PersonFieldMetadata `container_type` for the Photo is NAMED_CHAT_ROOM - The chat room has an emoji type avatar image set
             */
            emojiAvatarUrl?: string;
            /**
             * Unicode emoji representation of the chat room emoji avatar. This can be used by clients that use go/emoji-rendering directly so that they can present this with the same
             * version/style as the rest of their application. This value may also be useful to clients as alt-text for the image. This field will only be populated if all of: - The
             * PersonFieldMetadata `container_type` for the Photo is NAMED_CHAT_ROOM - The chat room has an emoji type avatar image set
             */
            glyph?: string;
            /** A set of HTML data provider attributions that must be shown with the result. Supported for PLACES photos only. See: go/understanding-places-api-attribution-requirements */
            htmlAttribution?: string[];
            /** True when the photo is synthetic or generated (i.e. a monogram or default photo), false when the person has a custom photo. */
            isDefault?: boolean;
            /**
             * Indicates if the photo is a monogram avatar. Combined with is_default, the type of photo can be determined by: is_default=true, is_monogram=true: Default monogram avatar.
             * is_default=true, is_monogram=false: Default silhouette avatar. is_default=false: Custom photo. is_monogram is irrelevant in this case.
             */
            isMonogram?: boolean;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** When is_monogram=true, this is the background color of the monogram photo as a hex RGB formatted string "RRGGBB". */
            monogramBackground?: string;
            /** For writes only. Indicates photo content for person photo-field update. Currently only used for profile-photo updates (not contact photos yet). */
            photoId?: AppsPeopleOzExternalMergedpeopleapiPhotoPhotoStorageId;
            /**
             * Most clients don't need to worry about this field and should just use the `url` to fetch the photo. See go/phototoken-migration-plan for some more context about this field. If you
             * think you want to use this please talk with people-api-eng@ first.
             */
            photoToken?: string;
            /** See go/people-api-concepts/photos for info on the different representations of URLs. */
            url?: string;
            /**
             * A URL for a UI to view the photo in its original context. For example, for a place photo, this is the url of a Google Maps page displaying the photo. Supported for place photos
             * only.
             */
            viewerUrl?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPhotoPhotoStorageId {
            /** For writes only, pass the media key that represents the image in photos backend. Note, this is not populated on reads. */
            mediaKey?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPlaceDetails {
            /** A URL hosted by Google providing more information about this place This is the URL returned by Places API in the Place.Url.google field */
            googleUrl?: string;
            latLng?: AppsPeopleOzExternalMergedpeopleapiLatLng;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            openingHours?: AppsPeopleOzExternalMergedpeopleapiOpeningHours;
            /** The name of the primary type. Examples of primary type are: "art_school", "clothing_wholesaler", etc. All primary types can be found at http://shortn/_veqh6UwWdc */
            primaryTypeName?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPlayGamesExtendedData {
            /** User's top achievements that are sorted for example by rarity. */
            achievements?: AppsPeopleOzExternalMergedpeopleapiPlayGamesExtendedDataAchievement[];
            /** The avatar image to display for the user. */
            avatarImageUrl?: string;
            /** Failure type if there is an error when fetching product profile data. */
            failure?: AppsPeopleOzExternalMergedpeopleapiProductProfileFailure;
            /** The gamer tag set by the user. Not set if the user hasn't set a gamer tag yet. */
            gamerTag?: string;
            /** User's level. */
            playerLevel?: number;
            /** Specifies the visibility of the player's profile. */
            profileVisibility?: string;
            /** Total number of friends. */
            totalFriendsCount?: string;
            /** How many achievements this player has unlocked. */
            totalUnlockedAchievements?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPlayGamesExtendedDataAchievement {
            /** The name of the achievement. */
            achievementName?: string;
            /** The achievement icon url shown to the user if it is unlocked. */
            achievementUnlockedIconUrl?: string;
            /** Rarity of unlocking this achievement (3% of players unlocked would be 3) */
            rarityPercentage?: number;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPlusPageInfo {
            /** Int64 ID of packaging-service entry; if set, the plus page is associated with a third-party application. */
            applicationId?: string;
            entityType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPointSpec {
            bounds?: GeostoreRectProto;
            point?: GeostorePointProto;
            pointSource?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPosixAccount {
            /** The user visible value is used to distinguish identical posix account fields with different customer key values. */
            accountId?: string;
            /**
             * Value indicates the uniqueness namespace that applies to the POSIX information. The value is included in all POSIX account uniqueness indices. The indexing prevents two accounts
             * within the same customer from having the same username. Namespacing allows Windows and Linux users to share the same username.
             */
            accountNamespace?: string;
            /** Value indicates whether the POSIX information is associated with a non-human entity and the validation logic to apply during PosixAccount mutation. */
            accountType?: string;
            /**
             * The customer associated with the POSIX identity. If the user is already associated with a G Suite Customer, this field has the same value as
             * http://google3/ccc/hosted/policies/settings/dthree_customer_info.proto
             */
            customerKey?: string;
            /** The value is automatically set to a SHA-256 fingerprint of the POSIX account. A fingerprint should uniquely identify a POSIX account entry. */
            fingerprint?: string;
            /** The GECOS (user information) entry for this account. */
            gecos?: string;
            /** The default group ID. */
            gid?: string;
            /** The path to the home directory for this account. */
            homeDirectory?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** Value indicates whether to use Linux or Windows specific validation logic during PosixAccount mutation. */
            operatingSystemType?: string;
            /** The path to the login shell for this account. */
            shell?: string;
            /**
             * System identifier for which account Username or Uid apply to. If not specified on mutate by a caller it will default to empty value if either Username or Uid are being set. SystemId
             * does require to have a value (even an empty one) because it is included into null-filtered Spanner index used to enforce uniqueness on Username and Uid fields.
             */
            systemId?: string;
            /** The user ID. */
            uid?: string;
            /** The username of the account. */
            username?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiProductMetadata {
            productSource?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiProductProfileFailure {
            failureType?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiProfileOwnerStats {
            /** Replacement for deprecated follower_count. Comes from the EdgeSummary. */
            incomingAnyCircleCount?: string;
            /** Deprecated. This field is no longer populated by the server. */
            viewCount?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiProfileUrl {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            url?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiPronoun {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            pronounData?: SocialGraphApiProtoPronounData;
        }
        interface AppsPeopleOzExternalMergedpeopleapiRawDeviceContactAnalyticalInfo {
            /** The data set within the account that this raw contact belongs to. */
            dataSet?: string;
            /**
             * The CP2 dirty field which indicates the sync state of the raw contact: https://developer.android.com/reference/android/provider/ContactsContract.SyncColumns#DIRTY True if the row is
             * changed but not synced
             */
            dirty?: boolean;
            /** Whether the source ID exists for non-Google contacts. Won't set for Google contacts. */
            sourceIdExist?: boolean;
            /** The Sync Info of a raw contact. */
            syncInfo?: SocialGraphApiProtoSyncInfo;
        }
        interface AppsPeopleOzExternalMergedpeopleapiRawDeviceContactInfo {
            /** Account name of raw contact, e.g. "google@gmail.com". */
            accountName?: string;
            /** Account type of raw contact, e.g. "com.google" or "com.linkedin.android". */
            accountType?: string;
            /**
             * The detailed app-specific endpoint data available for the given RawDeviceContactInfo instance. This proto should be used to obtain the list of actions and mimetypes supported by the
             * third-party app. Design: go/3p-contact-upload
             */
            appContactData?: SocialGraphApiAppContactData[];
            /** The app-specific endpoint data needed for app action fulfillment. Usage of this field should be avoided on the server-side, and should use the more detailed |full_app_info| field. */
            appInfo?: AppsPeopleOzExternalMergedpeopleapiAppUniqueInfo;
            /** If true, this raw contact can be used on other devices than the one it originated from. Assigned by the server. */
            crossDeviceAllowed?: boolean;
            /** Extra metadata for this raw contact. */
            deviceContactMetadata?: AppsPeopleOzExternalMergedpeopleapiDeviceContactExtraMetadata;
            /** The focus contact id for Google contacts. */
            googleContactId?: string;
            /**
             * The base64 serialized social.graph.peopleapi.proto.internal.RawDeviceContactId. This id should be used to correlate to field.metadata.encoded_container_id when the
             * field.metadata.container_type is RAW_DEVICE_CONTACT The id also correlates to person.metadata.identity_info.source_id.id.
             */
            id?: string;
            /** The type of photo from the device (if any). */
            photoType?: string;
            /** The id of the raw contact on the device. */
            rawContactId?: string;
            /** Only to be used by Romanesco team specifically for analytics. */
            rawDeviceContactAnalyticalInfo?: AppsPeopleOzExternalMergedpeopleapiRawDeviceContactAnalyticalInfo;
        }
        interface AppsPeopleOzExternalMergedpeopleapiReadOnlyProfileInfo {
            /** The account email linked to the profile, if any exists and is visible to the requester. */
            accountEmail?: AppsPeopleOzExternalMergedpeopleapiAccountEmail;
            /** Indicates whether the profile owner has blocked this person. */
            blockType?: string[];
            /** CustomerInfo for dasher user. The reader has to explicitly request this in the field_mask as 'read_only_profile_info.customer_info' */
            customerInfo?: AppsPeopleOzExternalMergedpeopleapiCustomerInfo;
            /** DEPRECATED. Use the `ReadOnlyProfileInfo.customer_info` field instead (b/138120418). Only populated if in_viewer_domain is true. */
            domainInfo?: AppsPeopleOzExternalMergedpeopleapiReadOnlyProfileInfoDomainInfo;
            /** Indicates whether this person is blocking the profile owner. */
            incomingBlockType?: string[];
            /**
             * DEPRECATED. Proxying trust between users in a domain should use go/flex-orgs-platform. For more info see:
             * http://doc/18i0-C7vWcz2UuXYBsmulnriVCK3_EuMPpRlPa2OmMHw#heading=h.dobotdwx25kg Indicates whether the profile owner is in the same domain as the viewer.
             */
            inViewerDomain?: boolean;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** DEPRECATED. */
            objectType?: string;
            /** The Focus-obfuscated Gaia ID of the profile owner (go/obfuscated-ids). */
            ownerId?: string;
            ownerUserType?: string[];
            /** DEPRECATED. Please use `person.plus_page_info` instead. */
            plusPageType?: string;
            /** Stats/counters pertaining to followers and incoming edges. */
            profileOwnerStats?: AppsPeopleOzExternalMergedpeopleapiProfileOwnerStats;
        }
        interface AppsPeopleOzExternalMergedpeopleapiReadOnlyProfileInfoDomainInfo {
            /** DEPRECATED. Organization badge for the domain this person is a member of. The badge is the primary hosted domain. */
            domainBadge?: string[];
            /** DEPRECATED. Hosted domain this person is a member of. Formerly only available via PersonExtendedData. */
            domainName?: string[];
        }
        interface AppsPeopleOzExternalMergedpeopleapiRelation {
            /**
             * Canonicalized `value` of the relation from this person to the user. This is currently used for data from contact annotations. Possible canonical values are based from
             * http://google3/googledata/quality/aliases/relationship_en.config.
             */
            canonicalValue?: string;
            /** The `type` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** The person whose email matches the Relation.value field, if it is a valid email address. This field is read-only and ignored on update. */
            relationDetails?: AppsPeopleOzExternalMergedpeopleapiRelationRelationDetails;
            /**
             * The relation type. The type can be free form or one of these predefined values: * `spouse` * `child` * `mother` * `father` * `parent` * `brother` * `sister` * `friend` * `relative`
             * * `domesticPartner` * `manager` * `assistant` * `referredBy` * `partner`
             */
            type?: string;
            /** The person this relation applies to. Custom value provided by the user. */
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiRelationRelationDetails {
            /** Equivalent to Name.display_name for the person_id profile. */
            displayName?: string;
            /** Equivalent to Organization.title for the primary organization of the person_id profile. */
            jobTitle?: string;
            personId?: string;
            /** Equivalent to Photo.url for the person_id profile. */
            photoUrl?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiRelationshipInterest {
            /** The `type` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** These fields may give away the sexual orientation of the user. */
            type?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiRelationshipStatus {
            /** The `type` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            type?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiRightOfPublicityState {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            state?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiRosterDetails {
            /**
             * Abridged / sample subset of member details of the roster. NOTE: This field is only returned if the request's field mask includes "person.roster_details.abridged_roster_memberships".
             * http://cs/symbol:google.apps.cloudidentity.groups.internal.GroupSummary.abridged_memberships
             */
            abridgedRosterMemberships?: AppsPeopleOzExternalMergedpeopleapiRosterMember[];
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** Indicates the number of members and sub-rosters of the roster. Corresponds to http://cs/symbol:google.apps.cloudidentity.groups.internal.Group.direct_member_count_per_type */
            rosterMemberCount?: AppsPeopleOzExternalMergedpeopleapiRosterMemberCount;
        }
        interface AppsPeopleOzExternalMergedpeopleapiRosterMember {
            /** Type of the member. */
            memberType?: string;
            /** Focus-Obfuscated Gaia Id of the member. */
            personId?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiRosterMemberCount {
            /** Indicates the number of direct sub-rosters of the roster. This comes from http://cs/symbol:google.apps.cloudidentity.groups.internal.Group.DirectMemberCountPerType.group_count */
            directGroupCount?: string;
            /**
             * Indicates the number of direct, non-roster members of the roster. This comes from
             * http://cs/symbol:google.apps.cloudidentity.groups.internal.Group.DirectMemberCountPerType.user_count
             */
            directUserCount?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiSearchProfile {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            searchProfileData?: SocialGraphApiProtoSearchProfileData;
        }
        interface AppsPeopleOzExternalMergedpeopleapiSipAddress {
            /** The `type` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** The type of the SIP address. The type can be free form or or one of these predefined values: * `home` * `work` * `mobile` * `other` */
            type?: string;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiSkills {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiSocialConnection {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            type?: string[];
        }
        interface AppsPeopleOzExternalMergedpeopleapiSortKeys {
            affinity?: AppsPeopleOzExternalMergedpeopleapiAffinity[];
            /** Deprecated. This field is only populated with 0.000 for legacy reasons. Clients should not use this field. */
            interactionRank?: string;
            lastName?: string;
            lastNameRaw?: string;
            name?: string;
            /** Raw name strings that were used to generate the name and last_name sort keys fields above. Contacts+ need them to generate section headers for list view (b/30642866). */
            nameRaw?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiSourceIdentity {
            /** The type of source. To be deprecated infavor of container_type */
            container?: string;
            /** The type of the source. */
            containerType?: string;
            /** In sync responses, indicates whether the identity source has been deleted. Not applicable to GOOGLE_GROUP. */
            deleted?: boolean;
            /**
             * The encoded id of the data source. This field correlates to PersonFieldMetadata.encoded_container_id. The possible values of this `id` field are as follows based on the value of the
             * `container_type` field: CONTACT: Hex-encoded contact id. PROFILE: DOMAIN_PROFILE: GOOGLE_GROUP: NAMED_CHAT_ROOM: Focus-obfuscated Gaia ID. DOMAIN_CONTACT: Synthetic-contact id
             * representing the domain shared contact. PLACE: Encoded PlaceId (go/javagoog/maps/api/places/util/PlaceIdEncoder.java) RAW_DEVICE_CONTACT: Pair of device_id and raw_contact_id,
             * encoded as base64 serialized social.graph.peopleapi.proto.internal.RawDeviceContactId proto. CONTACT_ANNOTATION: Pair of annotation_id and event_timestamp, encoded as base64
             * serialized social.graph.peopleapi.proto.internal.ContactAnnotationId proto. -- DEPRECATED container types -- If the container is CIRCLE, then the id is going to be the synthetic-
             * contact id representing the email-only circle member or gaia circle member for which the requester does not have a contact for.
             */
            id?: string;
            /**
             * Last update timestamp of this source. NOTE: Only populated for CONTACT container type in Java PeopleAPI. Populated for CONTACT, PROFILE, DOMAIN_PROFILE in Sharpen implementation.
             * NOTE: Not populated for GOOGLE_GROUP.
             */
            lastUpdated?: string;
            /** **DEPRECATED** Please use `last_updated` field instead. Last update timestamp of this source in microseconds. NOTE: Only populated for CONTACT container type. */
            lastUpdatedMicros?: string;
            /** NOTE: Not populated for GOOGLE_GROUP. */
            sourceEtag?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiSshPublicKey {
            expirationTime?: string;
            /** The value is automatically set to a SHA-256 fingerprint of an SSH public key. A fingerprint should uniquely identify an SSH public key. */
            fingerprint?: string;
            key?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
        }
        interface AppsPeopleOzExternalMergedpeopleapiStructuredPhone {
            /** The phone formatted type. See docs from mirrored proto: http://google3/ccc/grand_central/common/types.proto?l=128&rcl=241000760 */
            formattedType?: string;
            phoneNumber?: AppsPeopleOzExternalMergedpeopleapiStructuredPhonePhoneNumber;
            shortCode?: AppsPeopleOzExternalMergedpeopleapiStructuredPhoneShortCode;
            /** The type of phone. See docs from mirrored proto: http://google3/ccc/grand_central/common/types.proto?l=125&rcl=241000760 */
            type?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiStructuredPhonePhoneNumber {
            e164?: string;
            i18nData?: AppsPeopleOzExternalMergedpeopleapiStructuredPhonePhoneNumberI18nData;
        }
        interface AppsPeopleOzExternalMergedpeopleapiStructuredPhonePhoneNumberI18nData {
            countryCode?: number;
            internationalNumber?: string;
            isValid?: boolean;
            nationalNumber?: string;
            regionCode?: string;
            validationResult?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiStructuredPhoneShortCode {
            /** The phone code. See docs from mirrored proto: http://google3/ccc/grand_central/common/types.proto?l=70&rcl=241000760 */
            code?: string;
            countryCode?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiTagline {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiTeamsExtendedData {
            admins?: AppsPeopleOzExternalMergedpeopleapiPerson[];
            adminTo?: AppsPeopleOzExternalMergedpeopleapiPerson[];
            dottedLineManagers?: AppsPeopleOzExternalMergedpeopleapiPerson[];
            dottedLineReports?: AppsPeopleOzExternalMergedpeopleapiPersonListWithTotalNumber;
            failures?: string[];
            managementChain?: AppsPeopleOzExternalMergedpeopleapiPerson[];
            reports?: AppsPeopleOzExternalMergedpeopleapiPersonListWithTotalNumber;
        }
        interface AppsPeopleOzExternalMergedpeopleapiUserDefined {
            key?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiUserVisibleStats {
            /** Replacement for deprecated follower_count. Comes from the EdgeSummary. */
            incomingAnyCircleCount?: string;
            viewCount?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiVisibleToGuests {
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
        }
        interface AppsPeopleOzExternalMergedpeopleapiWebContactsExtendedData {
            /** Used by Contacts client-side to indicate whether a person is not completed. */
            isIncomplete?: boolean;
        }
        interface AppsPeopleOzExternalMergedpeopleapiWebsite {
            /** The `type` translated and formatted in the request locale. See go/people-api-howto/localization for details on how to usage. */
            formattedType?: string;
            metadata?: AppsPeopleOzExternalMergedpeopleapiPersonFieldMetadata;
            /** Currently in Oz: "Links": Links with no rel. "Other profiles": Links with rel=ME. "Contributor to": Links with rel=CONTRIBUTOR_TO or PAST_CONTRIBUTOR_TO. */
            rel?: AppsPeopleOzExternalMergedpeopleapiWebsiteRelationshipInfo[];
            /**
             * The type of the website. The type can be free form or one of these predefined values: * `home` * `work` * `blog` * `profile` * `homePage` * `ftp` * `reservations` *
             * `appInstallPage`: website for a Currents application. * `other`
             */
            type?: string;
            value?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiWebsiteRelationshipInfo {
            type?: string;
        }
        interface AppsPeopleOzExternalMergedpeopleapiYoutubeExtendedData {
            /** Information about a channel created by the user. A user can create multiple Youtube channels. */
            channelData?: AppsPeopleOzExternalMergedpeopleapiChannelData[];
            /** Failure type if there is an error when fetching product profile data. */
            failure?: AppsPeopleOzExternalMergedpeopleapiProductProfileFailure;
        }
        interface AssistantApiAccessControlOutput {
            /** If true, the user consented to use YouTube Kids as a video provider for non-unicorn users(voice recognized adults or guest). Unicorn accounts shouldn’t use this setting. */
            allowNonUnicornUserAccessYoutubeKids?: boolean;
            guestAccessOnYoutube?: string;
        }
        interface AssistantApiActionV2SupportedFeatures {
            /**
             * This flag is used to work around a bug in AGSA 6.8 that got away. The bug prevents users from accessing their shopping list if the URL of the shopping list is not a keep.google.com
             * URL. This will happen when switch the backend that stores the shopping list from Keep to a backend maintained by the Google Shopping Express team.
             */
            expressUrlInSettingsResponseSupported?: boolean;
            /**
             * Whether client supports reconnect client input in action v2 payload. This capability is needed to determine if client supports parsing client input payload from actionv2 proto for
             * workflow purposes. See go/personal-workflow. OWNER:nyzstar,vvvemuri.
             */
            reconnectClientInputSupported?: boolean;
            /**
             * Whether or not the surface supports a simple UnsupportedAction instead of a ModalState punt card for rendering. For ActionV2 punt cards, the ModalState extension on the ResourceSet
             * is the canonical way of building punt cards. However, while most all devices support the ActionV2 protocol, not all devices handle the ModalState rendering as part of the ActionV2.
             * For these devices, we want to build a modified ActionV2 for punt cards which omits this ModalState. At present, this is only Android Wear and should not be used for other devices if
             * they support ModalState or Conversation protocol.
             */
            simpleActionV2PuntSupported?: boolean;
            /** A list of all the action types supported by the client. These should be the string representation of majel.ActionTypes within "quality/majel/api/proto/action_v2.proto". */
            supportedActionType?: string[];
            /** Checks if screenshots can be taken on the client. This field is set on the client from AGSA 7.2 onwards. */
            takeScreenshotSupported?: boolean;
            /** If IMMERSIVE_ACTIONS UiType is supported by the client. */
            voiceDelightImmersiveUiSupported?: boolean;
            /**
             * If Voice Delight Stickers are supported by the client. In order to support Voice Delight stickers, the client should know how to extract sticker_url from
             * VoiceDelightSystemInteractionSegment.
             */
            voiceDelightStickersSupported?: boolean;
            /**
             * If Voice Delight Suggestion Chips are supported by the client. In order to support Voice Delight Suggestion Chips, the client should know how to extract suggestions form
             * VoiceDelightSystemInteraction.ResourceSet.
             */
            voiceDelightSuggestionsSupported?: boolean;
        }
        interface AssistantApiAndroidIntentCapabilities {
            androidIntentCapability?: AssistantApiAndroidIntentCapabilitiesAndroidIntentCapability[];
        }
        interface AssistantApiAndroidIntentCapabilitiesAndroidIntentCapability {
            /** The Action name of the Android Intent in standard notation (https://developer.android.com/reference/android/content/Intent#getAction()). */
            intentActionName?: string;
            /** The Android provider packages that support the intent, e.g. "com.google.android.deskclock". */
            packageNames?: string[];
        }
        interface AssistantApiAppCapabilities {
            /** Indicates whether the provider is compatible for media fulfillment on this surface. For example, Amazon Music isn't compatible with the driving mode. */
            allowlistedForMediaFulfillment?: boolean;
            /** Currently unused. Will be used in the future when integrating with incremental app capabilities. */
            appIntegrationsSettings?: AssistantApiAppIntegrationsSettings;
            /** This system app is disabled in settings. */
            disabledSystemApp?: boolean;
            /** The installed app of the provider. */
            provider?: AssistantApiCoreTypesProvider;
            /** This provider has integrated its cloud backend with Google, and Google can route the user queries to the provider's cloud. */
            routableToProviderCloud?: boolean;
            /** This provider has an app that supports on-device search through the provider's own inventory. */
            searchableOnDevice?: boolean;
            /** This provider has integrated its content with Google, and Google has enabled to serve its content as a server-side solution. */
            searchableOnServer?: boolean;
            /** This provider has an app that supports starting new media playback when there is no screen (e.g. by integrating with the Bisto SDK). */
            supportsScreenlessInitiation?: boolean;
            /** This provider is an app which should be used for query annotations. This is useful for apps which may not be already indexed by Google or are client specific. */
            whitelistedForAnnotation?: boolean;
        }
        interface AssistantApiAppCapabilitiesDelta {
            /** Currently unused. Will be used in the future when integrating with incremental app capabilities. */
            appIntegrationsSettings?: AssistantApiAppIntegrationsSettings;
            /** The installed app of the provider. */
            providerDelta?: AssistantApiCoreTypesProviderDelta;
        }
        interface AssistantApiAppControlSupport {
            enabled?: string;
        }
        interface AssistantApiAppIntegrationsSettings {
            /** Whether to enable Assistant to handle request with predicted apps. */
            handleRequestsWithPredictedApps?: string;
        }
        interface AssistantApiAssistantContinuedPresenceSupport {
            /** Indicates in what cases assistant continued presence can be shown as a plate. This field is white-listed as being PII-free. Please do not add PII here. */
            plateSupport?: string;
        }
        interface AssistantApiAudioInput {
            environment?: string;
            quality?: string;
        }
        interface AssistantApiAudioOutput {
            alwaysOnSpeaker?: string;
            environment?: string;
            mediaTtsMixable?: string;
            quality?: string;
            volumeProperties?: AssistantApiVolumeProperties;
        }
        interface AssistantApiCallCapabilities {
            /** The supported call formats on the surface. */
            callFormats?: string[];
            /** The supported call mediums on the surface. */
            callMediums?: string[];
            /** The call options this surface can provide. For example, SPEAKERPHONE is available on Android OPA while iOPA doesn't support it yet. */
            callOptions?: string[];
            /**
             * If true, APP_ID queries initiated by this device should fall back to execution on the tethered device if it's available and if the primary device cannot perform the action (e.g. due
             * to the app not being installed).
             */
            fallbackToTetheredDeviceAppCapabilities?: boolean;
            /** Should only be checked if nonempty. */
            supportedRecipientTypes?: string[];
            /** Whether the surface supports Duo calling email endpoints. */
            supportsDuoEmailEndpoint?: boolean;
        }
        interface AssistantApiCameraCapabilities {
            /** Whether the device supports Face Match. */
            faceMatchCapable?: boolean;
            /** Whether the device has a camera. */
            hasCamera?: boolean;
        }
        interface AssistantApiCameraReceiverCapabilities {
            /** Whether the device has limited camera stream capability. If true, check supported_camera_receivers for detailed supported cameras. */
            hasLimitedCameraStreamCapability?: boolean;
            /** The camera receiver cast apps the device supports. Only used if has_limited_camera_stream_capability is true. */
            supportedCameraReceivers?: AssistantApiCoreTypesCastAppInfo[];
        }
        interface AssistantApiCarAssistantCapabilities {
            /**
             * Indicates whether the current Assistant should provide a multi Assistant specific punt when there are multiple Auto specific Google Assistants (Android Auto Projected (AAP) and
             * Android Auto Embedded (AAE)) in the same GAS enabled car. This will be used by both AAP and AAE. Design doc: go/doubledash++
             */
            shouldPuntMultiAssistantMode?: boolean;
        }
        interface AssistantApiCarSettingsCapabilities {
            /**
             * If true, it indicates that the auto surface client should receive a warmer welcome TTS for signed-out users. For signed-in user, we will rely on server side metadata.
             * go/aaae:preview-lang
             */
            playWarmerWelcome?: boolean;
            /** If true, it indicates that the client can be used to add cars after account linking with the OEM. */
            supportsAddingCars?: boolean;
        }
        interface AssistantApiCastAssistantSettingLinkingResult {
            /**
             * Cast linking status for ATV surfaces. This is derived from error messages returned from Cast Orchestration Server and will be used for data profiling
             * only(go/katniss-settings-dashboard).
             */
            castLinkingStatus?: string;
            /** The error msg returned from COS, truncated in case it's too large. */
            truncatedErrorMsg?: string;
        }
        interface AssistantApiCastCapabilities {
            /** Whether the device has limited camera stream capability and if yes, which receivers are supported. */
            cameraReceiverCapabilities?: AssistantApiCameraReceiverCapabilities;
            /**
             * The supported protocols for camera streaming. The value is used as string in go/smarthome-internal-api#camera-stream, so using a string for this field instead of an enum. Supported
             * protocols: (align the definition in go/smarthome-camerastream-trait) - "hls": HTTP Live Streaming - "dash": Dynamic Adaptive Streaming over HTTP - "smooth_stream": Smooth Streaming
             * - "progressive_mp4": Progressive MP4 (will likely only be used for Clips) - "webrtc": WebRTC (currently, only H.264 is supported) - "nexustalk": Internal-only protocol used for Nest
             */
            cameraStreamSupportedProtocols?: string[];
            /** True if we can cast things to this device. */
            canReceiveCast?: boolean;
            /**
             * Optional for primarily cast devices (e.g., Chirp, Chromecast). For devices that are NOT primarily cast devices, but having a cast receiver as secondary functionality, this field
             * SHOULD store the cast-device-id to be used to send remote casting commands to the device. Example: Android TV, which supports both Android-native actions as well as remote casting
             * using its built-in cast receiver. Android TV device id contains a DUSI id, which is not a cast-device-id. When executing a cast command on the Android TV, this field is used to
             * route the cast command (through CloudCastService) to the cast receiver on the device.
             */
            deviceId?: AssistantApiCoreTypesDeviceId;
            /**
             * Whether this device supports dynamic groups or not. It implies if a Stream Control operation (transfer, expansion, and contraction) could be applied on this device since Stream
             * Control is implemented as part of dynamic groups (ie, adding/removing devices from playback)
             */
            dynamicGroupsSupported?: boolean;
            groupType?: string;
            /** Whether UI overlay applications are supported on this device. It's used by Chromecast only. */
            overlayApplicationsSupported?: boolean;
            /**
             * Whether the device supports playing games through Yeti. This is set by the cast device when the device is updated: Chromecast updates -> Chromecast registers its capabilities with
             * CCS -> CCS passes the capabilities to the AssistantSettingsService -> AssistantSettingsService stores the device's capabilities. go/yeti-gaming-supported-cast-capability
             */
            yetiGamingSupported?: boolean;
        }
        interface AssistantApiClientOpPropertiesDeviceModifySettingClientOpProperty {
            /**
             * Additional specific setting capabilities. This boolean is used to indicate whether we want to skip the Android and GSA version check in CheckSettingSchemaAndMaybeGetUris() from
             * assistant/vertical/device/fulfillment/utils/setting_utils.h. Consider setting this field to true if your device is neither Android or GSA (especially when the UserAgent string of
             * your device's TaskRequest will not contain a valid/up-to-date Android/GSA version).
             */
            skipAndroidAndGsaVersionCheck?: boolean;
            /** Uses DeviceSetting enum which corresponds to setting_id. This indicates which specific settings are supported by client. An empty list implies all settings are supported. */
            supportedSettings?: string[];
            /** Additional specific setting capabilities. This boolean is used to indicate if do not disturb with duration is supported through device.MODIFY_SETTING clientop on a client or not. */
            supportsDoNotDisturbWithDuration?: boolean;
            /** Additional specific setting capabilities. This boolean is used to indicate if new unmute logic is enabled on a client or not. */
            supportsMuteUnmute?: boolean;
        }
        interface AssistantApiClientOpPropertiesProviderOpenClientOpProperty {
            /** Whether conversation is kept alive after opening the app. See go/keep-opa-conversation-alive for details. */
            keepsConversationAliveAfterOpeningApp?: boolean;
        }
        interface AssistantApiClockCapabilities {
            /** Maximum number of alarms that can be created on the client. */
            maxSupportedAlarms?: number;
            /**
             * Maximum extended timer duration supported by the client. The extended timer duration is the total start-to-finish duration after an AddTimeToTimer operation. E.g. if a user sets a
             * timer for 30 minutes, and later adds 10 minutes, the extended duration is 40 minutes.
             */
            maxSupportedExtendedTimerDuration?: AssistantApiDuration;
            /** Maximum duration of timers that can be created on the client. */
            maxSupportedTimerDuration?: AssistantApiDuration;
            /** Maximum number of timers that can be created on the client. */
            maxSupportedTimers?: number;
            /** The preferred provider to use for stopwatch related functionality. */
            preferredStopwatchProvider?: AssistantApiCoreTypesProvider;
            /** Whether the client restricts alarms to ring within the next 24 hours. */
            restrictAlarmsToNext24h?: boolean;
        }
        interface AssistantApiCommunicationUiCapabilities {
            fluidActionsUiType?: string;
        }
        interface AssistantApiContactLookupCapabilities {
            /** If true, contact.LOOKUP should be routed to the tethered device (if present) if the tethered device supports contact.LOOKUP and the primary device does not. */
            fallbackToTetheredDevice?: boolean;
        }
        interface AssistantApiCoreTypesAndroidAppInfo {
            accountType?: string;
            /**
             * Intent associated with the app. We include intents here as different versions of the same app may support different intents. In those cases, the package_name is not enough to
             * identify the app and we should use the combination of package_name and android_intent. This field might contain sensitive data, if represents ClientOp with encapsulated PII such as
             * user query.
             */
            androidIntent?: string;
            /** Store the app unique id endpoint. This will be passed over to app to fulfill the action. */
            appUniqueId?: string;
            /** The android app version. Deprecated because https://developer.android.com/reference/android/content/pm/PackageInfo.html#getLongVersionCode */
            appVersion?: number;
            /** data_mimetype and account_type are the what AGSA uses to filter which contacts support this Android app in ContactProvider. */
            dataMimetype?: string;
            /** If true, client should broadcast the intent instead of open the intent. */
            isBroadcastIntent?: boolean;
            /** App is the default app for it's core functionality. For example, it will be true for Android messages if it is the default app to send and receive SMS on the phone. */
            isDefault?: boolean;
            /** The localized app name. */
            localizedAppName?: string;
            /** The long android app version. */
            longVersionCode?: string;
            /**
             * Store mimetype of this endpoint. We will use this as the differentiator for Assistant to know whether to use the RawContact for messaging, call or video call. For example, send
             * message mimetype for whatsapp: "vnd.android.cursor.item/vnd.com.whatsapp.profile" voice call mimetype for whatsapp: "vnd.android.cursor.item/vnd.com.whatsapp.voip.call"
             */
            mimetype?: string;
            /** The android app package of the provider, like "com.spotify.music". */
            packageName?: string;
            /**
             * The OemProviderType is specific for OEM system Android apps. For example, in Auto Embedded, the OEM will have a system Radio/Media app. The system app’s capabilities/core
             * functionalities are captured here. For physical media sources, the OEM may decide to implement one media app (thus, one package name) that handles multiple physical media sources.
             * For these cases, each physical media source will be sent as different providers even though the package name is the same.
             */
            providerType?: string;
            /**
             * Id of the app's Android shortcut to be launched by Assistant. The client is expected to use the Android LauncherApps API to execute this shortcut which in turn will open the app.
             * For example, Whatsapp may create an Android shortcut for a frequently messaged contact with an id "contact_123". This field will contain that id and the client can execute it to
             * open up the chat with that particular contact. If this field is set, the package_name field must also be set since both will be used by the LauncherApps API for execution. If this
             * field is set, the intent related fields will be ignored and not used as a fallback. Design: go/shortcut-id-in-provider-open-clientop This field should only be set for devices with
             * Android API level >= 25 (since that is the version from which the LauncherApps startShortcut API is available)
             */
            shortcutId?: string;
            /** The fully qualified target class name of the provider, like "com.example.myapp.GetOrderService". */
            targetClass?: string;
            /** The android app version name, like "4.1.091.05.40d", "11.2.7.21.alpha". Android Docs: https://developer.android.com/reference/android/content/pm/PackageInfo#versionName */
            versionName?: string;
        }
        interface AssistantApiCoreTypesAndroidAppInfoDelta {
            /** The android app information of the provider. Like, Spotify. */
            androidAppInfo?: AssistantApiCoreTypesAndroidAppInfo;
            /** The client-side timestamp in millis when the app is last updated, installed or deleted. */
            lastUpdateTimestamp?: string;
            /** App is installed or deleted. */
            updateType?: string;
        }
        interface AssistantApiCoreTypesCalendarEvent {
            /** Attendees invited to the event, usually includes also the organizer. */
            attendees?: AssistantApiCoreTypesCalendarEventAttendee[];
            /** The background color of the event, in RGB format. */
            backgroundColor?: number;
            /** Optional calendar containing the event. */
            calendarId?: string;
            /** The person who created this event. */
            creator?: AssistantApiCoreTypesCalendarEventAttendee;
            /** Optional description of the event (plain text). */
            description?: string;
            /** The end time of the event. Start and end time must either both be date or both be datetime. End is exclusive, ie. the first day / first second when the event is over. */
            end?: AssistantApiDateTime;
            /**
             * Optional event id provided by assistant server. Needs to be unique, at least on a per-user and calendar level, ideally globally unique. If none is given, the server will assign an
             * id.
             */
            eventId?: string;
            /**
             * The flair name, calculated according to the event title (go/as-cal-flair). With the flair name, background images can be got from gstatic (go/scs):
             * https://ssl.gstatic.com/tmly/f8944938hffheth4ew890ht4i8/flairs/
             */
            flairName?: string;
            /** The foreground color of the event, in RGB format. */
            foregroundColor?: number;
            /** Whether the guests can invite other guests. */
            guestsCanInviteOthers?: boolean;
            /** Whether the guests can modify the event. */
            guestsCanModify?: boolean;
            /** Whether the guests of the event can be seen. If false, the user is reported as the only attendee to the event, even though there may be more attendees. */
            guestsCanSeeGuests?: boolean;
            /** Optional id of the Habit (Calendar Goal) this event is linked to */
            habitId?: string;
            /** Optional status for this habit event instance. */
            habitStatus?: string;
            /** Absolute link to this event in the Calendar web UI. */
            htmlLink?: string;
            /** Optional location of the event (plain text). */
            location?: string;
            meetingContacts?: AssistantApiCoreTypesCalendarEventMeetingContact[];
            /** The organizer of this event. */
            organizer?: AssistantApiCoreTypesCalendarEventAttendee;
            /**
             * Whether not all attendees are included in the attendee list. This is set when the attendees list has been truncated (e.g., when the number of attendees is beyond the maxAttendees
             * limitation).
             */
            otherAttendeesExcluded?: boolean;
            /** The user's response (the owner of this copy of the event) to this event. */
            participationResponse?: string;
            /** If this is an instance of a recurring event, recurring_event_id identifies the recurring series as a whole. */
            recurringEventId?: string;
            /** Meeting rooms associated to this event. */
            rooms?: AssistantApiCoreTypesCalendarEventRoom[];
            /** The start time of the event. This event is an all-day event if start has no time_of_day. */
            start?: AssistantApiDateTime;
            /** The title of the event. */
            summary?: string;
            /** Optional visibility of the event. */
            visibility?: string;
        }
        interface AssistantApiCoreTypesCalendarEventAttendee {
            /** Display name, present only if available. */
            displayName?: string;
            /** Email address of the attendee (calendar), for regular events. For +Events, this field is not populated, instead "id" is used. */
            email?: string;
            /**
             * Given (first) name, present only if available. This is used for generating meeting titles as given name is preferred over display (full) name (ie: "Jeff : Sundar" is better than
             * "Jeff Dean : Sundar Pichai").
             */
            givenName?: string;
            /** Profile ID of the principal, for +Events. For regular events, this field is not populated, instead "email" is used. */
            id?: string;
            /** Is this the organizer? */
            organizer?: boolean;
            /** Attendees response status. */
            responseStatus?: string;
            /** Is this the owner of this copy of the event? */
            self?: boolean;
        }
        interface AssistantApiCoreTypesCalendarEventMeetingContact {
            /** ID that corresponds to in ConferenceData.conference_id in calendar.common.ConferenceData proto. For Meet, this is the identifier used to join a meeting via URL. */
            conferenceId?: string;
            dialInNumberClasses?: string[];
            /** Default meeting phone number, for example: "tel:+1-475-777-1840" */
            phoneNumberUri?: string;
            /** A PIN that the participant will need to input after dialing in the conference. */
            pinNumber?: string;
            /** Provider info for the meeting. */
            provider?: AssistantApiCoreTypesProvider;
            /** The region code for the default meeting phone number */
            regionCode?: string;
            source?: string;
            /** The universal meeting PIN number for phone numbers in all available countries */
            universalPinNumber?: string;
            /** URL that can be used to join the meeting. */
            url?: string;
        }
        interface AssistantApiCoreTypesCalendarEventRoom {
            /** Room email that identifies the room and is used to book it. */
            email?: string;
            /** Additional room details. Read-only, populated on request. */
            locationDetails?: AssistantApiCoreTypesCalendarEventRoomRoomLocationDetails;
            /** Room name (ex: "MTV-PR55-5-A-Shadow 5K0 (13) GVC (No external guests)"). */
            name?: string;
        }
        interface AssistantApiCoreTypesCalendarEventRoomRoomLocationDetails {
            /** Building where the room is (ex: "PR55"). */
            building?: string;
            /** City where the room is (ex: "MTV"). */
            city?: string;
            /** Floor where the room is (ex: "5"). */
            floor?: string;
            /** The latitude in degrees. */
            latitude?: number;
            /** The longitude in degrees. */
            longitude?: number;
            /** Section in the floor (ex: "A"). */
            section?: string;
            /** Room name (ex: "Shadow 5K0"). */
            simpleName?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface AssistantApiCoreTypesCalendarEventWrapper {
        }
        interface AssistantApiCoreTypesCastAppInfo {
            /**
             * The cast app id. |cast_app_id| is the ID of the cast app used on the current device and |content_app_id| is the ID of the app that provides the actual content. For example, in a
             * group playback, on a follower device, the |cast_app_id| is the follower cast app ID and the |content_app_id| is the leader cast app ID.
             */
            castAppId?: string;
            /**
             * The id of the cast app that provides the content in a group. The field will always be filled. In the case of a group playback and the current device is a follower, the |cast_app_id|
             * has the ID of the follower app, and |content_app_id| has ID of the actual content app. In all other cases, |content_app_id| and |cast_app_id| will be the same.
             */
            contentAppId?: string;
        }
        interface AssistantApiCoreTypesChromeOsAppInfo {
            /** The localized app name. */
            localizedAppName?: string;
            /** Unique package name that identifies a ChromeOS app of the provider. */
            packageName?: string;
        }
        interface AssistantApiCoreTypesCloudProviderInfo {
            agentStyle?: AssistantApiCoreTypesCloudProviderInfoAgentStyle;
            /**
             * URL to a directory page about the third party agent in Assistant HQ. This is a universal (https) URL that may be handled natively by clients to show HQ or launch to the HQ directory
             * web page.
             */
            directoryUrl?: string;
            /** The logo url for the third party provider. */
            logoUrl?: string;
            /** The user visible name of the cloud provider, which may be used for example in the chat header during a conversation with the third party. */
            name?: string;
        }
        interface AssistantApiCoreTypesCloudProviderInfoAgentStyle {
            /** The background color of the agent. Used if no background image is specified for the given display orientation, or if the provided background image does not fit. */
            backgroundColor?: AssistantApiCoreTypesGovernedColor;
            headerTheme?: string;
            /** URL for the background image of the agent on landscape display. */
            landscapeBackgroundImageUrl?: string;
            /**
             * URL for the image containing the 3p logo. This can include logomark and logotype, or logotype only. If present, this can be used in place of the square logo contained in the top
             * level logo_url field in CloudProviderInfo. See go/cards-logo-customization for details on applying this logo.
             */
            logoUrl?: string;
            /** The color of the mask to apply to the background. See go/aog-cards-background-mask for details on applying this mask. */
            maskColor?: AssistantApiCoreTypesGovernedColor;
            /** URL for the background image of the agent on portrait display. */
            portraitBackgroundImageUrl?: string;
            /** The primary color of the agent. Used by the client to style the header and suggestion chips. */
            primaryColor?: AssistantApiCoreTypesGovernedColor;
        }
        interface AssistantApiCoreTypesDeviceConfig {
            /** Pantheon Project ID that uniquely identifies the consumer project ID. Required */
            agentId?: string;
            /** Unique identifier for the device. Example: DBCDW098234. Required */
            deviceId?: string;
        }
        interface AssistantApiCoreTypesDeviceId {
            /** The client_instance_id on devices with GSA. See 'client_instance_field' in go/androidids. */
            agsaClientInstanceId?: string;
            /**
             * Allo Id. Corresponds to the GBotRequest.Sender.sender. NOTE(dychen): This may change to standard android/ios physical device ids in order to enable shared data (e.g. installed app
             * on physical device shared between Allo and Opa apps on Nexus).
             */
            alloDeviceId?: string;
            /**
             * A unique device ID for Assistant devices as proposed by go/ocelot-team to solve the device id fragmentation problem. The value of this id is the HomeGraph id of the device. See
             * go/ocelot-track-0-registry-design. New surfaces should use the canonical_device_id instead of using other ids, and the registration should utilize the DeviceDataLayer (go/ddl-v0).
             * Please contact the assistant-state-management@ team for guidance. Note: We didn't reuse |home_graph_device_id| because in Assistant code base |home_graph_device_id| is common to
             * associate it with 3P devices. See go/project-yellowstone for more context.
             */
            canonicalDeviceId?: string;
            /** If set, indicates that the device is a cast device, and contains the UUID of the cast device. Corresponds to the device_id field of the CastDevice proto. */
            castDeviceId?: string;
            /**
             * DUSI (go/dusi) is used as the identifier here. This identifier is unique to the user and device. This will help identify which device or application the user's request originated
             * from. This is not to be confused with the client_instance_id that android devices provide. This is currently used by surfaces that use the assistant-legacy-nexus and
             * assistant-legacy-clockwork pipelines. DUSI is created and set in S3. This field is only filled for GAIA requests.
             */
            clientInstanceId?: string;
            /** A device ID produced by a connected dock, which is registered in HomeGraph. */
            connectedDockId?: string;
            /** The unique DeviceConfig to the specific third party device. It is also used by Android Auto Embedded first party device. See go/opa-ids. */
            deviceConfig?: AssistantApiCoreTypesDeviceConfig;
            /**
             * The device's surface type. This is the string version of surface_type. The server should use the SurfaceType value derived from this string. If the device_type isn't supported
             * within the SurfaceType enum, it will be set as UNKNOWN. Developers should use the enum in ServerParams instead of this string.
             */
            deviceType?: string;
            /**
             * The unique device ID for HomeGraph devices. This is the HomeGraph ID, created when the device is registered into HomeGraph. It is immutable for the same device unless it is
             * completely deleted and recreated. See go/home-graph for details.
             */
            homeGraphDeviceId?: string;
            /** The unique ID for libassistant based devices. See go/libassistant-id for details. */
            libassistantDeviceId?: string;
            /**
             * If set, indicates that the device is participating the multi-hotword arbitration and the id is an UUID to distinguish it from other devices. It should also be consistent between
             * requests from a single device within a session (or short duration).
             */
            multiHotwordArbitrationDeviceId?: string;
            /** The unique device ID for the Assistant App on iOS. See go/opa-ios-design for details. */
            opaIosDeviceId?: string;
            /** The unique ID of a Quartz device. See go/quartz-design-doc for more details. Quartz ID is a hash of (android_id + gaia). */
            quartzDeviceId?: string;
        }
        interface AssistantApiCoreTypesDeviceUserIdentity {
            /** The identifier of the device. */
            deviceId?: AssistantApiCoreTypesDeviceId;
            /** The identifier of the user. */
            gaiaId?: string;
        }
        interface AssistantApiCoreTypesGovernedColor {
            /**
             * The fraction of this color that should be applied to the pixel. That is, the final pixel color is defined by the equation: pixel color = alpha * (this color) + (1.0 - alpha) *
             * (background color) This means that a value of 1.0 corresponds to a solid color, whereas a value of 0.0 corresponds to a completely transparent color. If omitted, this color object
             * is to be rendered as a solid color (as if the alpha value had been explicitly given with a value of 1.0).
             */
            alpha?: number;
            /** The amount of blue in the color as a value in the interval [0, 1]. */
            blue?: number;
            /** The amount of green in the color as a value in the interval [0, 1]. */
            green?: number;
            /** The amount of red in the color as a value in the interval [0, 1]. */
            red?: number;
        }
        interface AssistantApiCoreTypesGovernedRingtoneTaskMetadata {
            /**
             * The category related with the ringtone. It's used to generate ringtone related with the category if the entity_mid is not be populated. E.g. for instrument, the ringtone may be
             * piano sound.
             */
            category?: string;
            characterAlarmMetadata?: AssistantApiCoreTypesGovernedRingtoneTaskMetadataCharacterAlarmMetadata;
            characterTag?: string;
            /**
             * The freebase mid of the entity related to the ringtone. It will be used to generate the ringtone for the alarm or timer (with support for i18n). For instance, for the "cat" mid, the
             * related ringtone will be a cat sound in some language, and for the "Beyonce" mid, the ringtone will be, e.g., a playlist of Beyonce's best hits.
             */
            entityMid?: string;
            funtimeMetadata?: AssistantApiCoreTypesGovernedRingtoneTaskMetadataFuntimeMetadata;
            genMlAlarmMetadata?: AssistantApiCoreTypesGovernedRingtoneTaskMetadataGenMlAlarmMetadata;
            /** Gentle wake information for this alarm. */
            gentleWakeInfo?: AssistantApiCoreTypesGovernedRingtoneTaskMetadataGentleWakeInfo;
            onDeviceAlarmMetadata?: AssistantApiCoreTypesGovernedRingtoneTaskMetadataOnDeviceAlarmMetadata;
            /** Will be deprecated. Use OnDeviceAlarmMetadata. */
            onDeviceAlarmSound?: string;
            routineAlarmMetadata?: AssistantApiCoreTypesGovernedRingtoneTaskMetadataRoutineAlarmMetadata;
        }
        interface AssistantApiCoreTypesGovernedRingtoneTaskMetadataCharacterAlarmMetadata {
            /**
             * For character alarm, the media resources are provided through AOG apps. During alarm trigger phase, aog apps with the specified agent_ids are used to get the media resources.
             * Multiple "AoG agents" can satisfy a character_tag. So the user will select the agents they want at alarm creation time. The chosen agents will be recorded so that the resources only
             * from those agents will be used at trigger time. The number of selected agent_ids will not exceed 3. See go/character-alarm-aog.
             */
            agentIds?: string[];
            /**
             * The Character Alarm tag. Tags are needed to identify the theme of the alarm. For example, if the tag is 'astronaut', astronaut based audio is played during alarm ring. Note : We
             * have made it repeated so that the user can choose multiple character alarm themes at one go. At present, the user is allowed to choose only one theme during alarm creation.
             */
            characterTags?: string[];
            /** Icons urls corresponding to a character. Note : We have made it repeated so that we can show different images when the alarm rings. At present, we only support only one image. */
            iconUrls?: string[];
        }
        interface AssistantApiCoreTypesGovernedRingtoneTaskMetadataFuntimeMetadata {
            /**
             * For FunTime alarms and timers, the media resources are provided through AOG apps during their ringtone. Multiple AoG agents can satisfy a label. So a random agent will be chosen
             * from those that are supplied. See go/funtime-engdesign.
             */
            agentIds?: string[];
            /** These bytes may represent the blob of the Rive animation that we pass to the Opal App. We will deprecate this field if we figure out a solution to load the animation from the web. */
            animationBlob?: string;
            /** Url for Rive animation that is brought up on ring. Rive is a lightweight animation library that is compatible with Flutter on Opal. See https://rive.app/. */
            animationUrl?: string;
            /** The url used to load the image that is at the center of the timer during timer countdown visuals. */
            timerHeroUrl?: string;
            /**
             * This is used to call S3 to realize the TTS. Is in the form of bytes because of a circular dependency issue in libassistant protos. It is a serialized proto of type
             * speech.s3.TtsServiceRequest.
             */
            ttsServiceRequestBytes?: string;
        }
        interface AssistantApiCoreTypesGovernedRingtoneTaskMetadataGenMlAlarmMetadata {
            isEnabled?: boolean;
            /** Label for the generated ringtone. */
            ringtoneLabel?: string;
        }
        interface AssistantApiCoreTypesGovernedRingtoneTaskMetadataGentleWakeInfo {
            /** Specifies how long the effect lasts. Allowed for effect to last after the alarm has started ringing. If unset or negative or 0, effect is assumed to last until alarm trigger time. */
            effectDurationMs?: string;
            /**
             * Indicates if gentle wake action is to be performed before this alarm fires. This is enabled only if the device supports sunrise alarm capability.
             * http://cs/symbol:assistant.api.SunriseFeaturesSupport
             */
            isEnabled?: boolean;
            /** Specifies how long before the alarm fire time, the wakeup effect will start. ALWAYS POSITIVE. */
            startTimedeltaMs?: string;
        }
        interface AssistantApiCoreTypesGovernedRingtoneTaskMetadataOnDeviceAlarmMetadata {
            /** Opal/UI layer will set this bit based on the user selection. */
            onDeviceAlarmSound?: string;
            /** A string label to identify the alarm sound name. Opal/UI layer will set this as per product definition. This will be used to display the name of the selected ringtone. */
            onDeviceAlarmSoundLabel?: string;
            /**
             * This is used to call S3 to realize the TTS. Is in the form of bytes because of a circular dependency issue in libassistant protos. It is a serialized proto of type
             * speech.s3.TtsServiceRequest. This request will contain an ssml with the url to the ringtone files hosted on gstatic.
             */
            ttsServiceRequestBytes?: string;
        }
        interface AssistantApiCoreTypesGovernedRingtoneTaskMetadataRoutineAlarmMetadata {
            /** The unique id for each routine. When the alrm is dismissed, it will trigger the routine of the routine alarm's creator if feasible. */
            routineId?: string;
        }
        interface AssistantApiCoreTypesHomeAppInfo {
            /** The localized app name. */
            localizedAppName?: string;
            /** Unique package name that identifies a Home app of the provider. */
            packageName?: string;
        }
        interface AssistantApiCoreTypesImage {
            /** A text description of the image to be used for accessibility, e.g. screen readers. */
            accessibilityText?: string;
            /**
             * App identifier. This field is specific to mobile surfaces and stands for app package name for Android surface, and app bundle identifier for iOS. In case identifier is specified but
             * invalid, some default icon will be used, e.g. PackageManager.getDefaultActivityIcon() for Android. If you want to show image for AGSA versions which don't support this field, you
             * can specify source_url as backup.
             */
            appIconIdentifier?: string;
            /** This is the image that is displayed as the badge on the main image. */
            badgeImage?: AssistantApiCoreTypesImage;
            /** Content of the image in bytes. */
            content?: string;
            height?: number;
            /** Indicate the data source where the image is fetched. */
            imageSource?: string;
            /** Content of image in form of JSON representation. */
            jsonContent?: string;
            /** Text used to generate a letter drawable (a letter icon with color). It will be the default icon if the source_url is empty or cannot be rendered. */
            letterDrawableText?: string;
            /** Url of the image provider, which is the website containing the image. For example, https://www.agentx.com. */
            providerUrl?: string;
            /** The source url of the image. For example, https://www.agentx.com/logo.png */
            sourceUrl?: string;
            /** Type of the source url. */
            sourceUrlType?: string;
            /** The width and height of the image in pixels. */
            width?: number;
        }
        interface AssistantApiCoreTypesInternalProviderInfo {
            /** Specifying which type of internal provider. */
            type?: string;
        }
        interface AssistantApiCoreTypesIosAppInfo {
            /** Bundle identifier that identifies an iOS app of the provider. */
            bundleIdentifier?: string;
            /** The localized app name. */
            localizedAppName?: string;
            /** A URL to open the provider's app. */
            openAppUrl?: string;
        }
        interface AssistantApiCoreTypesKaiOsAppInfo {
            /** The localized app name. */
            localizedAppName?: string;
            /** A URL to open the provider's app. */
            openAppUrl?: string;
            /** Unique package name that identifies a KaiOS app of the provider. */
            packageName?: string;
        }
        interface AssistantApiCoreTypesLocationCoordinates {
            /** The accuracy of the coordinates in meters. */
            accuracyMeters?: number;
            /** Latitude degrees. */
            latDegrees?: number;
            /** Longitude degrees. */
            lngDegrees?: number;
        }
        interface AssistantApiCoreTypesMessageNotification {
            /** App name of the message notification, e.g. Hangouts. */
            appName?: string;
            /** The key used to group this notification into a cluster. */
            bundleId?: string;
            /** Uri for the attachment (image, audio, video etc.). */
            dataUri?: string;
            /** The group key of a proactive notification. Details in assistant.api.client_op.NotificationArgs.grouping_key. */
            groupingKey?: string;
            /** Name of the group associated with the message notification. This field is set iff this is a group message. */
            groupName?: string;
            /** Index of the message notification. */
            index?: number;
            /** Boolean indicating if the mark_as_read action is available for this message. */
            markAsReadActionAvailable?: boolean;
            /**
             * Length of the message/notification content in characters. Note: We can't send the full content because of privacy restriction, preventing sending client content to our backends.
             * Concatenated message_length of all notification_entries.
             */
            messageLength?: number;
            messageRecipientType?: string;
            /** Mime type of the data_uri. e.g. 'audio/wav', 'video/mp4', 'image/png'. */
            mimeType?: string;
            notificationEntries?: AssistantApiCoreTypesMessageNotificationNotificationEntry[];
            /** On-device cache key for notification icon. */
            notificationIconKey?: string;
            /** String key of the notification. It is the key from original StatusBarNotification received from Android OS. It is used to identify the original notification to send a reply. */
            notificationKey?: string;
            /** The opaque_token of a proactive notification. Details in assistant.api.client_op.NotificationArgs.opaque_token. */
            opaqueToken?: string;
            /** App pkg of the message notification, e.g. "com.google.android.talk". */
            packageName?: string;
            /** Timestamp of the last notification's post time. */
            postTime?: string;
            /** Boolean indicating if the reply action is available for this message. */
            replyActionAvailable?: boolean;
            sender?: AssistantApiCoreTypesMessageNotificationPerson;
            /** Sender's name of the message notification, e.g. Elsa. Last sender name in case of a group conversation. */
            senderName?: string;
        }
        interface AssistantApiCoreTypesMessageNotificationNotificationEntry {
            /** Uri for the attachment (image, audio, video etc.). */
            dataUri?: string;
            /** Content of the message body in the notification. */
            messageBody?: string;
            /** Mime type of the data_uri. e.g. 'audio/wav', 'video/mp4', 'image/png'. */
            mimeType?: string;
            /** Timestamp of the notification's post time. */
            postTime?: string;
            /** Sender of the message notification. */
            sender?: AssistantApiCoreTypesMessageNotificationPerson;
        }
        interface AssistantApiCoreTypesMessageNotificationPerson {
            isImportant?: boolean;
            key?: string;
            name?: string;
        }
        interface AssistantApiCoreTypesProvider {
            /** The android app information of the provider. */
            androidAppInfo?: AssistantApiCoreTypesAndroidAppInfo;
            /** The cast app information of the provider. */
            castAppInfo?: AssistantApiCoreTypesCastAppInfo;
            /** The ChromeOS app information of the provider. */
            chromeosAppInfo?: AssistantApiCoreTypesChromeOsAppInfo;
            /** The third party provider information. */
            cloudProviderInfo?: AssistantApiCoreTypesCloudProviderInfo;
            /** A URL to fallback to if app can not be opened. */
            fallbackUrl?: string;
            homeAppInfo?: AssistantApiCoreTypesHomeAppInfo;
            /** Public URL pointing to an icon image for the provider. e.g. https://lh3.googleusercontent.com/UrY7BAZ-XfXGpfkeWg0zCCeo-7ras4DCoRalC_WXXWTK9q5b0Iw7B0YQMsVxZaNB7DM */
            iconImageUrl?: string;
            /** The internal assistant provider information. */
            internalProviderInfo?: AssistantApiCoreTypesInternalProviderInfo;
            /** The iOS app information of the provider. */
            iosAppInfo?: AssistantApiCoreTypesIosAppInfo;
            /** The KaiOS app information of the provider. */
            kaiosAppInfo?: AssistantApiCoreTypesKaiOsAppInfo;
            /** The sip information of the provider. */
            sipProviderInfo?: AssistantApiCoreTypesSipProviderInfo;
            /** The web provider information. */
            webProviderInfo?: AssistantApiCoreTypesWebProviderInfo;
        }
        interface AssistantApiCoreTypesProviderDelta {
            /** The android app information of the provider. */
            androidAppInfoDelta?: AssistantApiCoreTypesAndroidAppInfoDelta;
            /** A URL to fallback to if app can not be opened. */
            fallbackUrl?: string;
            /** Public URL pointing to an icon image for the provider. e.g. https://lh3.googleusercontent.com/UrY7BAZ-XfXGpfkeWg0zCCeo-7ras4DCoRalC_WXXWTK9q5b0Iw7B0YQMsVxZaNB7DM */
            iconImageUrl?: string;
        }
        interface AssistantApiCoreTypesSipProviderInfo {
            /**
             * The providers id (MID) which is the primary identifier for a call provider within the Assistant. A MID, or machine identifier, is a unique identifier issued by Knowledge Graph for
             * all entities contained in it's graph.
             */
            providerId?: string;
            /** Calling realm to be use for each call. i.e. For anonymous, this would be set to anonymous.chirp.google.com */
            realm?: string;
            /** If true, client should use the Birdsong TaCL API for this call. Uses the VoiceCallManager API by default. For more details: go/birdsong-migration-google-home */
            useBirdsongTacl?: boolean;
        }
        interface AssistantApiCoreTypesSurfaceIdentity {
            /** The identifier of the device. */
            deviceId?: AssistantApiCoreTypesDeviceId;
            /**
             * The device's surface type. The types are defined at google3/assistant/api/core_types/surfaces.gcl. NOTE: This is the new field that is going to replace the `surface_type_string`
             * field above. For more details please refer to go/ontologicalize-surface-type.
             */
            surfaceType?: string;
            /**
             * The device's surface type. This is the string version of the assistant.api.core_types.SurfaceType enum. The server should not use this field, rather it should use the SurfaceType
             * value derived from this string.
             */
            surfaceTypeString?: string;
            /** The version of the surface/client. This is different from the Conversation protocol version. */
            surfaceVersion?: AssistantApiCoreTypesSurfaceVersion;
        }
        interface AssistantApiCoreTypesSurfaceType {
            type?: string;
        }
        interface AssistantApiCoreTypesSurfaceVersion {
            major?: number;
            minor?: number;
        }
        interface AssistantApiCoreTypesWebProviderInfo {
            /** Serialized storage (context) persisted and retrieved for the app and home. */
            homeStorage?: string;
            /** The localized app name. */
            localizedAppName?: string;
            /** A URL to open the provider's app. */
            openAppUrl?: string;
            /** Info about 3P Custom NLU used in this web provider. TODO(b/321644453) remove when QRewrite is able to call SERoot. */
            thirdPartyCustomNluInfo?: AssistantApiCoreTypesWebProviderInfoThirdPartyCustomNluInfo;
        }
        interface AssistantApiCoreTypesWebProviderInfoThirdPartyCustomNluInfo {
            /** The locale of this agent version, represented by BCP-47 language strings, such as "en", "en-US", "fr", "fr-CA", "sr-Latn", "zh-Hans-CN", etc. */
            locale?: string;
            /** Unique internal identifier of 3P Custom NLU agent. UUID. */
            nluAgentId?: string;
            /** Identifies the 3P Custom NLU agent version. */
            nluAgentVersion?: string;
        }
        interface AssistantApiCrossDeviceExecutionCapability {
            /** Whether the device has torus/usonia capabililities enabled or not. */
            localConnectivityEnabled?: boolean;
            /**
             * Whether the device supports cast media originated from a remote device to be executed through local execution and can upload results asynchronously. Needs to be checked before
             * sending remote media initiation through local channel since it needs an async result upload path.
             */
            remoteCastMediaEnabled?: boolean;
        }
        interface AssistantApiDate {
            /** The day, in 1...31. */
            day?: number;
            /** The month, in 1...12. */
            month?: number;
            /** The year, e.g. 2016. */
            year?: number;
        }
        interface AssistantApiDateTime {
            /** A Gregorian calendar date. */
            date?: AssistantApiDate;
            /** A civil time relative to a timezone. */
            timeOfDay?: AssistantApiTimeOfDay;
            /** A time zone in IANA format. */
            timeZone?: AssistantApiTimeZone;
        }
        interface AssistantApiDeviceCapabilities {
            /** Capabilites related to Android intent support. */
            androidIntentCapabilities?: AssistantApiAndroidIntentCapabilities;
            /** These capabilities are scoped to the ability to gather audio. It includes information like the type of audio that can be gathered (e.g. public, private). */
            audioInput?: AssistantApiAudioInput;
            /** These capabilities are scoped to the ability to play audio. It includes information like the type of audio that can be played (e.g. public, private). */
            audioOutput?: AssistantApiAudioOutput;
            /** The call capabilities of this device. go/call-capabilities */
            callCapabilities?: AssistantApiCallCapabilities;
            /** These capabilities are scoped to the camera abilities of this device. */
            camera?: AssistantApiCameraCapabilities;
            /** UX restrictions for Auto. */
            carUxRestrictions?: string[];
            /** These capabilities are scoped to the cast abilities of this device. */
            cast?: AssistantApiCastCapabilities;
            communicationUiCapabilities?: AssistantApiCommunicationUiCapabilities;
            contactLookupCapabilities?: AssistantApiContactLookupCapabilities;
            /**
             * This is the same device id that is specified in the conversation protocol and should be unique to each device/user/model combination. For example, if a request is coming from a
             * watch through AGSA the watch and AGSA should have different device_ids. Note: this field should only be used to determine which device the capabilities belong to and not to access
             * the id of the device. Instead DeviceProperties should be used and accessed through ParamsAccessor.
             */
            deviceId?: AssistantApiCoreTypesDeviceId;
            /** Capabilities related to Android tablet UX experience. */
            deviceUxMode?: string;
            /**
             * Indicates that the device has connection to cellular network that allows it to make voice calls. This is distinct from device just being capable of voice telephony, because the
             * device can be capable yet miss the suitable SIM card (for example, it could miss SIM card altogether, or have data-only SIM card).
             */
            hasVoiceTelephony?: boolean;
            /** Indicates if the client supports Javascript Whatsnext (go/jwn). Also contains the Jwn libraries present on the client along with their versions. */
            jwnCapabilities?: AssistantApiJwnCapabilities;
            /** Capabilities related to Lens Perception, i.e. image understanding. See go/lens-perception-sdk. */
            lensPerceptionCapabilities?: AssistantApiLensPerceptionCapabilities;
            /** These capabilities are scoped to the location abilities of this device. */
            location?: AssistantApiLocationCapabilities;
            /** Data which is produced for logging and debugging. Servers MUST NOT use this for any other purposes, such as branching on it. */
            loggingOnlyData?: AssistantApiLoggingOnlyData;
            messageCapabilities?: AssistantApiMessageCapabilities;
            /** These capabilities are scoped to abilities of the device to move around. */
            movement?: AssistantApiMovementCapabilities;
            /**
             * DEPRECATED: Use SystemNotificationRestrictions instead. Specifies whether the surface is able to display notifications. This field is superficially similar to
             * ProactiveNotificationOutput, but unlike that field which tracks a per-user preference on the OPA side, this field captures whether the surface is capable of displaying
             * notifications.
             */
            notificationCapabilities?: string;
            /**
             * Settings, that reflect whether a specific notification type is allowed for current device, e.g. if the user opted out from notification category or category group. This settings are
             * server-side stored and evaluated unlike SystemNotificationRestrictions field.
             */
            notificationOutputRestrictions?: AssistantApiNotificationOutputRestrictions;
            /** These are user configured restrictions indicating what the device is allowed to output from the privacy point of view. */
            outputRestrictions?: AssistantApiOutputRestrictions;
            /**
             * Capability to support Pop on lockscreen. TODO(b/230626444) this is for short term workaround for TNG MA DF. Should be deprecated when long term solution is available.
             * go/pop-on-lockscreen-for-tng-ma.
             */
            popOnLockscreenCapability?: string;
            /** Indicates if the client has safety related restriction. */
            safetyRestrictions?: string;
            /**
             * These capabilities are scoped to the ability to see and interact with the Assistant through a screen. If the device has no screen it should send an empty ScreenCapabilities. Sending
             * no ScreenCapabilities will cause this to be overridden with the surface default.
             */
            screen?: AssistantApiScreenCapabilities;
            /** Capabilities related to SODA (Speech On-Device API). */
            sodaCapabilities?: AssistantApiSodaCapabilities;
            /** These capabilities are scoped to the software available on the device as well as the set of supported Assistant features. */
            software?: AssistantApiSoftwareCapabilities;
            /** DEPRECATED Capabilities related to speech detection on devices. */
            speechCapabilities?: AssistantApiSpeechCapabilities;
            /**
             * Locales supported by assistant settings for speaking and display. This is independent from device language that is defined in device setting. New locales are added based on rollout,
             * whitelist and app version releases because older versions does not have model support. Currently supported locale list differs by surface type.
             */
            supportedLocale?: string[];
            /** The set of information that helps the server identify the surface. */
            surfaceIdentity?: AssistantApiCoreTypesSurfaceIdentity;
            /**
             * The device's surface type. This is the string version of the assistant.api.core_types.SurfaceType enum. The server should not use this field, rather it should use the SurfaceType
             * value derived from this string.
             */
            surfaceTypeString?: string;
            /**
             * Restrictions related to system-level notifications. This field is superficially similar to ProactiveNotificationOutput, but unlike that field which tracks a per-user preference on
             * the OPA side, this field captures system level notifications restrictions. This field is not stored and is merged to capablities from conversation params. It exists mostly for
             * logging purposes of android channel state and global app-level notification opt out.
             */
            systemNotificationRestrictions?: AssistantApiSystemNotificationRestrictions;
            /** Capabilities related to third party integration. */
            thirdPartyCapabilities?: AssistantApiThirdPartyCapabilities;
        }
        interface AssistantApiDuration {
            /**
             * Signed fractions of a second at nanosecond resolution of the span of time. Durations less than one second are represented with a 0 `seconds` field and a positive or negative `nanos`
             * field. For durations of one second or more, a non-zero value for the `nanos` field must be of the same sign as the `seconds` field. Must be from -999,999,999 to +999,999,999
             * inclusive.
             */
            nanos?: number;
            /** Signed seconds of the span of time. Must be from -315,576,000,000 to +315,576,000,000 inclusive. */
            seconds?: string;
        }
        interface AssistantApiFeatureSpecificActionSupport {
            /** Whether client supports clarification suggestion chip to be displayed see |assistant.suggestions.ClarificationData| */
            clarificationDataSupported?: boolean;
        }
        interface AssistantApiFitnessFeatureSupport {
            /** A list of fitness activity types supported by this client. */
            supportedActivities?: string[];
        }
        interface AssistantApiFluidActionsSupport {
            /** Specifies the params proto that Fluid Actions uses to sync state with server. */
            stateSyncMethod?: string;
        }
        interface AssistantApiGacsCapabilities {
            /** DeviceId of the accessory device (eg. watch) Commonly the go/dusi (eg. client_instance_id) is provided. */
            deviceId?: AssistantApiCoreTypesDeviceId;
            /** Configuration sent by device. */
            responseConfig?: GoogleAssistantAccessoryV1ResponseConfig;
            /** DEPRECATED: Format of TTS audio requested by the device. */
            ttsEncoding?: string;
        }
        interface AssistantApiGcmCapabilities {
            /** GCM registration id for the device. Used to pass messages to the device. */
            gcmRegistrationId?: string;
            /** Assistant supports GCM on the device. ClientOps can be sent to it over GCM and will be executed. */
            supportsAssistantGcm?: boolean;
            /**
             * If it is set to true, then it indicates to server that device is capable of receiving a GCM payload with serialized client input. The client input will be sent back to Assistant
             * Server over conversation protocol.
             */
            supportsClientInputOverGcm?: boolean;
        }
        interface AssistantApiGestureCapabilities {
            /** Whether Gesture is supported. When false, override the value for tap and omniswipe. */
            gestureSensing?: boolean;
            /** Whether omniswipe is supported */
            omniswipeGestureCapable?: boolean;
            /** Whether tap is supported */
            tapGestureCapable?: boolean;
        }
        interface AssistantApiGuestAccessOutput {
            guestAccessOnYoutube?: string;
        }
        interface AssistantApiImmersiveCanvasSupport {
            /** Whether the client supports confirmation messages in Immersive Canvas actions. */
            confirmationMessageSupported?: boolean;
            /** Whether the client support canvas pause signal. If true, the Assistant Server will send a signal when canvas transitioning to pause mode. */
            pauseSignalSupported?: boolean;
        }
        interface AssistantApiJwnCapabilities {
            /** The name and version of the jwn libraries currently stored on the client. These are the same that the server communicated when the library was first sent down. */
            librariesVersionMap?: { [P in string]: string };
            /** Compression algorithms supported on the client. Server can choose one of these to compress WhatsNext Javascript programs and libraries. */
            supportedCompressionMode?: string[];
            /** Whether the client supports running jwn code. */
            supportsJwn?: boolean;
        }
        interface AssistantApiLensPerceptionCapabilities {
            /** Whether the device supports Lens Perception. */
            hasLensPerception?: boolean;
            /** Indicates whether Lens supports Lens Direct Intent (go/lensdirectintent). */
            isLensDirectIntentAvailable?: boolean;
            /** Indicates whether Lens supports Live view-finder experience. */
            isLensLiveViewfinderAvailable?: boolean;
            /** Indicates whether Lens supports Post-capture experience with an image payload. */
            isLensPostCaptureAvailable?: boolean;
            /** Contains the capabilities that Lens can support. */
            lensCapabilities?: AssistantApiLensPerceptionCapabilitiesLensCapabilities;
        }
        interface AssistantApiLensPerceptionCapabilitiesLensCapabilities {
            /** The presence of this message means that Dining is supported. */
            dining?: any;
            /** The presence of this message means that Education is supported. */
            education?: any;
            /** The presence of this message means that Outdoor is supported. */
            outdoor?: any;
            /** The presence of this message means that Shopping is supported. */
            shopping?: any;
            /** The presence of this message means that intenting directly into the text filter is supported. */
            text?: AssistantApiLensPerceptionCapabilitiesLensCapabilitiesText;
            /** The presence of this message means that Translation is supported. */
            translate?: AssistantApiLensPerceptionCapabilitiesLensCapabilitiesTranslate;
        }
        // tslint:disable-next-line:no-empty-interface
        interface AssistantApiLensPerceptionCapabilitiesLensCapabilitiesDining {
        }
        // tslint:disable-next-line:no-empty-interface
        interface AssistantApiLensPerceptionCapabilitiesLensCapabilitiesEducation {
        }
        // tslint:disable-next-line:no-empty-interface
        interface AssistantApiLensPerceptionCapabilitiesLensCapabilitiesOutdoor {
        }
        // tslint:disable-next-line:no-empty-interface
        interface AssistantApiLensPerceptionCapabilitiesLensCapabilitiesShopping {
        }
        interface AssistantApiLensPerceptionCapabilitiesLensCapabilitiesText {
            /** Indicates whether text-to-speech is supported. */
            isTextToSpeechSupported?: boolean;
        }
        interface AssistantApiLensPerceptionCapabilitiesLensCapabilitiesTranslate {
            /**
             * The list of language IETF BCP 47 tags that are supported. See the full details in the comment on the equivalent field in:
             * http://google3/java/com/google/android/apps/gsa/search/shared/service/proto/lens_service_event.proto;l=55;rcl=355512559
             */
            supportedLanguageTags?: string[];
        }
        interface AssistantApiLiveTvChannelCapabilities {
            /** A list of channel providers each of which provides a list of its channels. */
            channelsByProvider?: AssistantApiLiveTvChannelCapabilitiesChannelsByProvider[];
        }
        interface AssistantApiLiveTvChannelCapabilitiesChannelsByProvider {
            /**
             * A list of channels provided by this input. Keep the performance impact in mind when the number/size of the channels is large. When there are too many channels, consider stripping
             * out some data.
             */
            channels?: AssistantApiLiveTvChannelCapabilitiesLiveTvChannel[];
            /**
             * An identifier to identify the input source. For example for TIF based channels, this will be the TIF input ID to differentiate different tuner apps. See
             * https://source.android.com/devices/tv
             */
            inputId?: string;
            /** Type of provider who provides this channel input. */
            providerType?: string;
        }
        interface AssistantApiLiveTvChannelCapabilitiesLiveTvChannel {
            /** Unique channel identifier. */
            channelId?: string;
            /** A list of channel names and synonyms. */
            channelName?: string[];
            /** Channel number displayed to user. Optional. */
            channelNumber?: string;
            /** A deep link into the Live player app that tunes to this channel. */
            deeplink?: string;
            /** KG mid of the channel if it exists in KG. */
            mid?: string;
            /** Network KG mid of the channel if it exists in KG */
            networkMid?: string;
        }
        interface AssistantApiLiveTvProvider {
            /** Contains detailed provider information such as android app package name. */
            providerInfo?: AssistantApiCoreTypesProvider;
            /**
             * An provider enum string for OTT providers. The available key can be found in go/ump-provider-enum For Tuner provider, the provider key would be an ID the tuner app uploaded from
             * TIF. See https://source.android.com/devices/tv
             */
            providerKey?: string;
            providerType?: string;
        }
        interface AssistantApiLocationCapabilities {
            gpsAvailable?: boolean;
        }
        interface AssistantApiLoggingOnlyData {
            /**
             * The index of the account on the device. Useful when there are multiple accounts on a device such as distinguishing primary user data from secondary users. There is no guarantee that
             * this is a stable number but is relatively stable in practice.
             */
            accountIndex?: number;
            /** A user-readable string describing the ACP version (go/acp-version) of the client app used by the user to originate the conversation. */
            acpVersion?: string;
            /**
             * Random identifier assigned to Android mobile devices. Older logs may have previously stored other kinds of android IDs in this field, but all current logs should use the GServices
             * Id. See go/androidids.
             */
            androidId?: string;
            /** A user-readable string describing the version of the client app used by the user to originate the conversation. */
            appVersion?: string;
            /** An enum specifying when was this ATV AssistantSettings entry initially created. */
            assistantSettingsSource?: string;
            /** The type of board used by manufacturer for this device */
            boardName?: string;
            /** The revision of board used */
            boardRevision?: string;
            /** This field records the linking status between Assistant setting entry and Cast setting entry. Currently only ATV surface populates this field for profiling purpose. */
            castAssistantSettingLinkingResult?: AssistantApiCastAssistantSettingLinkingResult;
            /** A user-readable string describing the device's hardware platform. */
            deviceModel?: string;
            /**
             * Any relevant info concerning the build options of the embedder (that is the software which runs as the 'driver' of an Assistant library, such as libassistant. the embedder is
             * typically built by a third party)
             */
            embedderBuildInfo?: string;
            /** A string recording the app version that is initially used to created this settings entry. */
            initialAppVersion?: string;
            /** default display name of device over mdns. This is specified at the factory, not specified by the user. */
            mdnsDisplayName?: string;
            /** A user-readable string describing the device's software platform. */
            platformBuild?: string;
            /** A string describing device's release channel. For cast devices, the string will look like "qa-beta-channel", "eng-no-update", etc. */
            virtualReleaseChannel?: string;
        }
        interface AssistantApiMediaControlSupport {
            /** Whether to prevent confirmations (text, tts) for media control actions while media is playing so that the media session is not interrupted. */
            skipConfirmationsWhilePlaying?: boolean;
        }
        interface AssistantApiMessageCapabilities {
            /**
             * If true, APP_ID queries initiated by this device should fall back to execution on the tethered device if it's available and if the primary device cannot perform the action (e.g. due
             * to the app not being installed).
             */
            fallbackToTetheredDeviceAppCapabilities?: boolean;
            /** Should only be checked if nonempty. */
            supportedRecipientTypes?: string[];
        }
        interface AssistantApiMovementCapabilities {
            /** Indicates how much the device moves around. E.g., TV has a low mobility level, while Auto has a very high level. */
            mobility?: string;
        }
        interface AssistantApiNotificationOutputRestrictions {
            optOutState?: AssistantApiNotificationOutputRestrictionsOptOutState;
        }
        interface AssistantApiNotificationOutputRestrictionsOptOutState {
            categoryGroupState?: AssistantApiNotificationOutputRestrictionsOptOutStateCategoryGroupState[];
            categoryState?: AssistantApiNotificationOutputRestrictionsOptOutStateCategoryState[];
        }
        interface AssistantApiNotificationOutputRestrictionsOptOutStateCategoryGroupState {
            categoryGroup?: string;
            state?: string;
        }
        interface AssistantApiNotificationOutputRestrictionsOptOutStateCategoryState {
            category?: string;
            state?: string;
        }
        interface AssistantApiOemCapabilities {
            /** The OEM Cloud execution capability of this device, containing routing details for cloud fulfillment. */
            cloudCapability?: AssistantDevicesPlatformProtoCloudCapability;
            /** If fulfillment is done via 3P cloud and 3P supports device capabilities, this field will be set. */
            cloudDeviceCapabilities?: { [P in string]: any };
            /** Device Model Id from DeviceModelPackage. */
            deviceModelId?: string;
            /** Device Model Revision Id from DeviceModelPackage. */
            deviceModelRevisionId?: string;
            /** Opaque supported action data related to a specific domain of devices, for example for car. go/car-talk-registration-model */
            deviceSpecificData?: string;
            /** Internal-only config containing metadata about the Device Model, for example to control the ranking behavior. */
            internalCapability?: AssistantDevicesPlatformProtoInternalCapability;
            /**
             * 3P Action Metadata, populated from the Device Model lookup and the client request parameters. For example, an Assistant SDK request would have the billed project id of the Assistant
             * request added here in order to enable any Device Actions developed using the same Google Cloud project. This data is sent to Service Engine to mask triggering for Device Actions.
             */
            thirdPartyActionConfig?: AssistantApiThirdPartyActionConfig;
        }
        interface AssistantApiOnDeviceAssistantCapabilities {
            /**
             * Capabilities related to local network arbitration (go/local-network-arbitration). Indicates if the device is capable of being a host device in the LAN whiling doing local network
             * arbitration.
             */
            isLocalNetworkArbitrationSupported?: boolean;
            /** Capabilities related to on-device arbitration(go/arbitration-on-device). */
            isOnDeviceArbitrationSupported?: boolean;
            /** Indicates if on-device assistant is enabled on this device. Example usecases: NGA (go/nga) or Marble (go/marble). */
            isOnDeviceAssistantSupported?: boolean;
            /** This may be used by NGA. E.g. if understanding happens on device, we can have more aggressive logic when fulfilling some features on the server side, like teleport. */
            isOnDeviceUnderstandingSupported?: boolean;
        }
        interface AssistantApiOnDeviceSmartHomeCapabilities {
            /** Master bit for on-device Smart Home features. */
            isOnDeviceSmartHomeSupported?: boolean;
        }
        interface AssistantApiOnDeviceStorageCapabilities {
            /** Determines if an on-device storage is supported. */
            isSupported?: boolean;
        }
        interface AssistantApiOutputRestrictions {
            /** Access settings for all providers. */
            accessControlOutput?: AssistantApiAccessControlOutput;
            /** The type of Google Photo content which the device can output. */
            googlePhotoContent?: string;
            /** DEPRECATED: Use access_control_output instead. Access settings for guests. */
            guestAccessOutput?: AssistantApiGuestAccessOutput;
            /** The level of personal data which the device can output. See go/personal-readout for detail. */
            personalData?: string;
            /**
             * This controls if the server can proactively send notification to users, and it does not affect scenarios that users ask for information. The notification may include TTS and lights.
             * It could be only lights for chirp.
             */
            proactiveNotificationOutput?: string;
            /**
             * Restrictions on displaying and interacting with content on proactive surfaces (e.g. Dragonglass home screen). Note: NEVER access this field of OutputRestrictions directly, use the
             * code in assistant/assistant_server/settings/device/device_settings_util.h instead.
             */
            proactiveOutput?: AssistantApiProactiveOutput;
            /** Whether YouTube autoplay is allowed for queries from the user to this device. See go/assistant-youtube-settings for details. */
            youtubeAutoplayRestriction?: string;
            /** The type of YouTube content which the device can output. */
            youtubeContent?: string;
            /** The type of YouTube TV content which the device can output. */
            youtubeTvContent?: string;
        }
        interface AssistantApiProactiveOutput {
            /** Allows displaying all personal data on proactive surfaces with no face match capability. */
            allowAllPersonalData?: boolean;
            /** For ANDROID_TV devices, the location that this setting was last changed from. Note: this structure allows to extend to more per-vertical bits in the future. */
            androidTvAssistantSettingsSource?: string;
            /**
             * Allows displaying Health and Fitness content on proactive surfaces. This is a sub bit of the device-wide PR bit - the device-wide PR bit must be enabled AND this vertical sub bit
             * must be enabled for H&F content to be shown. This bit will be available on all surfaces that have the proactive-bit enabled. If the proactive-bit is not enabled, then we do not show
             * health and fitness content at all (or even allow access to this setting).
             */
            healthAndFitnessProactive?: string;
            /**
             * Allows displaying photos content on Dragonglass proactive surfaces. This is a sub bit of the device-wide PR bit - the device-wide PR bit must be enabled AND this vertical sub bit
             * must be enabled for photos content to be shown on Dragonglass surfaces. This bit will be available on all Dragonglass surfaces that have the proactive-bit enabled. If the
             * proactive-bit is not enabled or it's not a Dragonglass surface, then we do not show proactive photos content at all, nor allow access to this setting. See go/opa-photos-sg-settings
             * for more details.
             */
            photosProactive?: string;
            /**
             * Whether a device supports proactive output. Note that this is assumed to be true for all Smart Display devices, but surfaces that newly start supporting proactive_output should set
             * this bit.
             */
            supportsProactiveOutput?: boolean;
            /** Settings for displaying personal data on proactive surfaces with face match capability. */
            userMatchProactive?: string;
        }
        interface AssistantApiProtobuf {
            /** The serialized protocol buffer. */
            protobufData?: string;
            /**
             * The type of the protocol buffer to use. This must be a resolvable name (Namespace.ProtoName) and refer to a proto which is either compiled in to both client and server (e.g. a base
             * proto type) or to one which is part of the conversation package.
             */
            protobufType?: string;
        }
        interface AssistantApiRecurrence {
            /** The first day of the recurrence. If begin is not set, then the reminder will start infinitely in the past. */
            begin?: AssistantApiDate;
            /** A list of blacklisted dates to skip the alarm on. */
            blacklistedRanges?: AssistantApiRecurrenceDatetimeRange[];
            /** Specifies the date in a month. For example, if day_of_month is 15, then it represent the 15th day of the specified month. */
            dayOfMonth?: number[];
            /** Specifies a weekly or daily recurrence. Constraint: The date falls on one of these days of the week, in 0...6 (Sunday...Saturday). */
            dayOfWeek?: number[];
            /** The last day of the recurrence. */
            end?: AssistantApiDate;
            /**
             * Multiplier on the frequency of the recurrence. Use this to specify patterns that recur every X days, months, years, etc. Example: [remind me to call mom every 2nd week]. Default is
             * 1 (every day, every month, every year).
             */
            every?: number;
            /** Specifies the month in a year. Constrain: the month falls on one of these months, in 1, 2, ... 12 (January...December). */
            monthOfYear?: number[];
            /** The number of occurrences after which the recurrence should end. */
            numOccurrences?: number;
            /** Specifies the index of week in a month. For example, the second Tuesday every month, in this case, week_of_month should be 2. */
            weekOfMonth?: number[];
        }
        interface AssistantApiRecurrenceDatetimeRange {
            /** End date of the range. */
            endDate?: AssistantApiDateTime;
            /** Start date of the range. */
            startDate?: AssistantApiDateTime;
        }
        interface AssistantApiScreenCapabilities {
            /** The types of input that this screen supports. Note that this can be empty in which case the screen's input type is unknown. */
            inputType?: string[];
            /** Mask defined for this device, if any. */
            mask?: AssistantApiScreenCapabilitiesMask;
            /** The targeted schema version for ProtoLayout requests. */
            protoLayoutTargetedSchema?: AssistantApiScreenCapabilitiesProtoLayoutVersion;
            /** If this field is absent, the resolution of the screen is unknown. */
            resolution?: AssistantApiScreenCapabilitiesResolution;
            /** If screen is turned off. */
            screenOff?: boolean;
            /** The ability of the client to correctly report screen state. */
            screenStateDetection?: string;
            /** The primary supported rendering format for display on the device's screen. This may be used to determine what format of card to be returned when rendering cards. */
            supportedRenderingFormat?: string;
            /** The screen states that the client supports. The current screen state is specified in DeviceProperties.screen. */
            supportedScreenStates?: string[];
            /**
             * Whether the device enabled vision help features in accessiblity settings. The settings is config in Assistant App and on-device settings, and stored in footprints. When enabled,
             * font, color and TTS will be adjusted.
             */
            visionHelpEnabled?: boolean;
        }
        interface AssistantApiScreenCapabilitiesMask {
            type?: string;
        }
        interface AssistantApiScreenCapabilitiesProtoLayoutVersion {
            major?: number;
            minor?: number;
        }
        interface AssistantApiScreenCapabilitiesResolution {
            /** Dots (pixels) per inch of the screen. */
            dpi?: number;
            heightPx?: number;
            /** m_size is the smallest square box size to display a capital letter M so that the user can still easily understand it. */
            mSize?: number;
            /**
             * neng_size is the smallest square box size to display a letter 螚 (Neng, U+879A) so that the user can easily understand it. (Neng is a visually dense Chinese letter, and so may
             * require a larger box than an M.)
             */
            nengSize?: number;
            /** The dimensions of the application window, in pixels. */
            widthPx?: number;
        }
        interface AssistantApiSelinaCapabilites {
            /** A list of gestures that selina supports */
            gestureCapabilities?: AssistantApiGestureCapabilities;
            /** Whether the client supports selina. */
            selinaSupported?: boolean;
            /** Whether the client can monitor sleep. This allows us to show sleep CUJ related information: go/TwilightDesign */
            sleepSensingSupported?: boolean;
        }
        interface AssistantApiSettingsAmbientSettings {
            /** Whether any user sets personal photos on this device. See go/ambient-setting-in-assistant-design. */
            anyUserHasSetPersonalPhotos?: boolean;
            /**
             * Whether or not the user's current selection for their ambient photo frame includes the auto-generated "Recent Highlights" album. This is used to determine which users to display the
             * go/opa-photos-memories-tile. See go/opa-photo-memories-imax-optin for more discussion on why this bit was created.
             */
            recentHighlightsEnabled?: boolean;
            /**
             * Whether to enable the personal photo data in the ambient settings: https://screenshot.googleplex.com/Wd4OFkQfOyF See go/opa-photos-ambient-location-date-dd#heading=h.5x4iaouuiett
             * for explanation.
             */
            showPersonalPhotoData?: boolean;
            /** Whether current user sets personal photos on this device. See go/ambient-setting-in-assistant-design. */
            showPersonalPhotos?: boolean;
        }
        interface AssistantApiSettingsAppCapabilities {
            /** Capabilities that are associated with Assistant Settings on auto surfaces. */
            carSettingsCapabilities?: AssistantApiCarSettingsCapabilities;
            /** Whether the client supports reissuing query after setting up in Music Settings. */
            reissueQueryAfterMusicSetup?: boolean;
            /** Whether the client supports updating payments setting. */
            supportsPaymentsSettingsUpdate?: boolean;
        }
        interface AssistantApiSettingsAutoFramingSettings {
            isAutoFramingEnabled?: boolean;
        }
        interface AssistantApiSettingsCarrierCallDeviceSettings {
            /** Whether this device is allowed to receive incoming PSTN calls. */
            allowIncomingCalls?: boolean;
        }
        interface AssistantApiSettingsCommunicationsFilter {
            state?: string;
        }
        interface AssistantApiSettingsDeviceDowntimeSettings {
            schedules?: AssistantApiSettingsLabeledDowntimeSchedule[];
            /** The set of users of this device that will have these downtime settings applied. Must have at least one element. */
            targets?: string[];
        }
        interface AssistantApiSettingsDeviceFeatureFilters {
            /** Enables/disables all the filters at the same time. For new devices or non-Cast devices this is always false. */
            enabled?: boolean;
            /** The filters (feature restrictions) to apply when `enabled` is true. */
            featureFilters?: AssistantApiSettingsFeatureFilters;
            /** The set of users of this device that will have these settings applied. Must have at least one element. */
            targets?: string[];
        }
        interface AssistantApiSettingsDeviceLogsOptIn {
            /** Indicates whether the crash logs can be uploaded and the device logs can be enabled */
            optInEnabled?: boolean;
        }
        interface AssistantApiSettingsDeviceSettings {
            /** LINT.ThenChange(//depot/google3/assistant/ui/assistant_device_settings_ui.proto) */
            ackStatus?: string;
            /**
             * A human-readable address string for the location; generally a one-line address such as "34 Masonic Ave, San Francisco CA 94117, United States". Set this field to empty string for
             * deletion, in which case the rest of the location related fields below will be cleared as well.
             */
            address?: string;
            /**
             * The alias names of the device, e.g. my living room tv, tv, living room and etc., which user will usually use to refer to the device in addition to human_friendly_name. It can help
             * speech biasing and query understanding. This field is set by the user and already localized.
             */
            aliasName?: string[];
            /** Whether this device is allowed to receive incoming calls. */
            allowIncomingCalls?: boolean;
            /**
             * Ambient settings contains the configuration of Photo Frame on DG device. This field relies on IMAX service to do the update, sync happenes after user updates IMAX device settings or
             * a device registers in CloudCastDevice. So it's more like a cached version instead of definitive source-of-truth. More details at go/ambient-setting-in-assistant-design.
             */
            ambientSettings?: AssistantApiSettingsAmbientSettings;
            /** The additional device ids. Currently used only for ATV. go/project-yellowstone Note: This field is for internal (Within settings) use only. */
            ancillaryDeviceId?: AssistantApiSettingsInternalAncillaryDeviceId;
            /** Auto framing settings associated with a device. See go/auto-framing-presentation. */
            autoFramingSettings?: AssistantApiSettingsAutoFramingSettings;
            /** Indicates whether the user has enabled Blue Steel. See go/blue-steel for more info on this project. */
            blueSteelEnabled?: boolean;
            /** Describes roughly what a device is capable of doing and metadata around those capabilities. Note: this includes device limitations as well as user configurable settings. */
            capabilities?: AssistantApiDeviceCapabilities;
            /**
             * city and postal_code are sent to third party AoG Apps as location when permission is granted for precise or coarse location.
             * https://developers.google.com/actions/reference/rest/Shared.Types/Permission city and postal_code have the same description as in Proto Postal Address:
             * https://cs.corp.google.com/piper///depot/google3/location/country/postaladdress.proto city corresponds to locality_name, postal_code corresponds to postal_code_number. These two
             * fields are set in assistant_settings_service by AddressConverter. https://cs.corp.google.com/piper///depot/google3/location/addressformatter/public/addressconverter.h See
             * go/aog-i18n-address-parse for more information
             */
            city?: string;
            /**
             * Status of colocation. go/co-location-work-v2 Note: this is a cache at the Assistant level. The source of truth is inside CastAuthenticationServer, which is only used for Home
             * devices.
             */
            colocationStatus?: string;
            /** The timestamp that the device is linked with the user in milliseconds. */
            creationTimestampMs?: string;
            /** Availability of this device for Assistant Cross-surface handoffs. (go/assistant-cross-surface) */
            crossSurfaceAvailability?: AssistantApiSettingsDeviceSettingsCrossSurfaceAvailability;
            /** The identification of the default device which user want to output audio. See go/default-media-output-design for more info. */
            defaultAudioDeviceId?: AssistantApiCoreTypesDeviceId;
            /**
             * The identification of the default device which user want to output video. Note that, we don't fallback to this for audio playback when default_audio_device_id is not set. See
             * go/default-media-output-design for more info.
             */
            defaultVideoDeviceId?: AssistantApiCoreTypesDeviceId;
            /** The brand of the device, populated from DeviceOemParams. Examples: "google", "samsung". */
            deviceBrand?: string;
            /** The identification of the device. */
            deviceId?: AssistantApiCoreTypesDeviceId;
            /** The model ID of the device. This should be globally unique across manufactures/OEMs. Examples: "nest_cam_iq_2017", "comcast_voice_box_2017". */
            deviceModelId?: string;
            /**
             * The Device Platform Service lookup revision. (go/device-model-revision) For 1p devices, and most 3p devices with no custom feature, this should be always 0, which means no lookup
             * needed. For 3p devices with custom assistant feature, this is provided directly by OEM as incremental (e.g. 1, 2, 3, ...)
             */
            deviceModelRevision?: number;
            /** Only valid for ATV. Stores the android DUSI for the corresponding user. More details: go/auto-logout-on-unlink. */
            dusi?: string;
            /** List of errors that happened during the face enrollment process if it failed. See go/face-match-enrollment-error for more info. */
            faceEnrollmentErrors?: string[];
            /** Indicates whether the user's face has been successfully enrolled on this device. See go/face-match-server-design for more info. */
            faceEnrollmentStatus?: string;
            /** Indicates whether the user has enabled Face Match for this device. See go/face-match-server-design for more info on this project. */
            faceMatchEnabled?: boolean;
            /** When true, allow data collection of audio on this device for Federated Learning. */
            flAudioCacheEnabled?: boolean;
            /** When true, allow data collection of frames on this device. */
            flVisualFramesCacheEnabled?: boolean;
            /** Stores GCM info associated with a device. See go/quartz-design-doc for more info. */
            gcmSettings?: AssistantApiSettingsGcmSettings;
            /**
             * Holds the data that should be written to HomeGraph. Note: this field is not persisted in Assistant Settings storage. It is simply used for transporting data when client calls
             * UpdateSettings.
             */
            homeGraphData?: AssistantApiSettingsHomeGraphData;
            /**
             * The home graph ID that can be used to lookup the corresponding entry in HomeGraph. go/home-graph. Note: when this field is empty, it doesn't necessarily mean that the device is not
             * in home graph. It just means that Assistant doesn't know about the mapping.
             */
            homeGraphId?: string;
            /** Indicates whether the device is currently in Hospitality mode. go/hospitality-mode-design. This is moved to a per user setting in assistant settings. ref. go/hospitality-settings-v2 */
            hospitalityModeStatus?: AssistantApiSettingsHospitalityMode;
            /** The level of hotword sensitivity. go/hotword-sensitivity-prd */
            hotwordSensitivity?: string;
            /**
             * HotwordThresholdAdjustmentFactor contains threshold_adjustment_factor, and it's validity. TAF is a measure of adjustment applied to the hotword threshold as a result of go/autotune.
             * Currently, this is updated from query_settings_frame, but if we move to updating it from the client, this could also contain TAFs as a result of Hotword Sensitivity, in addition to
             * Autotune.
             */
            hotwordThresholdAdjustmentFactor?: AssistantApiSettingsHotwordThresholdAdjustmentFactor;
            /** The human-friendly name of the cast device, e.g., my living room tv. This field is set by the user and already localized. */
            humanFriendlyName?: string;
            /** Internal version of the DeviceSettings for measurement of the DeviceSettings mutation race conditions. See go/consistent-assistant-settings-update. */
            internalVersion?: AssistantApiSettingsInternalVersion;
            /** Indicates whether the device is also managed through HA cloud sync. go/ha-dev-guide */
            isCloudSyncDevice?: boolean;
            /** When true, the user has explicitly allowed audio and visual data collection on this device */
            isDeviceActivationCacheEnabled?: boolean;
            /** Specifies if kids-mode is enabled for the device. See go/aff-parentalsupervision-dd. */
            kidsMode?: AssistantApiSettingsKidsMode;
            /**
             * Device's latest registration timestamp provided by Cast side. This field is not necessarily up to date. The update frequency is defined in last_registration_update_frequency_in_days
             * field of AssistantConfig in java/com/google/chrome/dongle/common/proto/home_assistant_config.proto. go/cast-last-registration-time
             */
            lastCastRegistrationTimestamp?: string;
            /** Coarsened hourly timestamp of when the device was last used. */
            lastUsedCoarseTimestamp?: string;
            /** Stores pairing between different devices. See go/quartz-design-doc for more info. */
            linkedDeviceId?: AssistantApiCoreTypesDeviceId[];
            /** Please do NOT use this field without prior approval from PWG. Users who have signed in onto this device, go/linked-users-in-pkg. */
            linkedUsers?: AssistantApiSettingsLinkedUser[];
            /** The locale for the device: language + region, i.e., en-US, ja-JP. */
            locale?: string;
            /** Coordinate information of the device location. */
            locationCoordinates?: AssistantApiCoreTypesLocationCoordinates;
            /**
             * The feature proto of the location of the device. Note: client does not need to populate this. It will be auto-populated based on "address" field on server side. Currently, only
             * "bound" and "type" are persisted, since the entire FeatureProto is too big.
             */
            locationFeature?: GeostoreFeatureProto;
            /** See go/marketplace-disclosure for more info. */
            marketplaceDisclosure?: AssistantApiSettingsMarketplaceDisclosure;
            masqueradeMode?: AssistantApiSettingsMasqueradeMode;
            /** Information about how to send the user a notification. This won't be populated for fb-conv users (allo group chat users). */
            notificationProfile?: AssistantApiSettingsNotificationProfile;
            /**
             * OAuth client id for the device. This field is available for Assistant SDK devices. It is written when the device is registered to the user
             * (AssistantSettingsUiService.LinkAssistantDeviceUi). When user revokes grant on the Assistant device, Assistant Devices Platform Service will receive Pubsub notification with OAuth
             * client id for the revoked device, and we will compare that with this stored id to identity device to remove.
             */
            oauthClientId?: string;
            /** Device specific app related settings. */
            onDeviceAppSettings?: AssistantApiSettingsOnDeviceAppSettings;
            /** Specifies if device logs and crashes can be captured during SendFeedback */
            optInStatus?: AssistantApiSettingsDeviceLogsOptIn;
            /** DEPRECATED: Use DeviceCapabilities.OutputRestrictions.personal_data instead. Whether the user has enabled payments for this device. */
            paymentsEnabled?: boolean;
            /** Metadata about how personalization settings were configured. */
            personalizationMetadata?: AssistantApiSettingsPersonalizationMetadata;
            /** Specify whether polite mode is enabled for this device. See go/pretty-please-dd. */
            politeMode?: AssistantApiSettingsPoliteMode;
            postalCode?: string;
            /** Trusted device preferences Assistant reauth. go/assistant-reauth-verify-skip. */
            reauthTrustedDeviceSettings?: AssistantApiSettingsReauthTrustedDeviceSettings;
            /**
             * A human-readable shortened address. This is usually the street address. Note: client does not need to populate this. It will be auto-populated based on "address" field on server
             * side. Developers can use this field to avoid reading out the full address everytime.
             */
            shortenedAddress?: string;
            /** Indicates whether the user has enabled speaker-id for this device. See go/google-assistant-multi-user for more info on this project. */
            speakerIdEnabled?: boolean;
            /** Settings related to TTS output. */
            speechOutputSettings?: AssistantApiSettingsSpeechOutputSettings;
            /** Speech/hotword detection related settings. */
            speechSettings?: AssistantApiSettingsSpeechSettings;
            /** Restrictions on how and when certain users can use a device. See go/home-ft-prd. */
            supervisionSettings?: AssistantApiSettingsDeviceSupervisionSettings;
            /** The type of assistant surface. Only use this field when device type is ASSISTANT. */
            surfaceType?: AssistantApiCoreTypesSurfaceType;
            /** Presence indicates a tethered wearable. go/wearable-device-ids. */
            tetheredInfo?: AssistantApiSettingsTetheredInfo;
            /**
             * Device time zone. It's mainly used for a one-time notification for new users when they just bought and activated their devices. They may not have used Search or Assistant before, so
             * their timezone info may not available elsewhere when we want to send a notification. This should be used as a fallback only when other timezone sources such as
             * assistant_settings:user_attribute#inferred_user_timezone are not available. Also, when both |time_zone| and |location| are set, the |location| should be preferred to derive the most
             * up to date timezone. This info directly comes from the device through early device setting recording mechanism. See more details at go/early-device-setting-recording.
             */
            timeZone?: AssistantApiTimeZone;
            /**
             * Local network ID of the device (truncated to obfuscate devices and households globally). This is a temporary signal to determine proximity of Assistant devices in a house (HGS
             * place).
             */
            truncatedLocalNetworkId?: string;
            /** DEPRECATED: Use speech_settings instead. Indicates whether the user has enabled trusted voice for this device. See go/hotword-settings-on-cloud for more info on this project. */
            trustedVoiceEnabled?: boolean;
            /** The type of the device. Note: this should only be used for grouping devices for UI presentation purpose. Use |capabilities| to decide what the device can do. */
            type?: string;
            /**
             * Indicates whether to play verbose tts for Elementary on chirp. See: go/opa-cast-a11y-impl-design fore more info on this project. Note: this should probably be in SpeechOutputSetting
             * below.
             */
            verboseTtsForChromecastEnabled?: boolean;
            /** Coarsened hourly timestamp of when the user was last verified by VoiceMatch on this device. This is used for enforcing VoiceMatch model TTL. go/voicematch-pdd-ttl */
            vmLastUsedCoarseTimestamp?: string;
            /** Indicates whether the user's voice has been successfully enrolled on this device. */
            voiceEnrollmentStatus?: string;
            /** A boolean indicates whether voice input (mic-button, hotword, etc) is enabled. */
            voiceInputEnabled?: boolean;
        }
        interface AssistantApiSettingsDeviceSettingsCrossSurfaceAvailability {
            /** Last known locale of the client. */
            lastKnownClientLocale?: string;
            /** This is the timestamp when the AssistantRequestParams (in ASSISTANT_SNAPSHOT corpus) were last written for this device. */
            lastParamsWriteTimestamp?: string;
        }
        interface AssistantApiSettingsDeviceSupervisionSettings {
            /** Specification of times that a device shouldn't respond to certain users. See go/home-ft-prd. */
            downtimeSettings?: AssistantApiSettingsDeviceDowntimeSettings;
            /** Restrictions on features that certain users can access on a device. See go/home-ft-prd. */
            featureFilters?: AssistantApiSettingsDeviceFeatureFilters;
        }
        interface AssistantApiSettingsDowntimePeriod {
            /** True if downtime should be enabled during this period. */
            enabled?: boolean;
            /**
             * Time of day that this downtime period should end. Required. If end_time > start_time, end_time is relative to start_day. Otherwise, end_time is relative to the day after start_day.
             * For example, start_day: MONDAY, start_time: 9 p.m., end_time: 6 a.m. means that the downtime period starts at 9 p.m. on Monday and ends at 6 a.m. on Tuesday.
             */
            endTime?: GoogleTypeTimeOfDay;
            /** The day of the week when this downtime period starts. Required. */
            startDay?: string;
            /** Time of day that this downtime period should start. Required. */
            startTime?: GoogleTypeTimeOfDay;
        }
        interface AssistantApiSettingsDowntimeSchedule {
            /** True if this downtime schedule should be enabled. */
            enabled?: boolean;
            /**
             * Downtime entries for the days of the week, in no particular order. There can be at most one period defined for each day of the week. Days of the week with no explicit period defined
             * are treated as disabled, so the device is available all day (modulo an end time that may spill over from the previous day).
             */
            periods?: AssistantApiSettingsDowntimePeriod[];
        }
        interface AssistantApiSettingsDuoCallDeviceSettings {
            /** True if Duo Knock Kncok feature is enabled on the device. */
            allowKnockKnock?: boolean;
            /**
             * Boolean indicating if user has explicitly marked this device to be linked or not. This bit is used in case where unexpected errors occur and we have to check for account/device
             * status and mark the device linked after verification.
             */
            shouldBeLinked?: boolean;
            /** The call state of the device (i.e. whether an Duo call account has been setup on the device). */
            state?: string;
            /**
             * Client device settings: settings which are populated by client to give to duocore. TalkBack is an accessibility service that helps blind and vision-impaired users interact with
             * their devices. Indicates whether talkback is enabled for the device. Note: this is per device settings currently filled by client for all users.
             */
            talkbackEnabled?: boolean;
        }
        interface AssistantApiSettingsFeatureFilters {
            communicationsFilter?: AssistantApiSettingsCommunicationsFilter;
            musicFilter?: AssistantApiSettingsMusicFilter;
            newsFilter?: AssistantApiSettingsNewsFilter;
            podcastFilter?: AssistantApiSettingsPodcastFilter;
            searchFilter?: AssistantApiSettingsSearchFilter;
            thirdPartyAppsFilter?: AssistantApiSettingsThirdPartyAppsFilter;
            videoFilter?: AssistantApiSettingsVideoFilter;
            webviewFilter?: AssistantApiSettingsWebviewFilter;
        }
        interface AssistantApiSettingsGcmSettings {
            gcmId?: string;
            gcmPackage?: string;
        }
        interface AssistantApiSettingsHomeGraphData {
            /** Agent ID, aka project ID. Used as the AgentDeviceId.agent_id of device when calling Home Graph Service. */
            agentId?: string;
            /** See go/ha-dev-guide and HomeGraphItem.attribute in //assistant/verticals/homeautomation/proto/home_graph.proto */
            attributes?: { [P in string]: any };
            /** Device ID, used as AgentDeviceId.device_id of device when calling Home Graph Service. */
            deviceId?: string;
            /** HGS device type. See java/com/google/home/graph/service/config/protoconf.pi for the exhaustive list of type strings. */
            deviceType?: string;
            /**
             * Whether device data should be written to Home Graph via Assistant device_settings. Assistant SDK and Google Home write their devices into Home Graph through
             * AssistantSettingsService, while Home Automation Partner devices (e.g. SmartThings, Philips Hue, Nest, TP-Link, etc.) don't need to be written to Home Graph through
             * AssistantSettingsService. This field decides whether AssistantSettingsService writes devices to Home Graph or not.
             */
            shouldWriteToHomeGraph?: boolean;
            /** Supported traits of the device. See java/com/google/home/graph/service/config/protoconf.pi for the exhaustive list of trait-strings. */
            supportedTraits?: string[];
            /** Whether the device supports direct response. See HomeGraphItem.supports_direct_response in //assistant/verticals/homeautomation/proto/home_graph.proto */
            supportsDirectResponse?: boolean;
        }
        interface AssistantApiSettingsHospitalityCardSettings {
            /** Config for Hospitality UI modules. */
            cardConfig?: AssistantApiSettingsHospitalityCardSettingsCardConfig[];
            /** Toggle media tap gesture tutorial card. */
            showMediaTapGestureTutorial?: boolean;
            /** Toggle photo swipe gesture tutorial card. */
            showPhotoSwipeGestureTutorial?: boolean;
            /** Config for YouTube video cards. */
            youtubeCardConfig?: AssistantApiSettingsHospitalityCardSettingsYouTubeCardConfig[];
        }
        interface AssistantApiSettingsHospitalityCardSettingsCardConfig {
            /** Whether the UI module requires user action. If true, the UI module can peek on to the top of Ambient. See SmartDisplayModuleState::ACTIVE_ACTION_REQUIRED. */
            activeActionRequired?: boolean;
            /** Whether the UI module is dismissable. */
            dismissable?: boolean;
            /** The time that the module is effective and visible to the user. If not set, the module is effective immediately. */
            effectiveTime?: AssistantApiTimestamp;
            /** The time that the module is expired and invisible to the user. If not set, the module never expires. */
            expiryTime?: AssistantApiTimestamp;
            /** The image URL for the UI module. */
            imageUrl?: string;
            /** Module ID. */
            moduleId?: string;
            /** Payload query to the partner AoG action when user responds to UI Module, e.g. “Tell the hotel how my stay is going”. */
            payloadQuery?: string;
            /** Title of the message to be shown to user at the top of the UI Module. */
            title?: string;
        }
        interface AssistantApiSettingsHospitalityCardSettingsYouTubeCardConfig {
            /** URL of image to go on card. The URL must be a public link accessible from ZeroState. */
            imageUrl?: string;
            /**
             * ID of YouTube playlist to play on card tap. A playlist is used instead of a single video id to avoid autoplaying related videos. The playlist and the videos it contains must be
             * public or unlisted to be accessible from ZeroState.
             */
            playlistId?: string;
            /** Text on card (i.e., video title). */
            text?: string;
        }
        interface AssistantApiSettingsHospitalityMode {
            /** List of AOG app context ids that are linked to this device. These apps will have access to the structure information for the device. */
            aogContextId?: string[];
            /** Invocation phrase for hotel's AoG action. Used for ZS promotion card and "talk to my hotel" rewrites. Setting this to an empty value will mark it unset. */
            aogInvocationPhrase?: string;
            branding?: AssistantApiSettingsHospitalityModeBranding;
            cardSettings?: AssistantApiSettingsHospitalityCardSettings;
            /** The time when we received a request to reset the device. */
            deviceClearRequest?: AssistantApiTimestamp;
            /** Should the dialog have a shorter ttl. See go/ipp-consumer-prd#heading=h.ibu9b1ysdl4t and go/interpreter-device-clear#bookmark=id.hw8ey1bzjadn for context. */
            dialogTtlOverrideMicros?: string;
            /** Identifier for the enterprise which owns the device. Setting this to an empty value will mark it unset. */
            enterpriseId?: string;
            /** Indicates whether this device is in the hospitality mode. */
            hospitalityModeEnabled?: boolean;
            /**
             * Last time the device was cleared and placed in hospitality mode. Will be set when the switch is toggled on and reset when a guest checks out. On the device this triggers removing
             * alarms, timers, etc.
             */
            lastDeviceClear?: AssistantApiTimestamp;
            /** Indicates when hospitality settings were last updated. */
            lastModifiedTimestamp?: AssistantApiTimestamp;
            /** Last time the welcome message was played for the guest. If last_welcomed < welcome_request, the message should be replayed and this time set. */
            lastWelcomed?: AssistantApiTimestamp;
            /** Indicates whether or not the device must be reset manually (by voice or touch), as opposed to being automatically reset. go/hospitality-manual-reset */
            manualResetRequired?: boolean;
            /**
             * In order promoted languages for interpreter devices. This represents languages by BCP-47 language strings, such as "en", "en-US", "fr", "fr-CA", "sr-Latn", "zh-Hans-CN",
             * "zh-Hant-HK",etc.
             */
            promotedLanguages?: string[];
            type?: string;
            /** Whether we allow users to initiate clearing the device verbally. We generally allow this for private devices and not for public ones. */
            verbalResetSupported?: boolean;
            /** The time when we received a request to welcome the user. */
            welcomeRequest?: AssistantApiTimestamp;
        }
        interface AssistantApiSettingsHospitalityModeBranding {
            /** Brand display in the UI */
            displayName?: string;
            /**
             * Brand display in the UI for languages that the enterprise has a localized name that is different from its global branding name. For example, Hilton is 'ヒルトン' in Japanese and '希爾頓'
             * in Chinese. The keys are hospitality supported display locales, e.g. en, ja-JP, etc, defined in experiment parameter Hospitality__hospitality_display_supported_locales.
             */
            displayNameForLanguage?: { [P in string]: string };
            largeLogoUrl?: string;
            smallLogoUrl?: string;
        }
        interface AssistantApiSettingsHotwordThresholdAdjustmentFactor {
            /** Currently, is_valid is set to false whenever the TAF is not an Autotune aware value. This includes hotword sensitivity users, or devices not eligible for autotune. */
            isValid?: boolean;
            value?: number;
        }
        interface AssistantApiSettingsInternalAncillaryDeviceId {
            /** Contains device ids known to devices. eg. For ATV, it contains client_instance_id and cast_id. */
            deviceId?: AssistantApiCoreTypesDeviceId;
        }
        interface AssistantApiSettingsInternalVersion {
            /** Contains the timestamp when this version was generated. */
            generationTime?: string;
            /** Integer value of the version, it is a monotonically increasing number and starts at 0. On every update it is incremented by 1. */
            id?: string;
        }
        interface AssistantApiSettingsKidsMode {
            kidsModeEnabled?: boolean;
            /** Identifier of the account currently specified to be used with kids mode. */
            obfuscatedGaiaId?: string;
        }
        interface AssistantApiSettingsLabeledDowntimeSchedule {
            /** User-provided name for this schedule. */
            displayName?: string;
            schedule?: AssistantApiSettingsDowntimeSchedule;
        }
        interface AssistantApiSettingsLinkedUser {
            /** Time of linking of the device with the user provided by Cast. */
            castLinkingTime?: string;
            /** Primary email address of the user. */
            email?: string;
            gaiaId?: string;
            /** Supports features which depend on profile name, when no matching contact is found. */
            names?: AppsPeopleOzExternalMergedpeopleapiName[];
        }
        interface AssistantApiSettingsMarketplaceDisclosure {
            /** True if the user has confirmed the marketplace disclosure. */
            confirmed?: boolean;
            /** The time user confirmed the marketplace disclosure. */
            timestampMs?: string;
        }
        interface AssistantApiSettingsMasqueradeMode {
            lastEnterGuestModeTimestamp?: AssistantApiTimestamp;
            lastExitGuestModeTimestamp?: AssistantApiTimestamp;
            masqueradeModeEnabled?: boolean;
        }
        interface AssistantApiSettingsMusicFilter {
            /** Providers available at the time user updated settings. */
            availableProviders?: string[];
            /** Represents the state for the music provider filter. */
            providerFilterState?: string;
            state?: string;
            /** Contains the list of whitelisted music providers. */
            whitelistedProviders?: string[];
        }
        interface AssistantApiSettingsNewsFilter {
            state?: string;
        }
        interface AssistantApiSettingsNotificationProfile {
            /** Each device can have only one type of notification profile. */
            alloNotificationProfile?: AssistantApiSettingsNotificationProfileAlloNotificationProfile;
        }
        interface AssistantApiSettingsNotificationProfileAlloNotificationProfile {
            /** The send token of the conversation with the user. */
            botSendToken?: ChatBotPlatformBotSendToken;
            /** The fireball id of this user. */
            id?: ChatBotPlatformFireballId;
        }
        interface AssistantApiSettingsOnDeviceAppSettings {
            /** On device carrier call related settings. */
            carrierCallDeviceSettings?: AssistantApiSettingsCarrierCallDeviceSettings;
            /** On device duo call related settings. */
            duoCallDeviceSettings?: AssistantApiSettingsDuoCallDeviceSettings;
        }
        interface AssistantApiSettingsPersonalizationMetadata {
            faceMatch?: string;
            personalResults?: string;
            voiceMatch?: string;
        }
        interface AssistantApiSettingsPodcastFilter {
            state?: string;
        }
        interface AssistantApiSettingsPoliteMode {
            politeModeEnabled?: boolean;
        }
        interface AssistantApiSettingsReauthTrustedDeviceSettings {
            /** Mapping from integrator client id to device's trust settings. Id from assistant/agent_platform/transactions/reauth/reauth_client.proto. */
            trustSettingsForClient?: { [P in string]: AssistantApiSettingsReauthTrustedDeviceSettingsTrustSettings };
        }
        interface AssistantApiSettingsReauthTrustedDeviceSettingsTrustSettings {
            /** If true, don't ask user to trust this device again. */
            neverAskAgain?: boolean;
            /**
             * DEPRECATED: Use never_ask_again instead. Expiration timestamp of "never ask again" status. If this field is set and is later than current timestamp, we should NOT ask the user
             * whether they'd like to trust this device.
             */
            neverAskExpirationTimestamp?: string;
            /** Expiration timestamp of "trusted" status. If this field is set and is later than current timestamp, we can consider this device to be trusted. */
            trustDeviceExpirationTimestamp?: string;
        }
        interface AssistantApiSettingsSearchFilter {
            state?: string;
        }
        interface AssistantApiSettingsSpeechOutputSettings {
            speechOutput?: string;
        }
        interface AssistantApiSettingsSpeechSettings {
            /** Indicates whether Continued Conversation is enabled for this device. */
            continuedConversationEnabled?: boolean;
            /** Stores the device model type e.g Pixel. */
            deviceModelType?: string;
            /** Whether the device has DSP chip to enable always on hotword detection. */
            dspAvailable?: boolean;
            /** Whether hotword has been enabled by the user during navigation. */
            hotwordInNavigationEnabled?: string;
            /** Stores hotword setting status for the locales which don't support voice match. */
            hotwordSetting?: string;
            /** Whether pin/pattern lockscreen has been enabled by the user. */
            lockscreenEnabled?: boolean;
            /** Stores if Assistant is available for the user's device/locale, where Enabled means it is available and disabled means it is not. */
            opaEligibilityState?: string;
            /** Stores if Assistant is available for the user's device/locale. Deprecated as bools do not give accurate true/false ratios due to old clients reporting the default value. */
            opaEligible?: boolean;
            /** Stores the Android SDK version. This comes from android.os.Build.VERSION.SDK_INT. */
            sdkVersion?: number;
            /** Whether speaker ID model is present for the user. */
            speakerIdModelPresent?: boolean;
            /** Indicates whether the user has enabled speaker-id (fromAnyScreen/alwaysOn) for this device. Deprecated - use voice_match_setting instead */
            speakerIdRecognitionEnabled?: boolean;
            /** Indicates whether the user has enabled trusted voice for this device. */
            trustedVoiceEnabled?: boolean;
            /** A bool indicating whether device supports unlocking device with hotword. */
            unlockWithHotwordAvailable?: boolean;
            /** Stores if user was migrated from undecided to declined as apart of Mariko project. Used for potential growth targeting. */
            userMigratedToDeclined?: boolean;
            /** Stores the hotword/voice match setting status for the locales which support voice match. */
            voiceMatchSetting?: string;
        }
        interface AssistantApiSettingsTetheredInfo {
            /** The host this wearable is tethered to (e.g. phone). When host is AGSA then this is agsa_client_instance_id. When host is IOPA then this is opa_ios_device_id. */
            primaryHostDeviceId?: string;
        }
        interface AssistantApiSettingsThirdPartyAppsFilter {
            state?: string;
        }
        interface AssistantApiSettingsVideoFilter {
            /** State that indicates whether autoplay is enabled for youtube videos. */
            autoplayToggleState?: string;
            /** Providers available at the time user updated settings. */
            availableProviders?: string[];
            /** Represents the state for the video provider filter. */
            providerFilterState?: string;
            state?: string;
            /** Contains the list of whitelisted video providers. */
            whitelistedProviders?: string[];
        }
        interface AssistantApiSettingsWebviewFilter {
            /** Indicates if user has consented Jasper warning message. */
            jasperWebviewConsent?: boolean;
            state?: string;
        }
        interface AssistantApiSignInMethod {
            method?: string;
            /** Make Google sign-in mandatory for using Google Assistant on the device. */
            signInRequired?: boolean;
        }
        interface AssistantApiSodaCapabilities {
            /** Whether the device supports different levels of hotword sensitivity. go/hotword-sensitivity-prd */
            supportsHotwordSensitivity?: boolean;
            /** Whether Simple Stop (go/simple-stop) is enabled on the device. Simple stop allows users to stop firing alarms and timers by just saying "stop" without first saying the hotword. */
            supportsSimpleStop?: boolean;
            /**
             * Whether the device supports speaker-id (speaker identification based on hotword and/or spoken query - go/speaker-id). Note: there are existing devices that support speaker-id but
             * does not have this capability set. Not having this field populated doesn't necessarily mean the device doesn't support speaker-id.
             */
            supportsSpeakerId?: boolean;
            /** Whether the device supports WarmWords (go/warm-words-framework). */
            supportsWarmWords?: boolean;
        }
        interface AssistantApiSoftwareCapabilities {
            /**
             * IMPORTANT: Only one of AppCapabilities and AppCapabilitiesDelta should be in the SoftwareCapabilities. In the edge case if the client sends up both AppCapabilities and
             * AppCapabilitiesDelta, AppCapabilitiesDelta is ignored. Complete list of app capabilities.
             */
            appCapabilities?: AssistantApiAppCapabilities[];
            /** Incremental update for app capabilities. */
            appCapabilitiesDelta?: AssistantApiAppCapabilitiesDelta[];
            /** App integrations settings for each packge name. */
            appIntegrationsSettings?: { [P in string]: AssistantApiAppIntegrationsSettings };
            /** Capabilities related to Assistant on Auto surfaces. */
            carAssistantCapabilities?: AssistantApiCarAssistantCapabilities;
            /** Capabilities related to clock functionality, like alarms, timers, etc. */
            clockCapabilities?: AssistantApiClockCapabilities;
            /** A top-level version of Conversation protocol where the versions are explicitly defined at go/conversation-versions. */
            conversationVersion?: AssistantApiSupportedConversationVersion;
            /** For torus x-device execution support */
            crossDeviceExecutionCapabilities?: AssistantApiCrossDeviceExecutionCapability;
            gacsCapabilities?: AssistantApiGacsCapabilities;
            gcmCapabilities?: AssistantApiGcmCapabilities;
            /** Capabilities related to live TV channels. */
            liveTvChannelCapabilities?: AssistantApiLiveTvChannelCapabilities;
            /** List of actions OEM supports. This includes built-in actions and custom actions. */
            oemCapabilities?: AssistantApiOemCapabilities;
            /** on-device Assistant capabilities */
            onDeviceAssistantCapabilities?: AssistantApiOnDeviceAssistantCapabilities;
            /** Capability bits for on-device Smart Home. go/framework-for-local-semex */
            onDeviceSmartHomeCapabilities?: AssistantApiOnDeviceSmartHomeCapabilities;
            /** Reflects the storage capabilities on the device. */
            onDeviceStorageCapabilities?: AssistantApiOnDeviceStorageCapabilities;
            /** The operating system of the device. */
            operatingSystem?: string;
            /** An ordered list containing the live tv providers available in the client. The order of the providers reflects the ranking in the client and will be respected by server as well. */
            orderedLiveTvProviders?: AssistantApiLiveTvProvider[];
            /** The Soli capabilities on Elaine. go/dingo-dc-software */
            selinaCapabilities?: AssistantApiSelinaCapabilites;
            settingsAppCapabilities?: AssistantApiSettingsAppCapabilities;
            supportedClientOp?: AssistantApiSupportedClientOp[];
            supportedFeatures?: AssistantApiSupportedFeatures;
            supportedMsgVersion?: AssistantApiSupportedProtocolVersion;
            supportedProviderTypes?: AssistantApiSupportedProviderTypes;
            surfaceProperties?: AssistantApiSurfaceProperties;
        }
        interface AssistantApiSpeechCapabilities {
            /** A bool indicating whether device supports dsp based hotword detection. */
            dspAvailable?: boolean;
            /** A bool indicating whether device supports unlocking device with hotword. */
            unlockWithHotwordAvailable?: boolean;
        }
        interface AssistantApiSuggestionsSupport {
            /** Whether client supports user impersonation on suggestion chip click. go/suggestion-click-impersonation */
            clickImpersonationSupported?: boolean;
            /** Whether client supports suggestion chips with colored background/border. Deprecated in favor of go/color-token-suggestion-chip. */
            coloredChipBackgroundBorderSupported?: boolean;
            /** Whether client supports suggestion chips with colored text. See design doc: http://go/opa-suggestions-ux-eng-design. Deprecated in favor of go/color-token-suggestion-chip. */
            coloredChipTextSupported?: boolean;
            /** Whether client supports suggestions debug data to be displayed. */
            debugDataSupported?: boolean;
            /**
             * Whether DRL history chip is supported. Related bug: http://b/241837879, http://b/171854732 Design doc: http://go/panthera-history-chip-dd DRL history chip was originally rolled out
             * to Panthera in http://google3/googledata/experiments/mobile/agsa/studies/agsa_nga/opa_panthera_one_input_ui_launch.gcl?l=55&rcl=384682900. We plan to roll it out to NGA and TNG.
             * drl_history_chip_supported bit specifies whether the client support (and should have) DRL history chip.
             */
            drlHistoryChipSupported?: boolean;
            /** Whether client supports escape hatches aka post execution suggestions go/nga-escape-hatch-prd */
            escapeHatchSupported?: string;
            /** Whether the client can rewrite suggestion query text into executed text, if the latter is present. If this feature is disabled, the rewrite happens in Assistant Server. */
            executedTextSupported?: boolean;
            /** Whether the client supports passing back `execution_context` from |assistant.api.client_op.SuggestionProcessingParams| when the suggestion is clicked or spoken. */
            executionContextSupported?: boolean;
            /** Whether the client supports features in |SuggestionFeatureSpecificAction|. */
            featureSpecificActionSupport?: AssistantApiFeatureSpecificActionSupport;
            /**
             * Whether the client supports handling App Actions' notification when the suggestion is clicked. This will allow the server to populate the `app_actions_notification_data` extension
             * field from |SuggestionFeatureSpecificAction| proto message.
             */
            featureSpecificAppActionsNotificationSupported?: boolean;
            /**
             * Whether the rule_id field in the execution_context is supported. This is a temporary workaround to be able to identify clicks on Person entity suggestions on Sabrina and is expected
             * to be eventually deprecated. TODO(b/185517153) : Deprecate (but do not delete) once click tracking is correctly sent up from the Katniss client.
             */
            ruleIdInExecutionContextSupported?: boolean;
            /**
             * Whether the client can show executed_text after the click on the suggestion chip. Must be set to false on TNG. TNG disregards |SuggestionProcessingParams.show_executed_text| field
             * and always treats it as if |show_executed_text=true|.
             */
            showExecutedTextSupported?: boolean;
            /** Whether the client can show chip as (text | translation). go/lang-partner-doc */
            showTranslationSupported?: boolean;
            /** A list of suggestions display targets supported by this client. If unset only DEFAULT SuggestionDisplayTarget is supported. */
            supportedDisplayTargets?: AssistantApiSuggestionsSupportDisplayTargetSupport[];
            /** Whether client supports widget suggestion chip to be displayed. */
            widgetDataSupported?: boolean;
        }
        interface AssistantApiSuggestionsSupportDisplayTargetSupport {
            /** Whether the client can rewrite suggestion query text into executed text, if the latter is present for the display target. */
            executedTextSupported?: boolean;
            /** Whether PresentationParams.header_text is supported for the display target. */
            headerTextSupported?: boolean;
            /** Whether Suggestion.repress_impression is supported. If not repressed suggestions are not returned. */
            repressImpressionSupported?: boolean;
            /** Display target that is supported. */
            target?: string;
        }
        interface AssistantApiSunriseFeaturesSupport {
            /** If true, the device can slowly brighten the screen and simulate sunrise experience. Alarms with sunrise field enabled can be set on this device. */
            sunriseSimulationSupported?: boolean;
        }
        interface AssistantApiSupportedClientOp {
            /** This should be the same as the name of the SemanticClientOp that is supported. */
            clientOpName?: string;
            /** The properties associated with the ClientOp. This proto should be associated with the client_op_name. */
            clientOpProperties?: AssistantApiProtobuf;
            supportedExecution?: AssistantApiSupportedClientOpSupportedExecution;
            /**
             * A version of 0 is the equivalent to not having support for that client_op type. Note that a client_op is also unsupported if it is not included at all in the list of supported
             * client_ops.
             */
            version?: number;
        }
        interface AssistantApiSupportedClientOpSupportedExecution {
            /**
             * ClientOp execution supports special rendering behavior while the user is in the middle of expressing their query. This behavior includes: 1) New partial output always over-writes
             * prior partial output. 2) Canceling the interaction removes partial fulfilment from any user visible interaction history. If this is true, whether to apply the special rendering
             * behavior will be determined by PartialFulfillmentRenderingParams. More details can be found at go/ma-natcon-pf-api.
             */
            supportsPartialFulfillment?: boolean;
            /**
             * Client can support synchronous execution of the client op. For tts.OUTPUT client op it means that client would honor |synchronous_playback_args| argument. Please see more at
             * go/synchronous-sounds-design.
             */
            supportsSynchronousExecution?: boolean;
        }
        interface AssistantApiSupportedConversationVersion {
            /** Whether conversation protocol is supported explicitly. If true, SingleDeviceCapabilityChecker::SupportsConversationProtocol will always return true. */
            supportsConversationProtocol?: boolean;
            /** The supported version number. */
            version?: number;
        }
        interface AssistantApiSupportedFeatures {
            /** Whether the client supports the alternative message notification sources on AAE, in which case notification-related operations can access it. */
            aaeNotificationSourceSupported?: boolean;
            /** In what way is assistant continued presence supported. (go/opa-acp-prd) */
            acpSupport?: AssistantApiAssistantContinuedPresenceSupport;
            actionV2SupportedFeatures?: AssistantApiActionV2SupportedFeatures;
            /** Whether the client supports AlarmTimerManager API (go/alarm-timer-manager-api). */
            alarmTimerManagerApiSupported?: boolean;
            /** The client information for app control support. More details in: go/acaia. */
            appControlSupport?: AssistantApiAppControlSupport;
            /**
             * Whether the client supports the assistant explore section. This field will be active only when the Explore section is available to the user. This means that the user is (a)
             * signed-in, (b) a IOPA / AGSA user, and (c) in a locale where explore is available.
             */
            assistantExploreSupported?: boolean;
            /** Whether Assistant for Kids (a.k.a. Designed for Family) features are supported. */
            assistantForKidsSupported?: boolean;
            /**
             * Whether communications flows for the client can bypass the DI/DC check. The client will enforce some other equivalent permission as necessary concerning access to device contacts
             * and apps.
             */
            bypassDiDcCheckForComms?: boolean;
            /** Whether or not Assistant should enforce the dismissal of communication notifications associated with messages. */
            bypassMsgNotificationDismissal?: boolean;
            /** Whether the client supports 1m providers (go/1m-partner-expansion). */
            client1mProvidersSupported?: boolean;
            /** Whether the client can batch client op results before sending them to the server. */
            clientOpResultBatchingSupported?: boolean;
            /** Whether the client supports cross-device broadcast (i.e. on Torus). */
            crossDeviceBroadcastSupported?: boolean;
            /** The version of cross device broadcast (ie; broadcast on torus) which the client supports. */
            crossDeviceBroadcastVersion?: string;
            /** Whether the client supports csat visual overlay. (go/sd-od-csat) */
            csatVisualOverlaySupported?: boolean;
            /** The features set which duo client on the device supports. This should be serialized from proto {@code duo_client_api.DuoClientApiFeatures}. */
            duoClientApiFeatures?: string;
            /** Whether the client supports Duo group calling. */
            duoGroupCallingSupported?: boolean;
            /** Information about what support this device has for fitness. */
            fitnessFeatureSupport?: AssistantApiFitnessFeatureSupport;
            /**
             * Fluid Actions features supported by the client. If this field is not set in the incoming request, it could mean that the client does not support Fluid Actions. Alternatively, it
             * could mean that the client supports Fluid Actions, but syncs state with server using the old protocol, namely ConversationStateParams. When b/140733618 is resolved, Surface
             * Adaptation Layer will add this field for old clients that support Fluid Actions framework.
             */
            fluidActionsSupport?: AssistantApiFluidActionsSupport;
            /** Whether the surface client op performer supports Funtime alarms and timers. go/funtime-engdesign */
            funtimeSupported?: boolean;
            /** Whether account linking via Google Deep Integrations (GDI) is supported. go/opa-gdi-design */
            gdiSupported?: boolean;
            /** Whether the client supports the Gearhead message notification source, in which case notification-related operations can access it. */
            gearheadNotificationSourceSupported?: boolean;
            /** Whether the client has a physical radio installed. */
            hasPhysicalRadio?: boolean;
            /** Whether the client supports confirmation messages in Immersive Canvas actions. Deprecated: use the filed in immersive_canvas_support. */
            immersiveCanvasConfirmationMessageSupported?: boolean;
            immersiveCanvasSupport?: AssistantApiImmersiveCanvasSupport;
            /**
             * Whether the client supports account linking in-dialog (askForSignIn). This is used before this feature is moved to conversation protocol. To support this, the client needs to: -
             * Integrate with Google Deep Integrations. - Have logic to send the result of account linking back to AS.
             */
            inDialogAccountLinkingSupported?: boolean;
            /** Whether paired-phone contact upload is needed for communications queries to work (e.g. on AAE). */
            isPairedPhoneContactUploadNeededForComms?: boolean;
            /** Whether a Bluetooth-paired phone is a core component of communications flows on the client. */
            isPairedPhoneNeededForComms?: boolean;
            /** Which way of launching the keyboard the client supports. */
            launchKeyboardSupported?: string;
            /** Whether the client has Google Lens (Assistant Eyes). */
            lensSupported?: boolean;
            /**
             * Whether the surface supports LiveCards. In cases where the user intent flow cannot be completed within the Assistant, LiveCards are used to take the user to an external app or
             * website. These cards will be pushed to the Google Home app via the PushMessage ClientOp.
             */
            liveCardsSupported?: boolean;
            /** Whether the client supports Assistant dialogs within Maps. This field will be set only when the Maps on the surface supports Assistant dialogs embedded within Maps. go/gsa-gmm. */
            mapsDialogsSupported?: boolean;
            /** Whether the device supports masquerade mode (go/masquerade). */
            masqueradeModeSupported?: boolean;
            /** Information about how client handles media controls (play, pause, skip ...) */
            mediaControlSupport?: AssistantApiMediaControlSupport;
            /** The ability of the client to detect media sessions on the device. */
            mediaSessionDetection?: string;
            /** Whether the client supports joining a Google Meet meeting. */
            meetSupported?: boolean;
            /**
             * Whether the client can render no input response or just ignore it. No input response is returned when client has a no speech input interaction, eg. user tapped mic but didn't say
             * anything.
             */
            noInputResponseSupported?: boolean;
            /**
             * When the entry source is search, whether the client supports rendering a similar response as OPA one does. Entry source is defined at
             * http://cs/symbol:assistant.api.params.DeviceProperties.EntrySource
             */
            opaOnSearchSupported?: boolean;
            /**
             * Whether or not the client supports enabling parental controls. When a device to supports parental controls, it has the software necessary to store the relevant information required
             * for parental controls to work. This information includes a boolean "enabled bit" as well as the obfuscated gaia ID of the kid account selected for use with parental controls.
             * Devices supportings kids mode send this information to S3 via S3ClientInfo in every request. See go/aff-kidsproduct for details.
             */
            parentalControlsSupported?: boolean;
            /**
             * Whether the client supports persistent display. The new feature allows Assistant devices with screen to display a continuously updating permanent display, such as ambient weather,
             * without the need for a user to ask the Assistant. Design doc: go/assistant-persistent-display.
             */
            persistentDisplaySupported?: boolean;
            /** Whether the client supports the privacy-aware lockscreen protocol (go/assistant-lockscreen-spec). */
            privacyAwareLockscreenSupported?: boolean;
            /** Whether the client has remote casting enabled. For ex: we want to disable this for clients like Auto. */
            remoteCloudCastingEnabled?: boolean;
            /** Whether the Assistant Server should generate feedback suggestion chips. */
            serverGeneratedFeedbackChipsEnabled?: boolean;
            /** Whether the client supports SmartHome lock screen logic (i.e. on Tangor). */
            shLockScreenSupported?: boolean;
            /** Which kind of sign in the client supports. */
            signInMethod?: AssistantApiSignInMethod;
            /**
             * Whether the client can monitor sleep. This allows us to show sleep CUJ related information: go/TwilightDesign Use for development only, see the same field in
             * DeviceCapabilities.SoftwareCapabilities.SelinaCapabilities.
             */
            sleepSensingSupported?: boolean;
            /** Whether the client supports smart space cross-device timers. (go/ss-x-device-timer) */
            smartspaceCrossDeviceTimerSupported?: boolean;
            /**
             * Whether or not the client supports gesture detection via soli chips. The reason to prepend the name with soli is to distinguish it from computer vision based methods, e.g. Newman
             * devices.
             */
            soliGestureDetectionSupported?: boolean;
            /** Suggestion chips features, supported by the client. */
            suggestionsSupport?: AssistantApiSuggestionsSupport;
            /**
             * Whether the client supports the sunrise screen brightening feature before the alarm fires. This is used to indicate whether sunrise alarms can be set on the device.
             * http://cs/symbol:assistant.api.core_types.governed.RingtoneTaskMetadata.GentleWakeInfo
             */
            sunriseFeaturesSupport?: AssistantApiSunriseFeaturesSupport;
            /** Whether the client supports faster optimization for tap_to_read feature. */
            tapToReadOptimizationSupported?: boolean;
            /** Whether the device supports the 3p GUI framework, which allows third parties to enter the conversation with the user, showing their logo next to their chat bubbles, etc. go/3p-phone */
            thirdPartyGuiSupported?: boolean;
            /** Transactions features, supported by the client. Transactions feature may includes how Transactions team want to populate additional information from the device to the server. */
            transactionFeaturesSupport?: AssistantApiTransactionFeaturesSupport;
            /** The version of transactions which the client supports. */
            transactionsVersion?: string;
            /**
             * If set, it indicates that the client can open a separate HTML browser/webviewer (full viewer) to display certain visual results. These visual results usually require more memory to
             * render (e.g. high resolution photos). Compared to the regular viewer that display all other Assistant result, the full viewer does not have memory limit. The field is copied from
             * the device model. See http://google3/assistant/devices_platform/proto/device_model_capabilities.proto?l=225&rcl=312576471 Also see go/webassistant-full-card-viewer.
             */
            usesSeparateFullViewer?: boolean;
            /** Whether the client supports viewing of reminder hub page or not. Default is supported. Set to true to disable returning reminder hub page url in reminder responses. */
            viewReminderHubPageNotSupported?: boolean;
            /** Whether the client supports the programmatic warm welcome tutorial. Design doc: go/opal-pww-design. */
            warmWelcomeTutorialSupported?: boolean;
            /** Whether the supports opening a URL in a web browser. For example, we want to disable this for clients like Chirp. */
            webBrowserSupported?: boolean;
            /** Whether or not the client supports WhatsNext in the protocol. */
            whatsNextSupported?: boolean;
            /** Whether the client supports joining a Zoom meeting. */
            zoomSupported?: boolean;
        }
        interface AssistantApiSupportedProtocolVersion {
            messageVersion?: AssistantApiSupportedProtocolVersionMessageVersionPair[];
        }
        interface AssistantApiSupportedProtocolVersionMessageVersionPair {
            /** The full path of a message which should start from the package name. e.g. "assistant.api.core_types.Timer". */
            messageName?: string;
            /** The supported version number. */
            version?: number;
        }
        interface AssistantApiSupportedProviderTypes {
            supportedTypes?: string[];
        }
        interface AssistantApiSurfaceProperties {
            executionCapabilities?: AssistantApiSurfacePropertiesExecutionCapabilities;
            /** If this field is unset, the response format is unknown */
            responseDisplayFormat?: string;
            /** If true, the client supports receiving multiple responses. See go/multiple-response-in-media-use-cases for more details. */
            supportsMultiResponse?: boolean;
        }
        interface AssistantApiSurfacePropertiesExecutionCapabilities {
            /**
             * Completes the preloading ie., sets up the stage for the execution of client ops on the device while the previous conv delta is being executed. Refer to go/preload-convdelta for more
             * information.
             */
            supportsClientOpPreloading?: boolean;
            /**
             * A value of true indicates that the client supports streaming of non-finalized responses by use of ClientExecutionParams.response_stream_id. and
             * ClientExecutionParams.to_be_finalized.
             */
            supportsNonFinalizedResponses?: boolean;
            /** If true, the client supports receiving non-materialized interactions (go/as-streaming-protocol-nm). */
            supportsNonMaterializedInteractions?: boolean;
        }
        interface AssistantApiSystemNotificationRestrictions {
            categoryState?: AssistantApiSystemNotificationRestrictionsNotificationCategoryState[];
            channelState?: AssistantApiSystemNotificationRestrictionsNotificationChannelState[];
            /** Specifies whether the surface is able to display notifications. */
            notificationCapabilities?: string;
        }
        interface AssistantApiSystemNotificationRestrictionsNotificationCategoryState {
            /** Notification channel type. */
            categoryId?: number;
            /** Weather the notifications on this channel are disabled. */
            disabled?: boolean;
            disabledReason?: string;
        }
        interface AssistantApiSystemNotificationRestrictionsNotificationChannelState {
            /** Notification channel type. */
            channelType?: string;
            /** Whether the notifications on this channel are enabled. */
            enabled?: boolean;
        }
        interface AssistantApiThirdPartyActionConfig {
            /** DeviceActionCapability from DeviceModelPackage. */
            deviceActionCapability?: AssistantDevicesPlatformProtoDeviceActionCapability;
            /** List of Action project capabilities. */
            projectConfigs?: AssistantApiThirdPartyActionConfigProjectConfig[];
        }
        interface AssistantApiThirdPartyActionConfigProjectConfig {
            /** Google cloud project id for which the Action Package or Device Model is registered. */
            projectId?: string;
        }
        interface AssistantApiThirdPartyCapabilities {
            /** Restrictions for the device to share any data with third party apps. See details in go/atv-dsc. */
            dataSharingRestrictions?: string;
        }
        interface AssistantApiTimeOfDay {
            /** The hour, in 0...23. */
            hour?: number;
            /** The minute, in 0...59. */
            minute?: number;
            /** The fraction of seconds in nanoseconds, in 0..999999999. */
            nanosecond?: number;
            /** The second, in 0...59. Leap seconds are not supported. */
            second?: number;
        }
        interface AssistantApiTimestamp {
            /** Non-negative fractions of a second at nanosecond resolution. */
            nanos?: number;
            /** Seconds of UTC time since the Unix epoch. */
            seconds?: string;
        }
        interface AssistantApiTimeZone {
            /** Time zone in IANA format, e.g. America/Los_Angeles for USA Pacific Time. */
            ianaId?: string;
        }
        interface AssistantApiTransactionFeaturesSupport {
            /**
             * If true, setting this boolean means the device should not support voice PIN. For example, although the phone supports both voice and PIN pad, but we don't want users using voice.
             * https://docs.google.com/document/d/1M8iJQX3GuxGZGeidS8Gl4KJt3LuBWAIlolPlW10DkxU/edit#heading=h.8ovvdd3i2thv
             */
            voicePinSuppressed?: boolean;
        }
        interface AssistantApiVolumeProperties {
            /** The volume percentages for spelled out values. */
            defaultVolumePercentage?: number;
            highVolumePercentage?: number;
            /** The number of levels to move for a step. */
            levelStepSize?: number;
            lowVolumePercentage?: number;
            /** The max number of volume levels the client supports. */
            maximumVolumeLevel?: number;
            mediumVolumePercentage?: number;
            veryHighVolumePercentage?: number;
            veryLowVolumePercentage?: number;
        }
        interface AssistantDevicesPlatformProtoAlarmCapability {
            /** Maximum number of alarms that can be created on the client. Zero or unset indicates no maximum limit. */
            maxSupportedAlarms?: number;
            /** Whether the client restricts alarms to ring within the next 24 hours. */
            restrictAlarmsToNextDay?: boolean;
            /**
             * Whether the client supports the STOP alarm action. If this is false, stop actions will be represented by the MUTATE action, and the device may need to check alarm state to determine
             * if there's a firing alarm that needs to be dismissed.
             */
            supportsStopAction?: boolean;
        }
        interface AssistantDevicesPlatformProtoArgSpec {
            intValueSpec?: AssistantDevicesPlatformProtoIntValueSpec;
            optionValueSpec?: AssistantDevicesPlatformProtoOptionValueSpec;
            type?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface AssistantDevicesPlatformProtoCallCallCapability {
        }
        // tslint:disable-next-line:no-empty-interface
        interface AssistantDevicesPlatformProtoClientReconnectCapability {
        }
        interface AssistantDevicesPlatformProtoCloudCapability {
            /**
             * The list of CloudEndpoints supported by this Device Model. Note that each should have a unique |name|. If any cloud endpoints are provided here, then the first one in the list will
             * be used by default for all Cloud Execution. An Intent may override the default by providing an |execution_config|.
             */
            cloudEndpoints?: AssistantDevicesPlatformProtoCloudEndpoint[];
        }
        interface AssistantDevicesPlatformProtoCloudEndpoint {
            /** The name for this cloud endpoint. It's unique per Locale. This is not an API resource name. Ex: sample-nlu-endpoint */
            name?: string;
            /**
             * The list of scopes to be provided in the OAuth2 token. They must be a subset of the scopes registered in the Account Linking flow, or the request will fail. If the client itself
             * provides the token, then this field is ignored.
             */
            scopes?: string[];
            /** The URL for this endpoint, it must start with https. */
            url?: string;
        }
        interface AssistantDevicesPlatformProtoDeviceActionCapability {
            /**
             * Integrate your device with Google's Smart Home solution by putting your device into Google's Home Graph, a database that stores and provides contextual data about the home and its
             * devices. For example, Home Graph can store the concept of a living room that contains multiple types of devices, when you say "turn on the light" to a device, if you have light in
             * the living room, that light will be turned on.
             */
            assistantDeviceInRoomOptOut?: boolean;
            /** Specifies behavior for built-in device actions for this device model. If not specified, defaults to ENABLE_CONFIGURED_INTENTS_ONLY. */
            builtInIntentMode?: string;
            /**
             * Specifies which custom device actions should be enabled for this device model. This will only affect the behavior of intents corresponding to those from the Action Package of this
             * project. If not specified, defaults to ENABLE_ALL.
             */
            customIntentMode?: string;
            /** Default instructions for routing of any Intent. The data here could be overridden for specific Intents if provided directly in the 'intents' field. */
            defaultExecutionConfig?: AssistantDevicesPlatformProtoExecutionConfig;
            /** Specifies capabilities for device actions that are inlined in the google.assistant.embedded.v1.DeviceAction message. */
            inlinedActionCapability?: AssistantDevicesPlatformProtoInlinedActionCapability;
            /**
             * Intent configurations. Built-in and custom intents may be configured here. Note that built-in intents will always behave with IntentMode of ENABLE_CONFIGURED_INTENTS_ONLY. The
             * IntentMode for custom intents can be changed using the custom_intent_mode. To configure an intent, list it here with its intent name, e.g. "MY_CUSTOM_INTENT",
             * "google.assistant.car.model.capabilities.AC_TEMPERATURE".
             */
            intents?: AssistantDevicesPlatformProtoIntent[];
            /**
             * Provided data which augments the device action capabilities. Some built-in intents may require additional configuration to be provided. One example could be the list of channels
             * available for the `action.intent.SelectChannel` intent.
             */
            providedData?: AssistantDevicesPlatformProtoProvidedData[];
            /**
             * List of built-in traits such as "action.devices.traits.OnOff" See java/com/google/home/graph/service/config/protoconf.pi As of Nov. 2017, we also support custom traits for EAP
             * users. We'll eventually disable custom traits once custom actions are in place.
             */
            traits?: string[];
            /**
             * Specifies the format how Google routes queries to 3P cloud. By default, this field is unset, all partners should get shallow NLU. This is needed *ONLY* for specific partners for
             * strong business reasons.
             */
            understandingConfig?: AssistantDevicesPlatformProtoUnderstandingConfig;
        }
        interface AssistantDevicesPlatformProtoDeviceModifySettingCapability {
            clientOpProperty?: AssistantApiClientOpPropertiesDeviceModifySettingClientOpProperty;
        }
        // tslint:disable-next-line:no-empty-interface
        interface AssistantDevicesPlatformProtoDeviceTakePhotoCapability {
        }
        interface AssistantDevicesPlatformProtoExecutionConfig {
            /**
             * Instructions for performing a cloud execution request for the Intent when the execution_type is set to CLOUD. If non-empty, then the device execution would be routed to the
             * CloudEndpoint specified by this name. The Account Linking exchange may be performed to fetch the OAuth access token, and the access token will be included in the HTTP header.
             */
            cloudEndpointName?: string;
            /**
             * If this field is set, then the Syndication cloud call will be disabled for this intent. Note this only applies if any Syndication cloud endpoint is associated with the Device Model,
             * otherwise setting this field does nothing. By default, all Intents that are enabled and supported by the Syndication API will be routed through the Syndication cloud endpoint if
             * it's provided.
             */
            cloudIntentTranslationDisabled?: boolean;
            /**
             * Specifies the intent command format for this Action. For example, in order to launch an Android intent instead of receiving the device action payload on the client, then this field
             * can be set with "intent:/#Intent;...;my_extra={$.params.channels[0].channelCode};end" The parameter "{$.params.channels[0].channelCode}" is in JSON path format, and will be replaced
             * with the content from the original device action payload. Thus, with # JSON "execution": [ { "command": "action.devices.commands.SelectChannel", "params": { "channels": [{
             * "channelName": "exampleChannel", "channelCode": "1-1" }] } } ] as the original action result, then the final result would look like "intent:/#Intent;...;my_extra=\"1-1\";end"
             */
            intentCommandFormat?: string;
            /** If this field is set, then local execution capability is disabled for all matching intents. */
            localDisabled?: boolean;
            /** Specifies how to execute this Action when it is invoked locally (from the same device.) */
            localExecutionType?: string;
            /** If this field is set, then remote execution capability is disabled for all matching intents. */
            remoteDisabled?: boolean;
            /** Specifies how to execute this Action when it is invoked remotely (from a different device.) */
            remoteExecutionType?: string;
        }
        interface AssistantDevicesPlatformProtoInlinedActionCapability {
            /** Specifies capabilities for handling on-device alarms. The presence of this field, even if empty, implies that the device supports alarms. */
            alarm?: AssistantDevicesPlatformProtoAlarmCapability;
            /** Specifies the size limits on responses. If message is not defined then no limits exist. */
            responseLimits?: AssistantDevicesPlatformProtoResponseLimits;
            /** Specifies capabilities for handling assistant.embedded.v1.DeviceOp. */
            supportedDeviceOps?: AssistantDevicesPlatformProtoSupportedDeviceOps;
            /**
             * Whether this device model package support sdk.EXECUTE client_op (a.k.a action.devices.EXECUTE intent), which will be filled into
             * google.assistant.embedded.v1.DeviceAction.device_request_json. It is default to true (and not public), since all 3P will depends on the device_request_json. Only internal projects
             * like Edoras will set this to false.
             */
            supportSdkExecute?: boolean;
            /** Specifies whether server can send a series of responses for a single query. Example: Routines where multiple actions to be executed one after another. */
            supportsMultiResponse?: boolean;
            /** Specifies capabilities for handling on-device timers. The presence of this field, even if empty, implies that the device supports timers. */
            timer?: AssistantDevicesPlatformProtoTimerCapability;
        }
        interface AssistantDevicesPlatformProtoIntent {
            /** List of arguments associated this intent. Each of which depends a template for the expected argument. */
            argSpecs?: { [P in string]: AssistantDevicesPlatformProtoArgSpec };
            /** Instructions for the routing of this Intent. */
            executionConfig?: AssistantDevicesPlatformProtoExecutionConfig;
            /** The name of the intent. */
            name?: string;
            /**
             * List of provided data names used by this intent. Note that some built-in intents will not function properly without provided data, such as `action.intent.SwitchChannel` or
             * `action.intent.AppSelector`.
             */
            providedDataNames?: string[];
            /** Security configuration for this Intent. */
            securityConfig?: AssistantDevicesPlatformProtoSecurityConfig;
            /**
             * The conditions which must be met by the device before executing this Intent. More than one can be provided, in which case the conditions operate with the "AND" operator, i.e. the
             * first condition which is failed will be used to restrict the execution of this Intent.
             */
            triggerConditions?: AssistantDevicesPlatformProtoTriggerCondition[];
        }
        interface AssistantDevicesPlatformProtoInternalCapability {
            /**
             * When using the Assistant SDK (Embedded Assistant API), the project id used to authenticate the gRPC request is checked and must match against the project id of the Device Model. We
             * will additionally allow the project ids listed in the device model here to be let through. See https://docs.google.com/document/d/1InAczpQJs6LCH1l--2yy67JM9hsBJbiL57fusnL3A8A
             */
            allowedAssistantSdkAuthProjectIds?: string[];
            /** Load the assistant.api.AppCapabilities from DEVICE_INSTALLED_APP footprint corpus. See go/edoras-geller. */
            appCapabilitiesFromDeviceInstallApps?: boolean;
            /**
             * Uses this endpoint for device action fulfillment when there's no endpoint in syndication_metadata. 1p surfaces/devices such as telephone can enable this for its cloud action
             * fulfillment without enabling the whole syndication experience.
             */
            cloudDeviceActionEndpoint?: AssistantDevicesPlatformProtoCloudEndpoint;
            /** Signals that the model will have updated ranking behavior as described in https://docs.google.com/document/d/1SN_AgadRr_cdIrFe-qgRbIX2J1sOE7lcRXAvM1GUPoU. */
            deviceActionsEligibleForHighConfidence?: boolean;
            /** Make Google sign-in mandatory for using Google Assistant on the device. (This bit is initially added for Samsung TV.) */
            forceSignIn?: boolean;
            /**
             * When looking up device (for example for disclosure consent check), then always use the third party device id for lookup instead of any other device id which would normally have
             * higher precedence, such as cast_device_id.
             */
            forceThirdPartyDeviceIdForDeviceLookup?: boolean;
            /**
             * Adds "transactions.AUTHENTICATION" for car automation probers. Since the probers run as Assistant SDK requests, voice match always fails for car automation requests, so we add this
             * client op as a hack to allow probers to appear as personal devices and bypass voice match. See b/137221645.
             */
            forceTransactionsAuthentication?: boolean;
            /**
             * Signals that this device can "render" raw search results even with no screen (e.g., using a text reader). If this is true, fallback search results can be returned as a custom device
             * action in a SearchResults message. http://google3/assistant/embedded/proto_translation/utils/proto/search_results.proto
             */
            hasCustomSearchResultsRendering?: boolean;
            /**
             * When looking up device (for example for disclosure consent check), use this project id as part of the primary key for the device lookup (i.e. instead of the device_config.agent_id.)
             * The precedence is as follows: 1) this field, if set for the device's device model 2) device_config.agent_id 3) device_model.project_id
             */
            overrideProjectIdForDeviceLookup?: string;
            stadiaAssistantConfig?: AssistantDevicesPlatformProtoInternalCapabilityStadiaAssistantConfig;
            /** Telephone server is able to send attribution to user feature phone. See go/telephone-attribution. */
            telephoneAttribution?: boolean;
        }
        interface AssistantDevicesPlatformProtoInternalCapabilityStadiaAssistantConfig {
            stadiaPlatform?: string;
        }
        interface AssistantDevicesPlatformProtoIntValueSpec {
            maxValue?: string;
            minValue?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface AssistantDevicesPlatformProtoMediaNextCapability {
        }
        // tslint:disable-next-line:no-empty-interface
        interface AssistantDevicesPlatformProtoMediaPauseCapability {
        }
        // tslint:disable-next-line:no-empty-interface
        interface AssistantDevicesPlatformProtoMediaPlayMediaCapability {
        }
        // tslint:disable-next-line:no-empty-interface
        interface AssistantDevicesPlatformProtoMediaPreviousCapability {
        }
        // tslint:disable-next-line:no-empty-interface
        interface AssistantDevicesPlatformProtoMediaResumeCapability {
        }
        // tslint:disable-next-line:no-empty-interface
        interface AssistantDevicesPlatformProtoMediaStopCapability {
        }
        interface AssistantDevicesPlatformProtoOptionValueSpec {
            values?: string[];
        }
        interface AssistantDevicesPlatformProtoProvidedData {
            name?: string;
        }
        interface AssistantDevicesPlatformProtoProviderOpenCapability {
            clientOpProperty?: AssistantApiClientOpPropertiesProviderOpenClientOpProperty;
        }
        interface AssistantDevicesPlatformProtoResponseLimits {
            /** Max size in bytes of the total serialized AssistResponse receivable by the client. If response exceeds this max, response may be modified by the server. */
            maxAssistResponseSizeBytes?: number;
            /** Maximum size in bytes (not characters) of text the display can handle (which may be different from how much the display can show at a time due to scrolling). */
            maxDisplayLinesBytes?: number;
            /** Maximum size in bytes (not characters) for each suggestion chip. */
            maxSuggestionChipBytes?: number;
            /** Maximum number of suggestion chips the device can handle to display. */
            maxSuggestionChips?: number;
        }
        interface AssistantDevicesPlatformProtoSecurityConfig {
            /** Specifies auth mechanism to be used upon remote request for device action. */
            authMechanismForRemoteRequests?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface AssistantDevicesPlatformProtoSendChatMessageCapability {
        }
        interface AssistantDevicesPlatformProtoSupportedDeviceOps {
            /** |call_call| specifies the support for the call.CALL clientop, and the corresponding call_call field in assistant.embedded.v1.DeviceOp. */
            callCall?: any;
            /**
             * |client_reconnect| indicates support for client.RECONNECT using assistant.embedded.v1.DeviceOp. There is an alternative API/capability for client.RECONNECT specified in
             * RoutineCapability.supports_reconnect. Client should choose between this and RoutineCapability but not both.
             */
            clientReconnect?: any;
            /** |device_modify_setting| specifies the support for device.MODIFY_SETTING client_op, and the corresponding device_modify_setting field in assistant.embedded.v1.DeviceOp. */
            deviceModifySetting?: AssistantDevicesPlatformProtoDeviceModifySettingCapability;
            /** [device_take_photo] specifies the support for the device.TAKE_PHOTO clientop, and the corresponding device_take_photo field in assistant.embedded.v1.DeviceOp. */
            deviceTakePhoto?: any;
            mediaNext?: any;
            mediaPause?: any;
            mediaPlayMedia?: any;
            mediaPrevious?: any;
            mediaResume?: any;
            mediaStop?: any;
            /** |provider_open| specifies the support for provider.OPEN client_op, and the corresponding provider_open field in assistant.embedded.v1.DeviceOp. */
            providerOpen?: AssistantDevicesPlatformProtoProviderOpenCapability;
            /** |send_chat_message| specifies the support for the chat_message.SEND clientop, and the corresponding send_chat_message field in assistant.embedded.v1.DeviceOp. */
            sendChatMessage?: any;
        }
        interface AssistantDevicesPlatformProtoTimerCapability {
            /**
             * Maximum extended timer duration supported by the client. The extended timer duration is the total start-to-finish duration after an AddTimeToTimer operation. E.g. if a user sets a
             * timer for 30 minutes, and later adds 10 minutes, the extended duration is 40 minutes. Zero or unset indicates no maximum limit.
             */
            maxSupportedExtendedTimerDuration?: AssistantApiDuration;
            /** Maximum timer duration supported by the client. Zero or unset indicates no maximum limit. */
            maxSupportedTimerDuration?: AssistantApiDuration;
            /** Maximum number of timers that can be created on the client. Zero or unset indicates no maximum limit. */
            maxSupportedTimers?: number;
            /**
             * Whether the client supports the MUTATE timer action. If this is false, mutate operations may be handled by sending a pair of REMOVE and CREATE timer actions to replace the existing
             * timer instead of mutating it.
             */
            supportsMutateAction?: boolean;
        }
        interface AssistantDevicesPlatformProtoTriggerCondition {
            /**
             * The map of state keys along with their values which must be returned by the device, for example to start the dishwasher you may require states: {"door": "CLOSED",
             * "detergent_status": "READY"}.
             */
            requiredStateValues?: { [P in string]: AssistantDevicesPlatformProtoArgSpec };
            /** A simple TTS to play. */
            simpleTts?: string;
            /**
             * Refers to a defined ConditionalResult keyed by its status. It could be a built-in or custom ConditionalResult for this Intent. Note: the states provided by the device MUST contain
             * all of the states required by the ConditionalResult.
             */
            status?: string;
        }
        interface AssistantDevicesPlatformProtoUnderstandingConfig {
            /** Specifies the NLU level for the intent. */
            nluLevel?: string;
        }
        interface AssistantDeviceTargetingDeviceTargetingError {
            type?: string;
        }
        interface AssistantGroundingRankerContactGroundingProviderFeatures {
            /** Concept id for relationships in English, e.g. "Mother" for all non-English locales. It's only populated for source = RELATIONSHIP. */
            conceptId?: string;
            contactSource?: string;
            /** Whether the query is a relationship query based on the annotation source. */
            isRelationshipFromAnnotation?: boolean;
            /** Whether the contact has relationship in the contact metadata. */
            isRelationshipFromSource?: boolean;
            /** Whether only populates a single candidate. */
            isSingleCandidate?: boolean;
            /** Whether the contact is starred contact. */
            isStarred?: boolean;
            matchedNameType?: string;
            /** Number of alternate contact names from fuzzy contact match. (Not suggest using it since it can change due to retrieval iteration) */
            numAlternateNameFromFuzzyContactMatch?: number;
            /** Number of alternate contact names from S3_HYPOTHESES. (Not suggest using it since it can change due to retrieval iteration) */
            numAlternateNamesFromS3?: number;
            /** Number of alternate contact names from interpretation. (Not suggest using it since it can change due to retrieval iteration) */
            numAlternativeNamesFromInterpretation?: number;
            /** Number of contacts populated by the contact Grounding Provider. (Not suggest using it since it can change due to retrieval iteration) */
            numCandidates?: number;
            recognitionAlternateSource?: string;
        }
        interface AssistantGroundingRankerGroundingProviderFeatures {
            contactGroundingProviderFeatures?: AssistantGroundingRankerContactGroundingProviderFeatures;
            mediaGroundingProviderFeatures?: AssistantGroundingRankerMediaGroundingProviderFeatures;
            providerGroundingProviderFeatures?: AssistantGroundingRankerProviderGroundingProviderFeatures;
        }
        interface AssistantGroundingRankerMediaGroundingProviderFeatures {
            /** True if the media deeplink has tag SEED_RADIO. */
            isSeedRadio?: boolean;
            /** True if the user requests seed radio. */
            isSeedRadioRequest?: boolean;
            /**
             * MSC(Media Short Click) rate. MSC rate = total number of MSC events / total number of MSC candidates The event is considered as MSC candidate if the event is a media seeking
             * query(excluding follow-ons) and the media result is successfully fulfilled. The event is MSC event if any of the following is in the following queries within 30 secs:
             * FOLLOWED_BY_DUPLICATE FOLLOWED_BY_ADD_OR_DELETE_MANUAL_REFINEMENT FOLLOWED_BY_SAME_VERTICAL (MEDIA) FOLLOWED_BY_STOP More details: go/media-ranking, go/billboard-navboost,
             * go/magma-music-actions-efrac
             */
            mscRate?: number;
        }
        interface AssistantGroundingRankerProviderGroundingProviderFeatures {
            /** Provider quality score in the range [0,1] that can be used for ranking providers. Incorporates both policy rules and quality considerations. */
            pslScore?: number;
        }
        interface AssistantLogsAllMediaStreamLog {
            /** All active media streams while the user issues the query. */
            streams?: AssistantLogsMediaStreamLog[];
            /**
             * The stream selected by stream transfer logic to be transferred to another device. It will be empty for other features. Target_stream is different from target_device since
             * target_stream could have multiple devices.
             */
            targetStream?: AssistantLogsMediaStreamLog;
        }
        interface AssistantLogsAmbiguousTargetDeviceLog {
            /**
             * Device index of the initial ambiguous devices. The device index in this message is consistent with the device index in DeviceInfoLog. It would be used to track more detailed
             * information of a device if needed.
             */
            ambiguousDeviceIndex?: number[];
            /**
             * DeviceInfo for devices after the filters and promoters. - When device targeting is only configured for single target, these are ambiguous devices that would have been the output of
             * Lumos. Downstream may perform extra check before disambiguation dialog. For example, Media Initiation checks playability for devices. The output here is before the check. - When
             * configured for multi-target, these are just the target devices. For privacy consideration, we may only log device id field inside.
             */
            devicesAfterPromoters?: AssistantLogsDeviceInfoLog[];
            /** the final targeted device selected by playability filter or DeviceSelectionDialog */
            finalTargetDevice?: AssistantLogsDeviceInfoLog;
            /** Device index of the devices after playability filter */
            playabilityFilteredDevicesIndex?: number[];
            /**
             * When there is no qualified devices after playability check, it would populate punt_info below. If all devices are filtered out for the same reason, there would only be one item.
             * Otherwise, there will be multiple items.
             */
            puntInfoLog?: AssistantLogsAmbiguousTargetDeviceLogPuntInfoLog[];
            /** Device index of the devices after structure filter */
            structureFilteredDeviceIndex?: number[];
        }
        interface AssistantLogsAmbiguousTargetDeviceLogPuntInfoLog {
            /** Index of devices that have the same punt info during playability check, i.e. same media_excuse and provider_mid. */
            deviceIndex?: number[];
            /** Excuse for media action triggering. See: assistant/verticals/media/proto/media_excuse.proto. */
            mediaExcuse?: number;
            /** Provider id that the excuse belongs to. This is the KG MID of the provider, e.g., "/m/09jcvs" for Youtube. */
            providerMid?: string;
        }
        interface AssistantLogsCommunicationDeviceContactInfoLog {
            /** This list provides account information from the raw contact which is the source of this field. */
            rawContactInfo?: AssistantLogsCommunicationRawDeviceContactInfoLog[];
        }
        interface AssistantLogsCommunicationFuzzyNgramMatchLog {
            relativeCost?: number;
            type?: string;
        }
        interface AssistantLogsCommunicationGoogleAccountProvenance {
            email?: string;
            gaiaId?: string;
            isDasherAccount?: boolean;
        }
        interface AssistantLogsCommunicationPersonalContactDataLog {
            /** Google AccountProvenance of the contact. */
            accountProvenance?: AssistantLogsCommunicationGoogleAccountProvenance;
            /** Populated if matched_name_type is GIVEN_NAME_ALIAS or FULL_NAME_ALIAS. */
            commonNameAliasConfidence?: number;
            /** Concept id for relationships in English, e.g. "Mother" for all non-English locales. It's only populated for source = RELATIONSHIP. */
            conceptId?: string;
            /** Integer value corresponding to DeviceContactExtraMetadata.Attribute enum. http://google3/social/graph/wire/proto/merged_person.proto?l=933&rcl=320308954 */
            deviceContactAttributes?: number[];
            /** # emails stored for the contact. */
            emailIdCount?: number;
            /** Populate only if ContactRecognitionAlternate.Source is 'FUZZY_CONTACT_MATCH'. */
            fuzzyNgramMatch?: AssistantLogsCommunicationFuzzyNgramMatchLog[];
            /**
             * Contact owner's gaia id from cs/symbol::symbol:quality_qrewrite.PersonalContactData.shared_contact_owner_gaia_id. Only populated for is_shared = true and non sign-out mode and user
             * is not the owner of the contact(shared contact from other user).
             */
            gaiaId?: string;
            /** Boolean value indicating whether selected contact is from different account than the logged in account. */
            isContactFromSecondaryAccount?: boolean;
            /**
             * If this is a shared contact. This is true in 2 cases: - User is calling their own contacts that have been marked as shared. - User is calling shared contacts from some other user's
             * contact list.
             */
            isShared?: boolean;
            /** Indicate the contact matches the transliterated query. */
            isTransliteratedMatch?: boolean;
            /** True if the contact is a vanity contact(has email = user's email address). */
            isVanityContact?: boolean;
            /**
             * If the lookup was done using relationship which is visible to guests. This value will only be set if lookup was done using relationship. E.g. user has a guest relationship (doctor)
             * -> (John) And user says "call doctor", then this value will be true.
             */
            isVisibleToGuestsRelationship?: boolean;
            /** The matched name type of a contact candidate. */
            matchedNameType?: string;
            /** Alternate recognition term which was used to match this contact. */
            matchedRecognitionAlternateName?: string;
            /**
             * Ngram matched by starlight lookup for fuzzy matching in fulfillment. We need this to analyze how many contacts are returned by starlight lookup that is not matched by fuzzy
             * matching. For example, "Komal Dear" is matched to "Komal Dr" by fuzzy match. When doing starlight lookup, "Komal" and "Dr" will be looked up separately. So "Dr xxx" will also be
             * returned. We want to see how often this happens.
             */
            matchedStarlightLookupName?: string[];
            /** PersonMetadata of the selected contact. */
            metadata?: AssistantLogsCommunicationPersonMetadataLog;
            /**
             * The indices of the contact in |candidate_contact| whose name matches the |selected_contact_data|. |candidate_contact|:
             * http://google3/logs/proto/assistant/contact.proto?l=111&rcl=306283376 |selected_contact_data|: http://google3/logs/proto/assistant/contact.proto?l=108&rcl=306283376
             */
            nameMatchedContactIndex?: number[];
            /** The original name in the query as transcribed by ASR. */
            originalQueryName?: string;
            /** Information regarding the phone endpoints of the selected contact. Currently it is only logged for selected candidate. */
            phone?: AssistantLogsCommunicationPhoneLog[];
            /** # phone_numbers stored for the contact. */
            phoneNumberCount?: number;
            /** Encodes if pkg_person was resolved via a name or relationship reference. */
            pkgReferenceType?: string;
            /** Populate only if ContactRecognitionAlternate.Source is not NONE. */
            recognitionAlternateScore?: number;
            /** Recognition alternative source type. If not none, then it indicates the personal contact data is alternative and how the alternative is fulfilled. */
            recognitionAlternateSource?: string;
            /** The number of resolved relationship names and contact pointers from Assistant Memory. */
            relationshipMemoryCount?: number;
            /** Information regarding the selected phone endpoint. Currently it is only logged for selected candidate. */
            selectedPhone?: AssistantLogsCommunicationPhoneLog;
            /** Shortcut information of the contact. */
            shortcutContactInfo?: MajelContactInformationShortcutInformation;
            /** The contact source of a contact candidate. */
            source?: string;
            /** Integer value corresponding to SystemContactGroup enum. http://google3/social/graph/wire/proto/merged_person.proto?l=3151&rcl=320308954 */
            systemContactGroupId?: number[];
            /** DEPRECATED. Use phone instead. Used before 2020-01-13. Number of phone numbers annotated with Whatsapp. */
            whatsappPhoneNumberCount?: number;
        }
        interface AssistantLogsCommunicationPersonMetadataLog {
            deviceContactInfo?: AssistantLogsCommunicationDeviceContactInfoLog[];
        }
        interface AssistantLogsCommunicationPhoneLog {
            /** This list provides account information from the raw contact which is the source of this field. */
            rawDeviceContactInfo?: AssistantLogsCommunicationRawDeviceContactInfoLog[];
            /**
             * Label for phone number in the Contacts app. It can have standard values provided by the app e.g. MOBILE, HOME, WORK etc, but users are allowed to modify. So essentially it becomes
             * user content.
             */
            type?: string;
        }
        interface AssistantLogsCommunicationRawDeviceContactInfoLog {
            /** Account type of raw contact, e.g. "com.google" or "com.linkedin.android". */
            accountType?: string;
        }
        interface AssistantLogsDefaultDeviceLog {
            defaultSpeaker?: AssistantLogsDeviceInfoLog;
            defaultTv?: AssistantLogsDeviceInfoLog;
            sourceDeviceId?: string;
        }
        interface AssistantLogsDefaultDevicesLog {
            localDefaultDevices?: AssistantLogsDefaultDeviceLog;
            /** Default settings of nearby devices. */
            nearbyDefaultDevices?: AssistantLogsDefaultDeviceLog[];
        }
        interface AssistantLogsDeviceAnnotationLog {
            /** The raw text mentioning a device from the query, such as "any tv". */
            rawTextFromQuery?: string;
            /** The annotation type mentioned in the query. */
            type?: string;
            /** The matched device name set by the user, such as "big screen tv". */
            userDefinedName?: string;
        }
        interface AssistantLogsDeviceInfoLog {
            /** Device identifier string for the current device used in the arbitration service. */
            arbitrationDeviceId?: string;
            connectivity?: string;
            /**
             * The identification of the device. DeviceId (go/as-device-id) has multiple fields. To consloidate it to a single to make dremel easier, we use the string obtained by calling
             * go/get-device-id.
             */
            deviceId?: string;
            /** The identification of the device. The logging version of the full DeviceId. */
            deviceIdLog?: AssistantLogsSettingsDeviceIdLog;
            /** We index linked devices and log these index to avoid logging device_id. device_index should always be a positive number or -1. -1 means this device is not in homegraph. */
            deviceIndex?: number;
            /** This is the device_model_id field in device_settings proto. It has the same value for the same type of devices. e.g. Sonos.Sonos One.S13 */
            deviceModelId?: string;
            /** LINT.ThenChange(//depot/google3/assistant/context/proto/device_arbitration.proto:EstimatedRelativeDistance) */
            distance?: string;
            /** The lumos processor which eliminated this device, if applicable */
            eliminatingLumosProcessor?: string;
            isRemote?: boolean;
            /**
             * This flag indicates this is a non-local device that is tethered to local/originating device. Tethered device is a special case of is_remote and typically used in wearable scenarios.
             * This is always false for local device and when it is true, it implies is_remote is also true.
             */
            isTethered?: boolean;
            mediaCapabilities?: AssistantLogsMediaCapabilities;
            mediaDeviceType?: string;
            /** User defined device name */
            name?: string;
            /** This field should be populated only when there is at least one session on this device. */
            sessions?: AssistantLogsDeviceMediaSessionLog[];
            /** This field should be populated only when the device is an Assistant device. */
            surfaceType?: string;
        }
        interface AssistantLogsDeviceMediaSessionLog {
            deviceId?: AssistantApiCoreTypesDeviceId;
            mediaSessionType?: string;
            /**
             * The type of the media session. If provider does not report this field, we ## compute it by mapping provider type to media type. Here is the mapping: |ProviderType
             * |MediaItemMetadata.Type| |-------------------------------------- |MUSIC |TRACK | |VIDEO |VIDEO | |LIVE_TV |TV_CHANNEL | |AUDIOBOOK |AUDIO_BOOK | |PODCAST |PODCAST_EPISODE | ##
             * |LIVE_STREAMING|VIDEO |
             */
            mediaType?: string;
            /** The playback states of the session. */
            playbackState?: string;
            /** The KG mid of the media provider. */
            providerMid?: string;
            supportedTransportControl?: string[];
        }
        interface AssistantLogsDeviceSelectionLog {
            /** Default settings of all nearby devices Deprecated, use default_devices_log instead. */
            allDefaultDevices?: AssistantLogsDefaultDeviceLog[];
            /** Logs all active media sessions. */
            allMediaStreamLog?: AssistantLogsAllMediaStreamLog;
            /** DeviceSelectionLog for counterfactual logging. */
            counterfactualDeviceSelectionLog?: AssistantLogsDeviceSelectionLog;
            /** Include default tv and default speaker Deprecated, use all_default_devices below. */
            defaultDevices?: AssistantLogsDefaultDeviceLog;
            defaultDevicesLog?: AssistantLogsDefaultDevicesLog;
            /** Temporaray field for debugging ANDROID_AUTO multi_target_devices punt. This will be removed once we identify the root cause. */
            devicesStr?: string[];
            inputErrorLog?: AssistantLogsInputErrorLog[];
            /** Now we just log the media sessions on local device Deprecated, use NearbyDevicesLog::LocalDevice instead. */
            localDevice?: AssistantLogsDeviceInfoLog;
            /** Indicates which library populated the device_selection_log for this query. */
            logDataSource?: string;
            /** The Media Focus information. This field should be populated only when there is a Media Focus. Deprecated, use media_focuses below instead. */
            mediaFocus?: AssistantLogsMediaFocusInfoLog;
            /** Media focuses on all devices. */
            mediaFocusesLog?: AssistantLogsMediaFocusesLog;
            /** All nearby devices and local device. */
            nearbyDevicesLog?: AssistantLogsNearbyDevicesLog;
            /** This should log the query annotation features found in the device, such as the device annotation, the room annotation, and the structure annotation from the query. */
            queryAnnotation?: AssistantLogsQueryAnnotationLog;
            /** The result of device selection. */
            selectionResult?: AssistantLogsDeviceSelectionResultLog;
            testCodes?: AssistantLogsDeviceTargetingTestCode[];
        }
        interface AssistantLogsDeviceSelectionResultLog {
            /** Deprecated, please use qualified_devices. */
            ambiguousTargetDevices?: AssistantLogsAmbiguousTargetDeviceLog;
            deviceSelectionDecisionSummary?: AssistantLogsMediaDeviceSelectionDecisionSummary;
            deviceTargetingErrorType?: string;
            /** The class name for the final filter/promoter used by Lumos for device targeting. This filter or promoter runs for all users, and contains no data specific to the individual user. */
            finalLumosStage?: string;
            /**
             * ////////////////////////////////////////////////////////////////////////// Ambiguous Results: the library failed to select the final target device(s) but it narrows down to a set of
             * devices which are all valid target device candidates. The client needs to do further disambiguation, e.g., giving a dialog or having costomized logic. The low confidence target
             * device means the library falied to select the target device but it picked two devices for the client to do disambiguation.
             */
            lowConfidenceTargetDevice?: AssistantLogsLowConfidenceTargetDeviceLog;
            /** ////////////////////////////////////////////////////////////////////////// This field log the error while selecting target device in media_focus_selector. */
            mediaFocusSelectionErrorType?: string;
            /** The log for each stage of Lumos, showing the number of eliminated devices from each processor. */
            processorInfo?: AssistantLogsLumosProcessorInfo[];
            /**
             * We will apply several filters and dialogs to select a target device if media_focus_selector fail to select one. This field should log the devices left after each filter or dialog.
             * It also log the detailed info of the final target device.
             */
            qualifiedDevices?: AssistantLogsAmbiguousTargetDeviceLog;
            /**
             * ////////////////////////////////////////////////////////////////////////// Unambiguous Results: the library successfully selected the final target device(s) and no further
             * disambiguation is needed. Deprecated, please use target_device.
             */
            singleTargetDevice?: AssistantLogsDeviceInfoLog;
            targetDevice?: AssistantLogsTargetDeviceLog;
        }
        interface AssistantLogsDeviceTargetingTestCode {
            type?: string;
        }
        interface AssistantLogsInputErrorLog {
            errorCode?: number;
            errorType?: string;
        }
        interface AssistantLogsLowConfidenceTargetDeviceLog {
            /** The fallback device. */
            fallbackDeviceLog?: AssistantLogsDeviceInfoLog;
            /** The selected low confidence focus device. */
            lowConfTargetDeviceLog?: AssistantLogsDeviceInfoLog;
        }
        interface AssistantLogsLumosProcessorInfo {
            /** Number of candidate devices after this stage is run. */
            devicesAfterRun?: number;
            /** Number of candidate devices before this stage is run. */
            devicesBeforeRun?: number;
            /** Name of the processor for this stage. */
            processorName?: string;
        }
        interface AssistantLogsMediaCapabilities {
            canReceiveRemoteAction?: boolean;
            hasScreen?: boolean;
        }
        interface AssistantLogsMediaDeviceSelectionDecisionSummary {
            deviceSelectionPreferenceUsed?: string;
            deviceSelectionReason?: string;
            miscSelectionSignal?: string[];
        }
        interface AssistantLogsMediaFocusesLog {
            dialogTriggered?: boolean;
            localMediaFocus?: AssistantLogsMediaFocusInfoLog;
            /** Deprecated, use nearby_media_focuses instead. */
            mediaFocuses?: AssistantLogsMediaFocusInfoLog[];
            /** MediaFouces found on nearby devices. */
            nearbyMediaFocuses?: AssistantLogsMediaFocusInfoLog[];
        }
        interface AssistantLogsMediaFocusInfoLog {
            /** How long the device is in focus so far */
            currentFocusDurationSec?: number;
            /** TODO(b/134944092) Log MediaFocusDialogTrigger Enum in focus_status. */
            dialogTriggered?: boolean;
            /** LINT.ThenChange(//depot/google3/logs/proto/majel_gws/media_action_triggering_info.proto) The focus device. */
            focusDevice?: AssistantLogsDeviceInfoLog;
            /** The media focus state at the time of the request. */
            mediaFocusState?: string;
            /** The source device of media focus. */
            sourceDeviceId?: string;
        }
        interface AssistantLogsMediaStreamLog {
            /** The device index in this message is consistent with the device index in DeviceInfoLog. This field refers to the devices that hosting the session. */
            deviceIndex?: number[];
            session?: AssistantLogsDeviceMediaSessionLog;
        }
        interface AssistantLogsNearbyDevicesLog {
            /** The timestamp that DeviceArbitration is created in milliseconds. */
            deviceArbitrationCreationTimestampMs?: string;
            eliminatedByFurtherDistance?: number;
            eliminatedByLocalClosest?: number;
            eliminatedByUnknownDifferentRoom?: number;
            eliminatedByUnregisteredDevice?: number;
            localDevice?: AssistantLogsDeviceInfoLog;
            nearbyDevices?: AssistantLogsDeviceInfoLog[];
            numClosestDevices?: number;
            numEquallyCloseDevices?: number;
            numFurtherDevices?: number;
            numHearingDevices?: number;
            numUnknownDistanceDevices?: number;
        }
        interface AssistantLogsQueryAnnotationLog {
            /** Deprecated, please use room_annotations. */
            deviceAnnotation?: AssistantLogsDeviceAnnotationLog;
            /** Log the device annotations mentioned in the query. */
            deviceAnnotations?: AssistantLogsDeviceAnnotationLog[];
            /** TODO(b/171250187) Deprecates the optional RoomAnnotationLog and DeviceAnnotationLog. Deprecated, please use device_annotations. */
            roomAnnotation?: AssistantLogsRoomAnnotationLog;
            /** Log the room annotations mentioned in the query. */
            roomAnnotations?: AssistantLogsRoomAnnotationLog[];
            /** Log the structure annotations mentioned in the query. */
            structureAnnotations?: AssistantLogsStructureAnnotationLog[];
        }
        interface AssistantLogsReminderLog {
            /**
             * The reminder is created N seconds ago. This helps tracking how the user issues follow-up actions after reminder is created. For example, whether the user likes to issues another
             * [show reminders] query right after reminder is created?
             */
            createdSecondsAgo?: string;
            /**
             * If the reminder is retrieved by a ranking class (see go/opa-reminders-ranker), this will be populated with the class info. Refer to
             * assistant.productivity.ReminderRankingClass.RankingType. Since that proto is in proto2 format, we can only wire by int type.
             */
            retrievedRankingClass?: number;
        }
        interface AssistantLogsRoomAnnotationLog {
            /** The raw text mentioning a room from the query, such as "my living room". */
            rawTextFromQuery?: string;
            /** The number of rooms annotated, if there are multiple structures. They are guaranteed to have the same text_from_query and name due to exact matching. */
            roomCount?: number;
            /** The annotation type mentioned in the query. */
            type?: string;
            userDefinedName?: string;
        }
        interface AssistantLogsSettingsDeviceIdLog {
            /** The client_instance_id on devices with GSA. See 'client_instance_field' in go/androidids. */
            agsaClientInstanceId?: string;
            /** A unique device ID for Assistant devices as proposed by go/ocelot-team. */
            canonicalDeviceId?: string;
            /** If set, indicates that the device is a cast device, and contains the UUID of the cast device. Corresponds to the device_id field of the CastDevice proto. */
            castDeviceId?: string;
            /**
             * DUSI (go/dusi) is used as the identifier here. This identifier is unique to the user and device. This will help identify which device or application the user's request originated
             * from. This is not to be confused with the client_instance_id that android devices provide. This is currently used by surfaces that use the assistant-legacy-nexus and
             * assistant-legacy-clockwork pipelines. DUSI is created and set in S3. This field is only filled for GAIA requests.
             */
            clientInstanceId?: string;
            /**
             * The unique device ID for HomeGraph devices. This is the HomeGraph ID, created when the device is registered into HomeGraph. It is immutable for the same device unless it is
             * completely deleted and recreated. See go/home-graph for details. }
             */
            homeGraphDeviceId?: string;
            /** The unique ID for libassistant based devices. */
            libassistantDeviceId?: string;
        }
        interface AssistantLogsStructureAnnotationLog {
            /** The raw text mentioning a structure from the query, such as "my house". */
            rawTextFromQuery?: string;
            /** The annotation type mentioned in the query. */
            type?: string;
            userDefinedName?: string;
        }
        interface AssistantLogsTargetDeviceLog {
            devices?: AssistantLogsDeviceInfoLog[];
            lowConfidenceReason?: string;
            resultConfidenceLevel?: string;
        }
        interface AssistantPrefulfillmentRankerPrefulfillmentSignals {
            /** Assistant User Interaction Score for binding set. */
            bindingSetAuis?: number;
            /** A parsing score that is independently calibrated by each parser/IG. */
            calibratedParsingScore?: number;
            /** Indicates interpretation dominance predicted by KScorer */
            dominant?: boolean;
            /**
             * The total effective length of the spans for the arguments used to construct the parse. May include vertical specific adjustments. Eg: For the query [delete my 7 p.m. alarm called
             * chicken] and intent Delete_alarm(alarm_object=RD(category=AlarmObject( label="chicken", trigger_time_datetime=<< 7 PM >>))), the effective argument span is "7 p.m." + "chicken"
             * (total length of 13).
             */
            effectiveArgSpanLength?: number;
            /** Grounding Signals. Score indicating how grounded the intent is, populated by the Grounding Box. */
            groundabilityScore?: number;
            /**
             * Grounding Provider related ranking features, including general Grounding Provider ranking features(shared among multiple GPs) and specific Grounding Provider ranking
             * features(provided by a specific GP).
             */
            groundingProviderFeatures?: AssistantGroundingRankerGroundingProviderFeatures;
            /** This is a cross-intent feature which is calculated by iterating all intent candidates. This feature should be populated in post-IG stage (before GB). */
            inQueryMaxEffectiveArgSpanLength?: number;
            /** intent_name is used by PFR ensemble model. See go/pfr_ha_launch_doc */
            intentName?: string;
            /** QUS intent-based ranking signals. Assistant User Interaction Score which is aggregated using intent name. */
            intentNameAuisScore?: number;
            /** Assistant User Interaction Score which is aggregated using intent name from exp laelaps. */
            intentNameAuisScoreExp?: number;
            /** Feasibility of fulfilling the binding set. Eg: For PlayMedia, this is equivalent to playability. More details: go/hgr-feasibility-feature. */
            isFeasible?: boolean;
            /**
             * The rank order of the interpretation as determined by kscorer. The kscorer-determined dominant interpretation, if any, gets a rank of 0. The remaining N interpretations get a rank
             * of 1 through N.
             */
            kscorerRank?: number;
            /**
             * This feature is always false / no-op in serving time. In training time, this feature may be set true on specific examples for weighted training where when this signal is true, only
             * cross-intent level features are used for training and other candidate level features are masked (set as missing).
             */
            maskCandidateLevelFeatures?: boolean;
            /** Number of alternative hypotheses from speech recognition(S3). */
            numAlternativeHypothesis?: number;
            /** Sum of the number of constraints used by the Grounding Box to ground each variable. */
            numConstraints?: number;
            /**
             * Sum of the number of constraints satisfied for each variable. Depending on the match score for a constraint, this number can be fractional and is in the range [0, num_constraints].
             * Populated by the Grounding Box.
             */
            numConstraintsSatisfied?: number;
            /** Number of groundable arguments the intent has, populated by the Grounding Box. */
            numGroundableArgs?: number;
            /** Number of grounded arguments the intent has, populated by the Grounding Box. */
            numGroundedArgs?: number;
            /** Signals as proposed in go/improved-grounding-signals. Number of arguments, possibly nested, that the Grounding Box tried to ground. */
            numVariables?: number;
            /** Number of arguments, possibly nested, that the Grounding Box was able to ground. This includes ambiguously grounded arguments. */
            numVariablesGrounded?: number;
            /**
             * Cosine similarity between predicted query-to-term model and assistant intent-type-based salient terms. This is intended to be only used for ACE ranking and only populated for
             * assistant traffic.
             */
            pq2tVsAssistantIbstCosine?: number;
            /** Cosine similarity between predicted query-to-term model and intent-type-based salient terms. This is intended to be used as a backoff to pq2t_vs_qibst_cosine if it is missing. */
            pq2tVsIbstCosine?: number;
            /** Intent confidence predicted by the AssistantVerticalClassifier QRewrite servlet. */
            predictedIntentConfidence?: number;
            /** The determination made by the SearchDispatchingConfig as to whether and how this interpretation should be dispatched to Search. */
            searchDispatch?: string;
            /**
             * Average of per-word confidence for top speech recognition hypothesis. The value is from RecognizerHypothesisLog:
             * http://google3/logs/proto/speech/service/recognizer_log.proto?l=848&rcl=281400256
             */
            topHypothesisConfidence?: number;
            /** Horizontal feature that stores information about confidence scores for each resolution within the binding set. */
            verticalConfidenceScore?: number;
        }
        interface AssistantProductivityListItem {
            /** [REQUIRED] The name of the list item. */
            name?: string;
        }
        interface AssistantRemindersAttachment {
            /**
             * REQUIRED. An unique identifier for the attachment. We have a plan to index this field, so it's marked as REQUIRED. Chat with opa-reminders-eng@ if you have a use case without an
             * attachment ID.
             */
            id?: string;
            link?: AssistantRemindersAttachmentLink;
            /** REQUIRED. Surface types this attachment should be shown. */
            surfaceType?: string[];
        }
        interface AssistantRemindersAttachmentLink {
            /** REQUIRED. The link to surface to frontends (e.g., Hubpage, notifications.) This could also be a surface-specific deeplink (be sure to set `surface_type` accordingly.) */
            linkUrl?: string;
            /**
             * REQUIRED. The text for the notification link button. Note: We cannot take nlp_generation.TemplateData yet due to cyclic dependency. The plan is to cut dependency from TemplateData
             * to quality.actions.Reminder.
             */
            notificationText?: AssistantRemindersNlgTemplateKey;
        }
        interface AssistantRemindersMemoryPayload {
            /**
             * Whether the reminder created has a referenced_entity attached to it or not(go/hub-memory-payload). Since we plan to set this in Assistant reminder creation path flow, in case later
             * the referenced_entity is removed from the reminder, then this bit might still remain true. Also in case referenced_entity is later added to reminder(for example when
             * referenced_entity is attached by Server), then also this bit might remain false. This bit will be used to *guess* if the user has a memory-enabled AGSA, thus we'll surface the "open
             * memory" button on hubpage. This check is not perfect, as the user might have other phones with older AGSA, so this is just a *best guess*. This field won't be stored in Memory
             * backend, and will not be populated back when retrieving reminders.
             */
            hasReferencedEntityAtCreation?: boolean;
            /**
             * Id of record that is associated with Reminder. This will be set for all Assistant reminders created after the first launch of the Reminder Memory integration, see
             * go/reminders-memory for more details. Also, this might apply to all other types of reminders.
             */
            recordId?: string;
        }
        interface AssistantRemindersNlgTemplateKey {
            /** REQUIRED. */
            messageSet?: string;
            /** REQUIRED. */
            templateName?: string;
        }
        interface AssistantTeleportTeleportNicknameSignals {
            /** Whether the nickname could also refer to a location. For example, "walmart", "starbucks". */
            hasLocationInterpretation?: boolean;
            /** Indicates whether the user has the app installed. */
            installInfo?: string;
            /**
             * True when the name is generic, i.e when it could refer to multiple packages from different developrs. For example, "mail" is considered a generic name (since it can refer to
             * "gmail", "yahoo mail" etc.) but "facebook" although could refer to both "facebook" and "facebook lite" is not considered generic (both packages are from the same third party).
             */
            isGeneric?: boolean;
            /** The tier of the nickname. */
            nicknameTier?: string;
            source?: string;
        }
        interface AssistantVerticalsCommonContactMatchSignal {
            /** Neural contact match similarity score. */
            matchScore?: number;
        }
        interface AssistantVerticalsHomeautomationProtoActionProjectConfig {
            /** Actions-on-Google action context ID. See go/sdm-hospitality-design. */
            contextId?: string;
        }
        interface AssistantVerticalsHomeautomationProtoAgentDeviceId {
            /** The agent's ID. Generally it is the agent's Google pantheon project id. */
            agentId?: string;
            /** Device ID defined by the agent. */
            deviceId?: string;
        }
        interface AssistantVerticalsHomeautomationProtoAgentInformation {
            authType?: string;
            deviceSource?: string;
            executionPath?: string;
            /** Unique Agent ID which maps to a specific Agent. Not using Agent Name here as it may change over time. */
            id?: string;
            /** Agent's foreign key that uniquely identifies a user's device. */
            key?: string;
        }
        interface AssistantVerticalsHomeautomationProtoAttribute {
            structureBasedRoutine?: AssistantVerticalsHomeautomationProtoCommonStructureBasedRoutine;
        }
        interface AssistantVerticalsHomeautomationProtoAttributes {
            attributeProtos?: AssistantVerticalsHomeautomationProtoAttribute[];
        }
        interface AssistantVerticalsHomeautomationProtoCommonEventTrigger {
            enabled?: boolean;
            /** Detailed settings for the event trigger; unset if not applicable. */
            eventTriggerPayload?: { [P in string]: any };
            /**
             * Different event type may have different settings. For example: * SCHEDULED will have event_trigger_payload of cs/symbol:assistant.verticals.voice_shortcut.proto.Schedule * LOCATION
             * will have event_trigger_payload of cs/symbol:assistant.verticals.voice_shortcut.proto.LocationTriggerEvent
             */
            eventTriggerType?: string;
            /** Unique identifier for the EventTrigger, e.g. SCHEDULED_ROUTINES. See the enum values of cs/symbol:WorkflowTriggerInput.TriggerSource */
            triggerSource?: number;
        }
        interface AssistantVerticalsHomeautomationProtoCommonStructureBasedRoutine {
            /** Whether this Routine is enabled or not. If false, then this Routine can't be triggered by Voice. */
            enabled?: boolean;
            /** The unique identifier for a class of workflows. For example: * "sbr_001" => Away * "sbr_002" => Home * "category_template" => CUSTOM */
            googlePreconfigWorkflowId?: string;
            language?: string;
            /** Internal format payload primarily for Routines team use. */
            payload?: { [P in string]: any };
            /** The security level of the Structure Based Routine as determined by the most security-sensitive task. */
            securityLevel?: string;
            shared?: boolean;
            storagePayload?: { [P in string]: any };
            structureId?: string;
            /** Voice or event triggers. */
            triggers?: AssistantVerticalsHomeautomationProtoCommonStructureBasedRoutineTrigger[];
            type?: string;
            /** UI format payload primarily for external team use. */
            uiPayload?: { [P in string]: any };
        }
        interface AssistantVerticalsHomeautomationProtoCommonStructureBasedRoutineTrigger {
            eventTrigger?: AssistantVerticalsHomeautomationProtoCommonEventTrigger;
            voiceTrigger?: AssistantVerticalsHomeautomationProtoCommonVoiceTrigger;
        }
        interface AssistantVerticalsHomeautomationProtoCommonVoiceTrigger {
            query?: string;
        }
        interface AssistantVerticalsHomeautomationProtoConciergeFeatures {
            conciergeProductFeatures?: string[];
        }
        interface AssistantVerticalsHomeautomationProtoDeviceTargetingOutputQueryInfo {
            /** The query span for device mention. */
            annotatedSpanDevice?: string;
            /** The query span for room mention. */
            annotatedSpanRoom?: string;
            /** The query span for structure mention. */
            annotatedSpanStructure?: string;
            /** This field is from query_info.processed_mentioned_span in DTO. */
            processedMentionedSpan?: string;
        }
        interface AssistantVerticalsHomeautomationProtoHomeAutomation_MetaData {
            /** Custom actions that this item supports. */
            actionProjectConfigs?: AssistantVerticalsHomeautomationProtoActionProjectConfig[];
            /** Agent details. */
            agentInformation?: AssistantVerticalsHomeautomationProtoAgentInformation;
            /**
             * Device ID that matches the ID passed from the device to discourse_context when a user issues a query to an Assistant-enabled device that is registered with Cast (via CCS (see
             * go/castservers)), or some other service.
             */
            assistantDeviceId?: string;
            /** Attributes data as provided from SYNC. This gets used in mutation and execution and in some potential cases, in biasing. */
            attributes?: { [P in string]: any };
            /**
             * See Device.creator_gaia_ids in //home/graph/proto/service/types.proto. If empty, the GAIA ID from the request EUC is assumed to be the creator. We only need at most one
             * creator_gaia_id.
             */
            creatorGaiaId?: string;
            /**
             * Any types that are not the given item type, but derived later. For example, if an item has type action.devices.types.OUTLET but is named "floor lamp" we can derive that it also has
             * type action.devices.types.LIGHT. Also considered along with |type| when triggering type-based actions.
             */
            derivedType?: string[];
            /** See note in home_graph.proto; loaded into DE now to avoid having to double-read assistant settings records as per go/smarthome-removing-assistant-settings */
            deviceModelId?: string;
            /** GCM address for cloud execution across google cloud messaging rather than 3p cloud; for future use. */
            gcmExecutionAddress?: string;
            /** The hash value from go/de-consistency-check */
            hashValue?: string;
            /** Whether local home platform should discover new devices via LAN for the structure. */
            lanscanOptedIn?: boolean;
            /** Model name from HomeGraph, populated from model_manifest.model_name. See b/200087451. */
            modelName?: string;
            /**
             * Indicates whether notifications have been enabled by a user and will be announced for this device. This is set by the user within the Google app settings, and Google will announce
             * the device notification only if both notification_supported_by_agent and notification_enabled_by_user are true.
             */
            notificationEnabledByUser?: boolean;
            /**
             * Indicates whether the device is capable of sending notifications. This field will be set by the agent (partner) on an incoming SYNC. If a device is not capable of generating
             * notifications, the partner should set this flag to false. If a partner is not capable of calling ReportStateAndNotification to send notifications to Google, the partner should set
             * this flag to false. If there is a user setting in the partner app to enable notifications and it is turned off, the partner should set this flag to false.
             */
            notificationSupportedByAgent?: boolean;
            /**
             * Store custom data for agent calls here. This will likely be short-lived -- we will replace this with calls to HGS. (Note: This may end up not temporary if we only need it for a
             * couple partners -- more efficient to have it on a few users than require HGS reads for all users.
             */
            opaqueCustomData?: string;
            /** Operational CHIP Node ID that combines the fabric ID and node id in format of . (Hex format without 0x prefix, for example, 0F001234FA67AA39.1234ABCD1111DDDD). */
            operationalNodeId?: string;
            /**
             * Other agent id + foreign id pairs associated with the device. This can be used to represent a group of devices (e.g. Sonos' bonded zone) as a single device, or a device that comes
             * in through different sync flows (e.g. Newman with a Nest camera).
             */
            otherDeviceIds?: AssistantVerticalsHomeautomationProtoAgentDeviceId[];
            /** Additional device sources. This can be the result of the device being merged with other devices with a different source. */
            otherDeviceSources?: string[];
            /**
             * LINT.IfChange(home_graph_single_parent) At the moment, we just have a single string. In future this will expand with additional metadata from client or cloud execution data store.
             * In today's 'tree' HomeGraph each object has a single parent. In the future this may have a mesh for complex cases -- zones, doors, etc -- so we make this a repeated element today.
             * LINT.ThenChange(//depot/google3/assistant/assistant_server/settings/user_defined_actions/footprints/footprint_accessor.cc:home_graph_single_parent)
             */
            parentNode?: string[];
            /**
             * The type of the parent. Currently only set for devices, to distinguish between structure and room parents. Items currently have only one parent, and entries after the first
             * parent_type are ignored.
             */
            parentType?: string[];
            /**
             * User-given nicknames for an entity (e.g. "My house"). These nicknames are unique to the gaia user. Nickname in DeviceInfo is per-entity level nickname, while personalized_nicknames
             * is per-user per-entity.
             */
            personalizedNicknames?: string[];
            /** Stores the location for the STRUCTURE type. */
            physicalLocation?: AssistantVerticalsHomeautomationProtoPhysicalLocation;
            /** We use this to determine if the synonyms matched in the aqua interpretation is plural. Then we will return disambiguate dialog or execute commands with all the targets. */
            plural?: string[];
            /**
             * Which of the values was the original, user-provided name -- or our disambiguated, cleaned-up version of it. This is what we use in TTS when we need to identify an object that wasn't
             * just spoken uniquely by the user -- in disambiguation dialogue, or in response to a collective interrogative (e.g. "what lights are on in the kitchen?")
             */
            primaryName?: string;
            /** User's role information for this device. This will be used in Home Automation server to decide if user has authority to fulfill its request. */
            roleInformation?: AssistantVerticalsHomeautomationProtoRoleInformation;
            /** Only present for a target device. Indicates this target device is reachable by a local (AoGH) path via an AoGH device. */
            routableViaGcm?: boolean;
            /** SAFT Document with linguistic annotations for the primary device name. */
            saftDocument?: NlpSaftDocument;
            /** Data needed for SDM (fleet management). See go/enterprise-id-in-assistant. */
            smartDeviceManagementData?: AssistantVerticalsHomeautomationProtoSmartDeviceManagementData;
            /** SmartHome feature flags that may be enabled per-item. */
            smartHomeFeatures?: AssistantVerticalsHomeautomationProtoSmartHomeFeatures;
            /** The features that are available for a structure. Will only be populated if the item_type == STRUCTURE. */
            supportedStructureFeatures?: AssistantVerticalsHomeautomationProtoSupportedStructureFeatures;
            /**
             * Map from agent ID to supported traits. Some devices (e.g. Newman) have multiple agents, with each agent being associated with a specific set of traits. This could alternatively have
             * been formatted as map as {trait, agent} pairs instead of the {agent, list of trait} pairs, but we retain this format to be consistent with HomeGraph's representation. In practice, a
             * trait should only be paired with a single agent (i.e. we should not have two agents with the same trait in their value list). This field is optional and should only be provided if
             * the item has multiple agents.
             */
            supportedTraitsByAgent?: { [P in string]: AssistantVerticalsHomeautomationProtoHomeAutomation_MetaDataSupportedTraits };
            /**
             * This device supports direct response -- if the device itself is issuing the query (which means it's also an assistant surface) we can return its payload directly rather than via
             * cloud.
             */
            supportsDirectResponse?: boolean;
            /**
             * Only present for an AoGH device. HGS Device ID of a target device and the signal strength (RSSI in dB, higher is better) between that target device and the AoGH device. If this map
             * is empty, there are no target devices reachable by this AoGH device.
             */
            targetDeviceSignalStrengths?: { [P in string]: string };
            /**
             * The timestamp at which the TDSS map was last updated. This information is used to help determine which hub would be preferred if multiple hubs report the same reach-ability for a
             * device.
             */
            tdssUpdateTimestamp?: string;
            /** For SHED devices, some traits can only be executed on 3P cloud, e.g. "action.devices.traits.MediaInitiation", "action.devices.traits.Channel" go/shed-per-trait-routing */
            traitRoutingHints?: HomeGraphCommonTraitRoutingHints[];
            /** Map from traits to routing table. Metadata includes preferred execution path per trait and, when Matter is preferred, which endpoint should be used for the trait. */
            traitRoutingTable?: { [P in string]: HomeGraphCommonRoutingTable };
            /**
             * Map of trait to a proto representing the attribute. This is different from the attributes field above which is represented as a struct. The attributes here are represented as protos
             * and will require specific support per trait.
             */
            traitToAttributeProtos?: { [P in string]: AssistantVerticalsHomeautomationProtoAttributes };
            /** The item type, such as "action.devices.types.VACUUM" - to be used in triggering type-based actions, e.g. "start vacuuming": go/smarthome-type-based-actions. */
            type?: string;
            /** The priority order of speech targeting: 1. user_defined_device_type 2. derived_device_type 3. device_type */
            userDefinedDeviceType?: string;
            /**
             * Set to which level of voice match is needed. Enum based on string input from the partner in json sync. Values accepted: "none" (but in this case partners won't set it), "owner"
             * [requires matching one of the creator gaia IDs], or "member" [any recognized voice 'enrolled' on the device]. This may expand; only "owner" is in use for first partner, Tile.
             */
            voiceMatchRequired?: string;
            /** This device will report state; we can query realtime state from local HGS rather than slow QUERY intent to the 3p cloud. */
            willReportState?: boolean;
            /** SAFT Document with linguistic annotations for the zone name, if applicable. */
            zoneNameSaftDocument?: NlpSaftDocument;
        }
        interface AssistantVerticalsHomeautomationProtoHomeAutomation_MetaDataSupportedTraits {
            traits?: string[];
        }
        interface AssistantVerticalsHomeautomationProtoHomeAutomationDevice {
            /** the next 3 fields are for Lumos output (DTO) that needs to be propagated to the Fulfilment through the HomeAutomationDevice proto. */
            deviceSelectionLog?: AssistantLogsDeviceSelectionLog;
            dtoError?: AssistantDeviceTargetingDeviceTargetingError;
            /** This field is from query_info in DTO. */
            dtoQueryInfo?: AssistantVerticalsHomeautomationProtoDeviceTargetingOutputQueryInfo;
            /** Device meta data. */
            homeautomationMetadata?: AssistantVerticalsHomeautomationProtoHomeAutomation_MetaData;
            /** list of HomeAutomationDeviceItem. After migration completes, we will mark the above 4 field as deprecated and only use this field. */
            list?: AssistantVerticalsHomeautomationProtoHomeAutomationDeviceItem[];
            /** Corresponding to casse matched_item CustomTypeItem key. */
            matchedItemKey?: string;
            /** Corresponding to casse Argument raw_value. */
            matchedItemRawvalue?: string;
            /** Corresponding to casse matched_item CustomTypeItem value. */
            matchedItemValue?: string[];
        }
        interface AssistantVerticalsHomeautomationProtoHomeAutomationDeviceItem {
            /** Device meta data. */
            homeautomationMetadata?: AssistantVerticalsHomeautomationProtoHomeAutomation_MetaData;
            /** Corresponding to casse matched_item CustomTypeItem key. */
            matchedItemKey?: string;
            /** Corresponding to casse Argument raw_value. */
            matchedItemRawvalue?: string;
            /** Corresponding to casse matched_item CustomTypeItem value. */
            matchedItemValue?: string[];
        }
        interface AssistantVerticalsHomeautomationProtoPhysicalLocation {
            address?: string;
            geoLocation?: GoogleTypeLatLng;
        }
        interface AssistantVerticalsHomeautomationProtoRoleInformation {
            /** When true, role_type will be ignored, Nest IAM RPC will called to check authority. */
            iamCheckRequired?: boolean;
            roleType?: string;
        }
        interface AssistantVerticalsHomeautomationProtoSmartDeviceManagementData {
            /**
             * The enterprise that owns the structure. E.g. Disney, Dream Hotel, etc. This is used for log/analytics purpose. For privacy reasons, we log at enterprise level instead of structure
             * level.
             */
            enterpriseId?: string;
        }
        interface AssistantVerticalsHomeautomationProtoSmartHomeFeatures {
            /** Flag indicating whether the background Circadian Lighting effect is enabled for a particular light (go/circadian-lighting-e2e). */
            circadianLightingEnabled?: boolean;
            /** Flag indicating whether automatic Energy Savings are enabled for this item. */
            energySavingsEnabled?: boolean;
            /** Flag indicating whether Gentle Wake Up is enabled for this item (go/sleep-wake-design). */
            gentleWakeupEnabled?: boolean;
            /**
             * Flag indicating whether the user has enabled / disabled sending Home/Away status updates to the device through the Google custom IntelligenceEvents Matter cluster.
             * (go/google-clusters-design)
             */
            homeAwayOverMatterEnabled?: boolean;
        }
        interface AssistantVerticalsHomeautomationProtoSupportedStructureFeatures {
            conciergeFeatures?: AssistantVerticalsHomeautomationProtoConciergeFeatures;
        }
        interface AttentionalEntitiesMentionProperties {
            /** The unique device on which the mention occurred. For example, if the user has two Google Home devices, this indicates which of the two was used. */
            deviceId?: AssistantApiCoreTypesDeviceId;
            /**
             * ID of the event that resulted in this entity mention. For user and system turn AEs, this is taken from the ConversationSnapshotId of the snapshot containing this mention. For client
             * AEs, this is empty. This can be used to join back this particular mention to the specific "turn" in which this mention took place.
             */
            eventId?: EventIdMessage;
            /** If this mention corresponds to a WebAnswer, then this defines the score associated with that answer. */
            factoidScore?: number;
            /** If present, this entity was mentioned as part of a larger list. */
            listEntryInfo?: AttentionalEntitiesMentionPropertiesListEntryInfo;
            /** Estimates the recency of the mention. This is internally computed at runtime on a turn-by-turn basis. */
            recency?: string;
            /** The semantic role that the entity was used in. */
            role?: AttentionalEntitiesSemanticRoleId;
            /** How salient this mention is. This field will only be set if the mention is derived from a SearchAnswerValue. See go/webresultsdata-as-aes for more details. */
            salience?: string;
            /** Contains metadata about the source of the mention. */
            source?: AttentionalEntitiesMentionPropertiesSource;
            /** If present, properties of visual mentions (e.g., how they are displayed to the user, visibility, etc.). */
            spatialProperties?: AttentionalEntitiesSpatialProperties;
            /** Details about how this mention was presented. */
            surfaceForm?: AttentionalEntitiesSurfaceForm;
            /**
             * Unix timestamp noting (approximately) when this mention occurred. We do not guarantee that the time will correspond precisely to when the user uttered/heard a response. If mentions
             * within a single turn have *different* timestamps, they should accurately reflect the order in which the mentions occurred. If that order is unknown, they should all have the same
             * timestamp.
             */
            timestamp?: string;
        }
        interface AttentionalEntitiesMentionPropertiesListEntryInfo {
            /** The index of the entity presented to the user. NOTE: Indexing starts from 0. */
            index?: string;
            /**
             * A string which uniquely identifies the list item this entity represents in the list. For example, consider the "OrderPizza" intent with the "size" slot: U: I want to order a pizza
             * A: Sure. What size do you want: large, medium, or small? U: Gigantic The lexical_groundings_id can be "large" to identify the large item in the list. This lexical_groundings_id
             * together with the semantic role fields (i.e., role.intent_id & role.role_id) can be used to match the nlp_semantic_parsing::LexicalGroundings::ValueTermType to utilize lexical
             * grounding for i18n of static list selection items. Note that this field only needs to be populated when developers expect to provide lexical groundings for the list item this entity
             * represents. Effectively, this field will be populated when this entity is published by ListPresentationFrame and the
             * ::quality::dialog_manager::IntentStageSignals::FieldCandidate.lexical_groundings_id field is populated. See go/lpf-i18nv2 & go/taskstate-ae-sync for more details.
             */
            lexicalGroundingsId?: string;
        }
        interface AttentionalEntitiesMentionPropertiesSource {
            client?: any;
            system?: any;
            user?: any;
        }
        // tslint:disable-next-line:no-empty-interface
        interface AttentionalEntitiesMentionPropertiesSourceClient {
        }
        // tslint:disable-next-line:no-empty-interface
        interface AttentionalEntitiesMentionPropertiesSourceSystem {
        }
        // tslint:disable-next-line:no-empty-interface
        interface AttentionalEntitiesMentionPropertiesSourceUser {
        }
        interface AttentionalEntitiesSemanticRoleId {
            /**
             * Semantic roles will be defined locally, within the context of a single task/feature. The |intent_id| is a unique identifier for such a local cluster. In most cases, this should be
             * exactly the same as the name of the intent used for TaskState (see go/assistant-intent-catalog). In cases where the intent isn't well-defined, this can be an arbitrary,
             * feature-defined identifier.
             */
            intentId?: string;
            /**
             * Identifier for a semantic role, unique within the namespace of |intent_id|. When this role corresponds to a slot in the intent, the |role_id| should be equal to the name of that
             * argument. For example, consider an entry in the intent catalog: core_intent { id { id: "BookARide" } slot { name: "provider" type { string_type { } } } slot { name: "num_riders"
             * type { number_type { } } } } Then, the |role_id| would be "provider" or "num_riders" when referring to one of these slots. NOTE: when responding to the user, the Assistant may
             * actually make use of other roles such as "ETA" or "driver" that are not part of the intent declaration. These should still be assigned consistent semantic roles. For example, a
             * dialog with the Shopping feature: User: Where can I buy XYZ? Google: [Best Buy in Sunnyvale] has [XYZ] in stock. User: Great! Give me directions. In this case, both "Best Buy" and
             * "XYZ" would be pushed to attentional entities. Best Buy, in this case, may not be an argument in the ShoppingItemStockInquiry intent, but should still have a consistent |role_id|
             * such as "possessing_business".
             */
            roleId?: string;
        }
        interface AttentionalEntitiesSpatialProperties {
            visibility?: string;
        }
        interface AttentionalEntitiesSurfaceForm {
            text?: string;
        }
        interface BiasingPerDocData {
            biasingfield?: BiasingPerDocDataBiasingField[];
        }
        interface BiasingPerDocData2 {
            biasingField?: BiasingPerDocData2BiasingField[];
        }
        interface BiasingPerDocData2BiasingField {
            /** A fingerprint of the actual name of the field. */
            compressedName?: number;
            /** The value, under various representations to get maximum compression. Exactly one of them is guaranteed to be filled. value as a double. */
            value?: number;
            /** a floating value, represented as an integer by converting using floating_value * 1000. Useable for all floating values that need 3 digits of precision, and are small enough. */
            valueFloat?: number;
            /** value as an int32. When the value is encode-able as an integer. */
            valueInt?: number;
        }
        interface BiasingPerDocDataBiasingField {
            /** Fingerprint of the attribute name (no need to keep long field names) */
            Name?: string;
            /** Biasing value translated into a double for uniform comparison */
            Value?: number;
        }
        interface BlobstoreBlobRef {
            BlobID?: string;
            Options?: string;
            RefID?: string;
            ShardBin?: number;
            /** Size of the complete blob, in bytes. */
            Size?: string;
            /** The ID of the V2 blob this blob has */
            SourceV2BlobID?: string;
            /** Deprecated. */
            V2ReadBlobToken?: string;
        }
        interface BlogPerDocData {
            /** used for blogurl crowding. */
            blogurlFp?: string;
            /** This score captures how spammy the client is that the micropost was created with. The higher the score the worse. */
            clientSpamminess?: number;
            /** For the threaded conversation view. Only populated in docs with provider type SYNTHETIC_CONVERSATION_DOC. */
            convTree?: BlogsearchConversationTree;
            copycatScore?: number;
            docQualityScore?: number;
            /**
             * A syntactic reshare is a document that is * created from an original and shared with friends and * we detect this resharing property by syntactically parsing the doc. . For example,
             * a retweet is an example of a syntactic_reshare because we can detect that it's a reshare by grepping for "RT @".
             */
            isSyntacticReshare?: boolean;
            /** Experimental data for quality experiments. This will NOT be populated in prod, but we will use this for experiments. */
            microblogQualityExptData?: any;
            /** For replies/reshares. num_mentions = number of times the pattern @foo appears in the document. */
            numMentions?: number;
            outlinks?: BlogPerDocDataOutlinks[];
            /** The fingerprint for the body text of the microblog post. It is copied from MicroBlogPost.post_content_fingerprint. */
            postContentFingerprint?: number;
            qualityScore?: number;
            /** Blog scoring signals. */
            spamScore?: number;
            universalWhitelisted?: boolean;
            /** User and doc quality scores for updates (aka microposts). */
            userQualityScore?: number;
        }
        interface BlogPerDocDataOutlinks {
            /**
             * Representative id for an equivalence class of URLs. E.g. http://youtube.com/watch?v=12 and http://youtube.com/watch?v=12&feature=related have the same aggregation id since they're
             * effectively the same webpage
             */
            aggregationFp?: string;
            resolvedUrl?: string;
            siteSpamScore?: number;
            title?: string;
        }
        interface BlogsearchConversationNode {
            /** The username of the author of the microblog post represented by this node. */
            authorName?: string;
            /** A list of docids of child nodes. */
            children?: string[];
            /** The creation date of the doc. */
            date?: string;
            /** Docid of the microblog post represented by this node. */
            docid?: string;
            /** The docid of the parent node. The root of the tree will leave this empty. */
            parent?: string;
        }
        interface BlogsearchConversationTree {
            /** The id of this conversation. */
            convId?: string;
            /** The nodes in this conversation. No particular order is assumed. */
            nodes?: BlogsearchConversationNode[];
        }
        interface BlueGingerClientVisibleProtoBlueGingerSupportedServices {
            /** List of supported modules for a business. */
            modules?: BlueGingerClientVisibleProtoBlueGingerSupportedServicesBlueGingerModule[];
        }
        interface BlueGingerClientVisibleProtoBlueGingerSupportedServicesBlueGingerModule {
            /** Module name, e.g. hairdresser_reservation. from quality/views/extraction/kcube/bg/modules/modules.bzl. */
            name?: string;
            /** Services of this module that are supported by the business, e.g. haircuts. */
            services?: string[];
        }
        interface BookCitationPerDocData {
            /** the book id for the main citation */
            bookId?: string;
            /** the discretized citation score for the main book. we map the raw score 1.0-20.0 to 0 - 127 */
            discretizedCitationScore?: number;
            /** Is there a preview or excerpt of the book on this document? */
            previewable?: boolean;
            /** book id for the second citation if we can't separate the two top citations (they are too close). */
            secondBookId?: string;
            /** the discretized score for the second citation */
            secondDiscretizedCitationScore?: number;
        }
        interface BusinessHours {
            dayopen?: number;
            interval?: BusinessHoursInterval[];
        }
        interface BusinessHoursInterval {
            /** The interval ends at the start of this second */
            end?: number;
            /** Time in seconds since Midnight-Monday-Morn */
            start?: number;
        }
        interface ChatBotPlatformBotSendToken {
            /** Time since epoch (micros) that this will expire */
            expiryTimeMicros?: string;
            /** Encrypted InternalSendToken */
            sendToken?: string;
        }
        interface ChatBotPlatformFireballId {
            /**
             * When used as a user ID, it's the phone number of the sender. When used as a session ID: For group conversation, it is the group ID. For 1 to 1, it is the receiver or sender phone
             * number. For 1 to bot, it is the receiver phone number or empty.
             */
            id?: GoogleInternalCommunicationsInstantmessagingV1Id;
        }
        interface ClassifierPornAggregatedUrlPornScores {
            averageUrlPornScore?: number;
            urlCount?: number;
        }
        interface ClassifierPornClassifierData {
            classification?: ClassifierPornClassifierDataClassification[];
            /** Records whether the image linker is run already. This is only used for Alexandria but NOT for Segindexer. */
            imageBasedDetectionDone?: boolean;
            timestamp?: string;
        }
        interface ClassifierPornClassifierDataClassification {
            label?: string;
            score?: number;
        }
        interface ClassifierPornDocumentData {
            classifierdata?: ClassifierPornClassifierData;
            sitedata?: ClassifierPornSiteData;
        }
        interface ClassifierPornQueryClassifierOutput {
            /** This field is only filled for the CSAI vertical. */
            csaiClassification?: string;
            /**
             * DO NOT USE: This field is temporary and should be used only for the CSAI Onebox. This field is the result of the regular expression classifier alone as opposed to a combination with
             * Seti classifier as in csai_classification field.
             */
            csaiRegexpHighConfidenceClassification?: string;
            /** Human-readable debug information about the classification. This field is only set if output_debug is set in the classification input. */
            debug?: string;
            /** The bit that shows if this classifier outputs positive classification for the input query. Set by thresholding with a recommended threshold. */
            isPositive?: boolean;
            /** The score that the classifier assigned to the input query. This is filled by all verticals. */
            score?: number;
        }
        interface ClassifierPornQueryMultiLabelClassifierOutput {
            csai?: ClassifierPornQueryClassifierOutput;
            fringe?: ClassifierPornQueryClassifierOutput;
            medical?: ClassifierPornQueryClassifierOutput;
            offensive?: ClassifierPornQueryClassifierOutput;
            porn?: ClassifierPornQueryClassifierOutput;
            spoof?: ClassifierPornQueryClassifierOutput;
            violence?: ClassifierPornQueryClassifierOutput;
            vulgar?: ClassifierPornQueryClassifierOutput;
        }
        interface ClassifierPornQueryStats {
            /** A query text porn score for the queries which have clicks to the image: query_text_porn_score := sum(clicks(query) * text_porn_score(query)) / sum(clicks(query)) */
            queryTextPornScore?: number;
            totalClicks?: number;
        }
        interface ClassifierPornReferrerCounts {
            adult?: number;
            /** Number of referrers which are classified as porn and as adult. */
            porn?: number;
            /** Total number of referrers. */
            total?: number;
        }
        interface ClassifierPornSiteData {
            /** The average pedo page score for the site. */
            avgPedoPageScore?: number;
            finalPedoSiteScore?: number;
            /** The number of pages that were used to compute the scores and ratios. */
            numberOfPages?: string;
            /** The number of pages with pedo restrict. */
            numberOfPedoPages?: string;
            /** The ratio of porn/softporn of the site this page belongs to. */
            sitePornRatio?: number;
            siteSoftpornRatio?: number;
            versionedscore?: ClassifierPornSiteDataVersionedScore[];
            violenceStats?: ClassifierPornSiteViolenceStats;
        }
        interface ClassifierPornSiteDataVersionedScore {
            score?: number;
            siteRule?: string[];
            version?: number;
            /** Please talk to safesearch@ before relying on any of these internal fields: */
            verticals4Score?: number;
        }
        interface ClassifierPornSiteViolenceStats {
            meanFinalViolenceScore?: number;
            numberOfImages?: string;
            numberOfVideos?: string;
            videoViolenceScore?: number;
        }
        interface CommerceDatastoreDeepTag {
            /**
             * The confidence of the tag, encoded to 14 bits (range [0, 16383]). Due to modeling details, a large number of tags become trustworthy with confidence greater than 0.001, so two bytes
             * of precision are required.
             */
            confidence?: number;
            /** A Deep Tag enum in uint32 form. */
            tag?: number;
        }
        interface CommerceDatastoreImageDeepTags {
            /**
             * The set of outputs for a series of model versions. The size of this field should not extend beyond 4 at any time: two versions for slow-update track dependencies, and two versions
             * for fast-update track dependencies.
             */
            modelOutputs?: CommerceDatastoreImageDeepTagsModelOutput[];
        }
        interface CommerceDatastoreImageDeepTagsModelOutput {
            backgroundType?: CommerceDatastoreDeepTag;
            collage?: CommerceDatastoreDeepTag;
            /** We are looking to deploy a model for the Ads team to identify images with bad cropping. The model will be for Ads only and we will not populate the cropping field in CDS. */
            cropping?: CommerceDatastoreDeepTag;
            modelType?: CommerceDatastoreDeepTag;
            /** Tag corresponds to the shopping non-family safe (nfs) image signal. */
            nfs?: CommerceDatastoreDeepTag;
            objectCount?: CommerceDatastoreDeepTag;
            /** Tag corresponding to unwanted text overlay (watermarks, logos, promotional elements, artifacts, etc). */
            overlay?: CommerceDatastoreDeepTag;
            selfie?: CommerceDatastoreDeepTag;
            /** Tag corresponding to the text overlay classifier (watermarks, logos, promotional elements, artifacts, etc). */
            textOverlay?: CommerceDatastoreDeepTag[];
            version?: number;
        }
        interface CompositeDoc {
            /** Contains necessary information to enforce row level Docjoin access control. */
            accessRequirements?: IndexingPrivacyAccessAccessRequirements;
            additionalchecksums?: CompositeDocAdditionalChecksums;
            alternatename?: CompositeDocAlternateName[];
            anchors?: Anchors;
            anchorStats?: IndexingDocjoinerAnchorStatistics;
            /** This field is present iff the page has a bad SSL certificate itself or in its redirect chain. */
            badSslCertificate?: IndexingBadSSLCertificate;
            /** Visible content checksum as computed by repository::parsehandler::checksum::Checksum96bitsParseHandler. The value is a Fprint96 in "key format" (i.e., by Fprint96::AsKey()). */
            ContentChecksum96?: string;
            cseId?: QualityProseCSEUrlInfo[];
            /** URL should only be selected for CSE Index if it's pagerank is higher than cse_pagerank_cutoff. */
            csePagerankCutoff?: number;
            /** Contains the tracking version of various data fields in CompositeDoc. */
            dataVersion?: IndexingDocjoinerDataVersion;
            doc?: GDocumentBase;
            /** A generic container to hold document annotations and signals. For a full list of extensions live today, see go/wde. */
            docAttachments?: any;
            /**
             * Info about "selected" images associated with the document for which we (already) have ImageData. For each image URL, some fixed number of documents are selected as web referrers for
             * the image URL, and within those selected documents, we say the image is "selected". Within the remaining documents, we say the image is "rejected". Note that this distinction is
             * slightly different from selected for indexing. Only images within doc_images where is_indexed_by_imagesearch is true will be selected for indexing. You can find the rejected images
             * at composite_doc.doc_attachments().get(). You can find images that are selected, but for which we have no ImageData (yet) at
             * composite_doc.image_indexing_info().selected_not_indexed_image_link()
             */
            docImages?: ImageData[];
            /**
             * This message set is used for data pushed into the index using the signals framework that is never to be used in Mustang or TG Continuum scoring/snippeting code. Any protocol buffer
             * stored in this message set is automatically returned in a docinfo response - it ends up in the "info" message set in the WWWSnippetResponse, so it can be used in post-doc twiddlers
             * and for display in GWS with no code changes in Mustang or Teragoogle.
             */
            docinfoPassthroughAttachments?: any;
            /** Info about videos embedded in the document. */
            docVideos?: ImageRepositoryVideoProperties[];
            /**
             * Data produced by the embedded-content system. This is a thin message, containing only embedded_links_info data for the embedder and JavaScript/CSS embedded links (the
             * embedded-content bigtable also contains snapshots, compressed document trees and all embedded link types). Provided using the index signal API.
             */
            embeddedContentInfo?: IndexingEmbeddedContentEmbeddedContentInfo;
            extradup?: CompositeDocExtraDup[];
            forwardingdup?: CompositeDocForwardingDup[];
            includedcontent?: CompositeDocIncludedContent[];
            indexinginfo?: CompositeDocIndexingInfo;
            /** Serialized indexing intermediate data. */
            indexingIntermediate?: string;
            /** This field associates a document to particular labels and assigns confidence values to them. */
            labelData?: QualityLabelsGoogleLabelData;
            liveexperimentinfo?: CompositeDocLiveExperimentInfo;
            localinfo?: LocalWWWInfo;
            /**
             * Localized alternate names are similar to alternate names, except that it is associated with a language different from its canonical. This is the subset of webmaster-provided
             * localized alternate names being in the dup cluster of this document. Used during serving for swapping in the URL based on regional and language preferences of the user.
             */
            localizedAlternateName?: IndexingConverterLocalizedAlternateName[];
            localizedvariations?: CompositeDocLocalizedVariations;
            /** Only present in partial cdocs. */
            partialUpdateInfo?: CompositeDocPartialUpdateInfo;
            perDocData?: PerDocData;
            /** Porn related data used for image and web search porn classification as well as for diagnostics purposes. */
            porninfo?: ClassifierPornDocumentData;
            properties?: DocProperties;
            /** Contains information necessary to perform policy decision on the usage of the data assosiated with this cdoc. */
            ptoken?: PtokenPToken;
            qualitysignals?: CompositeDocQualitySignals;
            /** Information about the most recent creation and expiration of this domain. It's extracted from domainedge signal. */
            registrationinfo?: RegistrationInfo;
            /**
             * If present, indicates that some content was inserted, deleted, or replaced in the document's content (in CompositeDoc::doc::Content::Representation), and stores information about
             * what was inserted, deleted, or replaced.
             */
            richcontentData?: IndexingConverterRichContentData;
            /** rich snippet extracted from the content of a document. */
            richsnippet?: RichsnippetsPageMap;
            robotsinfolist?: CompositeDocRobotsInfoList;
            /** to copy to per-doc */
            scaledIndyRank?: number;
            /**
             * Sitelinks: a collection of interesting links a user might be interested in, given they are interested in this document. WARNING: this is different from the crawler Sitemaps (see
             * SitemapsSignals in the attachments).
             */
            sitemap?: Sitemap;
            /** Row timestamp in CDoc storage. */
            storageRowTimestampMicros?: string;
            subindexid?: string[];
            syntacticDate?: QualityTimebasedSyntacticDate;
            /**
             * WARNING!!! "url" field in CompositeDoc is optional, and is usually missing: e.g., Docjoin CompositeDoc's don't have CompositeDoc::url. has_url() checking is often useful. So don't
             * rely on CompositeDoc::url unless you're sure otherwise. Usually you want to use CompositeDoc::doc::url instead.
             */
            url?: string;
            /** Date in the url extracted by quality/snippets/urldate/date-in-url.cc This is given as midnight GMT on the date in question. */
            urldate?: string;
        }
        interface CompositeDocAdditionalChecksums {
            /** Same as ContentChecksum96 but without transient boilerplate. */
            NoTransientChecksum96?: string;
            /** Deprecated. Use simhash_v2 and simhash_v2_significance instead. */
            SimHash?: string;
            SimHashIsTrusted?: boolean;
            /**
             * Simhash-v2 is generated by SimHashParseHandler, designed as a complete replacement of simhash-v1 (a.k.a. the original simhash above) from ApproxDupsParseHandler. Simhash-v2 uses a
             * revised algorithm so that it is expected to work better in most cases than simhash-v1. They coexist in current transition period, then simhash-v1 will be retired.
             */
            simhashV2?: string;
            /**
             * Simhash-v2-significance is used to describe the confidence about the corresponding simhash-v2 value. It is defined as the average absolute difference from zero of all internal state
             * components when finalizing a simhash-v2 value in HashMultiSetDotCauchy. We used to compare the significance against some pre-defined threshold (default: 20) to get a boolean value
             * "trusted_simhash_v2". However, it is possible that this field is missing while "simhash_v2" is present, in such case (1) Use "SimHashIsTrusted" instead if it is present, AND/OR (2)
             * Assume "simhash_v2" is trusted if its value is non-zero.
             */
            simhashV2Significance?: number;
        }
        interface CompositeDocAlternateName {
            /** Fp96 of webmirror equivalence class as of last time this was exported. */
            ecnFp?: string;
            Url?: string;
            /** See webutil/urlencoding */
            UrlEncoding?: number;
        }
        interface CompositeDocExtraDup {
            /** Fp96 of webmirror equivalence class as of last time this was exported. */
            ecnFp?: string;
            /** The url of the non-forwarding dup. */
            url?: string;
        }
        interface CompositeDocForwardingDup {
            /** The name of the url's webmirror equivalence class. */
            ecn?: string;
            ecnFp?: string;
            /**
             * The purpose(s) of the forwarding dup indicating if it is used for forwarding signal/anchors generally, or only for forwarding some specific signal (e.g. navboost), or for some other
             * purposes (e.g., not for forwarding any data but for making "info:" complete). See indexing/dups/public/dups.h for more details.
             */
            purposes?: number;
            /** Raw pagerank of the url. */
            rawPagerank?: number;
            /** The webmirror repid of the forwarding dup. */
            repid?: string;
            /** The url of the forwarding dup. */
            url?: string;
            /** The encoding of the url (see webutil/urlencoding for details). */
            urlencoding?: number;
        }
        interface CompositeDocIncludedContent {
            includedDoc?: GDocumentBase;
            linkUrl?: string;
            perDocData?: PerDocData;
            properties?: DocProperties;
            /**
             * Indicate how this content came to be included. Legal values are constructed by bitwise-OR-ing values from the included_content::SourceType enum. Default SourceTypeBitfield =
             * included_content::INCLUDED_FRAME
             */
            SourceTypeBitfield?: string;
        }
        interface CompositeDocIndexingInfo {
            /** To hold extra info for building a final cdoc from raw cdoc and goldmine annotations. */
            cdocBuildInfo?: IndexingDocjoinerCDocBuildInfo;
            /**
             * Whether current page is under content protection, i.e. a page has been crawled as an error page, but we preserve its last known good content and keep its crawl_status as
             * converter.CrawlStatus::CONTENT.
             */
            contentProtected?: boolean;
            /**
             * If set, indicates that the crawl status was converted to ROBOTED for the reason specified by the enum value in converter.RobotedReasons.ConvertToRobotedReasons. See
             * indexing/converter/proto/converter.proto for details. If unset, then the document was not converted to roboted, and if the document crawl status is ROBOTED, then the document is
             * disallowed (at least to Google) in robots.txt.
             */
            convertToRobotedReason?: number;
            /**
             * One of the enum values in converter.CrawlStatus.State (see indexing/converter/proto/converter.proto for details). Default is converter.CrawlStatus::CONTENT. The document is roboted
             * if the value is converter.CrawlStatus::ROBOTED.
             */
            crawlStatus?: number;
            demotionTags?: string[];
            /** One of the enum values in converter.ErrorPageType (see indexing/converter/proto/error-page-detector-enum.proto for detail). Default is converter::ERROR_PAGE_NONE. */
            errorType?: number;
            freshdocsCorpora?: string[];
            /** The host id of the document. Used chiefly to determine whether the document is part of a parked domain. */
            hostid?: string;
            /** A short descriptive string to help identify the IE application or setup where this CDoc is generated. For example: websearch_m3 This field is for debuggability purposes. */
            ieIdentifier?: string;
            /** Indexing info about images (i.e. image links missing image data, etc). */
            imageIndexingInfo?: ImageSearchImageIndexingInfo;
            /**
             * The timestamp (the time since the Epoch, in microseconds) when the docjoin is exported from indexing. The main purpose of this field is to identify different versions of the same
             * document.
             */
            indexingTs?: string;
            /**
             * Page is deleted when indexing choice flips between different corpora (e.g. desktop, mobile, archive, scholar, etc.) for the same URL. It's only set for deletion cdocs. Downstreams
             * using URL as key should ignore the current deletion if the field is set.
             */
            isSiblingDeletion?: boolean;
            /**
             * If set, the timestamp in microseconds when the URL stopped being canonical. This should never be set for exported canonical documents. This field is used by dups during canonical
             * flip, and by webmain when doc selection switched between desktop and mobile. Union respects this timestamp to prevent old doc being deleted until the new doc is picked up
             */
            noLongerCanonicalTimestamp?: string;
            /**
             * This score is calculated by re-mapping the back onto the partition's score distribution, such that the score represents the score of the equivalently ranked organically-selected
             * document.
             */
            normalizedClickScore?: number;
            /** The raw navboost count for the canonical url without aggregating the navboost from dup urls. This field is used when building forwarding map. */
            rawNavboost?: number;
            /**
             * The timestamp (the time since the Epoch, in microseconds) to represent doc version, which is used in the downstream processing after Raffia. If it's not set, indexing_ts will be
             * used as row_timestamp. The timestamp is generally set by reprocessing to set slightly newer indexing_ts such that the system can respect the reprocessed version to overwrite old
             * data in storage.
             */
            rowTimestamp?: string;
            /** Selection tier rank is a language normalized score ranging from 0-1 over the serving tier (Base, Zeppelins, Landfills) for this document. */
            selectionTierRank?: number;
            /**
             * The tracing ids is to label the version of url for url status tracking. This repeated field will carry at most 10 tracing id. See more details in go/rich-tracing-design There will
             * be less than 2% base+uz cdocs carrying this field. The major sources of tracing ids include: * Indexing API pushed urls * Index Metrics sampling urls The tracing ids will be written
             * into cdocs by Webmain Ramifier. The consumer of the tracing ids is Union serving notification collector see more at go/serving-notification-from-union
             */
            tracingId?: string[];
            /** Changerate information for this doc (see crawler/changerate/changerate.proto for details). */
            urlChangerate?: CrawlerChangerateUrlChangerate;
            /**
             * Url change history for this doc (see crawler/changerate/changerate.proto for details). Note if a doc has more than 20 changes, we only keep the last 20 changes here to avoid adding
             * to much data in its docjoin.
             */
            urlHistory?: CrawlerChangerateUrlHistory;
            /** UrlPatternSignals for this doc, used to compute document score in LTG (see indexing/signal_aggregator/proto/signal-aggregator.proto for details). */
            urlPatternSignals?: IndexingSignalAggregatorUrlPatternSignals;
            /** Indexing info about videos. */
            videoIndexingInfo?: ImageRepositoryVideoIndexingInfo;
        }
        interface CompositeDocLiveExperimentInfo {
            /** List of necessary information for each live experiments. */
            perLiveExperimentInfo?: CompositeDocLiveExperimentInfoPerLiveExperimentInfo[];
        }
        interface CompositeDocLiveExperimentInfoPerLiveExperimentInfo {
            /** ID of a live experiment. */
            experimentId?: string;
            /** Partial CDoc for a live experiment. */
            partialCdoc?: CompositeDoc;
        }
        interface CompositeDocLocalizedVariations {
            /** A subset of computed variations, only the members which are dups to the main url. Used during serving for swapping in the URL based on regional and language preferences of the user. */
            dupsComputedAlternateNames?: IndexingDupsComputedLocalizedAlternateNamesLocaleEntry[];
            /**
             * All localized alternate names provided by the webmaster (canonical and dups, indexed and not-indexed). Used on the ranking side for swapping out results based on the webmaster
             * preference.
             */
            webmasterAlternateNames?: IndexingConverterLocalizedAlternateName[];
        }
        interface CompositeDocPartialUpdateInfo {
            /** List of goldmine annotator updates present in the enclosing partial cdoc. */
            goldmineAnnotatorNames?: string[];
            /** List of images signal updates present in the enclosing partial cdoc. Images signal name for a images signal is the unique name for the signal according to SignalSpec. */
            imagesSignalNames?: string[];
            /** Contains last full indexing information for partial updates. */
            lastFullIndexingInfo?: CompositeDocPartialUpdateInfoLastFullIndexingInfo[];
            /** Which tier we should do cdoc lookup to merge partial cdocs. This uses the integer value of indexing.selection.CorpusId. NOT intended for other usage. */
            shouldLookupDocjoinsTier?: number;
            /** List of signal updates present in the enclosing partial cdoc. Signal name for a signal is unique name for the signal according to SignalSpec. */
            signalNames?: string[];
        }
        interface CompositeDocPartialUpdateInfoLastFullIndexingInfo {
            /** The corpus of last full updates. */
            corpus?: string;
            /** Last full update indexing timestamp in microseconds. */
            lastFullIndexingTsMicros?: string;
        }
        interface CompositeDocQualitySignals {
            /**
             * Contains a date used for the "Date Last Modified" toolbelt restrict mode. Note: this date is a combined date and is different from the pure shingle-based signal stored in
             * contentage.last_significant_update field.
             */
            lastSignificantUpdate?: QualityTimebasedLastSignificantUpdate;
            oldnessInfo?: QualityTimebasedOldnessInfo;
            pagetype?: QualityTimebasedPageType;
        }
        interface CompositeDocRobotsInfoList {
            newsRobotsInfo?: IndexingConverterRobotsInfo;
        }
        interface CompressedQualitySignals {
            /** anchor_mismatch_demotion: converted from QualityBoost.mismatched.boost. */
            anchorMismatchDemotion?: number;
            /** authority promotion: converted from QualityBoost.authority.boost */
            authorityPromotion?: number;
            /** baby_panda_demotion: converted from QualityBoost.rendered.boost. */
            babyPandaDemotion?: number;
            /** New BabyPanda demotion, applied on top of Panda. This is meant to replace |baby_panda_demotion|. */
            babyPandaV2Demotion?: number;
            /** Impressions, unsquashed, host level, not to be used with compressed ratios. Not to be used in Pattern Data. */
            crapsAbsoluteHostSignals?: number;
            crapsNewHostSignals?: string;
            crapsNewPatternSignals?: string;
            /**
             * For craps_[url|pattern]_signals, please avoid accessing these fields directly, even in minor ways like checking has_craps_*. Instead, please use methods from
             * quality/navboost/craps/craps-lossy-compression.h or talk to dice-team.
             */
            crapsNewUrlSignals?: string;
            crapsUnscaledIpPriorBadFraction?: number;
            /**
             * Page quality signals converted from fields in proto QualityBoost in quality/q2/proto/quality-boost.proto. To save indexing space, we convert the float values in [0, 1] to integers
             * in range [0, 1023] (use 10 bits). exact_match_domain_demotion: converted from QualityBoost.emd.boost.
             */
            exactMatchDomainDemotion?: number;
            /**
             * This field is *not* propagated to shards, but it's populated at serving time by go/web-signal-joins (see b/207344056). See go/0DayLEs for details. This is only meant to be used
             * during LEs, it should *not* be used for launches.
             */
            experimentalNsrTeamData?: QualityNsrExperimentalNsrTeamData;
            /**
             * This field is *not* propagated to shards, but it's populated at serving time by go/web-signal-joins (see b/207344056). See go/0DayLEs for details. This is only meant to be used
             * during LEs, it should *not* be used for launches.
             */
            experimentalNsrTeamWsjData?: QualityNsrExperimentalNsrTeamWSJData[];
            /**
             * This field is *not* propagated to shards. It is meant to be populated at serving time using one of the versions present in the `experimental_nsr_team_wsj_data` field above (using
             * the `ExperimentalNsrTeamDataOverridesParams` opti to populate it; see http://source/search?q=ExperimentalNsrTeamDataOverridesParams%20file:ascorer.proto). The purpose of this field
             * is to be read by an experimental Q* component, in order to quickly run LEs with new delta components. See go/0DayLEs for details.
             */
            experimentalQstarDeltaSignal?: number;
            /**
             * This field is *not* propagated to shards. It is meant to be populated at serving time using one of the versions present in the `experimental_nsr_team_wsj_data` field above (using
             * the `ExperimentalNsrTeamDataOverridesParams` opti to populate it; see http://source/search?q=ExperimentalNsrTeamDataOverridesParams%20file:ascorer.proto). The purpose of this field
             * is to be read by an experimental Q* component, in order to quickly run LEs with new components. See go/0DayLEs for details.
             */
            experimentalQstarSignal?: number;
            /**
             * This field is *not* propagated to shards. It is meant to be populated at serving time using one of the versions present in the `experimental_nsr_team_wsj_data` field above (using
             * the `ExperimentalNsrTeamDataOverridesParams` opti to populate it; see http://source/search?q=ExperimentalNsrTeamDataOverridesParams%20file:ascorer.proto). The purpose of this field
             * is to be read by an experimental Q* component, in order to quickly run LEs with new site components. See go/0DayLEs for details.
             */
            experimentalQstarSiteSignal?: number;
            /** S2V low quality score: converted from quality_nsr.NsrData, applied in Qstar. See quality_nsr::util::ConvertNsrDataToLowQuality. */
            lowQuality?: number;
            /** nav_demotion: converted from QualityBoost.nav_demoted.boost. */
            navDemotion?: number;
            /** NSR confidence score: converted from quality_nsr.NsrData. */
            nsrConfidence?: number;
            /** NSR override bid, used in Q* for emergency overrides. */
            nsrOverrideBid?: number;
            /** Versioned NSR score to be used in continuous evaluation of the upcoming NSR version and assess quality impact on various slices. */
            nsrVersionedData?: NSRVersionedItem[];
            /** PairwiseQ data for QTJ. This field is *not* propagated to shards, but is populated at serving time by go/web-signal-joins. See b/175762140 */
            pairwiseqScoringData?: PairwiseQScoringData;
            /** Versioned PairwiseQ score to be used in continuous evaluation of the upcoming PairwiseQ versions and assess quality impact on various slices. */
            pairwiseqVersionedData?: PairwiseQVersionedItem[];
            /**
             * This is the encoding of Panda fields in the proto SiteQualityFeatures in quality/q2/proto/site_quality_features.proto. The encoding/decoding is performed using functions from
             * quality_coati::coati_util.
             */
            pandaDemotion?: number;
            /** Encoded page-level PQ signals. */
            pqData?: number;
            /** Stripped page-level signals, not present in the encoded field 'pq_data'. */
            pqDataProto?: QualityNsrPQData;
            productReviewPDemotePage?: number;
            /** Product review demotion/promotion confidences. (Times 1000 and floored) */
            productReviewPDemoteSite?: number;
            productReviewPPromotePage?: number;
            productReviewPPromoteSite?: number;
            /** Scam model score. Used as one of the web page quality qstar signals. Value range from 0 to 1023. */
            scamness?: number;
            /** serp demotion: applied in Qstar. */
            serpDemotion?: number;
            /** site_authority: converted from quality_nsr.SiteAuthority, applied in Qstar. */
            siteAuthority?: number;
            /** Versioned TopicEmbeddings data to be populated later into superroot / used directly in scorers. */
            topicEmbeddingsVersionedData?: QualityAuthorityTopicEmbeddingsVersionedItem[];
            /** Unauthoritative score. Used as one of the web page quality qstar signals. */
            unauthoritativeScore?: number;
            /** NSR for low-quality videos, converted from quality_nsr.NsrData.vlq_nsr. */
            vlqNsr?: number;
        }
        interface ContentAttributions {
            /** Selected outgoing attributions extracted on FreshDocs. */
            freshdocsOutgoing?: ContentAttributionsOutgoingAttribution[];
            /** Selected outgoing attributions extracted via offline MR jobs. */
            offlineOutgoing?: ContentAttributionsOutgoingAttribution[];
            /** Selected outgoing attributions extracted online on Alexandria. */
            onlineOutgoing?: ContentAttributionsOutgoingAttribution[];
        }
        interface ContentAttributionsOutgoingAttribution {
            bestEvidenceType?: string;
            docid?: string;
            properties?: number;
            usableForClustering?: boolean;
        }
        interface ContentAwareCropsIndexing {
            /** Compact representation for Mustang storage. See image/search/utils/packed_crops.h for details on the packing format. */
            mustangBytes?: string;
            mustangBytesVersion?: number;
        }
        interface CopleyLexicalMetadata {
            /**
             * Mid for an entity that has lexical data (a LexiconEntry). See https://g3doc.corp.google.com/nlp/generation/g3doc/lexical_data.md for for more information about lexical data. This is
             * the canonical mid for this entity (eg. it would be for "mother" in EN even if user referred to "mom").
             */
            canonicalLexicalMid?: string;
        }
        interface CopleyPersonalReference {
            /** The manner in which the entity was referenced (e.g. "my hotel", "the airport"). */
            personalReferenceType?: string;
        }
        interface CopleyPersonalReferenceMetadata {
            /**
             * A list of all references made. Empty if no personal references exist. Multiple references can be present when multiple references were made in a single query, or the type of
             * reference was ambiguous.
             */
            references?: CopleyPersonalReference[];
            /** The strength of the personal reference. For example "my flight" may receive a high reference_score, whereas "the airport" may receive a low score. */
            referenceScore?: number;
            /** Subreference metadata for all compound references on this span. */
            subreferenceMetadata?: CopleySubreferenceMetadata;
        }
        interface CopleySourceTypeList {
            sourceTypeMetadata?: CopleySourceTypeMetadata[];
        }
        interface CopleySourceTypeMetadata {
            /** Annotation ID of a contact annotation, e.g. a relationship set via Assistant. This ID is generated by People Write Server. It is used to delete Contact Annotations via People API. */
            contactAnnotationId?: string;
            displayableName?: string;
            /**
             * Only used if personal_data_provenance == PERSONAL_SOURCE_GMAIL. Used to create a link to the source email in the form:
             * mail.google.com/mail/u/0/?extsrc=sync&client=h&plid={email_identifier}
             */
            emailIdentifier?: string;
            /** Populated for some footprints data sources; uniquely identifies the footprint that generated the personal data that this provenance is attached to. */
            eventId?: EventIdMessage;
            localDiscoverySettingsMetadata?: PersonalizationSettingsApiProtoLocalDiscoveryLocalDiscoverySettingsMetadata;
            personalDataProvenance?: string;
            personalDataType?: string;
            provenanceCategory?: string[];
            /** Sensitivity applying to this copley annotation. */
            sensitivity?: KnowledgeAnswersSensitivitySensitivity;
        }
        interface CopleySubreferenceMetadata {
            /** Resolved entities are sorted from highest resolution score to lowest. */
            mostCompoundResolvedEntities?: CopleySubreferenceResolution[];
            /** This is a merged representation of the compound reference having the most_compound_resolved_entities as an argument. */
            mostNestedUnresolvedReference?: CopleySubreferenceReference;
        }
        interface CopleySubreferenceReference {
            /** Type of reference. There may be multiple for a single reference (e.g. relationship and contact). */
            personalReferenceTypes?: string[];
            /** Highest reference score for any references merged in this span. */
            referenceScore?: number;
            /** Only set for unresolved relationship references and can be used to get the canonical word for the relationship (e.g. "mother") in TTS. */
            relationshipLexicalInfo?: CopleyLexicalMetadata;
        }
        interface CopleySubreferenceResolution {
            /** Can be used with PKG Service for looking up metadata about this entity at fulfillment/GenX time. */
            mid?: string;
            /** Name of the entity represented by this resolution. */
            name?: string;
            /** A resolution score of 0 indicates that it did not resolve to a real entity. */
            resolutionScore?: number;
        }
        interface CorpusSelectionInfo {
            corpus?: string;
            /** Corpus specific score for an image */
            corpusScore?: number;
            /** Whether an image was selected for indexing. */
            isSelectedForIndexing?: boolean;
            /** Set of referrers indexed with the image. */
            referrerDocid?: string[];
            /** Set of referrer urls indexed with the image. */
            referrerUrls?: string[];
        }
        interface CountryClickDistribution {
            /** To store confidence in the distribution in cases when total is not set. */
            confidence?: number;
            item?: CountryClickDistributionItem[];
            /** To store total clicks on this page/domain. */
            total?: number;
        }
        interface CountryClickDistributionItem {
            doubleValue?: number;
            name?: string;
            value?: number;
        }
        interface CountryCountryAttachment {
            /** Store weighted click distribution for page level country-id classification. */
            clickDistribution?: CountryClickDistribution;
            /** Is true if the country attachment was computed through the UGC pipeline. */
            countryidFromUgc?: boolean;
            /** A non critical field to store debug info for a country attachment. Used in experiments and for debugging. */
            debug?: string;
            /**
             * Set to the signal source URLs when merging country signals in Alexandria during sitemoves. Essentially if sites A and B move to C, and we merge A and B's signal to C, in the
             * countryattachment signal C will have URL A and B as source_url. Only used for debugging and it doesn't show up in docjoins.
             */
            debugSourceUrl?: string[];
            /** Specifies the origin of `geo_locations`. Right now, it can either come from deprecated Docloc system or the new Brainloc system when Docloc doesn't have sufficient evidence. */
            documentLocationSource?: string;
            existNextLevel?: boolean;
            /** Booleans to keep track of where the country-id of the page came from. These are used for debugging and/or unittests, and cleared in production. */
            fromLanguageFallback?: boolean;
            fromRestricts?: boolean;
            fromSgDomains?: boolean;
            fromTld?: boolean;
            fromUgc?: boolean;
            fromUrlPattern?: boolean;
            fromWmx?: boolean;
            /**
             * New MetroID: Now called GeoLocations since the locations could be sublocalities, cities or states. GeoLocations are always more fine grained than country. TODO (jayeshv): Once new
             * MetroID/GeoLocations is launched everywhere, deleted old MetroID related fields.
             */
            geoLocations?: CountryGeoLocations;
            global?: boolean;
            /** Set to true if the local_countries field can be used for country restricts as well. */
            isValidForCountryRestrict?: boolean;
            /** two-letter(lower-case) countrycode, e.g. us countries that is local to */
            localCountries?: string[];
            /**
             * Fields that actually store the country id in docjoins. The format of this data is defined in //i18n/identifiers/stableinternalregionconverter.cc. Converter defined there can be used
             * to convert it to RegionCode format.
             */
            localCountryCodes?: number[];
            /** Metro locations: list of NavBoost feature V2 associated with a doc, along with the enclosing province. Metro locations with new tags. */
            metroIdList?: CountryMetroNBFeature[];
            /** Metro level data. metro_location_id stores geotokens for metro restricts. */
            metroLocationId?: string[];
            /** Metro navboost: list of (NavBoost feature V2, navboost float) pairs. */
            metroNavboost?: CountryMetroNBFeature[];
            provinceGeotokenList?: CountryProvinceGeotoken[];
            /** two-letter(lower-case) countrycode, e.g. us countries that is related to, but not local to */
            relatedCountries?: string[];
            relatedCountryCodes?: number[];
            /** List of two-letter(lower-case) countrycodes(e.g. us) valid for restricts. Typically cloned out of local_countries if is_valid_for_country_restrict is set to true. */
            restrictCountries?: string[];
            /** [Experimental]: Top salient countries for a doc. If a country can not be found on this field it can be considered that this doc is not relevant to it. */
            salientCountries?: CountrySalientCountry[];
            salientCountrySet?: QualitySalientCountriesSalientCountrySet;
            /** Domain name of keys in filtering metro reducer class, used only by the intermediate mapreduces to produce filtered data. */
            sitename?: string;
            /** Super global pages get lesser demotion than global pages. A document can only be either global or super_global but not both. */
            superGlobal?: boolean;
            urlPatternBasedCountry?: number;
            /** Language and country extracted using the URL pattern map. */
            urlPatternBasedLanguage?: number;
            /** This is used to store the visible country id computed from logs data */
            userVisibleCountryFromLogs?: string;
            /**
             * This is the country id we show to users on the result page. This is kept different from country demotion country id because we dont want to expose our backoff and url based
             * detection algorithm - also we want to be ultra conservative in showing this.
             */
            userVisibleLocalCountry?: number;
            /** If result is global, store weight above ideal, as a confidence signal. Used in query localness, cleared in production CountryAttachment. */
            weightAboveIdealForLocalness?: number;
            /** Country specified for a web-site through webmaster console. */
            wmxCountry?: string;
        }
        interface CountryGeoLocation {
            /** The radius (in miles) around the assigned location that the document gets 50% of its clicks. */
            clickRadius50Percent?: number;
            /** Confidence on the location. Ranges in [0.0, 1.0]. Cleared during index creation. */
            confidence?: number;
            /** Confidence mapped to [0, 100]. Converted to integer for efficient storage. Populated during index creation. */
            confidencePercent?: number;
            /**
             * Used for compressed docloc data. In compressed data, instead of location_info, only an integer ID for that LocationInfo is stored. A separate lookup table is used to get full
             * LocationInfo from the internal ID.
             */
            internalId?: number;
            locationInfo?: CountryLocationInfo;
            /**
             * True if this location is assigned to one of the subpages, and not to the page itself. If the total number of locations assigned to all the subpages of a page is small (usually up to
             * 5), then that page also gets assigned those locations, and this flag is set for those locations.
             */
            propagatedFromASubpage?: boolean;
        }
        interface CountryGeoLocations {
            geoLocation?: CountryGeoLocation[];
            /**
             * This will be set to true for documents which receive several clicks but are not assigned any location because the click distribution is flat. Typical examples are global sites like
             * facebook.com, chains like walmart.com, informational sites like wikipedia.org etc. This flag is not propagated to deeper pages since this signal is meant to indicate that a website
             * or a part of website is conclusively non-local, so propagating this information to deeper pages does not make sense. If this flag is set, then the only possible geo_location will be
             * the ones which are propagated_from_a_subpage.
             */
            isNonLocationSpecific?: boolean;
            /**
             * Depth of the URL from it's nearest parent in GeoLocation data. Webpages inherhit locations from their parent pages. For example, if foo.com/a is assigned location L1, and
             * foo.com/a/b is not assigned any location, then http://www.foo.com/a/b inherits location L1 from it's nearest parent foo.com/a in GeoLocation data. This attribute is the distance
             * from the nearest parent which is present in GeoLocation data. In this particular case, it will be 1.
             */
            propagationDepthFromParent?: number;
        }
        interface CountryLocationInfo {
            /**
             * The latitude and longitude of the conceptual center of the location. For cities, this would be the center of the downtown, or maybe the location of city hall. For states and
             * countries it might be the capital city. But there are no guarantees and this may be any random point inside the location.
             */
            center?: GeostorePointProto;
            city?: string;
            /** Human readable name hierarchy. Only the relevant fields will be present. For example for city GeoLocations, sub_locality field will not be present. Cleared during index creation. */
            country?: string;
            county?: string;
            /** Oyster feature ID of the enclosing state. Cleared during index creation. */
            enclosingStateFeatureId?: GeostoreFeatureIdProto;
            /** Oyster feature ID of the location. Cleared during index creation. */
            featureId?: GeostoreFeatureIdProto;
            state?: string;
            /**
             * 32 bit fingerprint of the feature id of the state of this location. For cities and sub-localities it will be the enclosing state. For state locations, it will be fingerprint of the
             * feture-id of the location itself. Populated during index creation.
             */
            stateIdFprint?: number;
            subLocality?: string;
            /** Type of the location (sub-locality, city, state etc). */
            type?: string;
        }
        interface CountryMetroNBFeature {
            /**
             * The enclosing_province_geotoken is a 32 bit fingerprint of the state encosing the (metro) id. MetroId's can span multiple states. Enclosing geotoken is filled in with the state name
             * for disambiguation. ProvinceGeotoken field is different as it indicates an "interest". Format: 32 bit fingerprint(__state__country).
             */
            enclosingProvinceGeotoken?: number;
            /** A 32 bit navboost v2 feature id encoding (country, language, metro). NavBoosterUtils class (google3/quality/navboost/nav_booster_utils.h) provides functions to decode this feature. */
            id?: number;
            /** This is the multiplier to apply to the result for this locale & query. NOTE: This is for serving purposes only and should not be populated in the index. */
            navboost?: number;
        }
        interface CountryProvinceGeotoken {
            geotoken?: number;
        }
        interface CountrySalientCountry {
            compressedSalience?: number;
            countryCode?: number;
            salience?: number;
        }
        interface CrawlerChangerateMultipleComponentDistribution {
            components?: CrawlerChangerateSingleComponentDistribution[];
        }
        interface CrawlerChangerateSingleComponentDistribution {
            /**
             * Scaling factor to ensure the approximated posterior to have the same scale as the product of prior and likelihood. This value is used to compute posterior weights. Uses log scale to
             * provide a wider range. This field is for internal use only.
             */
            logScaling?: number;
            /** The type indicates the type of the distribution. */
            type?: string;
            /** The weight is only used in multiple component scenarios. */
            weight?: number;
        }
        interface CrawlerChangerateUrlChange {
            /**
             * Duplicate UrlChanges crawled within a specified time range will be merged together. UrlChanges are considered duplicates if the simhash, simhash_is_trusted, simhash_v2,
             * simhash_v2_is_trusted, and shingle_simhash are the same. additional_changes_merged indiciates the number of duplicate UrlChanges merged into this UrlChange.
             */
            additionalChangesMerged?: number;
            /** Deprecated fields. The fraction of tiles (0 to 1) that changed. */
            fractionalTileChange?: number;
            /** The length in seconds of the change. */
            interval?: number;
            /** Whether the content of the off-domain links changed. */
            offDomainLinksChange?: boolean;
            /** The new count of off-domain links, if they changed. */
            offDomainLinksCount?: number;
            /** The new count of on-domain links, if the count changed. */
            onDomainLinksCount?: number;
            /** Whether the number of on-domain links changed. */
            onDomainLinksCountChange?: boolean;
            /** The old simhash value obtained from shingles. */
            shingleSimhash?: IndexingConverterShingleFingerprint;
            /**
             * The simhash-v1 value. Use of simhash-v1 is deprecated, and newer UrlChange should only contain simhash-v2. During this transition period, UrlChange can contain either simhash or
             * simhash_v2. It is possible that previous UrlChange only contain simhash-v1 and the next UrlChange only contain simhash-v2. In this case, we skip that interval in our changerate
             * computation. [go/changerate-simhash-v2-migration]
             */
            simhash?: string;
            /** Whether the simhash-v1 should be trusted. */
            simhashIsTrusted?: boolean;
            /** The simhash-v2 value. */
            simhashV2?: string;
            /** Whether the simhash-v2 value should be trusted. */
            simhashV2IsTrusted?: boolean;
        }
        interface CrawlerChangerateUrlChangerate {
            /** The approximated posterior distribution. */
            approximatedPosterior?: CrawlerChangerateMultipleComponentDistribution;
            /**
             * The "significance" of the average change we saw of this document (from 0 to 1). Influenced by content changes. This can be used for prioritizing the crawl (higher significance
             * first).
             */
            averageChangeSignificance?: number;
            /**
             * //////////////////////////////////////////////////////////////////////////// The classic changerate estimation.
             * //////////////////////////////////////////////////////////////////////////// The classic estimate of change period (in seconds). It is computed by inserted a "fake" change and
             * no-change interval as a prior distribution. This field is generally not used and should NOT be accessed directly. See above for correct method for determining the change period
             * estimate.
             */
            changeperiod?: number;
            /** The confidence (between 0 and 1) in the changeperiod guess. */
            confidence?: number;
            /**
             * //////////////////////////////////////////////////////////////////////////// The changerate estimation based on the global prior.
             * //////////////////////////////////////////////////////////////////////////// The global-based changeperiod. This is our estimate (in seconds) for the average time between changes.
             * It is computed using the new prior method based on global_based_prior_period and the global_based_prior_strength specified below. This is used for computing pattern priors. Use
             * pattern_based_change_period or changeperiod fields for all other purposes.
             */
            globalBasedChangePeriod?: number;
            /**
             * The 'confidence' of the global-based changeperiod. This is the n-th root of the posterior evaluated at MAP point, where n is the number of history intervals. For now, it is hard to
             * interpret the meaning of the absolute values of 'average' posterior cross different sets of data.
             */
            globalBasedChangePeriodConfidence?: number;
            /** The 2 parameters below specify the prior employed in calculating the global_based_change_period. These values are precomputed through an offline analysis and specified via flags. */
            globalBasedPriorPeriod?: number;
            globalBasedPriorStrength?: number;
            /** The last time (unix timestamp) we saw a changed copy of the document. Provided iff we have seen the page change. */
            lastChanged?: number;
            /**
             * The "significance" of the last change we saw of this document (from 0 to 1). Influenced by content changes, etc. This can be used for prioritizing the crawl (higher significance
             * first).
             */
            lastChangeSignificance?: number;
            /** The last time (unix timestamp) we saw a fetched copy of the document. */
            lastFetched?: number;
            /** The number of intervals we've seen for this document (where an interval is two different versions). */
            numIntervals?: number;
            /**
             * //////////////////////////////////////////////////////////////////////////// The changerate estimation based on the pattern prior.
             * //////////////////////////////////////////////////////////////////////////// The pattern-based changeperiod. This is our estimate (in seconds) for the average time between changes.
             * It is calculated based on the pattern_based_prior_period and pattern_based_prior_strength below. This quantity will eventually replace the old changeperiod calculation.
             */
            patternBasedChangePeriod?: number;
            /** The same as global_based_change_period_confidence, except it is computed using pattern based priors. */
            patternBasedChangePeriodConfidence?: number;
            /** The lower edge of a confidence interval for the pattern-based change period. */
            patternBasedLowerChangePeriod?: number;
            /**
             * The 2 parameters below specify the prior employed in calculating the pattern_based_change_period. These values are calculated in a separate process and looked up based on the URL
             * pattern.
             */
            patternBasedPriorPeriod?: number;
            patternBasedPriorStrength?: number;
            /** The version number of the algorithm, refer to ChangePeriodVersion for more information. */
            patternChangePeriodVersion?: number;
            /**
             * //////////////////////////////////////////////////////////////////////////// Basic information of a document.
             * //////////////////////////////////////////////////////////////////////////// The type of the document determined by crawl histories, refer to TYPE for more information.
             */
            type?: number;
            /**
             * //////////////////////////////////////////////////////////////////////////// The UGC changerate estimation.
             * //////////////////////////////////////////////////////////////////////////// Information on change period generated from user generated content (UGC) change history.
             */
            ugcChangePeriod?: number;
            ugcChangePeriodConfidence?: number;
        }
        interface CrawlerChangerateUrlHistory {
            /** All the changes we've seen for this URL. */
            change?: CrawlerChangerateUrlChange[];
            /** The latest version we've seen. */
            latestVersion?: CrawlerChangerateUrlVersion;
            /** This field in only set in 'url_history' column of Union repository to avoid having to read CompositeDocs. */
            url?: string;
        }
        interface CrawlerChangerateUrlVersion {
            /** Same as the field in UrlChange. This allows us to merge identical UrlVersions into a single UrlVersion. */
            additionalChangesMerged?: number;
            /** The content type of the page. */
            contentType?: number;
            /** Whether this is an IMS response (a 304, not modified). */
            isImsNotModified?: boolean;
            /** The date from the LastModified header, if present. */
            lastModified?: number;
            /** The checksum of all the off-domain links on the page. */
            offDomainLinksChecksum?: number;
            /** The count of all the off-domain links on the page. */
            offDomainLinksCount?: number;
            /**
             * The count of all the on-domain links on the page. We aren't worried about the contents themselves, since they might often change (e.g., session ids). We assume that a change in the
             * number of links is significant, however.
             */
            onDomainLinksCount?: number;
            /** The simhash value obtained from shingles. */
            shingleSimhash?: IndexingConverterShingleFingerprint;
            /**
             * The simhash-v1 value. The simhash-v1 is now deprecated and new UrlVersions should only populate simhash-v2. During migration phase from using simhash-v1 to simhash-v2, it is
             * possible that previous UrlChange only contain simhash-v1 and the next UrlChange / UrlVersion could only contain simhash-v2. In this case, we skip that interval in our changerate
             * computation. [go/changerate-simhash-v2-migration]
             */
            simhash?: string;
            /** Whether the simhash-v1 should be trusted. */
            simhashIsTrusted?: boolean;
            /** The simhash-v2 value. */
            simhashV2?: string;
            /** Whether the simhash-v2 value should be trusted. */
            simhashV2IsTrusted?: boolean;
            /**
             * The tiles of the document body. We use int32s instead of int64s (the norm) in order to save space. Since rare inaccuracy doesn't really matter, we've decided this is an okay
             * tradeoff.
             */
            tile?: number[];
            /** The timestamp we crawled the page. */
            timestamp?: number;
        }
        interface CrowdingPerDocData {
            newscluster?: CrowdingPerDocDataNewsCluster[];
        }
        interface CrowdingPerDocDataNewsCluster {
            /** Fingerprint combination of all urls in a cluster */
            ClusterId?: string;
            /** This is the X in the "and X related >>" link on headlines and search results */
            ClusterSize?: number;
            /** When was this clustered (needed for keeping last X iterations around and discarding earlier ones) */
            ClusterTimeStamp?: number;
        }
        interface DeepCropIndexing {
            /** Compact representation for indexing, see creatism::CropBitmap for details on the packing format. */
            cropBytes?: string;
        }
        interface DeepCropPixels {
            /** Pixels version of the DeepCropIndexing bytes, this corresponds to the crop box for a given image (based input image size and desired aspect ratio). */
            x0?: number;
            x1?: number;
            y0?: number;
            y1?: number;
        }
        interface DocProperties {
            /** The average weighted font size of a term in the doc body */
            avgTermWeight?: number;
            /** Missing or meaningless title */
            badTitle?: boolean;
            badtitleinfo?: DocPropertiesBadTitleInfo[];
            /** A Language enum value. See: go/language-enum */
            languages?: number[];
            /** Leading text information generated by google3/quality/snippets/leadingtext/leadingtext-detector.cc */
            leadingtext?: SnippetsLeadingtextLeadingTextInfo;
            numPunctuations?: number;
            numTags?: number;
            /**
             * The number of tokens, tags and punctuations in the tokenized contents. This is an approximation of the number of tokens, tags and punctuations we end up with in mustang, but is
             * inexact since we drop some tokens in mustang and also truncate docs at a max cap.
             */
            numTokens?: number;
            /** The restricts for CSE structured search. */
            proseRestrict?: string[];
            restricts?: string[];
            /** The time CDocProperties::StartDocument() is called, encoded as seconds past the epoch (Jan 1, 1970). This value is always refreshed and not reused. */
            timestamp?: string;
            /**
             * Extracted from the title tag of the content. This is typically extracted by TitleMetaCollector defined at google3/segindexer/title-meta-collector.h. Please see its documentation for
             * the format and other caveats.
             */
            title?: string;
        }
        interface DocPropertiesBadTitleInfo {
            score?: number;
            type?: string;
        }
        interface DrishtiDenseFeatureData {
            /** If extra is present it must be of the same length as value. */
            extra?: any[];
            generalExtra?: any;
            /** Dense data. */
            value?: number[];
        }
        // tslint:disable-next-line:no-empty-interface
        interface DrishtiFeatureExtra {
        }
        interface DrishtiFeatureSetData {
            /** Extra information for this particular FeatureSetData (example timestamp of this frame in the video). (Almost never used). */
            extra?: any[];
            /**
             * The following can have multiple FeatureSetElement(s) Each of these FeatureSetElement correspond to the various feature groups. One concrete example is the way these features are
             * generated - example audio, video or OCR.
             */
            feature?: DrishtiFeatureSetDataFeatureSetElement[];
            /** Labels for this particular FeatureSetData. (Almost never used). Only interesting when you have (for example) frame level labels. */
            label?: DrishtiLabelSetElement[];
        }
        interface DrishtiFeatureSetDataFeatureSetElement {
            dense?: DrishtiDenseFeatureData;
            indexed?: DrishtiIndexedFeatureData;
            /** A name for the feature group: example "AUDIO", "VIDEO", "OCR", etc. */
            name?: string;
            quantized?: DrishtiQuantizedDenseFeatureData;
            sparse?: DrishtiSparseFeatureData;
        }
        interface DrishtiFeatureSetDataSequence {
            /**
             * FeatureSetData contains the features. In most scenarios, you only have one element. However, multiple elements are appropriate in case of videos where each element may correspond to
             * a frame in the video.
             */
            element?: DrishtiFeatureSetData[];
            /** Some extra information about this FeatureSetDataSequence. (Almost never used). */
            extra?: any[];
            /**
             * Global (video-level) labels. In most cases, you only have one LabelSetElement. All the labels will be stored in this single LabelSetElement. Scenarios where you may have multiple
             * LabelSetElement(s) is (for example) when you want to differentiate the labels into various sub-groups - eg, central vs relevant, kg-ids vs queries, etc.
             */
            label?: DrishtiLabelSetElement[];
            /** If set, must be same length as element. Each entry is the timestamp in microseconds where the FeatureSetData element was extracted. */
            timestamp?: string[];
        }
        interface DrishtiIndexedFeatureData {
            /** If extra is present it must be of the same length as index and value. */
            extra?: any[];
            generalExtra?: any;
            /** Indexed data. index and value must be of the same length. */
            index?: string[];
            value?: number[];
        }
        interface DrishtiLabelSetData {
            extra?: any[];
            generalExtra?: any;
            targetClass?: string[];
            targetClassName?: string[];
            targetValue?: number[];
            targetWeight?: number[];
            /** Weight assigned to this set of labels. */
            weight?: number;
        }
        interface DrishtiLabelSetElement {
            label?: DrishtiLabelSetData;
            name?: string;
        }
        interface DrishtiQuantizedDenseFeatureData {
            /** If extra is present it must be of the same length as value. */
            extra?: any[];
            generalExtra?: any;
            /** Quantized Dense data. */
            value?: string[];
        }
        interface DrishtiSparseFeatureData {
            /** If extra is present it must be of the same length as label and value. */
            extra?: any[];
            generalExtra?: any;
            /** Indexed data. label and value must be of the same length. */
            label?: string[];
            value?: number[];
        }
        interface DrishtiVesperEncodedThumbnail {
            /** JPEG/WEBP quality factor in range [0,100]. */
            encodingQuality?: number;
            /** Image encoding type. */
            encodingType?: string;
            height?: number;
            /** Encoded thumbnail bytes. Prefer this over `image_string` as we are not supposed to store image bytes in a proto string field. */
            imageBytes?: string;
            /** Please migrate to `image_bytes`. */
            imageString?: string;
            /** Thumbnail resolution. */
            width?: number;
        }
        interface DrishtiVesperMovingThumbnail {
            /** The begin timestamp in milliseconds. */
            beginTimestampMs?: number;
            /**
             * The duration of the moving thumbnail in milliseconds. Note that the duration may not be the difference between begin_timestamp_ms and end_timestamp_ms, esp when the moving thumbnail
             * covers multiple clips from the video.
             */
            durationMs?: number;
            encodedGifAnimation?: string;
            /** The encoded video string. */
            encodedVideoString?: string;
            /** The encoded WebP animation. */
            encodedWebpAnimation?: string;
            /** The end timestamp in milliseconds. */
            endTimestampMs?: number;
            /** Pixel height of the moving thumbnail. */
            height?: number;
            /** MovingThumbnail id (e.g., the video id). */
            id?: string;
            /** If set, this is the algorithm version used to generate this moving thumbnail. */
            movingThumbnailerVersion?: string;
            /** MovingThumbnail name. */
            name?: string;
            /** The score of the moving thumbnail. */
            score?: number;
            scoreComponents?: DrishtiVesperMovingThumbnailScoreComponents;
            /** A set of single frame thumbnails in the MovingThumbnail. */
            thumbnails?: DrishtiVesperThumbnail[];
            /** MovingThumbnail type. */
            type?: string;
            /**
             * The actual quality of the Webp animation. Note this value may not be equal to the quality value requested in the animation creator's options. This is because other requirements,
             * such as the max file size, may force the creator to lower the actual quality value.
             */
            webpQualityLevel?: number;
            /** Pixel width of the moving thumbnail. */
            width?: number;
        }
        interface DrishtiVesperMovingThumbnailScoreComponents {
            audienceRewindRatioScore?: number;
            iconicFaceScore?: number;
            matchingScore?: number;
            motionScore?: number;
            titleMatchingScore?: number;
            videoThumbQualityScore?: number;
        }
        interface DrishtiVesperThumbnail {
            /** Thumbnail dense features */
            denseFeatures?: number[];
            /** Thumbnail image as an encoded image. Deprecated, use encoded_thumbnails instead. */
            encodedImageString?: string;
            /** Thumbnail image as an encoded image with smaller resolution. Deprecated, use encoded_thumbnails instead. */
            encodedImageStringSmall?: string;
            /** Encoded thumbnail images. */
            encodedThumbnails?: DrishtiVesperEncodedThumbnail[];
            /** Thumbnail id. */
            id?: string;
            /** Text in video thumbnails that was detected by OCR. */
            ocrText?: string;
            /** Thumbnail quality scores. */
            qualityScores?: DrishtiVesperThumbnailQualityScore[];
            /** If true, this thumbnail should update default thumbnail. */
            shouldUpdateDefaultThumbnail?: boolean;
            /** Thumbnailer Version. */
            thumbnailerModelVersion?: string;
            /** Thumbnail timestamp in milliseconds. */
            timestampMs?: number;
            /** Thumbnail type. */
            type?: string;
            userReportedThumbnail?: DrishtiVesperUserReportUserReportedThumbnail;
            /** All user reported thumbnails of interest. */
            userReportedThumbnails?: DrishtiVesperUserReportUserReportedThumbnail[];
            /** Thumbnail version, i.e., the unix time in seconds when the thumbnail was created. */
            version?: number;
        }
        interface DrishtiVesperThumbnailQualityScore {
            score?: number;
            type?: string;
        }
        interface DrishtiVesperUserReportHumanLabel {
            racyLevel?: string;
        }
        interface DrishtiVesperUserReportModelScore {
            modelName?: string;
            score?: number;
        }
        interface DrishtiVesperUserReportUserReportedThumbnail {
            denseFeatures?: number[];
            /** Number of days in which volume is calculated. */
            duration?: number;
            humanLabel?: DrishtiVesperUserReportHumanLabel;
            /** Daily aggregared impressions for the reported video. */
            impressions?: number;
            /** Whether the thumbnail needs a human label. */
            needHumanLabel?: boolean;
            rawHumanLabels?: DrishtiVesperUserReportHumanLabel[];
            reportScore?: DrishtiVesperUserReportModelScore;
            reportType?: string;
            score?: DrishtiVesperUserReportModelScore;
            useCase?: string;
            /** Number of reports. */
            volume?: number;
        }
        interface DrishtiVesperVideoThumbnail {
            /** Video id. */
            id?: string;
            movingThumbnails?: DrishtiVesperMovingThumbnail[];
            thumbnails?: DrishtiVesperThumbnail[];
        }
        interface EmbedsDeepLinkData {
            /** Application ID (or project ID) from Google API Console. */
            appId?: string;
            /** The data for a Google API Console client is entered by a developer during client registration and is stored in PackagingService. */
            client?: EmbedsPackagingServiceClient[];
            /**
             * The ID for non-URL content. Embeds may either have no analogous web presence or prefer a native mobile experience if supported. In the case of no web presence, instead of setting
             * the "url" field of an embed, such developers will set this field and other content fields, e.g. thumbnail, title, description. If set, this field is used to construct the deep-link
             * URI. Note that the native experience is preferred over the web link and the web link is used as a fallback.
             */
            deepLinkId?: string;
            /** Analogous web presence. Used as desktop fallback or when no native link data is present. */
            url?: string;
        }
        interface EmbedsEmbedClientItem {
            /**
             * The canonical ID of the embed. If absent, the canonical ID is equal to the ID; if present, then the canonical ID represents an "equivalence class" of embeds which really refer to
             * the same object. (For example, the URLs http://www.foo.com/ and http://foo.com/ refer to the same object) This field may be updated periodically by background processes.
             */
            canonicalId?: string;
            /**
             * Deep-linking data to take the user to the right place in a mobile app. This is only used for preview and attribution. Links that are specific to a given embed type should live on
             * that specific embed's proto by using Link. See http://goto.google.com/mariana-design.
             */
            deepLinkData?: EmbedsDeepLinkData;
            /** The ID of the embed. This corresponds to the schema.org ID, as represented in the ItemScope.id field. */
            id?: string;
            /**
             * The provenance of the embed, populated when the embed originated from a web fetch. The provenance captures information about the web page the embed had originated, like the URL that
             * was retrieved and the retrieved URL's canonical form. This is useful in the case where the URL shared by the URL redirects (e.g., in the case of a shortened URL).
             */
            provenance?: EmbedsProvenance;
            /**
             * The ID used to identify the embed during rendering. This field will match ID, if set, otherwise it will be the ID of the parent activity. This field is only populated on the server
             * for client use and is not persisted to storage.
             */
            renderId?: string;
            /** Signature of the embed, used for verification. */
            signature?: string;
            /** Transient generic data that will not be saved on the server. */
            transientData?: any;
            /**
             * The first value in `type` determines which extension field will be set. When creating an EmbedClientItem, you only need to set the first (primary) type in this field. When the
             * server receives the item, it will populate the full type list using the parent annotations in the ItemType enum.
             */
            type?: string[];
        }
        interface EmbedsPackagingServiceClient {
            /** Android app's package name to generate the deep-link URI. */
            androidPackageName?: string;
            /** iOS app's App Store ID to generate the App Store URL when app is not installed on device. */
            iosAppStoreId?: string;
            /** iOS app's bundle ID to generate the deep-link URI. */
            iosBundleId?: string;
            /** Type of Google API Console client. */
            type?: string;
        }
        interface EmbedsProvenance {
            /** Annotation blob from Annotation Service. */
            annotationBlob?: string;
            /** Canonical url of the retrieved_url, if one was resolved during retrieval, for example, if a rel="canonical" link tag was provided in the retrieved web page. */
            canonicalUrl?: string;
            /**
             * The url originally passed in the PRS request, which should be used to re-discover the content. Note that this URL may be a forwarding service or link shortener (bit.ly), so it
             * should not be assumed to be canonical, but should be used for navigation back to the original source of the itemscope.
             */
            inputUrl?: string;
            /**
             * Contains exact types as parsed, whether or not we recognized that type at parse time. If an itemscope is created by merging SchemaOrg markup and open graph markup then the first
             * itemtype would be schemaorg type, the second would be open graph and so on. example: http://schema.org/VideoObject, og:video.movie Plain text; usually a URL
             */
            itemtype?: string[];
            /** The server retrieved timestamp (in msec). */
            retrievedTimestampMsec?: string;
            /** The final URL that was the actual source of the itemscope, after any redirects. */
            retrievedUrl?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface EmbedsTransientData {
        }
        interface EntitySignalsClassificationOutput {
            /** Filled if used logistic regression (see ewok.proto for available labels). */
            labels?: EntitySignalsWeightedRelevanceRating[];
            /** If using linear regression, this is the output value of the regression. If using logistic regression, this is the weighted aggregated rating. See http://go/entitymetric */
            relevanceScore?: number;
        }
        interface EntitySignalsEntityClassification {
            /** Entity id. */
            entityId?: string;
            /** Input features used in classification. */
            features?: EntitySignalsEntityFeature[];
            /** Classification output. */
            output?: EntitySignalsClassificationOutput;
        }
        interface EntitySignalsEntityFeature {
            code?: string;
            /** Name of the feature. For a completely list of available features, please check http://go/entityclassifierfeatures */
            name?: string;
            /** Value of the feature. */
            value?: number;
        }
        interface EntitySignalsWeightedRelevanceRating {
            rating?: string;
            weight?: number;
        }
        interface EventIdMessage {
            /**
             * process_id is an integer that identifies the process on this machine that generated this event. This id is calculated once when the server generates its first event, and may change
             * if the process is migrated to a different host. This field has a very specific format mandated by the logs collection infrastructure, which is subject to change WITHOUT NOTICE. As
             * of 2013-01-09, this format is: uint32 process_id = (time(NULL) << 24) + (getpid() & 0xFFFFFF); If you are generating an extended_pid directly, you MUST use one of the maintained
             * library implementations in order to generate it properly: C++ //borg/borgletlib:extended_pid; call borg::ExtendedPid() Python //borg/borgletlib/python:pyextendedpid; call
             * ExtendedPid() Go //borg/borgletlib/go:extendedpid; call Get() Java //java/com/google/common/logging; call EventId.getPid() If you think that you need to parse the values of this
             * field, please contact logs-collection-dev@ to discuss your requirement.
             */
            processId?: number;
            /**
             * server_ip is the IPv4 address or http://go/ghostid of the machine running the server that created this event message. This allows us to distinguish between events that occur at the
             * same time on different servers. Format: 10.1.2.3 is stored as 0x0a010203, and GHostId 1 as 0x00000001.
             */
            serverIp?: number;
            /**
             * time_usec is the number of microseconds since the epoch (i.e., since 1970-01-01 00:00:00 UTC) as an int64: 1e6 * (unix time) + microseconds. Applications must ensure that
             * EventIdMessages have increasing times, artificially increasing time_usec to one greater than the previous value if necessary. Alternate implementations were considered: 1. storing
             * unix time and microseconds separately would require a bit more storage, and the convenience of having a single value representing the time seemed more useful than having trivial
             * access to a unix time. 2. storing unix time in the upper 32 bits would allow for more precision - up to 4G events/second, but it wouldn't print nicely as a decimal value and it
             * seems unlikely that any single server would ever sustain more than 1M events/second. 3. Java-compatible time uses millis - this would limit servers to 1000 events per second - too
             * small. Other names for this field were considered, including time, time_stamp, and utime. We felt that including the units in the name would tend to produce more readable code.
             * utime might be interpreted as user time. unix timestamp * 1e6 + microseconds
             */
            timeUsec?: string;
        }
        interface ExtraSnippetInfoResponse {
            matchinfo?: ExtraSnippetInfoResponseMatchInfo;
            querysubitem?: ExtraSnippetInfoResponseQuerySubitem[];
            tidbit?: ExtraSnippetInfoResponseTidbit[];
        }
        interface ExtraSnippetInfoResponseMatchInfo {
            /** bitvector of query items matching the title */
            titleMatches?: string;
            /** bitvector of query items matching the url */
            urlMatches?: string;
            /** bitvector of query items considered by chooser */
            weightedItems?: string;
        }
        interface ExtraSnippetInfoResponseQuerySubitem {
            /** Additional information from the SnippetQuery. */
            isHighlighted?: boolean;
            isOptional?: boolean;
            /** true iff this subitem was an original query term or phrase. Can only be false if want_all_query_subitems == true in the request. */
            isOriginal?: boolean;
            /** a bitvector of the query items corresponding to this subitem. Typically only one bit is set, but see comment above. */
            items?: number;
            /** text associated with this query item */
            text?: string;
            /** the weight of this query item, as calculated by SubitemWeight(): https://qwiki.corp.google.com/display/Q/SnippetWeights */
            weight?: number;
        }
        interface ExtraSnippetInfoResponseTidbit {
            anchorinfo?: ExtraSnippetInfoResponseTidbitAnchorInfo;
            /** For tidbits only: position of tidbit in the document. More specifically, tidbit is found at [begin, end) in the document's tokens. */
            begin?: number;
            end?: number;
            /** a bitvector of each query term within this tidbit */
            items?: string;
            /**
             * the score for this tidbit if there was one this is returned for Snippets and Tidbits and is only meaningful for comparing between objects of the same type (snippet to snippet,
             * tidbit to tidbit)
             */
            score?: number;
            /** the tidbit text, with search terms already highlighted */
            text?: string;
            type?: string;
        }
        interface ExtraSnippetInfoResponseTidbitAnchorInfo {
            offdomainCount?: number;
            ondomainCount?: number;
        }
        interface FaceIndexing {
            /** Always use image/search/utils/face_proto_util.h for packing and unpacking these values. */
            mustangBytes?: string;
            mustangBytesVersion?: number;
        }
        interface FatcatCompactBinaryClassification {
            /** Either binary_classifier will be set, using the enum above, or binary_classifier_name will be set, if it is not one of the classifiers in the enum - never both. */
            binaryClassifier?: string;
            binaryClassifierName?: string;
            /**
             * A CompactDocClassification will not usually have a weight. For a CompactSiteClassification, this value will be 0...127 corresponding to 0.0...1.0, indicating fraction of the site
             * that this label applies to
             */
            discreteFraction?: number;
        }
        interface FatcatCompactDocClassification {
            binary?: FatcatCompactBinaryClassification[];
            clusters?: FatcatCompactRephilClusters;
            epoch?: string;
            langCode?: string;
            /** The id of the Rephil model used to generate the Rephil clusters. If it is absent, Rephil 4 is assumed. */
            rephilModelId?: number;
            taxonomic?: FatcatCompactTaxonomicClassification[];
            /** not needed if the url is the sstable / bigtable key used during intermediate processing only */
            url?: string;
            /**
             * The relative weight of this doc within a site, typically something like pagerank or navboost impressions. May be a large number (like an actual pageviews estimate), not limited to a
             * small range.
             */
            weight?: string;
        }
        interface FatcatCompactRephilClusters {
            cluster?: FatcatCompactRephilClustersCluster[];
        }
        interface FatcatCompactRephilClustersCluster {
            /** 0...127 corresponds to 0.0 - 1.0 */
            discreteWeight?: number;
            id?: number;
        }
        interface FatcatCompactTaxonomicClassification {
            category?: FatcatCompactTaxonomicClassificationCategory[];
            classifierVersion?: string;
            /** Either taxonomy will be set, using the enum above, or taxonomy_name will be set (if the taxonomy is not one of the ones in the enum) - never both */
            taxonomy?: string;
            taxonomyName?: string;
        }
        interface FatcatCompactTaxonomicClassificationCategory {
            /** go/petacat-faq#how-should-i-interpret-classification-weights Discrete to reduce size. Range is [0,127], corresponding to [0.0,1.0]. */
            discreteWeight?: number;
            /** The category's ID, e.g. 20 for /Sports in the go/verticals4 taxonomy. */
            id?: number;
        }
        interface FocusBackendContactDetailHash {
            type?: string;
            /**
             * The hash here will be a 16-bit weak hash to avoid reverse engineering for decoding the actual contact detail. The hash value is computed by the fingerprint of the raw contact detail
             * mod 2^16.
             */
            value?: number;
        }
        interface FocusBackendContactPointer {
            /**
             * The annotation ID. Annotations are only allowed to point to annotations that do not themselves have a pointer (avoids any possibilty of loops). Cast this field to string in
             * javascript to make it compile in js.
             */
            annotationId?: string;
            /** The raw contact ID from an active mobile device of the user. */
            deviceRawContactId?: FocusBackendDeviceRawContactId;
            /** The contact ID from the Focus backend. Cast this field to string in javascript to make it compile in js. */
            focusContactId?: string;
            /** Additional contact ids that are not actively used to match contact pointers to contacts. */
            otherContactId?: FocusBackendOtherContactId;
            /** The secondary identifier of contact. It will be used when the primary ID doesn't match any contact. */
            secondaryId?: FocusBackendSecondaryContactId;
        }
        interface FocusBackendDeviceContactId {
            /** DeviceContact Id. */
            ContactId?: string;
            /** Device Id. */
            DeviceId?: FocusBackendDeviceId;
        }
        interface FocusBackendDeviceId {
            /** The GServices id on Android. See go/android-id. */
            AndroidDeviceId?: string;
            /**
             * DeviceId.Hash is a SHA256 of some attribute of the user and device. For Android devices: Hash = SHA256(gaia_account_name + “:” + “1” + “:” + (android id - LSB)); For iOS devices:
             * Hash = TOLOWER(HEX(GMCSComputeUserDeviceToken(userId, iOsDeviceId)) For more details see go/client-instance-id.
             */
            Hash?: string;
        }
        interface FocusBackendDeviceRawContactId {
            DeviceId?: FocusBackendDeviceId;
            /** Raw ID assigned by the device. Cast this field to string in javascript to make it compile in js. */
            RawContactId?: string;
        }
        interface FocusBackendOtherContactId {
            /**
             * Device contact ID, when available: - The annotation points to a device contact, and the device contact id was correctly populated when the annotation was created. Note that the
             * device contact id is populated once per device contact on a device. It is distinct from RawContactId - a single device contact may have multiple raw contact ids. - The annotation
             * points to a Focus contact that was merged with device contact information in Starlight. When the annotation was created, a device contact id was available on the merged person
             * object. - The contact annotation was created from April 2021 onwards. All prior annotations do not populate this field. ContactPointer creation relies on the client caller to
             * correctly populate the device contact id, and does not enforce any assumptions on availability of this field. This field is repeated because in rare cases Starlight may merge device
             * contact information across different devices into a single merged person object. WARNING: Use with extreme caution! This ID is not stable. For more details see
             * go/fbs-support-for-device-contacts.
             */
            deviceContactId?: FocusBackendDeviceContactId[];
        }
        interface FocusBackendSecondaryContactId {
            /** The hashes of the contact details (e.g. phone number and email address). */
            contactDetailHash?: FocusBackendContactDetailHash[];
            /** The contact's full name, not hashed. */
            contactName?: string;
            /** The hash of contact's full name, generated using Fingerprint2011(). Cast this field to string in javascript to make it compile in js. */
            contactNameHash?: string;
        }
        interface FreebaseCitation {
            /** Mid of the dataset. */
            dataset?: string;
            /** If set to true, the citation is required to be displayed when the data is used. */
            isAttributionRequired?: boolean;
            /** Name of the project of the data's origin. */
            project?: string;
            /** The name of the provider of this information. */
            provider?: string;
            /** A human readable statement of attribution. */
            statement?: string;
            /** Uri link associated with this data. */
            uri?: string;
        }
        interface FreebaseId {
            /**
             * "id" may be a human readable ID (HRID) or a MID. Originally it was intended to always be a human readable ID, but that convention was not always followed so clients should be wary.
             * Not every topic has an id.
             */
            id?: string;
            /**
             * The "mid" should be used whenever a globally unique, primary key into the Knowledge Graph is needed. These keys are always prefixed with the "/m" and "/g", (and more rarely the "/x"
             * and "/t") namespaces, and are alphanumeric strings consisting of lowercase letters excluding vowels, numbers and the underscore character. (Applications should not assume a constant
             * length for these strings as Livegraph reserves the right to extend the number of characters to accommodate more topics.)
             */
            mid?: string;
        }
        interface FreebaseLatLong {
            latDeg?: number;
            longDeg?: number;
        }
        interface FreebaseMeasurement {
            magnitude?: number;
            /** Repeated units are interpreted as a product. i.e. (meter ^ 1) * (second ^ -2) */
            unit?: FreebaseMeasurementUnit[];
        }
        interface FreebaseMeasurementUnit {
            power?: number;
            unit?: FreebaseId;
            /** Deprecated fields. */
            unitMid?: string;
        }
        interface FreebaseNestedStruct {
            propertyValue?: FreebasePropertyValue[];
        }
        interface FreebasePropertyValue {
            /** The id of the property. */
            property?: FreebaseId;
            /** Indicates the total values that exist for this property, even if they aren't all present in the value field, due to truncation. */
            totalValueCount?: string;
            /** The value associated with the property for the containing topic. */
            value?: FreebaseValue[];
            /**
             * If ValueStatus is not set at all, the implication is that there are well-known value(s), specified in the "value" field. (It should be considered malformed data to have value_status
             * set when len(values) > 0.)
             */
            valueStatus?: string;
        }
        interface FreebaseTopic {
            /** The id (mid and human-readable id) of the topic. The id will always be present and will contain a mid value for topics in the topic sstable. */
            id?: FreebaseId;
            /**
             * The property-value bindings associated with the topic. Note that in the case where a property is relevant to a topic based on its type, but no values of that property are present
             * for the topic, the PropertyValue will simply not appear, rather than being present with a null value, or empty repeated value list.
             */
            propertyValue?: FreebasePropertyValue[];
        }
        interface FreebaseValue {
            /** key, uri, or datetime. Present when value is bool. */
            boolValue?: boolean;
            /** Citation data for this value. See: http://go/kg-clap */
            citation?: FreebaseCitation;
            /**
             * Compound values are those that contain either a number of simple valued facets (such as a latitude/longitude pair), or "mediator" topics representing multi-dimensional relationships
             * between topics. In both cases we represent them here with an embedded topic, although the topic's identity is somewhat secondary to the property/value pairs it contains. (The
             * identity is still made available so that it can be used to perform updates to that mediator on the Knowledge Graph.)
             */
            compoundValue?: FreebaseTopic;
            /** Deletion provenance for this value. */
            deletionProvenance?: StorageGraphBfgTripleProvenance[];
            /** The lang of the display_value field. */
            displayLang?: string;
            /** The display value of this value. This is a i18n-aware formatted value if present. */
            displayValue?: string;
            /** An optional name for a proto field. */
            expectedProto?: string;
            /** Present when value is float. */
            floatValue?: number;
            /** Present when value is an id. */
            idValue?: FreebaseId;
            /**
             * Index of the value relative to the containing property (if any). Knowledge Graph supports a loose notion of indexing: some non-unique properties may have indices, while others may
             * not. Furthermore, for a single property, some values may have indices (such as the top 5 actors in a film), while others may not (the film's supporting cast). Un-indexed values will
             * appear at the end of the repeated value list. This field contains the index value only when is present in the Knowledge Graph.
             */
            index?: string;
            /** Present when value is int. */
            intValue?: string;
            /** Whenever the value is text with TYPE_TEXT, the lang field is populated with the III LanguageCode associated with the string_value field. */
            lang?: string;
            latLongValue?: FreebaseLatLong;
            measurementValue?: FreebaseMeasurement;
            /** Populated if this value holds NestedStruct. 'type' field needs to be set to TYPE_NESTED_STRUCT. */
            nestedStruct?: FreebaseNestedStruct;
            /** Provenance for this value. */
            provenance?: StorageGraphBfgTripleProvenance[];
            /** Similar to string_value/etc but contains raw bytes. */
            rawValue?: string;
            /** Present when value is text, enum, */
            stringValue?: string;
            subgraphId?: string[];
            /** The ISO-8601 timestamp corresponding to when this value was created (when it was written to the Knowledge Graph). Deprecated in favor of timestamp_usec. */
            timestamp?: string;
            /** The microsecond timestamp corresponding to when this value was created. */
            timestampUsec?: string;
            type?: string;
        }
        interface GDocumentBase {
            content?: GDocumentBaseContent;
            /** unix secs from epoch */
            ContentExpiryTime?: number;
            directory?: GDocumentBaseDirectory[];
            /**
             * Sometimes the URL displayed in search results should be different from what gets indexed (e.g. in enterprise, content management systems). If this value is not set, we default to
             * the regular URL.
             */
            DisplayUrl?: string;
            /**
             * 64-bit docid of the document (usually fingerprint of URL, but not always). WARNING: This does NOT uniquely identify a document ANYMORE. For a unique identifier across all documents
             * in production please refer to the field 'id().key()' listed above.
             */
            DocId?: string;
            /** 96-bit fingerprint of the canonical url's webmirror equivalence class name as of when this cdoc was exported. */
            ecnFp?: string;
            ExternalFeedMetadata?: string;
            /** Enterprise-specific external metadata. See http://engdoc/eng/designdocs/enterprise/enterprise_indexing_metadata.html */
            ExternalHttpMetadata?: string;
            /** Deprecated, do not use, this field is not populated since 2012. */
            FilterForSafeSearch?: number;
            /**
             * The primary identifier of a production document is the document key given in the ServingDocumentIdentifier, which is the same as the row-key in Alexandria, and represents a URL and
             * its crawling context. In your production code, please always assume that the document key is the only way to uniquely identify a document. ## Recommended way of reading: const
             * string& doc_key = cdoc.doc().id().key(); ## CHECK(!doc_key.empty()); More background information can be found in google3/indexing/crawler_id/servingdocumentidentifier.proto The
             * ServingDocumentIdentifier uniquely identifies a document in serving and also distinguishes between experimental vs. production documents. The SDI is also used as an input for the
             * union/muppet key generation in serving.
             */
            id?: IndexingCrawlerIdServingDocumentIdentifier;
            /** IP addr in binary (allows for IPv6) */
            IPAddr?: string;
            /** Localsearch-specific data. */
            localsearchDocInfo?: any;
            NoArchiveReason?: number;
            NoFollowReason?: number;
            NoImageframeOverlayReason?: number;
            NoImageIndexReason?: number;
            /**
             * When these reasons are set to a non zero value, the document should not be indexed, or show a snippet, or show a cache, etc. These reasons are bit maps of
             * indexing.converter.RobotsInfo.RobotedReasons enum values reflecting the places where the restriction was found.
             */
            NoIndexReason?: number;
            NoPreviewReason?: number;
            NoSnippetReason?: number;
            NoTranslateReason?: number;
            /** Ocean-specific data. */
            oceanDocInfo?: OceanDocInfo;
            originalcontent?: GDocumentBaseOriginalContent;
            /** Pagerank for doc (if known) */
            Pagerank?: number;
            /** Pagerank-NearestSeeds is an alternative pagerank score for the doc. */
            PagerankNS?: number;
            /**
             * is the webmirror representative id of the canonical url. Urls with the same repid are considered as dups in webmirror. WARNING: use this field with caution! The webmirror duprules
             * change frequently, so this value only reflects the duprules at the time when the canonical's docjoin is built.
             */
            Repid?: string;
            /** Citation data for science articles. */
            ScienceMetadata?: ScienceCitation;
            /**
             * WARNING: the URL does NOT uniquely identify a document ANYMORE. For a unique identifier across all documents in production please refer to the field 'id().key()' listed above.
             * Reason: foo.bar:/http and foo.bar:/http:SMARTPHONE share the same URL, but the body of the two documents might differ because of different crawl-context (desktop vs. smartphone in
             * this example).
             */
            URL?: string;
            URLAfterRedirects?: string;
            /** See webutil/urlencoding */
            URLEncoding?: number;
            /**
             * The user agent name used to crawl the URL. See //crawler/engine/webmirror_user_agents.h for the list of user-agents (e.g. crawler::WebmirrorUserAgents::kGoogleBot). NOTE: This field
             * is copied from the first WEBMIRROR FetchReplyClientInfo in trawler_fetch_info column. We leave this field unpopulated if no WEBMIRROR FecthReplyClientInfo is found. As the
             * submission of cl/51488336, Alexandria starts to populate this field. However, docjoins from freshdocs (or any other source), won't have this field populated, because we believe no
             * one needs to read this field from freshdocs docjoins.
             */
            userAgentName?: string;
        }
        interface GDocumentBaseContent {
            AuthMethod?: number;
            /** The actual length of the content: If Representation is compressed, this equals to Content.UncompressedLength; otherwise it is the length of the representation string. */
            ContentLength?: number;
            /** See enum ContentType in webutil/http/content-type.proto. */
            ContentType?: number;
            /** Crawled file size of the original document. */
            crawledFileSize?: number;
            /** Seconds since Unix epoch. */
            CrawlTime?: string;
            /** GeometryAnnotations, encoded with GeometryUtil::DeltaEncode() to reduce disk space usage. Use GeometryUtil::DeltaDecode() to decode this field. */
            encodedGeometryAnnotations?: string;
            /** See //depot/google3/i18n/encodings/public/encodings.h Encoding of representation */
            Encoding?: number;
            /** Set to false if Representation does not contain HTTP headers. */
            HasHttpHeader?: boolean;
            /** A Language enum value. See: go/language-enum Default is english */
            Language?: number;
            /**
             * If OriginalEncoding is present, the body part of the Representation was converted to UTF-8, Encoding was set to UTF8, and OriginalEncoding was set to the original encoding before
             * conversion. However, the HTTP headers part of the content might not be valid UTF-8. -1=an invalid value
             */
            OriginalEncoding?: number;
            /** Possibly compressed for old documents. It is not compressed for docjoins produced by Raffia after ~2012. */
            Representation?: string;
            /** Historically present if Representation is compressed. */
            UncompressedLength?: number;
            /**
             * Whether the content was visual right-to-left, and if so, what type of visual document it is. Must be one of the values in enum VisualType from google3/repository/rtl/visualtype.h
             * Default is NOT_VISUAL_DOCUMENT. See http://wiki/Main/RtlLanguages for background.
             */
            VisualType?: number;
        }
        interface GDocumentBaseDirectory {
            /** encoded in UTF8 */
            Category?: string;
            /** encoded in UTF8 */
            Description?: string;
            DescriptionScore?: number;
            /** "gwd", etc. */
            Identifier?: string;
            /** go/language-enum */
            Language?: number;
            /** encoded in UTF8 */
            Title?: string;
            /** Deprecated; do not use. There is no code populating these fields as of Oct 2017. */
            TitleScore?: number;
            URL?: string;
        }
        interface GDocumentBaseOriginalContent {
            Representation?: string;
            /** present iff rep is compressed */
            UncompressedLength?: number;
        }
        interface GenericSnippetResponse {
            /** Per-doc debug information. */
            debugInfo?: string[];
            /** Servlet-specific response info. */
            info?: any;
            /**
             * Lines of the snippet HTML. Typically gws concatenates these and lets the browser wrap. The values include trailing spaces, so inserting additional spaces is not necessary. However,
             * for very old browsers, gws may insert break tags after each snippet line. This field is confusing and poorly named; "snippet_line" would be better. In particular, note that this
             * does not return multiple snippets for a result. Nor are these fields the individual tidbits of the snippet.
             */
            snippet?: string[];
            /**
             * The title HTML. It may contain tags to denote query term matches. It may be already truncated and "..." is put instead (note that truncation does not always happen at the very end
             * of the title text). However the existence of "..." does not guarantee that the snippet generation algorithm truncated it; e.g. webmasters themselves can write "...".
             */
            title?: string;
            /** Snippet-specific members (tag ids 16+, must be optional!) Example: optional NewContentResponse new_response; */
            wwwSnippetResponse?: WWWSnippetResponse;
        }
        interface GeoOndemandAssistantSupportedActions {
            /** Whether this local entity allows guest checkout for reservations. */
            allowsGuestCheckout?: boolean;
            /** Whether or not this local entity supports asynchronous restaurant reservations, through the above restaurant_reservation_url. */
            isAsynchronousRestaurantReservation?: boolean;
            /** URL for the Madden restaurant reservation flow, e.g. for display in a WebView. Not populated if restaurant reservations are not supported for the local entity. */
            restaurantReservationUrl?: string;
        }
        interface GeostoreAccessPointProto {
            /** RESERVED */
            canEnter?: boolean;
            /** RESERVED */
            canExit?: boolean;
            /**
             * The ID of the feature that defines the access point. The bounding box of the feature is expanded to include the bounding box of the feature with the access point in accordance with
             * the standard practice for bucketing map/reduce operations. See the wiki page at http://wiki/Main/OysterBucketingMapReduce for more information. For access points to TYPE_SEGMENT
             * features, this may be re-derived if necessary by looking up the nearest segment to existing geometry.
             */
            featureId?: GeostoreFeatureIdProto;
            /**
             * The type of the feature. Required, to allow handling the access point differently based on feature type. For access points to non-TYPE_SEGMENT features, this cached type also makes
             * things easier for clients that aren't running a bucketing map-reduce. For access points to TYPE_SEGMENT features, this is used to find to find the nearest segment of the given type.
             */
            featureType?: number;
            /**
             * For indoor access points, this should be set to the level that the access point is on. The feature_id should point to the indoor segment, but when it is missing or invalid, and we
             * need to derive it from geometry, only segments on this level will be considered. For non-indoor access points, level should remain unset, and when we derive feature_id from
             * geometry, only segments not on any level (non-indoor segments) will be considered. The bounding box of the level feature is expanded to include the bounding box of the feature with
             * the access point in accordance with the standard practice for bucketing map/reduce operations. See the wiki page at http://wiki/Main/OysterBucketingMapReduce for more information.
             * (Though in general the feature should reside on the level already anyway..)
             */
            levelFeatureId?: GeostoreFeatureIdProto;
            /** Field-level metadata for this access point. */
            metadata?: GeostoreFieldMetadataProto;
            /**
             * For access points to non-TYPE_SEGMENT features, the location of the access point. For access points to TYPE_SEGMENT features, this can be supplied as a fuzzy access point that is
             * not guaranteed to be on the correct side of road. It should not be used by end clients in case of TYPE_SEGMENT access points.
             */
            point?: GeostorePointProto;
            /**
             * If the access point is defined by a TYPE_SEGMENT feature, this is the location of the access point displaced slightly to the correct side of the segment. This offset is in a
             * direction perpendicular to the direction of travel along the segment. The actual offset distance is unspecified. It would typically be relatively small (approximately 1 meter). You
             * can subtract the "off segment" point from the "on segment" point to get a vector of unknown length pointing from "on segment" point to the "off segment" point. You can then scale
             * that vector to whatever length you want. Note that extending this displacement vector a large distance (10s of meters) may result in a new point that is in the middle of some other
             * feature (park, street, intersection). This is the preferred basic geometry field for incoming data from editing clients and importers, if side-of-road is well-established.
             */
            pointOffSegment?: GeostorePointProto;
            /**
             * If the access point is defined by a TYPE_SEGMENT feature, this is the point on the centerline of the segment that is closest to the actual access point. May be re-derived if
             * necessary to maintain precise placement on segment.
             */
            pointOnSegment?: GeostorePointProto;
            /** LINT.ThenChange(//depot/google3/geostore/cleanup/callbacks/\ ID_DUPLICATE_ACCESS_POINT.cc) */
            priority?: string;
            /**
             * If the access point is defined by a TYPE_SEGMENT feature, this is the location of the access point expressed as a fractional distance along the segment. The value runs from 0 to 1
             * inclusive. May be re-derived if necessary to maintain precise placement on segment.
             */
            segmentPosition?: number;
            /**
             * This list represents the travel modes for which this access-point should be avoided. If this list is empty, the access-point is suitable for any travel mode. If all access points
             * are unsuitable for the current travel mode, client should revert to other heuristics (e.g. feature center). This is only used for access points to TYPE_SEGMENT features; access
             * points to non-TYPE_SEGMENT features, e.g. TYPE_ESTABLISHMENT_POI features with gcid:transit_station GConcepts are just identified by feature_type and feature_id.
             */
            unsuitableTravelMode?: string[];
        }
        interface GeostoreAddressComponentProto {
            /**
             * The id of the corresponding Feature, if such a feature is defined. As discussed above for feature_type, components of TYPE_FEATURE or TYPE_LANDMARK may have a corresponding feature
             * id.
             */
            featureId?: GeostoreFeatureIdProto;
            /**
             * For components of TYPE_FEATURE or TYPE_LANDMARK, this is the feature type (TYPE_COUNTRY, TYPE_LOCALITY, TYPE_ESTABLISHMENT_POI etc.). Note that some features may not actually exist
             * in the geostore (e.g. a village that we've never heard of), in which case the feature_id will be missing but the feature_type is still specified. Please refer to
             * IsValidAddressComponentFeatureType() in google3/geostore/base/public/addresscomponent.h for the definitive list of feature types allowed for the type (either TYPE_FEATURE or
             * TYPE_LANDMARK) of components.
             */
            featureType?: number;
            /**
             * The order of this address component relative to the ones that share the same feature_type in the AddressProto. For now, the primary use of this index field is to handle ordering
             * issue of multiple occurrences of AddressComponentProto with feature_type of TYPE_ROUTE (and subtypes), or TYPE_POLITICAL, where the order of the address components matters as there
             * are dependences. 0 is the smallest valid index value, representing the most specific address component. Index value of 1 represents a relatively less specific address component of
             * the same feature_type on which the 0-indexed address component depends.
             */
            index?: number;
            /**
             * The parsed_name field contains one or more names of an address component. Its actual contents depends on where in the Geo/Google stack you are reading a feature: 1. When an address
             * is initially parsed via a feed or other raw input and structured as an AddressProto, parsed_name should contain the set of names that corresponds to the (possibly normalized) raw
             * text from the raw input. 2. In MapFacts, the address component may be linked to an actual feature via feature_id. Any address formatting directly from MapFacts should follow links
             * to retrieve names when possible. The parsed_name contents may be formatted directly if the address component is unlinked following the same rules as selecting and formatting the
             * name of a feature. The cached parsed_name is regularly refreshed from the linked feature with the minimal set of names for address components (usually just a single, preferred name,
             * in the local language, plus a Latin-script name: go/story-of-ac-names). 3. In serving systems, the names of linked features may be denormalized into the parsed_name field to
             * facilitate quicker address formatting or for simple data filtering (e.g. finding all geocodes in California by name). If reading a feature from such a system, the parsed_name field
             * could contain multiple names in multiple languages that reflect a cached copy of the names associated with the linked features. Formatting of such names should follow the same rules
             * as selecting and formatting the name of a feature itself.
             */
            parsedName?: GeostoreNameProto[];
            /**
             * Any numerical address component may optionally be specified as a range. For example if a component of TYPE_STREET_NUMBER has the optional "range" attribute, then it represents a
             * range of addresses rather than a single address (see AddressRangeProto for details).
             */
            range?: GeostoreAddressRangeProto;
            /** A place for clients to attach arbitrary data to an address component. Never set in MapFacts. */
            temporaryData?: any;
            /**
             * Additional text to append before and/or after the parsed_name, when the address is formatted. Multiple instance should represent translations. Currently, this is only permitted on
             * TYPE_LANDMARK components, and only one instance is permitted.
             */
            textAffix?: GeostoreTextAffixProto[];
            /**
             * Every address component has a type. Most address components correspond to one of the feature types defined in FeatureProto, so rather than defining a separate category system here,
             * instead we mark them as TYPE_FEATURE and store the FeatureProto type in the feature_type() field. This is how we handle countries, cities, streets, etc. However, there are a few
             * types of address components that do not have a corresponding feature type (e.g. PO boxes). These components have their type defined here. An address component of TYPE_STREET_NUMBER
             * may correspond to a physical entity that defines a street number, such as a geocoded address or a land parcel. In this case, the address component may have a link to the
             * corresponding feature. A good reference for what types of address components are possible is the xAL standard, which is a published XML schema:
             * http://www.oasis-open.org/committees/ciq/download.shtml. This standard is the basis of the PostalAddress protocol message.
             */
            type?: string;
        }
        interface GeostoreAddressLinesProto {
            /**
             * The external form of a Google International Identifiers Initiative (III) LanguageCode object. See google3/i18n/identifiers/languagecode.h for details. We place extra restrictions on
             * languages in addition to what the III library requires. See http://go/geo-schema-reference/feature-properties/languages.md
             */
            language?: string;
            /** These lines are in display order. */
            line?: string[];
        }
        interface GeostoreAddressProto {
            /**
             * The unparsed portion (lines) of the address. An address can have multiple unparsed portions. Multiple unparsed portions sharing the same language should be modeled as one
             * address_lines instance having multiple lines. Historically, we also supported uparsed portions in different languages, but we no longer do. Consequently, only one value is allowed
             * for this field despite the fact that it is repeated. See go/address-lines-multi-language for information about why we made this change. If any components are filled in, this is
             * supplemental to (i.e. disjoint from) them. Furthermore, this must be the most specific portion of the address (except for the portion, if any, stored in the name field of
             * feature.proto). Unparsed lines are always formatted together in a block. Other address components are never formatted between the address lines. This doesn't imply that the address
             * lines are always either the first or the last part of the formatted output.
             */
            addressLines?: GeostoreAddressLinesProto[];
            /** A list of parsed address components, e.g. the street, city, etc. An address range is one type of component. */
            component?: GeostoreAddressComponentProto[];
            /** ** DEPRECATED ** This field is now deprecated (see b/33268032). If you want to store cross street information as part of an address, use the address_lines field. */
            crossStreet?: GeostoreAddressComponentProto[];
            /** Field-level metadata for this address. */
            metadata?: GeostoreFieldMetadataProto;
            /** reserved */
            partialDenormalization?: GeostoreAddressProto;
            /**
             * The opaque ID of the address template that contains rules for structuring this address. The id of the address template can be retrieved using
             * google3/geostore/address_templates/public/address_templates.h
             */
            templateId?: string;
            /** A place for clients to attach arbitrary data to an address. Never set in MapFacts. */
            temporaryData?: any;
        }
        interface GeostoreAddressRangeProto {
            /** Two or more address numbers. Each number represents an address that was mentioned by the data provider. */
            number?: number[];
            /**
             * For address range definitions: Two or more interpolation parameter values. The length of this array must match the length of the number array, and each parameter number specifies
             * the position of the corresponding address number. Each value is an interpolation between 0.0 and 1.0 inclusive. The value is proportional to the distance traveled along the
             * segment's polyline starting at its origin. The parameters must be provided in increasing order and the values in the number array must be in strictly increasing or decreasing order.
             * We make an exception for singleton addresses, which are represented as two copies of a (number, parameter) pair, for backwards compatibility. For address range references: This
             * array must be empty.
             */
            parameter?: number[];
            /**
             * If specified, the prefix or suffix is applied to all numbers in the range. For example, this can be used to indicate that addresses B1 through B99 are on one side of the street,
             * while A1 through A99 are on the other side of the street.
             */
            prefix?: string;
            /**
             * If 'same_parity' is true, then all 'number' values must have the same parity (even or odd), and this address range only includes addresses whose parity is the same as the given
             * 'number' values.
             */
            sameParity?: boolean;
            suffix?: string;
            /**
             * A place for clients to attach arbitrary data to an address range. Never set in MapFacts. Here are some examples: Example #1: Single non-numeric address (e.g., "Twelve") At the
             * moment this can only be represented as a street number (with the value in the parsed_name field of the AddressComponentProto). We have future plans to make other changes so we can
             * handle this case. Example #2: Single semi-numeric address (e.g., "12bis") The number array contains two copies of the single numeric value (12). The prefix is empty and the suffix
             * contains "bis". The parameter array has two identical values specifying the position of the single address. Example #3: Simple address range (e.g., "100 to 198, even numbers only")
             * The number array contains the two values "100" and "198". The prefix and suffix strings are empty in this example. The parameter array has two values, one for each number. The
             * same_parity flag is set in this example.
             */
            temporaryData?: any;
        }
        interface GeostoreAnchoredGeometryProto {
            /** The ID to be used to fetch the feature’s geometry from the 3D Geometry Store. */
            geometryId?: string;
        }
        interface GeostoreAppliedSpeedLimitProto {
            /** The actual speed limit value. */
            speedLimit?: GeostoreSpeedLimitProto;
            /** The level of trust we have in this speed limit value. */
            trustLevel?: string;
        }
        interface GeostoreAttachmentsAttachmentProto {
            /** attachment_id distinguishes messages of the same type_id associated with the same feature. It can not be set to 0x0. */
            attachmentId?: string;
            /**
             * This field specifies a namespace identifier that can be used to track the sources of attachments in a human friendly format. Name spaces must be at most 64 characters long and must
             * be composed entirely of alphanumeric characters, hyphens, and underscores. No other characters are allowed.
             */
            clientNameSpace?: string;
            /** comment is a human-readable string that is logged whenever this attachment is processed by the framework. */
            comment?: string;
            /** messages contains the structured data for this attachment. It should contain a single message with a type ID matching the value of the type_id field below. */
            messages?: any;
            /** type_id determines the type of the actual attachment that should be set in the messages MessageSet. It can not be set to 0x0. */
            typeId?: string;
        }
        interface GeostoreAttributeIdProto {
            /** The id of the attribute. Stored as a stripped format of the gcid (e.g. "foo" instead of "gcid:att_foo"). */
            id?: string;
            /** Set because it's required, but not really meaningful in geostore (always set to "Geo"). */
            providerId?: string;
            type?: string;
        }
        interface GeostoreAttributeProto {
            applicationData?: any;
            attributeDisplay?: GeostoreAttributeValueDisplayProto[];
            booleanValue?: boolean;
            /** The canonical attribute for this attribute instance. */
            canonicalAttributeId?: GeostoreAttributeIdProto;
            doubleValue?: number;
            /** For those attribute ids that expect their values to be taken from an enumeration-style set of values, that value's gcid should be stored here, e.g. "gcid:attval_yes". */
            enumIdValue?: string;
            floatValue?: number;
            int64Value?: string;
            integerValue?: number;
            itemClassId?: GeostoreAttributeIdProto;
            /** Field-level metadata for this attribute */
            metadata?: GeostoreFieldMetadataProto;
            /** Fully qualified package name because genprotohdf uses genproto for this proto2 syntax: https://wiki.corp.google.com/twiki/bin/view/Main/Proto2WithGenproto */
            protoValue?: any;
            /** The attribute value falls into one of these fields, based on value_type: */
            stringValue?: string;
            uint32Value?: number;
            /** Used to store language-specific names of this attribute's value (e.g. a translation into another language). */
            valueDisplay?: GeostoreAttributeValueDisplayProto[];
            valueSpaceId?: GeostoreAttributeIdProto;
            valueType?: string;
        }
        interface GeostoreAttributeValueDisplayProto {
            language?: string;
            synonym?: string;
        }
        interface GeostoreBarrierLogicalMaterialProto {
            material?: string[];
        }
        interface GeostoreBestLocaleProto {
            /** The ID of the best-match TYPE_LOCALE feature for this feature. */
            locale?: GeostoreFeatureIdProto;
            /**
             * The ID of the localization policy to apply when selecting a name for a feature. This field should always be set. If feature_id is also defined, this field should have the same
             * localization policy ID as the referenced locale feature. Localization policy IDs are arbitrary identifiers (up to some number of bytes; see geostore/base/public/constants.h) that
             * uniquely distinguish a set of language-selection rules.
             */
            localizationPolicyId?: string;
            /** Field-level metadata for this best locale. */
            metadata?: GeostoreFieldMetadataProto;
        }
        interface GeostoreBizBuilderReferenceProto {
            /** Listing id. Used in queries to BizBuilder backend for listing access. */
            id?: string;
        }
        interface GeostoreBorderProto {
            /**
             * The ids of the area features to the left and right of the border, relative to the start and end of this borders' polyline geometry. These features should have the same type as the
             * "type" attribute above. These ids are not required because the corresponding features may be nonexistent or difficult to obtain.
             */
            featureIdLeft?: GeostoreFeatureIdProto;
            featureIdRight?: GeostoreFeatureIdProto;
            /** The logical borders which this border is a part of. */
            logicalBorder?: GeostoreFeatureIdProto[];
            /** List of border status overrides. Due to legal reasons, we may be required to display some borders differently on some domains for instance. */
            overrideStatus?: GeostoreOverrideBorderStatusProto[];
            /** The border status identifies the legal status of the border line. */
            status?: string;
            /**
             * The type of the features this border separates. Should always be a subtype of TYPE_POLITICAL. NOTE: as of December 2019, we currently require this to be equal to TYPE_COUNTRY or
             * TYPE_ADMINISTRATIVE_AREA1. In the future, we may support TYPE_BORDER for lower types of political features.
             */
            type?: number;
        }
        interface GeostoreBoundingMarkerProto {
            /** References to any gcid:physical_lane_marker features that bound this lane or lane connection. */
            boundingMarker?: GeostoreFeatureIdProto;
            /** A token that can be used to identify the version of the data about this bounding marker. */
            boundingMarkerToken?: string;
            /**
             * Which part of the flowline does this association refer to? These should be between 0 and 1. These are optionally set, but can be approximated geometrically if they aren’t set. NOTE:
             * These refer to the geometry of this feature.
             */
            flowlineAdjacencyBeginFraction?: number;
            flowlineAdjacencyEndFraction?: number;
            /**
             * Which part of the marker track does this association refer to? These should be between 0 and 1. These are optionally set, but can be approximated geometrically if they aren’t set.
             * NOTE: These refer to the geometry of the marker feature.
             */
            markerAdjacencyBeginFraction?: number;
            markerAdjacencyEndFraction?: number;
            /** Which side of the flowline does the marker occur on. */
            side?: string;
        }
        interface GeostoreBuildingProto {
            /** The height of the base of this building, in meters above ground-level, if known. */
            baseHeightMetersAgl?: number;
            /**
             * The level in this building that should get displayed by default. If present, the default display level must be one of this building's levels that are listed in the level[] field,
             * and if a level is set as a default level of one building, all buildings sharing the level should have that same level as their default level. If not present, clients should not
             * display any level by default for that building.
             */
            defaultDisplayLevel?: GeostoreFeatureIdProto;
            /**
             * The number of floors above the base of the building, if known. For example a regular 1-story building would set this to "1". Use a value of GeostoreConstants::kDefaultHeightPerFloor
             * when converting "floors" to "height_meters".
             */
            floors?: number;
            floorsMetadata?: GeostoreFieldMetadataProto;
            /** The height of the building above its base, in meters, if known. */
            heightMeters?: number;
            heightMetersMetadata?: GeostoreFieldMetadataProto;
            /** The levels in this building, in no particular order. These levels refer back to the building via another strong reference (the LevelProto.building field). */
            level?: GeostoreFeatureIdProto[];
            /** "Structure" denotes a physical architecture of the building that is readily visible. This attribute is useful in that rarer structures can make good landmarks. */
            structure?: string;
        }
        interface GeostoreBusinessChainProto {
            /** Canonical GConcepts describe the ideal state of the GConcepts of this business chain's members. */
            canonicalGconcepts?: GeostoreCanonicalGConceptProto[];
        }
        interface GeostoreBusinessHoursProto {
            /** The actual hours represented by this BusinessHoursProto. */
            data?: BusinessHours;
            /** Field-level metadata for these hours. */
            metadata?: GeostoreFieldMetadataProto;
        }
        interface GeostoreCallToActionProto {
            /** Required. */
            ctaType?: string;
            url?: GeostoreUrlProto;
        }
        interface GeostoreCanonicalGConceptProto {
            gconcept?: GeostoreGConceptInstanceProto;
            /** Whether the gconcept must be on a member. This must be true for a primary gconcept. */
            isRequired?: boolean;
        }
        interface GeostoreCellCoveringProto {
            /** Array of S2 cell ids that represent the covering. There is no preset limit on how many cells can be used. */
            cellId?: string[];
        }
        interface GeostoreComposableItemProto {
            /** Call to action for the individual product. */
            callToAction?: GeostoreCallToActionProto;
            jobMetadata?: GeostoreJobMetadata;
            /** Any photos describing this item. */
            media?: GeostoreMediaItemProto[];
            /**
             * The repeated name_info field is for price list sections listed in multiple languages. At least one name_info containing id must be specified. There should be at most one name_info
             * for any given language. When representing a job item, there should be exactly one name_info specified.
             */
            nameInfo?: GeostorePriceListNameInfoProto[];
            /** Represents if an item is offered at a business. For TYPE_JOB, this represents if this job is offered by the corresponding business */
            offered?: string;
            /** Price of the item. There should be at most one price for any given currency. */
            price?: GeostorePriceRangeProto;
            /**
             * Represents which price format is being used by this item, which determines the usage/meaning of the “price” field above. Optional – the default value is legal and safe (represents
             * no price if the “price” field is unset).
             */
            priceFormat?: string;
            /**
             * Numerical score which can be provided by data sources to indicate preferred item ordering. This is purely a hint – we are not required to followed it if we have a different order we
             * think is better. Higher scores represent items that should be shown more prominently/earlier. Optional.
             */
            rankingHint?: number;
        }
        interface GeostoreCountComparisonProto {
            comparisonOperator?: string;
            count?: number;
        }
        interface GeostoreCrossingStripePatternProto {
            borderLine?: GeostorePhysicalLineProto;
            borderPattern?: string;
            /** Colors found on this crossing. */
            color?: GeostorePaintedElementLogicalColorProto[];
            stripePattern?: string;
        }
        interface GeostoreCurveConnectionProto {
            bezierParams?: GeostoreCurveConnectionProtoBezierParams;
            circleParams?: GeostoreCurveConnectionProtoCircleParams;
            type?: string;
        }
        interface GeostoreCurveConnectionProtoBezierParams {
            /** Internal Bezier handles. One can be used for a quadratic curve, two for cubic Beziers. */
            controlPoint?: GeostoreCurveConnectionProtoBezierParamsControlPoint[];
        }
        interface GeostoreCurveConnectionProtoBezierParamsControlPoint {
            /**
             * We use this parameterization to make curves change predictable when endpoints move. Each point P is defined in terms of the straight edge [S, E] between the start point of the curve
             * S and its end point E. *P / / / S *------------* E Counter-clockwise angle between vector SE and vector SP.
             */
            angleDegrees?: number;
            /** Distance(S, P) in units of Distance(S, E). */
            distanceMultiplier?: number;
        }
        interface GeostoreCurveConnectionProtoCircleParams {
            /** Arc radius. Must be greater than half-distance between two endpoints. */
            radius?: number;
        }
        interface GeostoreDataSourceProto {
            /**
             * This is the URL of a website representing this DataSource as a whole. If this DataSource feature is specific to a particular dataset or product, the page may contain information
             * relevant to that dataset or product or may be the main page of the organization.
             */
            attributionUrl?: GeostoreUrlProto[];
            /** A UTF8 string that will be inserted in copyright messages to refer to this copyright owner, e.g. "Tele Atlas". */
            copyrightOwner?: string;
            /** The copyright year of this data (which may be different than the year of the release date), e.g. 2005. */
            copyrightYear?: number;
            /**
             * A free-form description of this data source. Ideally the description should include: - Where the data was obtained (URL, company name, individual, etc). - Where to find detailed
             * documentation. - A brief summary of the licensing terms. - As much internal and external contact information as possible (e.g. who to ask about licensing questions, interpreting the
             * data, updating the data, fixing bugs in the importer, etc).
             */
            description?: string;
            /** The build information of the importer binary used to generate this data source. */
            importerBuildInfo?: string;
            /** The build target of the importer binary used to generate this data source. */
            importerBuildTarget?: string;
            /** The Perforce client information of the importer binary used to generate this data source. */
            importerClientInfo?: string;
            /**
             * If the importer was built as an MPM, the version number can be stored in this field. As with build_info, this can be useful when tracking down issues that may be due to the use of a
             * particular binary.
             */
            importerMpmVersion?: string;
            /** The timestamp of the importer binary used to generate this data source. */
            importerTimestamp?: string;
            /** The provider type of this data source. */
            provider?: string;
            /** For every key that is used in raw_data from this source, there must be a corresponding entry in raw_metadata that describes this key. */
            rawMetadata?: GeostoreRawMetadataProto[];
            /**
             * A release string that doesn't have to be a date. This is provided so that we can preserve provider release strings that aren't based on dates. If you don't set it, the release_date
             * will get formatted into this field for debugging purposes.
             */
            release?: string;
            /** The release date of this data. */
            releaseDate?: GeostoreDateTimeProto;
            /**
             * A data provider defined string describing the source dataset from which the features of this data source were generated. For example, the MultiNet "fra" dataset produces features
             * for both France and Monaco.
             */
            sourceDataset?: string;
        }
        interface GeostoreDateTimeProto {
            /**
             * This attribute describes the precision of the date and time. It would be unusual for a data provider to provide a precision along with their date. It is more likely that the
             * precision of a date will be inferred from the date format. For example "19th century" is likely to be correct to the century, while "1800" is probably correct to the year. The
             * precision should be semantically interpreted as a cast, so a DateTimeProto object with a seconds value corresponding to 2018-03-28 18:40:00 UTC and a precision of MONTH should be
             * interpreted as "March 2018". The enums above are only some of the possible precision levels for dates and times. Clients may wish to add more precision enums in the future. However,
             * these enums must be ordered by decreasing duration. Clients should be able to write date formatting code that looks like this: if (datetime.precision() <=
             * DateTimeProto::PRECISION_CENTURY) { date = FormatCenturyDate(proto.seconds()); } else if (proto.precision() <= case DateTimeProto::PRECISION_DECADE) { date =
             * FormatDecadeDate(proto.seconds()); } else { ... } See geostore/base/public/datetime.h for date formatting utility functions.
             */
            precision?: string;
            /**
             * Number of seconds since (or before) the UNIX epoch (January 1, 1970). This is also the standard epoch for Java and Python time representations. If it is important for this time be
             * displayed correctly for different time zones, convert the time to Coordinated Universal Time (UTC).
             */
            seconds?: number;
        }
        interface GeostoreDimensionComparisonProto {
            comparisonOperator?: string;
            dimensionWithUnit?: GeostoreDimensionProto;
        }
        interface GeostoreDimensionProto {
            dimension?: number;
            unit?: string;
        }
        interface GeostoreDisplayDataProto {
            /** The location where this feature should be rendered. */
            displayLocation?: GeostorePointProto;
        }
        interface GeostoreDoodleProto {
            /** The type of this feature -- see comments above. */
            type?: string;
        }
        interface GeostoreDurationBasedRateProto {
            /** If true, represents that the rate is free; i.e. the price is 0 in any currency. If this is true, price must be empty. */
            isFree?: boolean;
            /**
             * The billable unit of the rate; i.e. after having utilized the service for exactly periodicity_seconds, the total cost should increase by ‘price’. For example, if the rate expresses
             * a price per hour, then periodicity_seconds should be set to 3600. If this is unset, then the rate does not vary based on duration, and price represents a flat cost. May only be set
             * if price is nonempty.
             */
            periodicitySeconds?: number;
            /**
             * The total price, in each applicable currency, of utilizing the service for periodicity_seconds, or for the entire duration expressed by range_start_seconds and range_end_seconds if
             * periodicity_seconds is 0. Each entry should have an ID of /measurement_unit/money_value and consist of two properties: one with an ID of /measurement_unit/money_value/amount and a
             * float value with the amount, and another with the ID /measurement_unit/money_value/currency and an ID value with the MID of the proper currency. May only be set if is_free is false.
             */
            price?: FreebaseTopic[];
            /** Upper bound for durations to match, exclusive. Unset implies indefinite. */
            rangeEndSeconds?: number;
            /** Lower bound for durations to match, inclusive. Required; a value of 0 expresses that the price applies from the start of the utilization period. */
            rangeStartSeconds?: number;
        }
        interface GeostoreElevationModelProto {
            /**
             * Defines the relative order in which terrain data should be rendered. Features with higher blend_order should be blended on top of features with lower blend_order. NOTE: this is
             * backwards from the way BlendRank works in Magrathean.
             */
            blendOrder?: number;
            /** The zoom level at which this data is defined. Level 0 is world level data, and each increase in zoom level corresponds to a factor of 2 increase in scale. */
            dataLevel?: number;
            /** The maximum (finest) level at which this terrain data has sufficient resolution to be displayed. */
            dataMaxlevel?: number;
            /** A place to store an elevation data protocol buffer. Currently, this must be a keyhole::AssetTileCompressed (see google3/keyhole/common/proto/magrathean.protodevel). */
            elevationData?: any;
            /** If true, all of the data contained in this feature is available at the next highest (more detailed) level. If this is true, partial_child_data_available should also be true. */
            fullChildDataAvailable?: boolean;
            /** If true, at least part of the data contained in this feature is available at the next highest (more detailed) level. */
            partialChildDataAvailable?: boolean;
        }
        interface GeostoreElevationProto {
            /** The average elevation of the feature in meters above the local mean sea level. */
            averageElevationMeters?: number;
            /** Additional details for TYPE_PEAK and TYPE_VOLCANO features. */
            peak?: GeostorePeakProto;
        }
        interface GeostoreEntranceProto {
            allowance?: string;
            /** DEPRECATED. Please use enter_or_exit instead. */
            canEnter?: boolean;
            /** Whether the target can be entered through this entrance. Whether the target can be exited through this entrance. */
            canExit?: boolean;
        }
        interface GeostoreEntranceReferenceProto {
            /** Feature ID of the related entrance. References should refer to TYPE_ENTRANCE or TYPE_COMPOUND features that are entrances or exits of the referencing feature. */
            featureId?: GeostoreFeatureIdProto;
        }
        interface GeostoreEstablishmentProto {
            /**
             * Reference to BizBuilder data for this establishment. The bizbuilder_reference field indicates that a feature is claimed in CBDB (with the canonical state in MapFacts). The
             * bizbuilder_reference is different from the social_reference's claimed_gaia_id because some BizBuilder clients will not have +Pages. All claimed businesses should have a
             * bizbuilder_reference.
             */
            bizbuilderReference?: GeostoreBizBuilderReferenceProto;
            /** Regular opening hours for the establishment (weekly schedule). */
            hours?: GeostoreTimeScheduleProto;
            /**
             * Opening hours for this establishment, including regular weekly hours and exceptional hours (e.g. on holidays). NOTE: in practice, only the exceptional hours are filled in this
             * message. A schema migration for regular weekly hours was planned back in 2015 (see b/23105782) but was not completed and is (as of May 2018) not prioritized. Clients should continue
             * getting regular opening hours from the `hours` field above. In openinghours.h there is a utility function `GetOpeningHoursFromFeature` that merges `EstablishmentProto.hours` into
             * this proto.
             */
            openingHours?: GeostoreOpeningHoursProto;
            /** Pricing for products and services offered. Example: menus for restaurants. */
            priceInfo?: GeostorePriceInfoProto;
            serviceArea?: GeostoreServiceAreaProto;
            /** Telephone number and related information. */
            telephone?: GeostoreTelephoneProto[];
            /** ** DEPRECATED ** This is deprecated in favor of the top-level (in FeatureProto) set of GConcepts. The type of establishment -- see comments above. */
            type?: string;
        }
        interface GeostoreExceptionalHoursProto {
            /**
             * The weekly schedule to be applied for the dates that fall within the range. The schedule may contain hours only for days of the week that occur during the date range specified in
             * the range field.
             */
            hours?: GeostoreBusinessHoursProto;
            /** Field-level metadata for this exception. */
            metadata?: GeostoreFieldMetadataProto;
            /**
             * The dates for which this exception applies, expressed as a half open interval. For example, an exception that applies for the entire month of December 2015 should have a range
             * December 1, 2015 to January 1, 2016. Any regular hours that start on days in this range are ignored and replaced by the exceptional hours for that day. The TimeIntervalProto for the
             * range must be a fully specified, non-empty, and non-inverted range of dates. Concretely, the requirements are: * the range must be a TYPE_RANGE interval * the interval may not be
             * inverted * the endpoints of the interval must specify a year, month, and day * the day_type of each endpoint must be type DAY_OF_MONTH * the endpoints may not specify hour, minute,
             * second, week, or week_type * the begin endpoint must predate the end endpoint
             */
            range?: GeostoreTimeIntervalProto;
        }
        interface GeostoreExistenceProto {
            /**
             * Indicates whether the place is closed (permanently or temporarily), i.e., not operational in the present, but was at in the past and/or will be in the future. WARNING: New code
             * should use Geo Schema's libraries instead, specifically the OpeningStatus APIs, available in: * C++ (cs/f:google3/geostore/base/public/feature.h%20function:ExistenceState) * Java
             * (cs/f:google3/java/com/google/geostore/base/Existence.java%20function:OpeningStatus) * Python (cs/f:google3/geostore/base/public/python/feature.clif%20existence_state)
             */
            closed?: boolean;
            /** Structured reason for the permanent closure (if any). */
            closeReason?: string;
            /** RESERVED */
            endAsOfDate?: GeostoreDateTimeProto;
            endDate?: GeostoreDateTimeProto;
            /**
             * ** DEPRECATED ** This field is now deprecated (see b/22878252). Please use the Geo Schema GetFeatureBirthTimestamp() API to extract the birth timestamp of a feature. The timestamp
             * in seconds since the UNIX epoch (January 1, 1970) when this feature becomes live in the Geo repository. Different from start_date in that this is the birth date of Google's
             * representation of the place whereas start_date is the birth date of the place in the physical world.
             */
            featureBirthTimestampSeconds?: string;
            /**
             * Indicates whether the feature is marked as removed in the Geo repository. Removed features are still present in the Geo repository but are considered to be in an inactive state (not
             * valid for lint purposes, not retrievable except explicitly by feature ID, etc.). NOTE: If you have access to a complete FeatureProto, do NOT read this bit directly to find out
             * whether a feature is removed. Instead, rely on the IsFeatureRemoved() API, available in C++ (geostore/base/public/feature.h) and Java (geostore/base/Feature.java).
             */
            removed?: boolean;
            /** Structured reason why the feature is marked as removed. Relevant only when removed == true. */
            removedReason?: string;
            /**
             * (Initial) opening and (permanent) closing dates of the establishment, such that start_date is the first day open and end_date is the first day closed. The only allowed precisions
             * are PRECISION_DAY, PRECISION_MONTH, PRECISION_YEAR. DateTimeProto.seconds should have the lowest legal value for the desired date/time and precision. E.g. for PRECISION_MONTH,
             * 2019-02-15 21:10:30 is not valid, it should be 2019-02-01 00:00:00 instead. NOTE: The start_date and end_date are stored in UTC but should be interpreted as being in the local
             * timezone. So clients should convert the DateTimeProto to local (civil) time using UTC+0, and then treat the result as local to the feature.
             */
            startDate?: GeostoreDateTimeProto;
        }
        interface GeostoreFeatureFieldMetadataProto {
            fieldProvenance?: GeostoreFeatureFieldMetadataProtoFieldProvenance[];
        }
        interface GeostoreFeatureFieldMetadataProtoFieldProvenance {
            /** Represents all fields for which this SourceInfo is valid. NOTE: Field paths are rooted at FeatureProto level. */
            fieldPath?: GeostoreStableFieldPathProto[];
            provenance?: GeostoreProvenanceProto;
        }
        interface GeostoreFeatureHistoryMetadataProto {
            /**
             * The timestamp (in microseconds since the UNIX epoch) when this feature first went live in the Geo repository. Note that this has no relation to the birth data of that geographical
             * entity in the real world.
             */
            featureBirthTimestampUs?: string;
            /**
             * The timestamp (in microseconds since the UNIX epoch) of the last modification to the feature. Note this includes attachment modifications. The feature's initial creation is also
             * considered as a modification. This is useful for those that consume features via both listening to notifications and reading from repository snapshots. This timestamp can be used to
             * decide whether a feature in the snapshot was already seen in a more recent state through the notifications.
             */
            lastModificationTimestampUs?: string;
            /**
             * The timestamp (in microseconds since the UNIX epoch) of the deletion time of the feature. If the feature is currently removed, this field gets populated with the timestamp the
             * feature first became removed after being live (or being removed from beginning). This field won't be set if the feature is live.
             */
            removalTimestampUs?: string;
        }
        interface GeostoreFeatureIdForwardingsProto {
            /**
             * If the feature has been marked as a DUPLICATE of another feature, this is the feature ID of that other feature. Note that the other feature may itself be removed. This field is NOT
             * set in (1).
             */
            duplicateOf?: GeostoreFeatureIdProto;
            /** The feature ID of the forwarded feature. This field is only set in case (3). */
            forwardedId?: GeostoreFeatureIdProto;
            /**
             * If other features have been marked as DUPLICATE of this feature, this is the set of all such feature IDs. All feature IDs in this set should be for removed (aka inactive) features.
             * Note that in the context of historical read requests against MapFacts (when ReadRequest.version_selection.timestamp is set), this field won't be set.
             */
            inactiveDuplicate?: GeostoreFeatureIdProto[];
            /**
             * If the feature has been REPLACED by one or more other feature(s), this is the list of feature IDs of the replacement feature(s). Note that the other features may themselves be
             * removed.
             */
            replacedBy?: GeostoreFeatureIdListProto;
            /**
             * If the feature has been transitively marked as a DUPLICATE of another feature (via a chain of size >= 1), this is the feature ID of that other feature which is the end of the chain.
             * The field is always set even if the chain is of size 1. Note that the other feature may itself be removed. This field is only set in case (3).
             */
            transitivelyDuplicateOf?: GeostoreFeatureIdProto;
        }
        interface GeostoreFeatureIdListProto {
            /** The list of feature IDs. While the exact semantics of these IDs are usage-dependent, the list should never be empty or contain duplicates. */
            id?: GeostoreFeatureIdProto[];
        }
        interface GeostoreFeatureIdProto {
            /**
             * The S2CellId corresponding to the approximate location of this feature as of when it was first created. This can be of variable accuracy, ranging from the exact centroid of the
             * feature at creation, a very large S2 Cell, or even being completely randomized for locationless features. Cell ids have the nice property that they follow a space-filling curve over
             * the surface of the earth. (See s2cellid.h for details.) WARNING: Clients should only use cell IDs to perform spatial locality optimizations. There is no strict guarantee that the
             * cell ID of a feature is related to the current geometry of the feature in any way.
             */
            cellId?: string;
            /**
             * A 64-bit fingerprint used to identify features. Most clients should rely on MapFacts or OneRing to choose fingerprints. If creating new fprints, the strategy should be chosen so
             * that the chance of collision is remote or non-existent, and the distribution should be reasonably uniform. For example, if the source data assigns unique ids to features, then a
             * fingerprint of the provider name, version, and source id is sufficient.
             */
            fprint?: string;
            /** A place for clients to attach arbitrary data to a feature ID. Never set in MapFacts. */
            temporaryData?: any;
        }
        interface GeostoreFeatureMetadataProto {
            /**
             * This field indicates whether the feature is subject to bulk updates. Caution must be exercised while editing such features since the changes made by the edits will be overwritten by
             * the bulk update (if the feature is bulk updated). See go/mapfacts-abu for more information.
             */
            bulkUpdatable?: string;
            /** core_version_token is an opaque token representing the version of the core fields of the feature. This field is not updated when attachments are changed. */
            coreVersionToken?: string;
            /** Metadata for tracking when a feature is derived from or replaced by another feature or set of features. */
            featureReplacementInfo?: GeostoreFeatureReplacementInfoProto;
            /** Metadata about certain repeated fields and their subfields, for which field type is not granular enough. */
            fieldMetadata?: GeostoreFeatureFieldMetadataProto;
            /** Feature ID forwardings, if applicable. */
            forwardings?: GeostoreFeatureIdForwardingsProto;
            /** Metadata related to the history. */
            history?: GeostoreFeatureHistoryMetadataProto;
            /** version_token is an opaque token representing the version of this feature. It can be used as a concurrency token when sending edits. */
            versionToken?: string;
        }
        interface GeostoreFeaturePropertyIdProto {
            /** Required when field_type == ATTACHMENT. */
            attachmentTypeId?: string;
            /** Required when field_type == FEATURE_ATTRIBUTE. */
            attributeId?: string;
            fieldType?: string;
            /** Required when field_type == KNOWLEDGE_GRAPH_PROPERTY. */
            kgPropertyId?: string;
            /** RESERVED */
            nameLanguage?: string;
        }
        interface GeostoreFeatureProto {
            /**
             * Optional access point information. Access points hold detailed information about routing endpoints. For example, the main Google office is at "1600 Amphitheatre Parkway". The
             * feature representing that office has a polygon, a center, and an address with components for the street number, route, locality, etc. The access point information, on the other
             * hand, identifies the specific segment, the latitude/longitude of the driveway, and so forth.
             */
            accessPoint?: GeostoreAccessPointProto[];
            /**
             * Address for this feature. A Geo Schema address is designed to model a mailing address, so only features that have mailing addresses in the real world may have addresses. Each
             * feature should have only one address. If you want to describe the geographic location of a feature which does not have a mailing address with respect to other well-known features,
             * some other schema constructs should be used. Note that the field is defined as repeated though features that use this field with its intended semantics are constrained to have a
             * single address even if they may have multiple mailing addresses in the real world. The “single address” rule is enforced by lint. Current exceptions to the single address rule and
             * mailing address rule are described in the g3doc. Bear note that the schema team is actively working on eliminating these exceptions. http://go/geo-addresses Note the following
             * conventions: - Addresses follow the postal hierarchy, not the political hierarchy. Addresses may have components that refer to political entities when those entities also appear in
             * the postal hierarchy. - As stated previously, but it bears repeating, addresses on features are mailing addresses. In many cases the physical address and the mailing address are the
             * same but the address stored on a feature represents the mailing address of the feature. An example of a non-physical mailing address would be a PO Box. - These addresses are
             * commonly defined and verifiable by a governmental authority (e.g. the United States Postal Service in the United States, Royal Mail in the United Kingdom, Correios in Brazil, etc.)
             * and should follow conventions and rules defined by those authorities.
             */
            address?: GeostoreAddressProto[];
            /** Represents information about the feature’s anchored geometry. */
            anchoredGeometry?: GeostoreAnchoredGeometryProto;
            /** The collection of attachments for this feature. Documentation: http://go/geo-attachments */
            attachment?: GeostoreAttachmentsAttachmentProto[];
            /**
             * ** DEPRECATED ** A list of attributes that describe defined aspects of this feature. An attribute must be a concrete, high quality, and editable piece of information about a
             * feature, and must be used on some general consumer facing Google property. The data types used for attributes must be primitive types or reusable in a generic manner.
             */
            attribute?: GeostoreAttributeProto[];
            /** Describes the best-match locale for this feature. */
            bestLocale?: GeostoreBestLocaleProto;
            border?: GeostoreBorderProto;
            /**
             * A latitude-longitude rectangle used by bucketing MapReduces. See the documentation on bucketing MapReduce for details. This field can be a source of confusion. Because it is called
             * "bound", it is often assumed that it is a tight bound on the geometry but it can be (and often is) much larger. If a tight bound is needed then use the standard
             * GetFeatureGeometryBound() function instead. To be more explicit, if you are using this field for *anything* else than a bucketing MapReduce, you are doing the wrong thing. Not all
             * features are required to have bounding boxes. See geostore::IsBoundRequiredForFeatureType() for the list of feature types required to have a bounding box. This bound field will be
             * updated when a feature changes in MapFacts to include its geometry. Also, a GeoSchema pipeline, go/geo-schema-pipelines-docs#expand-bounds runs periodically to update the field for
             * strong references from other features. Therefore, most editors don't need to edit this field explicitly. See go/geo-changes:no-edit-for-feature-bound for the details.
             */
            bound?: GeostoreRectProto;
            building?: GeostoreBuildingProto;
            /** Data specific to business chain features, e.g., Canonical GConcepts. */
            businessChain?: GeostoreBusinessChainProto;
            /**
             * The conceptual center of the feature, used for routing. For cities, this would be the center of the downtown, or maybe the location of city hall. For states and countries it might
             * be the capital city. Most feature types will not have a conceptual center - by default, routing will use the centroid of the feature's geometry. If you need a feature center point
             * consider using GetFeatureGeometryCenter() function from geostore/base/public/feature.h rather than reading from this field directly.
             */
            center?: GeostorePointProto;
            /**
             * Features can define themselves as a collection of other features. For example, a route is a collection of road segments, and a feature for the "Great Lakes" could be defined as
             * lakes Superior, Michigan, Huron, Erie, and Ontario. It is not recommended to design a multi level tree using the child field to build up a feature because it requires fetching many
             * features to see the details of the feature. In practice this is used to model archipelago, route, transit (agencies, lines, trips, departures), and river features. The geometry of a
             * feature is implicitly defined by its children, so if a feature has children then it should not have any points, polylines, or polygons. In general, this field should not be used to
             * represent political or postal hierarchies. For example, a county would not list its cities as children, because the county is not defined in terms of its cities (it also contains
             * unincorporated areas, etc.).
             */
            child?: GeostoreFeatureIdProto[];
            /**
             * S2 cell coverings for this feature. See util/geometry/s2cell_union.h for more information about S2 cells. Coverings are useful for quick containment or intersection tests. S2
             * covering that consists of cells that intersect with the feature.
             */
            covering?: GeostoreCellCoveringProto;
            dataSource?: GeostoreDataSourceProto;
            /** Data used to render this feature on a map. */
            displayData?: GeostoreDisplayDataProto;
            /** ** DEPRECATED ** */
            doodle?: GeostoreDoodleProto;
            elevation?: GeostoreElevationProto;
            /** Captures elevation data used on TYPE_DIGITAL_ELEVATION_MODEL features. */
            elevationModel?: GeostoreElevationModelProto;
            entrance?: GeostoreEntranceProto;
            /**
             * Also allowed on TYPE_BUSINESS_CHAIN and TYPE_TRANSIT_AGENCY features, to model the feature's phone number(s). Other fields within EstablishmentProto are not permitted on
             * non-TYPE_ESTABLISHMENT features.
             */
            establishment?: GeostoreEstablishmentProto;
            /**
             * A list of feature ids of polygon based restrictions that do not apply to this feature. This may only include features of TYPE_REGULATED_AREA that also have a
             * feature.regulated_area.restriction field defined. Setting this field opts the feature out of all restrictions set on that regulated area.
             */
            exemptRegulatedArea?: GeostoreFeatureIdProto[];
            /**
             * Specifies the TYPE_FUTURE_GEOMETRY whose geometry will replace this feature's geometry. If this field is populated, the referenced future geometry must have a future_geometry_for
             * referencing this feature.
             */
            futureGeometry?: GeostoreFeatureIdProto;
            /**
             * Specifies the feature that this feature's geometry will replace. If this field is populated, the referenced feature must have a future_geometry reference back to this feature. This
             * field is only allowed (and required) for TYPE_FUTURE_GEOMETRY features.
             */
            futureGeometryFor?: GeostoreFeatureIdProto;
            /**
             * If set, the feature's actual location can be assumed to be somewhere within a circle of this radius, centered on the feature's location. More information on this field at
             * go/gpm-definition-update. NOTE: Only applicable to features with 'point' geometry. Please contact geo-schema-team@ if you have non-point use cases for which this field would be
             * useful.
             */
            geometryPrecisionMeters?: number;
            /** RESERVED */
            geopoliticalGeometry?: GeostoreGeopoliticalGeometryProto;
            /** ** DEPRECATED ** Features can have zero or more HTML texts associated with them. These might be HTML balloons used by Google Earth, for example. */
            htmlText?: GeostoreHtmlTextProto[];
            /** The globally unique id for this feature. */
            id?: GeostoreFeatureIdProto;
            /** RESERVED */
            inferredGeometry?: GeostoreInferredGeometryProto;
            /** S2 interior covering that consists of cells completely enclosed within the feature's geometry (for features with polygonal geometry). */
            interiorCovering?: GeostoreCellCoveringProto;
            /**
             * Additional internal feature-level attributes that may be set by data providers to be used inside the Geo Data infrastructure. This field should never be present in the output of the
             * Geo Data infrastructure that read-only clients consume.
             */
            internal?: GeostoreInternalFeatureProto;
            intersection?: GeostoreIntersectionProto;
            intersectionGroup?: GeostoreIntersectionGroupProto;
            /**
             * Properties that apply to this feature whose schema is defined in the Knowledge Graph schema (see https://hume.google.com/graph/schema). Not all properties that exist in the KG
             * schema can be asserted via this mechanism. The set of properties that are allowed to be set on a feature depends on the feature's GConcepts (and feature type). For instance, only
             * gcid:country features may have the /geo/type/country/president property (made up example, since that property doesn't actually exist in the KG schema). GConcept hierarchy is taken
             * into account for deciding the set of allowed properties. Additionally, the specific properties allowed are further constrained by the list specified at go/kg-property-allowlist.
             * NOTE: not all types of properties are allowed to appear in the Geo Schema. For now, we limit ourselves to properties whose value type is TYPE_BOOL, TYPE_COMPOUND, TYPE_DATETIME,
             * TYPE_FLOAT, TYPE_ID, TYPE_INT, TYPE_NESTED_STRUCT, TYPE_TEXT, or TYPE_URI. NOTE(b/35039936): We are in the process of changing how a KG property with multiple values is stored in
             * this field. Currently, such a KG property is stored in a single instance of the kg_property field. However, we will be changing this so that each value will be stored in its own
             * instance of kg_property. Any client that wants to read from this field should be prepared to read data represented in either format. See b/35039936 or the announcement at
             * http://g/geo-schema-announce/7IXR3Fex8to/7yFyT5UoAwAJ for an example and more details. The mechanism to assert that a KG property has no value is via the property_value_status field
             * below. freebase.PropertyValue.value_status is not allowed be set here for consistency reason.
             */
            kgProperty?: FreebasePropertyValue[];
            /** RESERVED */
            knowledgeGraphReference?: GeostoreKnowledgeGraphReferenceProto;
            laneMarker?: GeostoreLaneMarkerProto;
            /** Represents information about TYPE_LEVEL features. */
            level?: GeostoreLevelProto;
            locale?: GeostoreLocaleProto;
            logicalBorder?: GeostoreLogicalBorderProto;
            /**
             * Metadata about this particular feature. Metadata is managed internally by the Geo Data Infrastructure and in general should not be set by clients. Features that don't ultimately
             * come from the Geo repository (MapFacts) won't have any metadata set.
             */
            metadata?: GeostoreFeatureMetadataProto;
            /** The name(s) of this feature. A feature may have different names in different languages, colloquial or "vanity" names, etc. */
            name?: GeostoreNameProto[];
            /**
             * Information about this feature's operations, e.g. when this feature is temporarily closed. NOTE: for legacy reasons, some closure-specifc information (e.g. permanent closure reason)
             * lives in ExistenceProto instead. In the future, such information should move here in OperationsProto.
             */
            operations?: GeostoreOperationsProto;
            /**
             * This field is used internally by the pipeline for id stability. It should not be set by individual importers, nor should it be read by consumer clients. In particular, this field
             * will not be present in features read or snapshotted from the Mapfacts Repository.
             */
            originalId?: GeostoreFeatureIdProto;
            parent?: GeostoreFeatureIdProto[];
            /** Describes parking details for the feature. */
            parking?: GeostoreParkingProto;
            /**
             * Defines the geometry of the feature. The geometry may be specified as an arbitrary union of points, poses, polylines, tracks, and polygons. Points, poses, polylines, and tracks are
             * assumed to represent regions of unspecified size or width rather than regions of zero area. Most features should have some sort of geometry. Geometry may be synthesized if none is
             * available (e.g., polygons for postal codes). The synthetic_geometry flag should be set in that case. Point is currently enforced as a non-repeating field for all feature types,
             * though it is defined as repeating in case future modeling requires multiple points. The number of allowed polylines, tracks, or polygons vary based on feature type. A feature can
             * have at most one pose (it is an optional field).
             */
            point?: GeostorePointProto[];
            /** ** DEPRECATED ** Detail discussion could be found at b/18611003. */
            political?: GeostorePoliticalProto;
            polygon?: GeostorePolygonProto[];
            /** Provide version of the geometry suitable for display. This has been subject to water removal and (possibly) moderate simplification. */
            polygonForDisplay?: GeostorePolygonProto;
            polyline?: GeostorePolyLineProto[];
            /** Defines the geometry of a feature as a 6D pose, including lat, lng, altitude, roll, pitch, and yaw along the WGS-84 ellipsoid. Only the lat and lng are strictly required. */
            pose?: GeostorePoseProto;
            /**
             * The preferred viewport for this feature. If present, this latitude-longitude rectangle holds the preferred viewport for the feature. For example, it might hold the bounds of the
             * "central" portion of a large city. There are no aspect ratio requirements. This is an optional field: if no viewport is supplied, interested clients can use heuristics to determine
             * a viewport. Calling the standard GetFeatureGeometryBound() function would be a good way to start but note that it can return an empty bounding box (e.g., if the feature has no
             * geometry). The preferred viewport is not necessarily fully contained by the above bounding box.
             */
            preferredViewport?: GeostoreRectProto;
            /**
             * The value status of properties on this feature. For example, this specifies whether the feature is known to have no name (this is the value status of the 'FEATURE_NAME' property).
             * Only property IDs which have no specific value are allowed to have a value status. Note: not all field types will be supported, please contact geo schema team if you want to enable
             * this field for a field type that is not currently supported.
             */
            propertyValueStatus?: GeostorePropertyValueStatusProto[];
            /**
             * WARNING: Please do NOT introduce new uses of this field; treat it as if it were deprecated. For appropriate ranking contacts, see
             * g3doc/company/teams/gdeng/geo-schema-reference/home/feature-properties/rank.md. A floating-point number between 0.0 and 1.0 indicating how "important" we think this feature is. This
             * can be used to decide which features to render on maps, and how to rank results when the user does a search. The rank can depend on any number of factors such as the number of
             * references to this feature in web pages, geographic size, population, number of referring geographic entities, "priority" information encoded in the source data, etc.
             */
            rank?: number;
            /**
             * The rank field is computed as a weighted sum of several signals. This field contains a protocol buffer whose fields give those signals and their weights. Clients should try very
             * hard not to depend on these individual signals and use the single rank field instead. At some point in the future, this field will not be exposed anymore.
             */
            rankDetails?: GeostoreRankDetailsProto;
            /**
             * Geo Ontology GConcept Instances - Design doc linked off http://go/geo-ontology - In order to shield clients from changes in GConcept representation we provide an accessor library:
             * geostore/base/public/gconcept_instance.h
             */
            rawGconceptInstanceContainer?: GeostoreOntologyRawGConceptInstanceContainerProto;
            regulatedArea?: GeostoreRegulatedAreaProto;
            /**
             * For TYPE_COUNTRY or TYPE_ADMINISTRATIVE_AREA1 features, this field defines the associated TYPE_BORDERs which reference this feature. The linked TYPE_BORDERs must have the
             * feature.border set, pointing to this feature. TYPE_COUNTRY or TYPE_ADMINISTRATIVE_AREA1 features must have this field set for each TYPE_BORDER referencing them.
             */
            relatedBorder?: GeostoreFeatureIdProto[];
            /** Logical relationship to other features that are entrances or exits to this feature. */
            relatedEntrance?: GeostoreEntranceReferenceProto[];
            /**
             * Geographic or logical relationships to other features. Importers don't need to fill a geographic relationship in - it is handled by related feature processing by a standalone
             * pipeline. Adding "contained by" country relations is however encouraged (and required for TYPE_ROUTE features). WARNING: Updates to this field handled by standalone pipelines are
             * NOT atomic with regard to updates to the features being referenced; we do not guarantee that a given MapFacts snapshot will be consistent between this field and the related
             * features.
             */
            relatedFeature?: GeostoreRelationProto[];
            /** Terminal points associated with this feature. For instance, an airport terminal may have specifically designated pickup and drop-off points. */
            relatedTerminalPoint?: GeostoreFeatureIdProto[];
            /**
             * Contains time zones known to be associated with a feature. Most features are associated with the single time zone that contains them. However, some larger features (countries,
             * continents, etc.) are associated with all of the time zones they contain. Most features can have any number of related time zones, but TYPE_SEGMENT and TYPE_ESTABLISHMENT_POI
             * features can have at most 1.
             */
            relatedTimezone?: GeostoreTimezoneProto[];
            restrictionGroup?: GeostoreRestrictionGroupProto;
            roadMonitor?: GeostoreRoadMonitorProto;
            /**
             * Additional details on the feature types below can be found in the individual protocol buffer definitions. These extensions capture data that is specific to a set of feature types
             * and which makes no sense for other feature types.
             */
            route?: GeostoreRouteProto;
            schoolDistrict?: GeostoreSchoolDistrictProto;
            segment?: GeostoreSegmentProto;
            segmentPath?: GeostoreSegmentPathProto;
            sign?: GeostoreRoadSignProto;
            skiBoundary?: GeostoreSkiBoundaryProto;
            skiLift?: GeostoreSkiLiftProto;
            skiTrail?: GeostoreSkiTrailProto;
            /**
             * All establishments must have a social reference. WARNING: Aside from creating new establishments, please do NOT introduce new uses; treat social references as if they were
             * deprecated. For alternatives and more, see g3doc/company/teams/gdeng/geo-schema-reference/home/feature-types/establishments/social-reference.md.
             */
            socialReference?: GeostoreSocialReferenceProto;
            /**
             * A list of the data sources that were used to construct this feature, together with optional "raw data" in the provider's format. Raw data should not be used by production clients
             * but may be useful for exploring data that is not currently converted to a canonical form.
             */
            sourceInfo?: GeostoreSourceInfoProto[];
            /** All features can have "existence" information associated with them. */
            status?: GeostoreExistenceProto;
            /** Represents information about the store front geoemtry. Only TYPE_ESTABLISHMENT_POI should have this field set. */
            storefrontGeometry?: GeostoreAnchoredGeometryProto[];
            /**
             * We prefer features that have geometry over those that do not. In some cases we synthesize geometry (e.g., polygons for postal codes). This flag is set to indicate features that have
             * such synthetic geometry.
             */
            syntheticGeometry?: boolean;
            /** A place for clients to attach arbitrary data to a feature. Never set in MapFacts. */
            temporaryData?: any;
            /**
             * Captures full model representing the feature's 3D geometry. Should only be found on TYPE_COMPOUND_BUILDING features for now, but not part of the BuildingProto extension for possible
             * future extensions.
             */
            threeDimModel?: GeostoreThreeDimensionalModelProto;
            /** Represents information about TYPE_TOLL_CLUSTER features. */
            tollCluster?: GeostoreTollClusterProto;
            /**
             * Defines the geometry of a feature as a sequence of 6D poses, including lat, lng, altitude, roll, pitch, and yaw. Only lat and lng are typically required. Each track has an index so
             * that they can be viewed in a stable order.
             */
            track?: GeostoreTrackProto[];
            transitLine?: GeostoreTransitLineProto;
            /** RESERVED */
            transitLineVariant?: GeostoreTransitLineVariantProto;
            /** RESERVED */
            transitStation?: GeostoreTransitStationProto;
            /** The type of this feature -- see comments above. */
            type?: string;
            /** Represents vertical ordering for this feature relative to other geometrically-overlaping features. See go/aboutgrades for more information about distinction among different levels. */
            verticalOrdering?: GeostoreVerticalOrderingProto;
            /** RESERVED */
            waterRemovedPolygon?: GeostorePolygonProto;
            /** The official website of this feature. Stored as a repeated field to allow for multilingual official websites (see comments in url.proto). */
            website?: GeostoreUrlProto[];
        }
        interface GeostoreFeatureReplacementInfoProto {
            /** This feature was created to replace other features that are referenced by this field. */
            derivedFrom?: GeostoreFeatureIdProto[];
            /** This feature was replaced by other features that are referenced by this this field. */
            replacedBy?: GeostoreFeatureIdProto[];
        }
        interface GeostoreFieldMetadataProto {
            internal?: GeostoreInternalFieldMetadataProto;
        }
        interface GeostoreFieldWithRightsProto {
            /** ** DEPRECATED ** If field_type is set to FEATURE_ATTRIBUTE or KNOWLEDGE_GRAPH_PROPERTY, the attribute ID / KG property ID that makes this field with rights complete. */
            attributeId?: string;
            featurePropertyId?: GeostoreFeaturePropertyIdProto;
            /** The field type for which the rights level are tracked on. The default value here has to match the value of fieldtype::NONE. */
            fieldType?: number;
            /** The minimum rights level for all the current values on the field type. */
            minRightsLevel?: string;
        }
        interface GeostoreFlowLineProto {
            track?: GeostoreTrackProto;
        }
        interface GeostoreFoodMenuItemOptionProto {
            allergenAbsent?: string[];
            allergenPresent?: string[];
            calories?: number;
            /** Ingredients of the food dish option. */
            ingredients?: GeostoreFoodMenuItemOptionProtoIngredient[];
            /** Photos of the food dish option. */
            media?: GeostoreMediaItemProto[];
            /**
             * The repeated name_info field here is for item options with names or descriptions listed in multiple languages. When an item option has no names or descriptions, the size of the
             * repeated field name_info may be 0. For example, when a food menu item does not have multiple options, the item option proto is used only to specify price and nutritional
             * information, so it will not have a name_info field. There should be at most one name_info for any given language.
             */
            nameInfo?: GeostorePriceListNameInfoProto[];
            /** Nutrition facts of the food dish option. Note that it also includes calories information with a finer defined unit information. */
            nutritionFacts?: GeostorePriceInfoFoodNutritionFacts;
            /** Size of the order, represented in units of items. (e.g. 4 "skewers”, 6 "pieces”) */
            portionSize?: GeostoreFoodMenuItemOptionProtoPortionSize;
            /** Methods on how the food dish option is prepared. */
            preparationMethods?: string[];
            /**
             * We use PriceRangeProto here but we expect the lower_price and upper_price to be both set to equal numbers because an option should have a single price. This field is not required
             * because food item prices may be variable depending on season.
             */
            price?: GeostorePriceRangeProto;
            restriction?: string[];
            /** Number of people can be served by this food dish option. */
            servesNumPeople?: number;
            spiciness?: string;
        }
        interface GeostoreFoodMenuItemOptionProtoIngredient {
            /** The repeated name_info field is for the ingredient in multiple languages. */
            nameInfo?: GeostorePriceListNameInfoProto[];
        }
        interface GeostoreFoodMenuItemOptionProtoPortionSize {
            /** Required. */
            quantity?: number;
            /** Required. The repeated name_info field is for the unit in multiple languages. */
            unit?: GeostorePriceListNameInfoProto[];
        }
        interface GeostoreFoodMenuItemProto {
            itemOption?: GeostoreFoodMenuItemOptionProto[];
            /** The repeated name_info field is for items listed in multiple languages. */
            nameInfo?: GeostorePriceListNameInfoProto[];
        }
        interface GeostoreGConceptInstanceProto {
            /** The unique identifier of a GConcept (e.g. "gcid:railway"). */
            gconceptId?: string;
            /** Field-level metadata for this GConcept. */
            metadata?: GeostoreFieldMetadataProto;
            /**
             * The relative prominence of this category to this feature according to the data provider, as one of the values from the enum above. Prominence is a measure of how well the given
             * GConcept describes the feature. An example is a gas station with convenience store and ATM. All three GConcepts are very relevant, but the gas_station GConcept is the most
             * prominent. If the prominence of this GConcept is unknown, this field should not be set.
             */
            prominence?: string;
        }
        interface GeostoreGeopoliticalGeometryProto {
            /**
             * The unsimplified, water-subtracted polygon representing the feature's geometry as viewed by the rest of the world, which may differ from its default polygon, for example by
             * excluding certain regions.
             */
            restOfWorldPolygon?: GeostorePolygonProto;
            /**
             * The unsimplified, water-subtracted polygon representing the feature's geometry as viewed by the country that administers it, which may differ from its default polygon, for example
             * by including disputed areas.
             */
            selfPolygon?: GeostorePolygonProto;
        }
        interface GeostoreGradeLevelProto {
            /** The index of the point along the segment, where 0 is the starting point. This means that the index of a point along a segment and its sibling will be different. */
            index?: number;
            /**
             * The grade level of the indexed point. The grade level can be thought of as a relative vertical ordering with respect to other segments at the same point, where larger/more positive
             * numbers are "higher". Negative grade level values are allowed and are typically used for points below grade level (0 is a common choice to represent the level of points at the
             * ground level). For vertical segments, the height, i.e. the vertical length, is represented by difference of levels in millimeters. For example,
             * feature.segment().grade_level(0).level() == 0 and feature.segment().grade_level(1).level() == 5000, then the length of the vertical segment feature is 5000 millimeters (5 meters).
             */
            level?: number;
        }
        interface GeostoreHtmlTextProto {
            /**
             * Zero or more texts of the specified type, in various languages. If this is a HTML_DESCRIPTION blob then these texts would hold the description in English, German, and so forth. The
             * text is an HTML fragment, not a full page. The fragment should be suitable for including in a DIV. It must have balanced HTML tags. It may use HTML's "class" attributes to assign
             * classes to HTML elements. This allows the HTML to be formatted by an (external) style sheet. The HTML should not have embedded style sheet definitions, nor should it have embedded
             * JavaScript.
             */
            text?: GeostoreLanguageTaggedTextProto[];
            type?: string;
        }
        interface GeostoreInferredGeometryProto {
            /** Features whose geometry depends on this feature's geometry. */
            definesGeometryFor?: GeostoreFeatureIdProto[];
            /** Features whose geometry to exclude while inferring geometry. */
            excludesGeometryOf?: GeostoreFeatureIdProto[];
            /** Features whose geometry to include while inferring geometry. */
            includesGeometryOf?: GeostoreFeatureIdProto[];
        }
        interface GeostoreInternalFeatureProto {
            /** A unique identifier for this feature's polygon data which is being held externally in Shapestore (see go/shapestore). */
            polygonShapeId?: string;
            /**
             * A unique identifier for this feature's rest-of-world view polygon data which is being held externally in Shapestore (see go/shapestore). This is part of the feature's geopolitical
             * geometry.
             */
            restOfWorldPolygonShapeId?: string;
            /** Per-field rights for this feature. See http://g3doc/geostore/g3doc/developers-guide/inputs/rights-tracking for more information. */
            rightsStatus?: GeostoreRightsStatusProto;
            /** A unique identifier for this feature's self view polygon data which is being held externally in Shapestore (see go/shapestore). This is part of the feature's geopolitical geometry. */
            selfPolygonShapeId?: string;
            /**
             * Trust signals/annotations for the feature. In an input feature, these signals are computed at the beginning of the pipeline and are immutable during the processing. In output
             * features, this proto may define the rules/criteria that a newer edit should meet, in order to be applied.
             */
            trust?: GeostoreTrustSignalsProto;
            /** A unique identifier for this feature's water-removed polygon data which is being held externally in Shapestore (see go/shapestore). */
            waterRemovedPolygonShapeId?: string;
        }
        interface GeostoreInternalFieldMetadataProto {
            /**
             * Whether or not the piece of data has been generated automatically (i.e., by a bot/automated process based on heuristics/algorithms rather than coming as a fact set by some human
             * user or data provider based on their knowledge). Note that this does NOT imply that the value was set as a result of a bot operation on the repository, since it is conceivable to
             * use a bot/automated process simply as a way of convenience to ingest large amount of canonical/ground truth data.
             */
            isAuto?: boolean;
            /** Information about the source providing the piece of data this metadata is attached to. */
            sourceSummary?: GeostoreInternalSourceSummaryProto;
        }
        interface GeostoreInternalSegmentProto {
            /** The set of restrictions that apply to this segment; these are actually *POSITIVE* restrictions, i.e. they are known to be allowed. */
            travelAllowance?: GeostoreRestrictionProto[];
        }
        interface GeostoreInternalSourceSummaryProto {
            /**
             * Within the above provider, the dataset from which this piece of data was generated. For fields that are auto-generated the "dataset" is likely to be some algorithm's or program's
             * name. Similar to SourceInfoProto.dataset but with the difference that it is required to always be set. Providers that don't have a concept of dataset may use "default".
             */
            dataset?: string;
            /** The data provider from which this piece of data was generated. Equivalent to SourceInfoProto.provider in the public schema. */
            provider?: string;
        }
        interface GeostoreIntersectionGroupProto {
            /** All artifact intersection groups that are in this logical group. */
            childGroup?: GeostoreFeatureIdProto[];
            groupType?: string;
            /**
             * The list of TYPE_INTERSECTION features that form this intersection group, but are NOT in any of this group's child groups. This could be an empty list, though that is sub-optimal.
             * Even an empty list would allow the paint team to draw a label for a named intersection, but a non-empty list would, for example, enable PathFinder to generate better directions.
             * Each of the TYPE_INTERSECTION feature referred here must refer back to this feature in its IntersectionProto.
             */
            intersection?: GeostoreFeatureIdProto[];
            /** Parent logical intersection group. An artifact group that does not have an associated parent logical group is assumed to be both an artifact and logical group. */
            parentGroup?: GeostoreFeatureIdProto;
        }
        interface GeostoreIntersectionProto {
            /**
             * The artifact or logical intersection group to which this intersection belongs. If present, the intersection group must also refer back to the intersection. If an intersection is
             * within both the artifact and logical group, then this reference should be to the artifact group.
             */
            intersectionGroup?: GeostoreFeatureIdProto;
            /** RESERVED */
            outSegment?: GeostoreFeatureIdProto[];
            /**
             * The list of segments that terminate at this intersection, in any order. Note that all segments are directed towards the intersection, i.e. their endpoints indicate what sort of
             * intersection this is. This should not be empty because an intersection with no associated segment is meaningless.
             */
            segment?: GeostoreFeatureIdProto[];
            /** The toll cluster to which this intersection belongs. If present, the toll cluster must also refer back to the intersection. */
            tollClusterId?: GeostoreFeatureIdProto;
        }
        interface GeostoreJobMetadata {
            /**
             * Describes how much time the service is going to take, e.g. how long it takes to do a haircut. Value of seconds must be from +60 (1 min) to +31,536,000 (365 days) inclusive. Value of
             * nanos must be zero.
             */
            duration?: string;
            /** Represents the name of a potential grouping of items. For TYPE_JOB, this is the category names of the categories that a user picked this job type from at the time of input. */
            jobRelatedCategories?: GeostoreJobRelatedCategory[];
            /**
             * Unique identifier for a job. This is required for standard jobs and blank for free-form jobs. Job type ids are prefixed with "job_type_id:". Notice this is a unique string
             * representation of a job across languages. E.g., “job_type_id:air_duct_repair”. The existence of a job_type_id means the job type is a standard one, and has a corresponding entry in
             * the Standard Jobs Taxonomy.
             */
            jobTypeId?: string;
            /** Represents the MID corresponding to the job_category entity in the Knowledge Graph. For example, job_type_id="job_type_id:install_faucet", job_type_mid="/g/11hzzxjv3f". */
            jobTypeMid?: string;
        }
        interface GeostoreJobRelatedCategory {
            gcid?: string;
            language?: string;
            /** Category name in the primary language of the feature. Generally intended to be used as a fallback when we are unable to fetch the name in the user's language. */
            name?: string;
        }
        interface GeostoreKnowledgeGraphReferenceProto {
            /** KG Identifier (MID). For details, see http://go/ke-bg-knowledge-graph#mids. */
            id?: string;
        }
        interface GeostoreLandmarkReferenceProto {
            /**
             * The type of the landmark feature. Allowed types: - TYPE_CARTOGRAPHIC e.g. a putting green or water hazard - TYPE_COMPOUND e.g. - the Empire state building (TYPE_COMPOUND_BUILDING) -
             * a park (TYPE_COMPOUND_GROUNDS) - a section of a retail store (TYPE_COMPOUND_SECTION) - TYPE_ESTABLISHMENT e.g. - the Eiffel Tower (TYPE_ESTABLISHMENT_BUILDING) - a sports field
             * (TYPE_ESTABLISHMENT_GROUNDS) - Starbucks (TYPE_ESTABLISHMENT_POI) - TYPE_INTERSECTION_GROUP e.g. a major intersection - TYPE_NATURAL_FEATURE e.g. a river - TYPE_SEGMENT e.g. a bike
             * trail or train tracks
             */
            featureType?: number;
            /** The feature ID of the landmark feature. */
            landmark?: GeostoreFeatureIdProto;
            /** The mode(s) of travel for which this landmark is useful. */
            travelMode?: string[];
        }
        interface GeostoreLaneMarkerProto {
            /** If this is a physical barrier marker, represent materials found on the marker. */
            barrierMaterials?: GeostoreBarrierLogicalMaterialProto;
            /** Pattern border and color for crossing markers. These include crosswalks, stop, and yield lines. */
            crossingPattern?: GeostoreCrossingStripePatternProto;
            /** Stripe pattern, spacing, and color for longitudinal markers. */
            linearPattern?: GeostoreLinearStripePatternProto;
        }
        interface GeostoreLaneProto {
            /** References to any gcid:physical_lane_marker features that bound this lane. */
            boundingMarker?: GeostoreBoundingMarkerProto[];
            /**
             * If the current lane is part of a merge/split area, indicates the type (split or merge) and whether the current lane is on the left or right or in the middle of the merge/split area,
             * as seen in the direction of traffic. See go/lane-split-merge-schema
             */
            conjoinedCategory?: string;
            /**
             * Gap between this lane and the next in meters. This is relevant when the divider is physical, or a wide painted area. For regular painted single or double lines, there is no gap.
             * This distance is duplicated between the innermost lanes for each side. Note that this is not used to describe smallish islands - this is only for long-running gaps. In particular,
             * this models the median width, the gap between HOV lanes/regular lanes on freeways, and the road verge between a curb and sidewalk. Note on split roads: We can model any split road
             * with a median as a single sibling pair with this distance set to the width of the median, or as two one-way sibling pairs.
             */
            distanceToNextLane?: number;
            /** The most logical path for the center of an object to travel along within the lane. Typically, this is the lane's center line, but doesn't have to be. */
            flow?: GeostoreFlowLineProto;
            /**
             * Connections to lanes of other segments at the end of this segment. These connections model the connectivity where you don't have to do a lane change maneuver. If any lane connection
             * is present, assume that all others are forbidden. Also note that segment level restrictions do apply if present, and can disallow some turn even if the lanes are connected. For
             * instance, this can happen with timed or vehicle type based restrictions on the segment. If lane connectivity implies a segment-level restriction (can't transition to some target
             * segment), that restriction will also exist as a segment level restriction. In effect - PathFinder does not have to look at lane connectivity to figure out segment connectivity.
             * Example: Typically, lanes are just connected to one other lane. Example: A splitting lane is connected to the two resulting lanes. Example: At an intersection, a lane is connected
             * to crossing lanes according to how lanes are painted across the intersection. In the common case, the target segment will be connected to the same intersection as this segment. That
             * will however NOT be true for complex intersections where there is an intersection group. The connections will be across the whole group, connecting to one of the outgoing segments
             * from the group. This is analogous to how we do turn restrictions around intersection groups.
             */
            laneConnection?: GeostoreLaneProtoLaneConnection[];
            /**
             * clang-format on Whether the divider to the inside of this lane can be crossed. Note that we assume this is symmetric, and that this also describes whether someone in the next inside
             * lane can cross to this one. The "inside" lane is the one with a lower lane_number. Note on lane markers: We do not model the painting, but only the resulting legality. There are
             * many painted marker styles and colors that lead to the same legality. We expect Paint or Driveabout to render lanes stylized, with solid meaning "can't cross", and dashed meaning
             * "can cross". Note on varying legality along segment: ALLOWED takes precedence - even if some small portion has a restriction (such as right before an intersection) , the lane change
             * will be ALLOWED.
             */
            laneDividerCrossing?: string;
            /**
             * These indicate for what portion of the segment the lane's flowline exactly follows the segment, and the lane is of constant width. This will be set to not include the whole segment
             * where there is a split/turn/merge at either end of the lane. The painting of the lane should completely synthesize the lane geometry outside of this portion, connecting it to
             * neighboring lanes to make graphical nice.
             */
            laneFollowsSegmentBeginFraction?: number;
            laneFollowsSegmentEndFraction?: number;
            /**
             * Lanes are numbered from inside of the road outward, i.e. the lane next to the center line is lane 0. The lanes then stack outwards, towards the side that one drives on this segment
             * (right or left). NOTE: do NOT use the lane_number as index for lookup. Lane_number is not guaranteed to match the segment.lane repeated field index.
             */
            laneNumber?: number;
            /** A token that can be used to identify the version of the data about this lane. */
            laneToken?: string;
            /** Field-level metadata for this lane. */
            metadata?: GeostoreFieldMetadataProto;
            /**
             * Restrictions that apply to this lane only. Examples include HOV lanes. If a lane restriction implies a segment-level restriction (can't route on the segment at all), that
             * restriction will also exist as a segment level restriction. In effect - PathFinder does not have to look at lane restrictions to figure out segment restrictions.
             */
            restriction?: GeostoreRestrictionProto[];
            /**
             * True if this lane is usable in both directions (left-turn lane, reversing lane, one-lane road, etc). To get the total number of lanes for a road, add up the lanes in each direction
             * counting 0.5 for each shared lane.
             */
            shared?: boolean;
            /** References to any gcid:physical_lane_marker features that intersect this lane, with the implication that a moving vehicle should stop there. */
            stopLine?: GeostoreFeatureIdProto[];
            /**
             * clang-format on LINT.ThenChange(//depot/google3/geostore/base/proto/segment.proto) Unlike the surface in SegmentProto, this field does not have a default value. This is because the
             * lane-level surface overrides the segment-level surface. The lane's surface should be unset unless explicitly overriding the segment's surface.
             */
            surface?: string;
            /** clang-format on */
            type?: string;
            /**
             * Width of this lane in meters. In many cases, we will collect this data by dividing the total road width by the number of lanes. On accuracy: This is a rough average width along this
             * segment. If and when we wanted to be more accurate, we'd extend this schema to have full polygons for segments/lanes rather than just this average width.
             */
            width?: number;
        }
        interface GeostoreLaneProtoLaneConnection {
            /** References to any gcid:physical_lane_marker features that bound this lane connection. */
            boundingMarker?: GeostoreBoundingMarkerProto[];
            /** A token that can be used to identify the version of the data about this lane connection. */
            connectionToken?: string;
            /**
             * Specifies how the flowline should be synthesized in this connection region. If unspecified, heuristics may be used to pick a sweep shape based on retraction values or neighboring
             * curves.
             */
            curve?: GeostoreCurveConnectionProto;
            /** The most logical path for the center of an object to travel along within the lane connection. Typically, this is the lane connection's center line, but doesn't have to be. */
            flow?: GeostoreFlowLineProto;
            /** This is the lane number on the target segment. This field is not set if the target segment doesn't have lanes, or we don't know the exact connectivity. */
            laneNumber?: number;
            /**
             * True if this connects to the unique, natural continuation of the current lane. At most one LaneConnection per lane can have this field set true. This attribute is of interest to
             * ADAS providers as a hint to which lane a vehicle is likely to follow, in the absence of other information about the vehicle's planned path.
             */
            primaryConnection?: boolean;
            /** This reference to the other segment is weak, since strong would blow up bounds of all segments. */
            segment?: GeostoreFeatureIdProto;
        }
        interface GeostoreLanguageTaggedTextProto {
            /**
             * The external form of a Google International Identifiers Initiative (III) LanguageCode object. See google3/i18n/identifiers/languagecode.h for details. We place extra restrictions on
             * languages in addition to what the III library requires. See http://go/geo-schema-reference/feature-properties/languages.md
             */
            language?: string;
            /** The text (UTF-8 encoding). */
            text?: string;
        }
        interface GeostoreLevelProto {
            /**
             * The building(s) to which this level belongs. A level will typically belong to a single building, but it is valid for a single level to be shared by multiple buildings (for example,
             * a large underground parking lot). These buildings refer back to the level via another strong reference (the BuildingProto.level field).
             */
            building?: GeostoreFeatureIdProto[];
            /**
             * The elevation of this level relative to the ground level, in levels. 0 = ground floor (even in locales that call the ground floor "1st floor"); 0.5 = between ground and first floor,
             * eg mezzanine; 1 = first floor (one level above ground floor); -3 = three levels below ground floor.
             */
            number?: number;
        }
        interface GeostoreLinearStripePatternProto {
            /** A linear marker may consist of one or more parallel physical lines. These are ordered left to right along the direction of the marker core polyline. */
            line?: GeostorePhysicalLineProto[];
        }
        interface GeostoreLocaleLanguageProto {
            /**
             * The language associated with this preference. The external form of a Google International Identifiers Initiative (III) LanguageCode object. See
             * google3/i18n/identifiers/languagecode.h for details. We place extra restrictions on languages in addition to what the III library requires. See
             * http://go/geo-schema-reference/feature-properties/languages.md
             */
            language?: string;
            /** Flag to indicate if the associated language is "official" within a locale. */
            official?: boolean;
            /** This value represents the preference of the associated language within a locale. It must be between 0.0 and 1.0. */
            preference?: number;
            /** Percentage of population that can speak the associated language within a locale. It must be between 0 and 100. */
            speakingPercent?: number;
            /** Percentage of population that can write the associated language within a locale. It must be between 0 and 100. */
            writingPercent?: number;
        }
        interface GeostoreLocaleProto {
            /** This holds the list of languages spoken within a locale. */
            language?: GeostoreLocaleLanguageProto[];
            /**
             * The ID of the localization policy (from googledata/geostore/localization/localization_policies.textpb) to apply to features that have this locale as their best match locale.
             * Localization policy IDs are arbitrary identifiers that uniquely distinguish a set of language-selection rules.
             */
            localizationPolicyId?: string;
        }
        interface GeostoreLogicalBorderProto {
            /**
             * All the border segments which make up this logical border. Border segments must be TYPE_BORDER features which have the same left/right features. This is a many-to-many bidirectional
             * relationship, so any border segment within this list might be part of another logical border.
             */
            borderSegment?: GeostoreFeatureIdProto[];
            /** The logical border status identifies its legal status. This is similar to the BorderStatus present within border segments, but applies to the group as a whole. */
            status?: string;
        }
        interface GeostoreMediaItemProto {
            /** The FIFE url associated with the media. NOTE: This FIFE URL must be PII-free, see go/product-catalogue-photo-storage */
            googleUrl?: string;
            mediaFormat?: string;
            /** The mediaKey associated with the media. NOTE: This media key must be PII-free, see go/product-catalogue-photo-storage */
            mediaKey?: string;
            mediaSize?: GeostoreMediaItemProtoMediaSize;
        }
        interface GeostoreMediaItemProtoMediaSize {
            originalHeightPx?: number;
            originalWidthPx?: number;
        }
        interface GeostoreNameProto {
            /** clang-format on The set of flags that apply to this name. */
            flag?: string[];
            /**
             * The external form of a Google International Identifiers Initiative (III) LanguageCode object. See google3/i18n/identifiers/languagecode.h for details. These strings should be
             * treated as opaque blobs. You can use LanguageCodeConverter::FromOther to convert the string to a LanguageCode reference. You can then call methods on the LanguageCode class to
             * extract language/script/region subtags (if any). See also http://g3doc/i18n/identifiers/g3doc/using-iii. We place extra restrictions on languages in addition to what the III library
             * requires. See go/geo-schema-reference/feature-properties/languages. This field may be missing if the name does not have a concept of language but should be set if the language is
             * unknown.
             */
            language?: string;
            /** Field-level metadata for this name. NOTE: there are multiple NameProto fields in the Geo Schema. Metadata here is only expected to be present on FeatureProto.name[]. */
            metadata?: GeostoreFieldMetadataProto;
            /**
             * ** DEPRECATED ** The name text provided in the original source data (UTF-8 encoding). This is the text provided in the source data unmodified with the exception of being converted
             * to UTF-8 and stripping extra leading, trailing and duplicate whitespaces (if necessary).
             */
            rawText?: string;
            /**
             * The short name text (UTF-8 encoding). Acronyms/abbreviations should be consistently used, for example "NE 57th St" rather than "Northeast 57th Street", "N.E 57th St." or some other
             * variant. This field should be populated with the chosen canonical version of the shortened name, based on per-term transformations. For feature specific abbreviations (such as 'CA'
             * for 'California'), one should define a separate name with FLAG_ABBREVIATED set. For other variants of the shortened name that are not the canonical one, devise client based logic
             * (ex: query rewriting rules).
             */
            shortText?: string;
            /** A place for clients to attach arbitrary data to a name. Never set in MapFacts. */
            temporaryData?: any;
            /**
             * The name text (UTF-8 encoding). Acronyms/abbreviations should be fully expanded, for example "Northeast 57th Street" rather than "NE 57th St". They can be shortened at display or
             * geocode time. This decision prevents ambiguity over such issues as whether "St" represents "Street" or "Saint". However, it pushes language-specific knowledge into code. We will
             * have libraries and data files to contract acronyms/abbreviations at run-time.
             */
            text?: string;
        }
        interface GeostoreOntologyRawGConceptInstanceContainerProto {
            instance?: GeostoreOntologyRawGConceptInstanceProto[];
        }
        interface GeostoreOntologyRawGConceptInstanceProto {
            /** This is the 'public' section of the GConceptInstance. */
            instance?: GeostoreGConceptInstanceProto;
            /**
             * ** DEPRECATED ** Was this GConcept explicitly added by an edit? Examples of gconcepts not added by edits include those inferred through geo ontology and those mapped from legacy
             * category forms by the feature updater. Note that it is possible for both is_added_by_edit and is_inferred to be true - it means this gconcept is added by an edit and there is also
             * another more fine-grained gconcept added by an edit.
             */
            isAddedByEdit?: boolean;
            /** RESERVED */
            isInferred?: boolean;
            /**
             * ** DEPRECATED ** These two fields combined describe the source of a GConceptInstance. They are based on geostore/base/proto/datasourceprovider.proto. Their use has been deprecated.
             * Use the FieldMetadataProto inside instance instead.
             */
            provider?: string;
            sourceDataset?: string;
        }
        interface GeostoreOpeningHoursProto {
            /** Date delimited exceptions to the typical recurring opening hours. May only be present if regular weekly hours are also specified. */
            exception?: GeostoreExceptionalHoursProto[];
            /**
             * Typical recurring opening hours, expressed as a weekly schedule. NOTE: this field was introduced to have a more client-friendly format for representing weekly hours but, as of
             * November 2018, it's not used for the main opening hours of TYPE_ESTABLISHMENT features (instead, the data is stored in the `EstablishmentProto.hours` field, see b/23105782 tracking
             * the possible schema migration). It is however used in other contexts where `OpeningHoursProto` appears in the Geo Schema. In openinghours.h there is a utility function
             * `GetOpeningHoursFromFeature` that merges `EstablishmentProto.hours` into this proto.
             */
            regularHours?: GeostoreBusinessHoursProto;
        }
        interface GeostoreOperationsProto {
            /**
             * Records temporary status change of the feature, such as remodel, vacation, etc.: the feature is temporarily (but not permanently) unavailable. This prevents users from going to the
             * feature. Supports an arbitrary number of past, present, and future temporary closures, with the feature's data owner choosing which range of past and future closures to permit or
             * guarantee to keep. All start and end dates must be unique from each other. If two consecutive dates are a start and an end of a TemporaryClosureProto, then the two dates must be
             * from the same TemporaryClosureProto. Otherwise, exact dates may be missing so long as there exist a possible sequence of temporary closures with both exact start_date and end_date
             * that keeps any known exact start_date and end_date. The earliest temporary closure must begin after whenever initial operations begin. Likewise, the latest temporary closure must
             * end before whenever the permanent closure begins. NOTE: does *not* guarantee chronological order.
             */
            temporaryClosure?: GeostoreTemporaryClosureProto[];
        }
        interface GeostoreOverrideBorderStatusProto {
            /** The two-letter ISO 3166-1 country code corresponding to the domain this status override applies to, when rendering the border polyline. */
            countryCode?: string;
            /** The override status, from the BorderStatus enumeration. The value here must be different from the main status (otherwise there's no point in providing the override). */
            status?: string;
        }
        interface GeostorePaintedElementLogicalColorProto {
            color?: string;
        }
        interface GeostoreParkingAllowanceProto {
            /** The type of parking for this allowance. Allowance details only apply to the type of parking specified. */
            allowanceType?: string;
            /**
             * If true, this allowance represents a discount rather than an individual rate; any rate values specified in this allowance describe a discount to be applied to the non-discount
             * allowances in the ParkingProto.
             */
            isDiscount?: boolean;
            /**
             * If this rate requires validation, this expresses the minimum purchase required for validation in each applicable currency. Should have an ID of /measurement_unit/money_value and
             * consist of two properties: one with an ID of /measurement_unit/money_value/amount and a float value with the amount, and another with the ID /measurement_unit/money_value/currency
             * and an ID value with the MID of the proper currency (from the /finance/currency type). A value of 0 suggests that no purchase is required. If empty, this suggests that no validation
             * is required for this rate.
             */
            minPurchaseForValidation?: FreebaseTopic[];
            /** Any additional details about the permit type; e.g. “Zone A”. In any local languages. Should only be set if allowance_type is PERMIT. */
            permitType?: GeostoreLanguageTaggedTextProto[];
            /** The types of services that this parking allowance applies to. For instance, some cities have streets that only allow traditional taxis to pick up passengers. */
            serviceType?: string[];
            /**
             * Describes the rate structures. Each TimeBasedRateProto defines a rate which may apply based on a particular arrival, departure or utilization time; for example, one rate might apply
             * if arriving before 9am, and another might apply regardless of arrival or departure time.
             */
            timeBasedRate?: GeostoreTimeBasedRateProto[];
            /** Restrictions on which vehicle type(s) the allowance applies to. By default, the allowance applies to any vehicle types. */
            vehicleType?: string;
        }
        interface GeostoreParkingProto {
            /**
             * Describes the parking allowances for the feature, which are the situations and requirements under which one is permitted to park at the feature’s parking facilities, or discounts
             * that a user may be eligible for.
             */
            allowance?: GeostoreParkingAllowanceProto[];
            /**
             * Hours in which the parking facility is open; that is, permits both arrivals and departures of the facility. Should only be set on compounds (i.e. parking lots or garages); roads are
             * considered to always be “open,” though parking at certain times may be prohibited via restrictions. If unset on a compound, this suggests we don’t know the opening hours, or they
             * are the same as the hours of the entity for which this feature offers parking facilities.
             */
            openingHours?: GeostoreOpeningHoursProto;
            /**
             * Indicates whether long-term parking is available at the feature; if true, long-term parking is available at the feature and parking allowances may be present on this feature, or
             * parking_provider_feature may indicate defered parking feature(s). If false, this is an explicit statement that there is no long-term parking associated with this feature. If unset,
             * we don't know whether there is long-term parking associated with this feature. If false or unset, only additional restrictions or short-term allowances will be populated.
             */
            parkingAvailable?: boolean;
            /**
             * If empty, indicates that the feature containing this ParkingProto provides parking facilities, which are described by this proto. If nonempty, indicates that the feature with this
             * ParkingProto does not contain parking facilities itself, but visitors of this feature may use the parking available to the referent feature(s). The referent feature(s) may
             * themselves contain parking facilities or defer to other features. A ParkingProto may defer parking details to another feature, but still include its own data. This suggests that a
             * visitor of the referrer feature is eligible for different rates or discounts. The data in these fields applies transitively, and any fields in a referrer may be applied to the
             * referent (for a visitor of the referrer).
             */
            parkingProviderFeature?: GeostoreFeatureIdProto[];
            /**
             * Describes any parking restrictions that apply to this feature. Should only be set on road segments for which parking is explicitly prohibited for some or all times; for roads which
             * do not prohibit parking and for all other facilities, the ability to park should be expressed using allowances. In the instance that both a restriction and an allowance applies at a
             * given time, restrictions always have precedence over the same parking allowances. However, explicit short-term allowances (PICKUP_GOODS, PICKUP_PASSENGERS) take precedence over
             * general NO_PARKING, NO_STANDING, or NO_STOPPING restrictions.
             */
            restriction?: GeostoreParkingRestrictionProto[];
        }
        interface GeostoreParkingRestrictionProto {
            /** Times at which parking is prohibited. */
            restrictedHours?: GeostoreTimeScheduleProto;
            /** clang-format on The type of restriction that applies at this time. */
            restrictionType?: string;
            /**
             * The types of services that this parking restriction applies to. We expect most parking restrictions to apply to all services, but some airports have specific rideshare parking or
             * taxi parking zones.
             */
            serviceType?: string[];
            /** The types of vehicles that this parking restriction applies to. For instance, some streets may allow motorcycles to park but not automobiles or trucks. */
            vehicleType?: string[];
        }
        interface GeostorePeakProto {
            /** Topographic prominence in meters: the height of the peak’s summit above the lowest contour line encircling it and no higher summit. */
            prominenceMeters?: number;
        }
        interface GeostorePedestrianCrossingProto {
            /**
             * This value specifies the angle of the crosswalk. Zero degrees represents a crosswalk perpendicular to the direction of travel, towards the right side of the segment. The crosswalk
             * angle, winds clockwise. Range [-90, 90]. The following crosswalk would have a 15 degree angle: / / <--/-------------------------------- / /
             */
            angleDegrees?: number;
            /**
             * This value enables crossing anywhere (not just at the segment’s endpoint), typically used on long, low-traffic residential streets. This attribute is only respected for trivial
             * segment -> sibling routes. All other routes can cross at a MapFacts intersection.
             */
            crossAnywhere?: boolean;
            /** Crossing type is used as a restriction and can also be used for rendering. */
            crossingType?: string;
            /**
             * The crossing offset defines a fraction between the distance from the segment endpoint to the centerline of the crosswalk and the length of the segment. For example, the segment
             * length is 20 meters and the distance from segment end to center of crosswalk is 2 meters, the value of offset will be 0.1.
             */
            offset?: number;
            /** Restrictions for this crossing (such as constructions on the crosswalk). They must not have subpath or travel_mode. */
            restriction?: GeostoreRestrictionProto[];
            /**
             * This value defines the full width of the crossing in the direction perpendicular to the direction which pedestrians walk on the crossing (in meters). The crossing is allowed to
             * "spill" into the next segment (0.5 * width can be greater than the offset). Cannot be a negative value.
             */
            width?: number;
        }
        interface GeostorePhysicalLineProto {
            /** Applicable for DASHED and DOTTED_DASHED lines. */
            dashLengthMeters?: number;
            /** This should be rarely needed, but can represent patterns of alternating colors. */
            gapColor?: GeostorePaintedElementLogicalColorProto;
            /** Applicable for DASHED, DOTTED, and DOTTED_DASHED lines. */
            gapLengthMeters?: number;
            material?: string[];
            /** Color for the painted elements. Applicable to all types. */
            paintColor?: GeostorePaintedElementLogicalColorProto;
            pattern?: string;
            /** A token that can be used to identify the version of the data about this marker line. */
            physicalLineToken?: string;
        }
        interface GeostorePointProto {
            latE7?: number;
            lngE7?: number;
            /**
             * NOTE: If removing metadata, remove 'option objc_class_prefix = "GS";' together. See cl/189921100. Field-level metadata for this point. NOTE: there are multiple PointProto fields in
             * the Geo Schema. Metadata here is only expected to be present on FeatureProto.point[] and FeatureProto.center.
             */
            metadata?: GeostoreFieldMetadataProto;
            /** A place for clients to attach arbitrary data to a point. Never set in MapFacts. */
            temporaryData?: any;
        }
        interface GeostorePointWithHeightProto {
            /** Altitude of this point is assumed to be relative to the ground level. */
            altitudeMeters?: number;
            point?: GeostorePointProto;
        }
        interface GeostorePoliticalProto {
            /** Many political regions have a conceptual center (capitals of a country or a top-level division are examples). If set, the target feature must be a TYPE_LOCALITY feature. */
            capital?: GeostoreFeatureIdProto;
            /** The Gross Domestic Product of the political region measured in millions of current United States dollars. It must not be negative. */
            grossDomesticProductUsdMillions?: number;
            /** Percentage of population that are literate within a political region. It must be between 0 and 100. */
            literacyPercent?: number;
            /**
             * The number of people in this political region. This field is intended to store accurate population, not an estimation such as representative value for population range. It must not
             * be negative.
             */
            population?: string;
        }
        interface GeostorePolygonProto {
            /**
             * The polygon loops above are basically flat: each point has a latitude and a longitude but no altitude. We don't want to build real 3D models here, but we do want to be able to
             * generate 2.5D models. A 2.5D model is built by translating the flat polygon upward some distance (base) then extruding it upward some additional distance (height). The elevation of
             * the bottom of the extruded polygon (above ground level).
             */
            baseMeters?: number;
            /**
             * ** DEPRECATED ** This is part of a splitting strategy for large polygons, which was never fully launched and we decided not to pursue. For features with very complex polygonal
             * geometry, we break up the polygon into pieces that align with S2 cells at various levels. We do this for performance reasons as some geometry operations have quadratic complexity
             * with regards to the total number of vertices. In these cases, we store the S2 cell ID corresponding to the piece of the overall polygon that is described by this specific
             * PolygonProto message. Each polygon piece is expected to be fully contained by the S2 cell corresponding to this cell ID. However, note that the S2 cell ID is not required to
             * correspond to the smallest S2 cell that fully contains the polygon (and often won't be). In addition, polygon pieces are required to not have any overlap (which translates to having
             * entirely disjoint S2 cell IDs, i.e. one can not be parent (or grand parent, etc.) of another).
             */
            cellId?: string;
            /** Encoding of the polygon using S2Polygon::Encode()'s compressed representation. */
            encoded?: string;
            /** The distance from the bottom of the extruded polygon to the top. */
            heightMeters?: number;
            /**
             * ** DEPRECATED ** We have switched to using exclusively the encoded form in the wire format to and from MapFacts, so this field should never be populated there. See
             * go/encoded-polygons for more info. "Classic" polygon representation, defined by one or more loops. The last vertex of each polyline is implicitly connected to the first vertex. All
             * loops should be specified in CCW order.
             */
            loop?: GeostorePolyLineProto[];
            /** Field-level metadata for this polygon. */
            metadata?: GeostoreFieldMetadataProto;
            /**
             * A unique identifier for this polygon's data which is being held externally in Shapestore (see go/shapestore). This is only ever set internally within MapFacts or underlying
             * infrastructure and if set is set in lieu of other fields. Clients of MapFacts (or anyone downstream of them) can rely on the guarantee that this field will never be set and that the
             * actual data for the polygon will be present instead. This field has been deprecated in favor of FeatureProto.internal.polygon_shape_id
             */
            shapeId?: string;
            /** A place for clients to attach arbitrary data to a polygon. Never set in MapFacts. */
            temporaryData?: any;
            /**
             * Some polygons are known to be rough proxies for a feature's "real" polygonal representation. Such polygons are generally unsuitable for display. Rendering clients should not show
             * these in most cases. Polygons unsuitable for display do have other uses, such as user location or containment analysis, or as an input to learning algorithms. This is an orthogonal
             * concept to FeatureProto.synthetic_geometry, which only pertains to the method by which a polygon was created, rather than its fidelity to ground truth. For features that have
             * multiple polygons, this bit should be consistently set to the same value on all polygons.
             */
            unsuitableForDisplay?: boolean;
        }
        interface GeostorePolyLineProto {
            /** Field-level metadata for this polyline. NOTE: there are multiple PolyLineProto fields in the Geo Schema. Metadata here is only expected to be present on FeatureProto.polyline[]. */
            metadata?: GeostoreFieldMetadataProto;
            /** A place for clients to attach arbitrary data to a polyline. Never set in MapFacts. */
            temporaryData?: any;
            /**
             * A sequence of vertices connected by geodesics (the equivalent of straight lines on the sphere). Adjacent vertices are connected by the shorter of the two geodesics that connect
             * them, i.e. all edges are 180 degrees or less. Note that the edge definition becomes numerically unstable as the arc length approaches 180 degrees. Polylines are generally expected
             * to be non-self-intersecting, but any such restriction is imposed by the user of the polyline rather than the polyline itself.
             */
            vertex?: GeostorePointProto[];
        }
        interface GeostorePoseProto {
            /** The height of the poses above the WGS-84 ellipsoid in meters. */
            altitude?: number;
            /** The index of the PoseProto in a list of PoseProtos. */
            index?: number;
            /** The latitude of the pose in degrees [-90, 90]. */
            lat?: number;
            /** The longitude of the pose in degrees (-180,180]. */
            lng?: number;
            /** The rotation around the longitude line East tangent in degrees [-90, 90]. */
            pitch?: number;
            /** The rotation around the latitude line North tangent in degrees (-180, 180]. */
            roll?: number;
            /** The rotation around the Up vector, from North, in degrees (-180, 180]. */
            yaw?: number;
        }
        interface GeostorePriceInfoFoodNutritionFacts {
            calories?: GeostorePriceInfoFoodNutritionFactsCaloriesFact;
            /** Cholesterol information for a given food dish. */
            cholesterol?: GeostorePriceInfoFoodNutritionFactsNutritionFact;
            /** Protein information for a given food dish. */
            protein?: GeostorePriceInfoFoodNutritionFactsNutritionFact;
            /** Sodium information for a given food dish. */
            sodium?: GeostorePriceInfoFoodNutritionFactsNutritionFact;
            /** Carbohydrate information for a given food dish. */
            totalCarbohydrate?: GeostorePriceInfoFoodNutritionFactsNutritionFact;
            /** Fat information for a given food dish. */
            totalFat?: GeostorePriceInfoFoodNutritionFactsNutritionFact;
        }
        interface GeostorePriceInfoFoodNutritionFactsCaloriesFact {
            lowerAmount?: number;
            /** Unit of the given calories information. */
            unit?: string;
            upperAmount?: number;
        }
        interface GeostorePriceInfoFoodNutritionFactsNutritionFact {
            lowerAmount?: number;
            /** Unit of the given nutrition information. */
            unit?: string;
            upperAmount?: number;
        }
        interface GeostorePriceInfoProto {
            /**
             * The actual food menus. This is a repeated field because a restaurant may offer multiple menus, e.g. for different language or for different available time, such as holidays vs
             * non-holidays.
             */
            priceList?: GeostorePriceListProto[];
            /**
             * All URLs that give price list information for this establishment. For food menus, this would represent menu_urls. Note that this field is a repeated list of UrlListProtos. Each
             * UrlListProto instance in the list is intended to hold lists of URLs that are translations of the same URL.
             */
            priceListUrl?: GeostoreUrlListProto[];
            /** Message containing metadata about the verified status of the PriceInfo. Only verified listings should be displayed. */
            status?: GeostorePriceInfoStatus;
        }
        interface GeostorePriceInfoStatus {
            isVerified?: boolean;
        }
        interface GeostorePriceListNameInfoProto {
            description?: string;
            /** IDs are intended to be unique identifiers of PriceInfoLists, Sections, and Menu items. This is enforced by the ID_DUPLICATE_PRICE_LIST_ID lint. */
            id?: string;
            /**
             * The external form of a Google International Identifiers Initiative (III) LanguageCode object. See google3/i18n/identifiers/languagecode.h for details. We place extra restrictions on
             * languages in addition to what the III library requires. See go/geo-schema-reference/feature-properties/languages.
             */
            language?: string;
            name?: string;
        }
        interface GeostorePriceListProto {
            /** For third party lists, represents the ID of the aggregator which provided this data. Optional. */
            aggregatorId?: string;
            /**
             * The time period when this price list is available. Establishments are not required to give available_time for any given price list, however, when this field is not set, the price
             * list is understood as available any time the establishment is open.
             */
            availableTime?: GeostoreTimeScheduleProto;
            /** Cuisine information if the location the price lists attached to is an eligible feature for a food menu price list. Cuisine information should also only show up in a food price list. */
            cuisines?: string[];
            /**
             * The repeated name_info field is for price lists listed in multiple languages. When a price list has no names or descriptions, the size of the repeated field name_info may be 0.
             * There should be at most one name_info for any given language.
             */
            nameInfo?: GeostorePriceListNameInfoProto[];
            /**
             * Each price list may have multiple sections. Note that these sections within the same price list should most times contain only the same type of items for sale, e.g. all sections
             * should usually contain only food items if the enclosing price list is representing food menu. However, sometimes such a requirement may be wrong, for example, McDonald's may sell
             * burgers as well as toys, and the toys may be in its own section. Thus we don't enforce any requirement that all sections contain only the same type of items.
             */
            section?: GeostorePriceListSectionProto[];
            /** Where this price list comes from. If set, this must also be a member of the price_list_url field, and represents translations of a single URL. */
            sourceUrl?: GeostoreUrlListProto;
        }
        interface GeostorePriceListSectionProto {
            /** Call to action for the section. */
            callToAction?: GeostoreCallToActionProto;
            /** To store food and drink items when the containing PriceListSectionProto is a food menu section. */
            foodItem?: GeostoreFoodMenuItemProto[];
            /** To store any items when the containing PriceListSectionProto is not food / legacy services. */
            item?: GeostoreComposableItemProto[];
            /** This has to have at most one value. */
            itemType?: string[];
            /** One or more media items (photos, videos, etc.) describing this section / category. */
            media?: GeostoreMediaItemProto[];
            /**
             * The repeated name_info field is for price list sections listed in multiple languages. When a price list section has no names or descriptions, the size of the repeated field
             * name_info may be 0. There should be at most one name_info for any given language.
             */
            nameInfo?: GeostorePriceListNameInfoProto[];
        }
        interface GeostorePriceRangeProto {
            /** Currency code for the price range: a valid currency code from i18n/identifiers/currencycode.h. Lower and upper price are both assumed to use the same currency. */
            currency?: string;
            /** This message allows unbounded price ranges. e.g. Lower_price is undefined. At least one of the two prices must be set for the price range to be meaningful. */
            lowerPrice?: number;
            /** clang-format on */
            units?: string;
            upperPrice?: number;
        }
        interface GeostorePropertyValueStatusProto {
            /** The property ID whose value status is defined by this proto. */
            propertyId?: GeostoreFeaturePropertyIdProto;
            /** `value_status` specifies whether the feature has a value for the property. This should always be set to something other than the default value (`PROPERTY_VALUE_STATUS_UNSPECIFIED`). */
            valueStatus?: string;
        }
        interface GeostoreProvenanceProto {
            /**
             * The dataset from which this the referenced data was created. The content of this string will be determined by the data provider, and may encode extra information, such as data
             * confidence.
             */
            dataset?: string;
            /** The data provider from which the referenced data was generated. */
            provider?: string;
        }
        interface GeostoreRankDetailsProto {
            /** A list of signals. Each one is extracted separately by a SignalExtractor. */
            signal?: GeostoreRankSignalProto[];
            /** The signal mixer that was used to calculate the rank. */
            signalMixerType?: string;
        }
        interface GeostoreRankSignalProto {
            /** Field-level metadata for this signal. */
            metadata?: GeostoreFieldMetadataProto;
            /**
             * A value in the range [0, 1] estimating Oyster Rank according to this signal. Non-provider specific signals (e.g. SIGNAL_POPULATION) are interpreted by some common code in the
             * ranking pipeline. Because of that, data providers should leave this field empty when setting such signals (so that the rank assignment can be uniform across all features regardless
             * of contributing data providers). On the other hand, provider-specific signals (e.g. SIGNAL_ZENRIN_CITY_CATEGORY) are required to specify the rank field (it is not optional for
             * them). That is because no code other than that of the provider itself will be able to fill in a meaningful value later on. We don't want clients to be reading from the raw_scalar /
             * raw_string fields to interpret the data.
             */
            rank?: number;
            /** The raw scalar value that was used to compute 'rank' above. The meaning of this attribute changes depending on the signal type. */
            rawScalar?: number;
            /** The raw string value that was used to compute 'rank' above. The meaning of this attribute changes depending on the signal type. */
            rawString?: string;
            type?: string;
        }
        interface GeostoreRawDataProto {
            /**
             * The key associated with this data item. For source data in shape file format, this will typically be a column name. Keys need to be unique with respect to a particular data source
             * (see DataSourceProto), but they do not need to be globally unique. You can look up the documentation for a key (e.g. a longer label and description) by following the source_id link
             * of the parent SourceInfoProto, which takes you to a TYPE_DATA_SOURCE feature, and then looking up the corresponding RawMetadataProto object for this key in that feature's optional
             * data_source field.
             */
            key?: string;
            /** All data items are represented as strings, the logic being that it is easy to convert other data types to strings, and there is no need to access this data efficiently. */
            valueString?: string;
        }
        interface GeostoreRawMetadataProto {
            /**
             * Method to use when conflating together RawDataProto values at the same key NB: If you add a new ConflationMethod, then you must add the corresponding logic to MergeRawData to
             * conflate the RawDataProto values using this method.
             */
            conflationMethod?: string;
            /** Self-contained documentation about what this field represents and how its values are encoded. */
            description?: string;
            /** The key being described. */
            key?: string;
            /** A longer, human-readable name associated with this key. The label might be used in a data explorer tool, for example. */
            label?: string;
        }
        interface GeostoreRectProto {
            hi?: GeostorePointProto;
            lo?: GeostorePointProto;
        }
        interface GeostoreRegulatedAreaProto {
            /**
             * The set of restrictions that apply to a zone. These restrictions may limit the routability of every segment contained within the defined feature.polygon. Repeated restrictions are
             * treated collectively as an OR meaning that segments in the zone are only routable if none of the restrictions apply. If any segments within the defined polygon should not have these
             * restrictions applied, they must list this regulated area's feature id in their feature.exempt_regulated_area field.
             */
            restriction?: GeostoreRestrictionProto[];
        }
        interface GeostoreRelationProto {
            /** Field-level metadata for this relation. */
            metadata?: GeostoreFieldMetadataProto;
            /** If and only if the other feature is of TYPE_COUNTRY, the 2-letter country code. This is the FLAG_COUNTRY_CODE_2 name of the country component. */
            otherFeatureCountryCode?: string;
            /**
             * The feature ID of the feature to which we're relating. WARNING: the related feature does not necessarily have a bound that encloses this feature, so in a bucketing MapReduce, you
             * may not be able to follow all relationships. Relations that use strong references are annotated above but you can also refer to IsRelationStrong() in
             * geostore/base/public/relation.h.
             */
            otherFeatureId?: GeostoreFeatureIdProto;
            /** RESERVED */
            otherFeatureName?: GeostoreNameProto[];
            /**
             * If and only if the other feature is of TYPE_DISPUTED_AREA, the territorial administrator found in its GeopoliticalAttachmentProto.administered_by field, if any. Since this string is
             * copied exactly, it may be a 2-letter country code or another type of descriptive string.
             */
            otherFeatureTerritorialAdministrator?: string;
            /** The type of the feature to which we're relating. */
            otherFeatureType?: number;
            /**
             * ** DEPRECATED ** If relation is exactly RELATION_OVERLAPS but not any of its subcategories, overlap_fraction contains an estimate of the fraction of the geometry of this feature
             * that intersects with the other feature, ranging from 0.0 to 1.0. Note that this is a rough estimate based on cell coverings, and may not be very accurate. In particular, values of
             * 0.0 and 1.0 are possible, even though in principle they should not be.
             */
            overlapFraction?: number;
            /**
             * The relationship of the feature that contains this RelationProto to the feature other_feature_id. Note the relation_is_reversed field below. Some relations imply weak references,
             * other strong ones. Strong references are annotated above but you can also refer to IsRelationStrong() in geostore/base/public/relation.h.
             */
            relation?: string;
            /** RESERVED */
            relationIsReversed?: boolean;
            /** A place for clients to attach arbitrary data to a relation. Never set in MapFacts. */
            temporaryData?: any;
        }
        interface GeostoreRestrictionGroupProto {
            /** Field-level metadata for this restriction group. */
            metadata?: GeostoreFieldMetadataProto;
            /** FeatureId of all segments that have a RestrictionProto referring back to this RestrictionGroup. */
            segment?: GeostoreFeatureIdProto[];
        }
        interface GeostoreRestrictionProto {
            /** The restriction only applies in these specific autonomous driving product scenarios. NOTE: This should only be set on restrictions with TRAVEL_AUTONOMOUS_VEHICLE travel mode. */
            autonomousDrivingProducts?: string[];
            /**
             * Actually *required* if style=STYLE_IN_OUT, otherwise forbidden. Typically the intersection group type is artifact, but either artifact or logical groups can be used for STYLE_IN_OUT
             * restrictions.
             */
            intersectionGroup?: GeostoreFeatureIdProto;
            /** Field-level metadata for this restriction. */
            metadata?: GeostoreFieldMetadataProto;
            /** Restriction group this restriction belongs to. */
            restrictionGroup?: GeostoreFeatureIdProto;
            /**
             * When specified, restriction applies only at particular times (operating hours or times of the year: reversing lanes, seasonal roads, no left turns from 3-5pm Mon-Fri except
             * holidays). Otherwise, restriction is in effect at all times.
             */
            schedule?: GeostoreTimeScheduleProto;
            /**
             * The scope that the restriction applies to. - SCOPE_DIRECTION means the segment/sibling pair is restricted in the direction of the segment that contains this RestrictionProto. For
             * segment/sibling pairs with pedestrian facilities (and thus side-of-road routing) the RestrictionProto restricts both facilities in the direction of the segment (assuming that the
             * restriction applies to travel mode TRAVEL_PEDESTRIAN). - SCOPE_SIDE means the RestrictionProto applies only to the side of road that the containing segment represents. That
             * sibling's pedestrian facility is restricted in both directions. Schema constraints: - SCOPE_SIDE must be set if and only if travel_mode == [TRAVEL_PEDESTRIAN] and the segment
             * containing the restriction has PEDESTRIAN_FACILITY_PRESENT. Such restrictions must have no subpath. - All other restrictions must have this field set to SCOPE_DIRECTION (whether
             * explicitly or implicitly). This distinction is necessary for cases such as pedestrian facility on one-way segment/sibling roads.
             */
            scope?: string;
            /** Restriction Style defines the semantics of the subpath field, as defined above in the documentation of subpath. */
            style?: string;
            /**
             * "subpath" specifies the GeoStore segments that this restriction applies to, according to the restriction_style field below. Segments that are referenced by this subpath field also
             * refer to this feature back via the same subpath field. For all styles of restriction, all segments in the subpath must have identical copies of the restriction. In other words,
             * restrictions are duplicated along every segment in the subpath. Note that subpaths of length 1 do not have any purpose and are disallowed. Note that it is possible to represent
             * restrictions either using STYLE_CONTIGUOUS, or depending on the length of the subpath, one of the more specific STYLE_SINGLE, STYLE_TURN, or STYLE_IN_OUT. New code should use the
             * more specific alternatives if possible, as they support instant updates. For restriction_style == STYLE_CONTIGUOUS (the default): "subpath" can either be empty, for a single-segment
             * restriction, or it specifies exactly the sequence of segments which this restriction applies to. The subpath may be used to specify a turn restriction (a subpath of length 2) or to
             * prohibit more complex maneuvers. For example, when merging onto a road from the right-hand side it may not be possible to make an immediate left turn due to insufficient time to
             * cross the intervening lanes or the presence of a physical barrier. This would be indicated by a subpath restriction of length 3 or more. For restriction_style == STYLE_SINGLE: The
             * subpath field of the Restriction must be empty. The restriction applies only to the segment it is attached to. There must not be an intersection group specified. For
             * restriction_style == STYLE_TURN: The subpath field of the Restriction must contain exactly two segments. The first is called the "in_segment", the second is the "out_segment". They
             * must be contiguous, i.e. the end intersection of the in_segment is the start intersection of the out_segment. The restriction applies only to a direct maneuver from the in_segment
             * to the out_segment. Other paths from the in_segment to the out_segment are not restricted. There must not be an intersection group specified. For restriction_style == STYLE_IN_OUT:
             * The subpath field of the Restriction must contain exactly two segments. The first is called the "in_segment", the second is the "out_segment". Note that the two segments define
             * paths, but may not actually be one. The end intersection of the in_segment must be in an intersection group which also contains the start intersection of the out_segment. The in-
             * and out-segments are not required to be adjacent, but may be. Either way, the restriction applies to any path from the in_segment to the out_segment through the intersection group,
             * not just direct turns. The intersection_group must be specified. Note that clients which read restrictions and need to know which paths are restricted by a given IN_OUT restriction
             * must expand the IN_OUT restriction by finding all paths through the intersection group from the in_segment to the out_segment.
             */
            subpath?: GeostoreFeatureIdProto[];
            /** A place for clients to attach arbitrary data to a restriction. Never set in MapFacts. */
            temporaryData?: any;
            /**
             * Restriction applies only to the given travel modes. This field should always be set, but may be missing in old data. WARNING: Restrictions with no travel modes are DEPRECATED.
             * Historically, no travel modes has meant "all travel modes", except they didn't really even mean that, because Pathfinder would use a complex set of heuristics to interpret the
             * "correct" travel modes. Pathfinder currently (last updated August 2013) has heuristics to cope with incomplete data that reduce or extend application of the specified restrictions
             * to pedestrians or bicycles. We are actively working to remove these heuristics and replace them with explicit, correct travel modes in the data. See b/8746491.
             */
            travelMode?: string[];
            /** clang-format on The type of restriction. This is not a condition, but rather tells you what kind of restriction it is. This field should always be set. */
            type?: string;
            /** The restriction only applies to vehicles that meet all of the attributes defined here. If this is empty, it does not affect the scope of the restriction. */
            vehicleAttributeFilter?: GeostoreVehicleAttributeFilterProto;
        }
        interface GeostoreRightsStatusProto {
            fieldWithRights?: GeostoreFieldWithRightsProto[];
        }
        interface GeostoreRoadConditionalProto {
            /**
             * Specifies what times the information is applicable. This can be specific times (3-5 PM) or days of the week (Mon - Fri), as well as more general times like school hours, dusk to
             * dawn, etc. If no value is set, the restriction is applicable at all times.
             */
            timeSchedule?: GeostoreTimeScheduleProto;
            /** Additional attributes that apply to the applied vehicle types. */
            vehicleAttribute?: GeostoreVehicleAttributeFilterProto;
            /** Restrictions applying to specific types of vehicles. */
            vehicleType?: string[];
        }
        interface GeostoreRoadMonitorProto {
            /** The TYPE_ROAD segment features that this road monitor may observe. */
            monitoredRoad?: GeostoreFeatureIdProto[];
        }
        interface GeostoreRoadSignComponentProto {
            /**
             * The id of the feature referred to by this component, typically the route or locality feature this sign points towards. In the ASCII art example above, this field would contain the
             * id for the routes A11 and E50 and the localities Chartres and Paris in the corresponding component.
             */
            featureId?: GeostoreFeatureIdProto;
            /** The type of the feature referred to by this component. If feature_id is specified type of that feature should be the same as this field. */
            featureType?: number;
            /**
             * This is the "major" position of this component within the set of components that make up a sign. This number can be thought of as the "row" of the sign on which the component
             * appears, but no guarantees are made that there is a one-to-one mapping between "major_position" and the rows of information on the actual sign being modeled. A "major_position"
             * value of zero would indicate that the component is near the top of the sign.
             */
            majorPosition?: number;
            /**
             * This is the position of a component within the components of a sign that share a common "major_position". It can be though of as the "column" of the component, but like
             * "major_position", no guarantees are made regarding its mapping to reality. For data sources that don't provide enough information to determine a component's major and minor
             * positions, major position should be populated and minor position should not be present. A "minor_position" value of zero would indicate that the component is near the "beginning" of
             * the sign. In countries where signs are read from left to right, "minor_position" zero would be near the left side of the sign.
             */
            minorPosition?: number;
            /** The direction of traffic for the referenced TYPE_ROUTE feature. */
            routeDirection?: string;
            /** If this sign component is of type "TYPE_TEXT", this field contains the text of the component. A NameProto is used to allow language and flags to be associated with the text. */
            text?: GeostoreNameProto;
            /** This type of content represented by this sign component. */
            type?: string;
        }
        interface GeostoreRoadSignProto {
            /** The list of components for a single road sign. A sign may be composed of multiple components, each with its own position and content. */
            component?: GeostoreRoadSignComponentProto[];
        }
        interface GeostoreRouteAssociationProto {
            /** clang-format on */
            displayPreference?: string;
            /** Field-level metadata for the route association. */
            metadata?: GeostoreFieldMetadataProto;
            /** Identifies the route feature to which this metadata applies. This is one of the routes the segment refers to via the SegmentProto.route field. */
            route?: GeostoreFeatureIdProto;
            /**
             * The direction of the TYPE_ROUTE feature in this route association. A small number of countries (mostly just the United States, Mexico, and Canada) use directional routes. For
             * example, in the United States highway US-1 is referred to as US-1 North or US-1 South on the sides where flow of traffic moves in those directions.
             */
            routeDirection?: string;
        }
        interface GeostoreRouteProto {
            /** The feature type of the route children. Should be set if and only if all children are of the same feature type. */
            childType?: number;
        }
        interface GeostoreSchoolDistrictProto {
            type?: string;
        }
        interface GeostoreSegmentPathProto {
            /**
             * Specifies a sequence of feature ids of GeoStore segments. The feature ids are ordered. The path "AB" is not the same as the path "BA". The segments along the path are assumed to be
             * connected via the appropriate intersections. The segment features that are referenced by this subpath refer to this feature back via the road_sign field in segment proto extension.
             */
            subpath?: GeostoreFeatureIdProto[];
        }
        interface GeostoreSegmentProto {
            advisoryMaximumSpeed?: GeostoreAppliedSpeedLimitProto[];
            /** RESERVED */
            altitude?: number[];
            /** The average speed that should be expected along this route under normal conditions, in kilometers per hour. (Hopefully we'll replace this with something a lot more sophisticated.) */
            avgSpeedKph?: number;
            /** Field-level metadata for the average speed. */
            avgSpeedKphMetadata?: GeostoreFieldMetadataProto;
            /** clang-format on */
            barrier?: string;
            /** Field-level metadata for the barrier. */
            barrierMetadata?: GeostoreFieldMetadataProto;
            /** clang-format on */
            bicycleFacility?: string;
            bicycleSafety?: string;
            condition?: string;
            /** Field-level metadata for the condition. */
            conditionMetadata?: GeostoreFieldMetadataProto;
            /** If known, the date that construction is scheduled to begin. */
            constructionBeginDate?: GeostoreDateTimeProto;
            /** If known, the date that construction is scheduled to end. */
            constructionEndDate?: GeostoreDateTimeProto;
            constructionStatus?: string;
            /** Field-level metadata for the construction status. */
            constructionStatusMetadata?: GeostoreFieldMetadataProto;
            /** Whether the segment is covered by a roof etc. If this field is missing, the status is unknown. */
            covered?: boolean;
            /**
             * Average distance between the segment's polyline and edge of the road on this side in meters. It need not be equal to the sum of width of all lanes in this direction. This width
             * includes on-street bicycle lanes but excludes off-street lanes such as sidewalks. The edge of the road is the rightmost edge for segments in right side driving countries and
             * leftmost edge for left side driving countries. Width of the road is sum of this and sibling's distance_to_edge.
             */
            distanceToEdge?: number;
            /** Field-level metadata for distance_to_edge. */
            distanceToEdgeMetadata?: GeostoreFieldMetadataProto;
            /**
             * These indicate for what portion of the segment does the outer curb of the segment follow the segment polyline - i.e., where do the sweep curves connect along the outer curb. If
             * unspecified, may be assumed to be equal to lane retraction, preferring outermost lane.
             */
            edgeFollowsSegmentBeginFraction?: number;
            edgeFollowsSegmentEndFraction?: number;
            /** clang-format on */
            elevation?: string;
            /** Field-level metadata for the elevation. */
            elevationMetadata?: GeostoreFieldMetadataProto;
            /** clang-format on */
            endpoint?: string;
            /** Field-level metadata for the endpoint. */
            endpointMetadata?: GeostoreFieldMetadataProto;
            /**
             * Detailed information about grade levels along the segment. If a GradeLevelProto is not present for any point (index) along the segment, the default grade level is zero. In between
             * two points (indexes), the grade level of the segment is taken to be the max of the grade levels on either side of it. See gradelevel.proto for semantics of repeated indexes.
             */
            gradeLevel?: GeostoreGradeLevelProto[];
            /** Internal-only data. */
            internal?: GeostoreInternalSegmentProto;
            /** If specified, the perpendicular offset in meters from a road segment to an interpolated address along that road segment. See go/synthetic-address-positions. */
            interpolationOffsetMeters?: number;
            /**
             * The intersection feature corresponding to the destination of this segment. Intersections are used to represent the connectivity between segments. Each intersection stores the
             * segment ids of all the incoming and outgoing segments that meet at that intersection. Turns can be made from this segment to any of the outgoing segments of its intersection, unless
             * there is a restriction that explicitly disallows the turn (see below). Every segment has an intersection object, even if there are no other segments to connect to (i.e., a
             * cul-de-sac or dead end).
             */
            intersection?: GeostoreFeatureIdProto;
            /** Specifies whether the max_permitted_speed_kph was derived from a heuristic as opposed to coming from an authoritative source. */
            isMaxPermittedSpeedDerived?: boolean;
            /**
             * Detailed information about each lane in this direction, if available. Lanes are numbered from inside of the road outward, i.e. the lane next to the center line is lane 0. Note that
             * lanes that are valid for travel in both directions appear in both segments of a segment pair (left turn lanes, one-lane roads, some passing lanes, reversing lanes). Some lanes may
             * not be usable by cars, such as bike lanes. Also, some lanes may not exist along the entire segment, e.g. left- or right-turn lanes that appear just before the intersection.
             */
            lane?: GeostoreLaneProto[];
            /**
             * The legal maximum, legal minimum, and advisory (recommended but non-legally binding) maximum speed limits that are permitted on this segment. These should be the segment's legal
             * limits; however, note that it may contain estimated values based on country-wide defaults and other heuristics (see 'AppliedSpeedLimitProto.trust_level'). Before exposing these
             * fields to users as the legal speed limit please consult with Google lawyers.
             */
            legalMaximumSpeed?: GeostoreAppliedSpeedLimitProto[];
            legalMinimumSpeed?: GeostoreAppliedSpeedLimitProto[];
            /**
             * The maximum speed that is permitted on this segment, in kilometers per hour. This should be the segment's legal speed limit; however, note that it may contain estimated values based
             * on country-wide defaults and other heuristics (see 'is_max_permitted_speed_derived' below). Before exposing this field to users as the legal speed limit please consult with Google
             * lawyers.
             */
            maxPermittedSpeedKph?: number;
            /** Field-level metadata for the maximum permitted speed. */
            maxPermittedSpeedKphMetadata?: GeostoreFieldMetadataProto;
            /**
             * Specifies whether this segment carries right-hand traffic (cars keep to the right side of the road) instead of left-hand traffic (cars keep to the left side). This is true for US
             * roads and false for UK roads, for example. See go/wikip/Left-_and_right-hand_traffic.
             */
            onRight?: boolean;
            /** Defines the pedestrian crossing(s) between the end point of this segment and the start point of this segment's sibling. */
            pedestrianCrossing?: GeostorePedestrianCrossingProto;
            /** clang-format on */
            pedestrianFacility?: string;
            pedestrianGrade?: string;
            /** LINT.ThenChange(//depot/google3/maps/pathfinder/pgraph/pgraph-segment-categories.cc) */
            priority?: string;
            /** Field-level metadata for the priority. */
            priorityMetadata?: GeostoreFieldMetadataProto;
            /**
             * The set of restrictions that apply to this segment. Restrictions may make a single segment, turn, or more complex maneuver along a set of segments unroutable for the specified
             * travel modes, or may only add penalties or warnings, depending on the restriction type. Turn restrictions are one example of a restriction. By default, turns are allowed onto all
             * outgoing segments from this segment's intersection (including the sibling of this segment, i.e. U-turns are allowed by default). If any of these turns are disallowed they will be
             * listed as "subpath restrictions". A subpath restriction disallows travel on given sequence of segments. In the case of a disallowed turn, the subpath simply consists of the source
             * and destination feature ids. There may also be restrictions that apply to all travel on this segment (e.g. chains required, or closed in winter), or restrictions that just apply to
             * certain lanes (e.g. high occupancy vehicle lanes).
             */
            restriction?: GeostoreRestrictionProto[];
            /** The road monitors that monitor this segment for traffic violations. */
            roadMonitor?: GeostoreFeatureIdProto[];
            /**
             * The road sign(s) which this segment refers to. These are features of TYPE_ROAD_SIGN that are applicable to this segment. For example, a sign that says "TO KIRKLAND" might apply to
             * several segments on a freeway off-ramp (until the end of the ramp). Note that this field makes it easy to find the signs for a given road segment. The feature for the sign lists the
             * segments that refer to it.
             */
            roadSign?: GeostoreFeatureIdProto[];
            /** The route(s) to which this segment belongs. */
            route?: GeostoreFeatureIdProto[];
            /**
             * Holds metadata about the associations between this segment and the route features listed in the route field. This metadata need not be present; the only consistency requirement is
             * that every feature ID that appears inside 'route_association' must also appear in the repeated 'route' field. If a route does not appear in route_association, consumers should
             * assume that it has a default initialized RouteAssociationProto.
             */
            routeAssociation?: GeostoreRouteAssociationProto[];
            /**
             * Indicates whether the segment's opposing lanes of traffic are separated from this segment, and hence have been represented in a separate feature. This means that there are two pairs
             * of siblings instead of one.
             */
            separatedRoadways?: boolean;
            /**
             * The other segment of this segment pair (see above). The segment that is referenced by the sibling field refers to this feature back via the same sibling field. Both segment and
             * sibling should have the same properties such as geometry, country code, elevation, level relation, priority etc. Since routes are required to have segment and sibling at the same
             * time, the set of routes on a segment is same to that of the sibling.
             */
            sibling?: GeostoreFeatureIdProto;
            /**
             * clang-format on LINT.ThenChange(//depot/google3/geostore/base/proto/lane.proto) If this option is missing it means that the surface is unknown. Specific lanes may override this
             * segment-level surface type.
             */
            surface?: string;
            /** Field-level metadata for the surface. */
            surfaceMetadata?: GeostoreFieldMetadataProto;
            /** The geometric sweeps between this segment and nearby segments, used for real road width rendering. A sweep describes the surface that connects to segments. */
            sweep?: GeostoreSweepProto[];
            /** If this segment is part of a toll road. It would be nice to have data about the toll cost, locations of toll booths, and so forth. Sadly, we don't have this data at this time. */
            tollRoad?: boolean;
            /** clang-format on LINT.ThenChange(//depot/google3/maps/pathfinder/pgraph/pgraph-segment-categories.cc) */
            usage?: string;
            /**
             * A collection of landmarks that are visible when traveling along this segment and useful for wayfinding to users following routes using this segment. The landmark need not be on the
             * segment. Each segment in a pair of siblings specifies its landmarks independently. A landmark applicable to both appears in both.
             */
            visibleLandmark?: GeostoreLandmarkReferenceProto[];
        }
        interface GeostoreServiceAreaProto {
            /**
             * The features that make up the service area for this establishment. These features are subject to the following constraints applied by editing middleware (notably, not strictly
             * enforced by lints in storage): 1. The following feature types (and their subtypes) may be used: + TYPE_ISLAND + TYPE_POLITICAL, except the following prohibited subtypes: -
             * TYPE_CONSTITUENCY - TYPE_LAND_PARCEL + TYPE_POSTAL 2. There is a maximum limit (currently 20) to the number of areas which may be provided. This is due to serving efficiency
             * limitations. 3. There are no additional geometry requirements for these features beyond the requirements based on the feature types above. In practice this means that these features
             * will either have polygonal or point-based geometries. 4. These referenced features are generally required to have names, though this is not strictly enforced.
             */
            servedFeature?: GeostoreFeatureIdProto[];
        }
        interface GeostoreServicedStopProto {
            /** Reference to a Transit POI feature (gcid:transit_station) or platform compound section (gcid:railway_platform) serviced by the line variant. */
            id?: GeostoreFeatureIdProto;
            /** An index representing the order in which the above station is serviced by the line variant. */
            index?: number;
        }
        interface GeostoreSkiBoundaryProto {
            type?: string;
        }
        interface GeostoreSkiLiftProto {
            /** clang-format on */
            type?: string;
        }
        interface GeostoreSkiTrailProto {
            difficulty?: string;
            type?: string;
        }
        interface GeostoreSocialReferenceProto {
            /** WARNING: Please do NOT introduce new uses; treat this field as if it were deprecated. */
            baseGaiaId?: string;
            /**
             * GAIA ID used when a business has been claimed. This value is a robot GAIA ID. Robots are a special type of GAIA account used to denote identity for a user or a group of users, but
             * are not logged-in directly by a user.
             */
            claimedGaiaId?: string;
            /** WARNING: Please do NOT introduce new uses; treat this field as if it were deprecated. */
            gaiaIdForDisplay?: string;
        }
        interface GeostoreSourceInfoProto {
            /**
             * This is the URL of a page representing all the data from this source in this feature. It may have be the ultimate source of the data (in case of scraping) or merely the same data
             * styled according the provider's taste. There is a similar field in DataSourceProto which is NOT cached in this field, since it has a different meaning.
             */
            attributionUrl?: GeostoreUrlProto[];
            /** The time that this particular piece of data was collected. If different attributes were collected on different dates, this is the date of the most recent edit. */
            collectionDate?: GeostoreDateTimeProto;
            /**
             * A source info may have a magic cookie whose content and semantics are defined by the specific import process or third-party feed. For feeds that are processed by Distillery, the
             * cookie, when set, should contain the unique identifier for the feature as provided by the feed.
             */
            cookie?: string;
            /**
             * The dataset from which this SourceInfoProto was created. The content of this string will be determined by the data provider (e.g. for MultiNet data, "fra" would indicate the dataset
             * for France). This field is unnecessary for providers that deliver a single dataset per release (e.g. Basarsoft).
             */
            dataset?: string;
            /**
             * The Gaia ID of the user who provided us with this data. This field should never be set on source infos present on features, but may be set on source infos present on edits.
             * DEPRECATED: Most clients should use the "user" field instead where Gaia IDs are encrypted.
             */
            gaiaId?: string;
            /** Information about an internal user or system that is operating on behalf of `user` by way of impersonation. */
            impersonationUser?: GeostoreUserProto;
            /** The name of the layer from which this SourceInfoProto was created. */
            layer?: string;
            /**
             * The OGR feature identifier from which this SourceInfoProto was created. This is an internal OGR record identifier and has nothing to do with any of the feature's fields or the
             * FeatureIdProto for the FeatureProto containing this SourceInfoProto. This field is present only for debugging purposes and possible use in the match pattern of a FeatureChangeProto
             * designed to fix bad source data very early in the importing process.
             */
            ogrFid?: string;
            /**
             * The data provider from which this source info was generated. The value must be equal to the one on the TYPE_DATA_SOURCE feature referenced by this source info via the source_id
             * reference (see above).
             */
            provider?: number;
            /**
             * A source info may optionally have a set of key-value pairs that provide "raw data" specific to that source. The types of raw data available will vary from one provider to another
             * and should not be used in production code. Instead, new fields and/or protocol buffers should be defined to represent this information in a canonical form, and the relevant
             * importers should be modified to populate these new fields.
             */
            rawData?: GeostoreRawDataProto[];
            /** The data release from which this SourceInfoProto was created. The format for this string is provider-dependent (e.g. a MultiNet release would look like "2008.01"). */
            release?: string;
            /**
             * A source info may have a corresponding TYPE_DATA_SOURCE feature that describes it (provider, copyright information, date of release, etc). In the context of edits and issues, this
             * field should not be set.
             */
            sourceId?: GeostoreFeatureIdProto;
            /** A place for clients to attach arbitrary data to a source info. Never set in MapFacts. */
            temporaryData?: any;
            /** RESERVED */
            user?: GeostoreUserProto;
        }
        interface GeostoreSourceTrustProto {
            /** The level of trust for the source of the observation. */
            level?: string;
        }
        interface GeostoreSpeedLimitProto {
            /** The type of speed limit. */
            category?: string;
            /** The conditions under which this speed limit is applicable. If multiple conditions are set, at least one of them must be true. */
            condition?: GeostoreRoadConditionalProto[];
            /** A constant speed limit. */
            speedWithUnit?: GeostoreSpeedProto;
            /** A speed limit with no limit value. When there is no speed limit in place. */
            unlimitedSpeed?: any;
            /** A dynamic speed limit that can vary within a range of values based on road conditions. */
            variableSpeed?: any;
        }
        interface GeostoreSpeedProto {
            speed?: number;
            unit?: string;
        }
        interface GeostoreStableFieldPathProto {
            /** A sequence of field selectors to be traversed starting from the root message. */
            fieldPath?: GeostoreStableFieldPathProtoStableFieldSelector[];
        }
        interface GeostoreStableFieldPathProtoStableFieldSelector {
            /** Field number to select. */
            fieldNum?: number;
            /**
             * Select repeated field entry by its version token. If this is used, then the message referenced by field_num must have a token field annotated with the (version_token) field option.
             * Must be omitted for leaf non-repeated fields. If unset for a repeated field, we consider this selector to apply equally to all descendants.
             */
            versionToken?: string;
        }
        interface GeostoreSweepProto {
            /** The segment feature connected to this segment via the sweep geometry. */
            otherSegmentFeatureId?: GeostoreFeatureIdProto;
            /** Polygonal geometry representing the area between this segment and the other segment. */
            polygon?: GeostorePolygonProto;
            /**
             * Describes parameters for generating the edge of this sweep that starts at edge_follows_segment_end_fraction. The other side of the sweep should be described on the sweep present on
             * the sibling pair.
             */
            sweepCurve?: GeostoreCurveConnectionProto;
            /** A token that can be used to identify the version of the data about this sweep. */
            sweepToken?: string;
        }
        interface GeostoreTelephoneProto {
            /** RESERVED */
            callRate?: GeostorePriceRangeProto[];
            /** Disambiguates between the types of information or service a caller might seek when contacting this phone number. */
            contactCategory?: string;
            flag?: string[];
            /**
             * True if this phone number is not unique to this establishment and might be shared with other features. In case an establishment shares a phone number with a business chain of which
             * it is a member, and the number canonically belongs to that chain, it should be marked as shared for the establishment but not shared for the chain.
             */
            isSharedNumber?: boolean;
            /** RESERVED */
            label?: GeostoreNameProto[];
            /** RESERVED */
            language?: string[];
            /** Field-level metadata for this telephone number. */
            metadata?: GeostoreFieldMetadataProto;
            /** ** DEPRECATED ** This is deprecated in favor of phone_number below. An internationalized representation of a phone number. See //location/country/telephonenumber.proto */
            number?: TelephoneNumber;
            /** An internationalized representation of a phone number. See //java/com/google/i18n/phonenumbers/phonenumber.proto */
            phoneNumber?: I18nPhonenumbersPhoneNumber;
            /**
             * The features from which this phone number can be called from. For instance, if a phone number can only be called from Europe, this field will contain a reference to the
             * TYPE_CONTINENT feature of Europe. This field is analogous to http://kg/schema/common/phone_number/service_location. The only valid destination feature types are TYPE_CONTINENT and
             * TYPE_POLITICAL. If empty, this phone number can be called from anywhere in Earth (this is the case for the majority of phones).
             */
            serviceLocationFeature?: GeostoreFeatureIdProto[];
            type?: string;
        }
        interface GeostoreTemporaryClosureProto {
            /** The latest when this closure may end, if the exact date is unknown. If set, the feature is operational again no later than this date. */
            endAsOfDate?: GeostoreDateTimeProto;
            /** RESERVED */
            endDate?: GeostoreDateTimeProto;
            /** The latest when this closure may start, if the exact date is unknown. If set, the feature is temporarily closed starting no later than this date. */
            startAsOfDate?: GeostoreDateTimeProto;
            /** RESERVED */
            startDate?: GeostoreDateTimeProto;
        }
        interface GeostoreTextAffixProto {
            /**
             * The external form of a Google International Identifiers Initiative (III) LanguageCode object. See google3/i18n/identifiers/languagecode.h for details. These strings should be
             * treated as opaque blobs. You can use LanguageCodeConverter::FromOther to convert the string to a LanguageCode reference. You can then call methods on the LanguageCode class to
             * extract language/script/region subtags (if any). See also http://g3doc/i18n/identifiers/g3doc/using-iii. We place extra restrictions on languages in addition to what the III library
             * requires. See http://go/geo-schema-reference/feature-properties/languages.md
             */
            language?: string;
            /** Text to prepend to the primary text, including any necessary trailing whitespace. At least one of prefix or suffix is required. */
            prefix?: string;
            /** Text to append to the end of the primary text, including any necessary leading whitespace. At least one of prefix or suffix is required. */
            suffix?: string;
        }
        interface GeostoreThreeDimensionalModelProto {
            /** Triangle vertex indices, each triple defines a triangle. */
            pointIndices?: number[];
            /** We store a triangular mesh in indexed format. Points array. */
            points?: GeostorePointWithHeightProto[];
        }
        interface GeostoreTimeBasedRateProto {
            /**
             * The rates for this rule. Each duration_based_rate defines the costs associated with a particular duration of a stay. There must be at least one rate with range_start_seconds set to
             * 0 and there cannot be gaps between durations (i.e. there should be no interval uncovered between 0 and the largest range_end_seconds of any duration-based rate).
             */
            durationBasedRate?: GeostoreDurationBasedRateProto[];
            /** If true, tax is included in the prices in this rate. If false, additional taxes may apply. */
            taxIncluded?: boolean;
            validEndWithin?: GeostoreTimeScheduleProto;
            /** Time period during which utilization of this rate must start in order to be eligible for the rate. If not set, there is no restriction on the time when the utilization starts. */
            validStartWithin?: GeostoreTimeScheduleProto;
        }
        interface GeostoreTimeComponentProto {
            componentType?: string;
            /** The time component is the intersection of these intervals */
            interval?: GeostoreTimeIntervalProto[];
        }
        interface GeostoreTimeEndpointProto {
            /** Valid ranges are 0-7, 1-31, and 1-366 (see day_type below) */
            day?: number;
            dayType?: string;
            /** Valid range is 0-24. Because it could be unclear what wrapping hours mean in relation to days, 24 is used to denote midnight at the end of a day. */
            hour?: number;
            /** Valid range is 0-59, except when a repetitive minute interval ends at the end of an hour, in which case 60 is a legal end value. */
            minute?: number;
            month?: string;
            /** Valid range is 0-59, except when a repetitive second interval ends at the end of a minute, in which case 60 is a legal end value. */
            second?: number;
            /** Valid ranges are 0-5 and 1-53 (depending on the value of week_type, see below). */
            week?: number;
            weekType?: string;
            year?: number;
        }
        interface GeostoreTimeIntervalProto {
            /**
             * Begin and end are used to specify a range of times: [begin, end). If one is present, the other must be present as well. Additionally, both must have matching time granularities -
             * all fields specified in the begin TimeEndpointProto must be present in the end TimeEndpointProto and vice-versa. Hours are not allowed to wrap (begin.hour() <= end.hour()).
             */
            begin?: GeostoreTimeEndpointProto;
            end?: GeostoreTimeEndpointProto;
            /**
             * If true, then this interval actually encodes the complement of the specified occasion or range. For example, the following TimeIntervalProto encodes all times other than the month
             * of May. TimeIntervalProto[ type = TYPE_RANGE inverted = true begin = TimeEndpointProto[ month = MAY ] end = TimeEndpointProto[ month = JUNE ] ]
             */
            inverted?: boolean;
            /** clang-format on */
            occasion?: string;
            type?: string;
        }
        interface GeostoreTimeScheduleProto {
            /** The schedule is the union of these components. */
            component?: GeostoreTimeComponentProto[];
        }
        interface GeostoreTimezoneProto {
            /** i18n recognized time zone identifier. For the full list of identifiers, see google3/i18n/identifiers/data/timezones.txt. */
            id?: string;
            /** Field-level metadata for this relation. */
            metadata?: GeostoreFieldMetadataProto;
        }
        interface GeostoreTollClusterProto {
            /**
             * The list of TYPE_INTERSECTION features that are toll points and form this toll cluster. A toll cluser can consist of either a single or a group of intersection points called toll
             * points at the end of various road segments in MapFacts that represent one or more lanes passing through a toll fixture that all go to the same routing destination. This relationship
             * is reciprocal, as a toll point intersection also stores a reference to the toll cluster it belongs to. A toll cluster must have reference to one or more toll points i.e.
             * toll_cluster.intersection should always be populated.
             */
            intersection?: GeostoreFeatureIdProto[];
        }
        interface GeostoreTrackProto {
            /** The index of this TrackProto in a list of TrackProtos. */
            index?: number;
            /** The instantaneous pose of points along this track. The fields set inside each pose must be set consistently along the track. */
            pose?: GeostorePoseProto[];
        }
        interface GeostoreTransitLineProto {
            /**
             * The transit agencies responsible for operating this line. All lines should have at least one agency, and most will have exactly one. The following cases are reasons for multiple
             * agencies: - Code share: Two or more agencies share trips - Alternations: Each trip is run by one of multiple agencies - Additional: All trips run by one agency, but a second one
             * sells tickets In all cases the order has no meaning. Clarification comes from the trips.
             */
            agency?: GeostoreFeatureIdProto[];
            /**
             * The background color of labels for that transit line. The encoding is like in HTML or CSS, eg. 0x11ff00 means a bit of red, full green, no blue, in sRGB color space. The most
             * significant byte must be zero, i.e. no transparency.
             */
            labelBackgroundColor?: number;
            /** The text color of labels for that transit line. Encoding like label_background_color. */
            labelTextColor?: number;
            /**
             * The transit stations (establishment POIs with gcid:transit_station) which this transit line can go through, in no particular order. Usage note: The source of truth are the transit
             * leg features in Transit Oyster. In MapFacts, that information is cached in two locations: in this field, and in transit station attachments on POIs. Do not assume these locations
             * are always up to date and/or synchronized with each other.
             */
            stations?: GeostoreFeatureIdProto[];
            /** The type of vehicle that applies to all trips that use this line. */
            vehicleType?: string;
        }
        interface GeostoreTransitLineVariantProto {
            /** Reference to the line variant’s line concept. */
            lineConcept?: GeostoreFeatureIdProto;
            /** Ordered list of stations or platforms serviced by this line variant. The order is captured by the ServicedStopProto.index field. */
            stops?: GeostoreServicedStopProto[];
        }
        interface GeostoreTransitStationProto {
            /** Transit agencies which service this transit station. A station can be serviced by one or more transit agencies. See go/transit-agency-relation-migration for more information. */
            agencies?: GeostoreFeatureIdProto[];
        }
        interface GeostoreTrustSignalsProto {
            /** Trust signals for the source of a given observation, typically based on historical evidences or status (like internal Google operator). */
            sourceTrust?: GeostoreSourceTrustProto;
        }
        // tslint:disable-next-line:no-empty-interface
        interface GeostoreUnlimitedSpeedProto {
        }
        interface GeostoreUrlListProto {
            url?: GeostoreUrlProto[];
        }
        interface GeostoreUrlProto {
            /**
             * The external form of a Google International Identifiers Initiative (III) LanguageCode object. See google3/i18n/identifiers/languagecode.h for details. We place extra restrictions on
             * languages in addition to what the III library requires. See http://go/geo-schema-reference/feature-properties/languages.md This field represents the language of the content of the
             * web site. It may be missing if the web site is language-independent or if the language is unknown.
             */
            language?: string;
            /** Field-level metadata for this URL. NOTE: there are multiple UrlProto fields in the Geo Schema. Metadata here is only expected to be present on FeatureProto.website[]. */
            metadata?: GeostoreFieldMetadataProto;
            /** ** DEPRECATED ** The pagerank of this URL. Valid values [0, 65535] See http://wiki/Main/NearestSeeds for more information. */
            pagerank?: number;
            /** The URL. */
            url?: string;
        }
        interface GeostoreUserProto {
            /** The user Gaia ID in encrypted form. Wipeout ids take value of "" in bytes. */
            encryptedGaiaId?: string;
            /** Required. The name of the key used to encrypt the Gaia ID. */
            encryptionKeyName?: string;
            /**
             * Required (valid default provided). The config ID of the owner of the above encryption_key_name. This field must be set if the encryption key name is *not*
             * "mapfacts_gaia_id_encryption_key".
             */
            keystoreConfigId?: number;
            /**
             * If possible, writers should set this to a full user email, including the domain. Readers should not assume that this is a well-formed email address. This field may only be set by
             * Atlas, Pushpin and OneRing because they are internal tools which have a PWG exception to store textual usernames in the clear.
             */
            username?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface GeostoreVariableSpeedProto {
        }
        interface GeostoreVehicleAttributeFilterProto {
            /** A repeated value here is treated as an AND operation. This allows for ranges to be represented by two values (ex: "count < 4" AND "count >= 2" means "2 <= count < 4"). */
            axleCount?: GeostoreCountComparisonProto[];
            /** Whether the applied vehicle types have a trailer attached to them. */
            hasTrailer?: boolean;
            /** List of prohibited hazardous goods for a vehicle to carry. A repeated value here is treated as an OR operation, meaning that they may not carry ANY of the goods listed. */
            hazardousGoods?: string[];
            /** A repeated value here is treated as an AND operation. This allows for ranges to be represented by two values (ex: "count <= 4" AND "count > 2" means "2 < count <= 4"). */
            numTrailers?: GeostoreCountComparisonProto[];
            /**
             * A repeated value here is treated as an AND operation. This allows for ranges to be represented by two values (ex: "length <= 53ft" AND "length > 48ft" means "48ft < length <=
             * 53ft").
             */
            trailerLength?: GeostoreDimensionComparisonProto[];
            /** A repeated value here is treated as an AND operation. This allows for ranges to be represented by two values (ex: "height > 3m" AND "height <= 5m" means "3m < height <= 5m"). */
            vehicleHeight?: GeostoreDimensionComparisonProto[];
            /** A repeated value here is treated as an AND operation. This allows for ranges to be represented by two values (ex: "length <= 40m" AND "length > 35m" means "35m < length <= 40m"). */
            vehicleLength?: GeostoreDimensionComparisonProto[];
            /** A repeated value here is treated as an AND operation. This allows for ranges to be represented by two values (ex: "weight < 8T" AND "weight >= 3T" means "3T <= weight < 8T"). */
            vehicleWeight?: GeostoreWeightComparisonProto[];
            /** A repeated value here is treated as an AND operation. This allows for ranges to be represented by two values (ex: "width < 4m" AND "width >= 2m" means "2m <= width < 4m"). */
            vehicleWidth?: GeostoreDimensionComparisonProto[];
        }
        interface GeostoreVerticalOrderingProto {
            /**
             * The level represents the relative vertical ordering of a feature among all overlapping features. For example, we may have features along freeway surface have level = 0, and features
             * on an overpass have level = 1. NOTE: It’s assumed that all features have level 0 by default, so that it’s not necessary for all overlapping features to have this set.
             */
            level?: number;
        }
        interface GeostoreWeightComparisonProto {
            comparison?: string;
            comparisonOperator?: string;
            weightWithUnit?: GeostoreWeightProto;
        }
        interface GeostoreWeightProto {
            unit?: string;
            weight?: number;
        }
        interface GoodocAnchorLabel {
            /** There is a generic method for composing such strings. Please take a look at GoodocUtils::GenerateUniqueAnchorName(...) in ocr/goodoc/goodoc-utils.h. */
            Anchor?: string;
            anchorScope?: number;
        }
        interface GoodocBoundingBox {
            Height?: number;
            /** Optional magic label, so objects can be sorted on bounding box dimensions easily */
            Label?: number;
            /** BoundingBox coordinates and sizes are expressed in pixels */
            Left?: number;
            Top?: number;
            Width?: number;
        }
        interface GoodocBoxPartitions {
            direction?: number;
            /** "span" is width or height, determined by "direction". If there are k partitions, then there are k - 1 "span" values, one for each except the last symbol (which is redundant). */
            span?: number[];
        }
        interface GoodocBreakLabel {
            BreakLabelType?: number;
            /** True if break prepends the element */
            isPrefix?: boolean;
        }
        interface GoodocCharLabel {
            /** The shift of a character from the base line of the string in pixels */
            BaseLine?: number;
            /** Height of small characters in pixels on the source image */
            CharacterHeight?: number;
            /** The foreground color of the symbol; the default color is 0 (black) */
            Color?: number;
            /** Symbol recognition confidence from OCR. Range depends upon OCR Engine. */
            Confidence?: number;
            /** The font ID refers to the fonts table in the document header */
            FontId?: number;
            /** Size in points (JFYI: point is 1/72"). This is rounded to the nearest whole number. */
            FontSize?: number;
            /** Size in points represented as float. */
            FontSizeFloat?: number;
            FontType?: number;
            /** If CharacterHeight is defined uncertainly */
            HasUncertainHeight?: boolean;
            /** The horizontal scaling for a character, in percents. The default value for this property is 100, which corresponds to no scaling. */
            HorizontalScale?: number;
            IsBold?: boolean;
            IsItalic?: boolean;
            IsSmallCaps?: boolean;
            IsStrikeout?: boolean;
            IsSubscript?: boolean;
            IsSuperscript?: boolean;
            /** If OCR Engine marked the character as "suspicious" (this character is likely to be recognized incorrectly). */
            IsSuspicious?: boolean;
            IsUnderlined?: boolean;
            /** True if a QA operator has marked this as not OCRable. This is used for complex equations, scripts that the operator can't type, or handwriting. */
            NotOcrablePerQA?: boolean;
            /** Symbol-level penalty from the garbage text detector. Lower is better; range = [0,100]. */
            Penalty?: number;
            /** The probability that a character is written with a Serif font */
            SerifProbability?: number;
        }
        interface GoodocDocument {
            /** Debug info, recording the history of any editing done through the interface in goodoc-editing.h. The strings look like "MoveParagraph(page_index = 0, source_block_index = 3, ...); */
            EditingHistory?: string[];
            header?: GoodocDocumentHeader;
            /**
             * Logical entities are stored as blobs. Depending on the kind of thing this is a goodoc of, a separate .proto file is expected to define the logical entity structure. Hence we can
             * still parse this as a goodoc for people who dont care about this, and people who care about this can parse it specifically. ocr/goodoc/logical-entity-utils.h has methods to read and
             * write these. See Goodoc++ doc
             */
            LogicalEntity?: string[];
            /**
             * The names of the proto messages serialized in LogicalEntity, one for each LogicalEntity. The repetitions should number 0 to leave this unspecified, or they should equal the number
             * of LogicalEntity strings.
             */
            LogicalEntityMessageName?: string[];
            page?: GoodocDocumentPage[];
            /** For multi-goodoc documents */
            SubDocuments?: GoodocDocument[];
        }
        interface GoodocDocumentHeader {
            font?: GoodocDocumentHeaderFont[];
            OcrEngineId?: string;
            OcrEngineVersion?: string;
        }
        interface GoodocDocumentHeaderFont {
            FontId?: number;
            FontName?: string;
        }
        interface GoodocDocumentPage {
            block?: GoodocDocumentPageBlock[];
            /** If the garbage text detector was run, the changelist that the binary was sync'ed to (or -1 if unknown), and whether the settings had their production values (or false if unknown). */
            GarbageDetectorChangeList?: number;
            GarbageDetectorWasProduction?: boolean;
            /** Height in pixels */
            Height?: number;
            /** Horizontal resolution in DPI. */
            HorizontalDpi?: number;
            Label?: GoodocLabel;
            mergedpageinfo?: GoodocDocumentPageMergedPageInfo[];
            /**
             * Score of porn classifier from analyzing images on page. Note: This should be named porn_score, but we use PornScore as the name in order to be consistent with the rest of this
             * proto.
             */
            PornScore?: number;
            /** Whether page-level text confidences and other summary data were computed by PostOcrUtils instead of the now-obsolete GarbageTextDetector */
            postOcrConfidence?: boolean;
            /** Page level stats (font size, line spacing, etc.) */
            stats?: GoodocSummaryStats;
            /** Page text recognition confidence. Range depends on the algorithm but should be consistent in a given volume. 0 is bad, 100 is good. */
            TextConfidence?: number;
            /** Vertical resolution in DPI. */
            VerticalDpi?: number;
            /** Width in pixels */
            Width?: number;
        }
        interface GoodocDocumentPageBlock {
            BlockType?: number;
            Box?: GoodocBoundingBox;
            Label?: GoodocLabel;
            /** Which way is upright for this block, and what is the reading order (applicable if there is text here). */
            OrientationLabel?: GoodocOrientationLabel;
            Paragraph?: GoodocParagraph[];
            /** If RotatedBox is set, Box must be set as well. See RotatedBoundingBox. */
            RotatedBox?: GoodocRotatedBoundingBox;
            /** Block text recognition confidence. Range depends on the algorithm but should be consistent in a given volume. 0 is bad, 100 is good. */
            TextConfidence?: number;
        }
        interface GoodocDocumentPageMergedPageInfo {
            OcrEngineId?: string;
            OcrEngineVersion?: string;
        }
        interface GoodocFontSizeStats {
            /** CharLabel.FontId and FontSize */
            fontId?: number;
            fontSize?: number;
            /** The measurements are in pixels */
            medianHeight?: number;
            /** top to bottom */
            medianLineHeight?: number;
            /** bottom to next top in para */
            medianLineSpace?: number;
            /** top to next top in para */
            medianLineSpan?: number;
            medianWidth?: number;
            /** Line stats for this font. "top" corresponds to the highest ascender and "bottom" to the lowest descender. num_lines = # lines with > 50% symbols having this font */
            numLines?: number;
            /** Lines (out of num_lines) that have a successor line within their para */
            numLineSpaces?: number;
            numSymbols?: number;
        }
        interface GoodocLabel {
            /** AnchorLabel identifies a link target. */
            AnchorLabel?: GoodocAnchorLabel[];
            BreakLabel?: GoodocBreakLabel;
            /** CharLabel is specifically intended for symbols */
            CharLabel?: GoodocCharLabel;
            /**
             * Languages used in the element (page, block, paragraph or word). Ordered by dominant-language first. Note: content scanjobs processed by the garbage_text_detector before CL 9223538
             * (Dec. 2008) have LanguageLabels in arbitrary order (within Page and Block elements) -- the confidence value should be inspected to find the dominant language guess for these, rather
             * than just taking the first.
             */
            LanguageLabel?: GoodocLanguageLabel[];
            /** SemanticLabel is defined in goodoc-semantics.proto, it allows rich annotation of content, identifying the nature of page elements. */
            SemanticLabel?: GoodocSemanticLabel;
        }
        interface GoodocLanguageCombinationLanguage {
            /** Bcp47 language code. Note, this is not the same as OceanCode used by goodoc::Document. */
            bcp47Tag?: string;
            /** Weight of language. This specifies how likely it is to see the language in the input text. The values don't have to add up to 1. */
            weight?: number;
        }
        interface GoodocLanguageLabel {
            /**
             * Closest id from i18n/languages/proto/languages.proto; caveat: may not accurately capture the language. GoodocLanguageCodeToLanguage() declared in ocr/goodoc/goodoc-utils.h may be
             * used to convert a Language enum (i18n/languages/proto/languages.proto) to a string suitable for this field.
             */
            ClosestLanguageId?: number;
            /** Confidence level on that language, between 0 and 100 */
            Confidence?: number;
            /**
             * Old (Ocean) Language Code Usage: The language code is inferred during the running of the Garbage Text Detector and gets set at the paragraph, block and page level. Language code is
             * a string of 3 or more characters. The first 3 letters specify the language, according to ISO 639. Optionally, the 3-letter code can be extended with an underscore and a language
             * variant specifier. Specifiers exist for regional variants or for different forms of language spelling. The regional variants are specified as 2-letter country code, according to ISO
             * 3166. Some examples: Standard "por" - Portuguese, standard "rus" - Russian, standard Regional variants: "por_br" - Portuguese, Brazilian "eng_us" - English, United States Variants
             * of spelling: "rus_old" - Russian, old spelling "chi_tra" - Chinese, traditional "ger_new" - German, new spelling LanguageToGoodocLanguageCode() declared in ocr/goodoc/goodoc-utils.h
             * may be used to convert a Language enum (i18n/languages/proto/languages.proto) to a string suitable for this field. New Language Code Usage: Most of the usages described above were
             * standardized in BCP 47, and these codes are the new stanadard to be used in this field. To load either new or old language codes to form LanguageCode objects, use the function
             * FromOceanCode() in ocr/quality/lang_util.h Note that the function ocr::FromOceanCode is capable of transforming either version of the LanguageCode to a C++
             * i18n_identifiers::LanguageCode.
             */
            LanguageCode?: string;
        }
        interface GoodocLogicalEntity {
            link?: GoodocLogicalEntityLink[];
            Metadata?: string;
        }
        interface GoodocLogicalEntityLink {
            /** The preferred way to link to an element is to create an AnchorLabel in the target element and name it here. Multiple elements may contain the same Anchor string. */
            Anchor?: string;
            BlockId?: number;
            /**
             * Links may also specifically locate the target element with the following indices. Note that during the course of layout analysis, goodoc elements may move around, so such hard links
             * should be created only very late (or not at all -- Anchors would be more reliable target addresses).
             */
            DocId?: number;
            PageId?: number;
            ParagraphId?: number;
            RouteId?: number;
            SymbolId?: number;
            /** If not defined, link points to the current doc */
            Url?: string;
            WordId?: number;
        }
        interface GoodocOrdinal {
            implicit?: string;
            sectionStringValue?: string;
            sectionValue?: number;
            /**
             * The following vars describe the section component of an ordinal (if exists). They are used to express situation where a page number has a section component, usually denoating the
             * chapter number. For example pages 5-14, 5-15 will both have the common section 5. (If exists). The semantcis of the section variables correspond to that of the primary part of the
             * ordinal. (Described above).
             */
            sectionValueType?: string;
            /** The string page value. */
            stringValue?: string;
            /** The numeric page value. */
            value?: number;
            /** The delta in which the value increases between pages. */
            valueDelta?: string;
            /** A value type from the Type enum above. */
            valueType?: string;
        }
        interface GoodocOrientationLabel {
            /**
             * After rotating so that the text orientation is upright, how many radians does one have to rotate the block anti-clockwise for it to be level? We guarantee: -Pi/4 <= deskew_angle <=
             * Pi/4
             */
            deskewAngle?: number;
            /**
             * Whether a text line is mirrored (e.g. reflected in a shiny surface or seen through the opposite side of a storefront window). The intent is that this is a quality of the text line
             * image. It needs to be reflected according to a vertical axis along the direction of upright characters to make it readable. This does not affect the shape of the bounding box. A
             * mirrored line with top to bottom writing remains top to bottom. A mirrored horizontal line will flip left to right. However any child entities (symbols) will remain in the same
             * order, and the writing direction imposed by the language (ltr or rtl) will remain the same.
             */
            mirrored?: boolean;
            orientation?: string;
            textlineOrder?: string;
            writingDirection?: string;
        }
        interface GoodocOverrides {
            /** For text blocks only: do not allow this block to be turned into an image when rendering, even if your algorithms want to do so: */
            blockImagination?: string;
            /** For graphic blocks, we often expand the block a bit for rendering, to compensate for bad image segmentation. do_not_expand_graphic_box forces this behavior to be turned off. */
            doNotExpandGraphicBox?: boolean;
            /** For Pages only: explicitly specify whether or not this page should be rendered fully as an image */
            fullPageAsImage?: string;
            /** For Pages only: explicitly specify whether or not all text on this page should be treated as "LINEATED" */
            fullPageLineated?: string;
            /** For Pages only: explicitly specify whether or not this page should be skipped. */
            fullPageSkipped?: string;
            /** This GRAPHIC block's image can be shown even when GoodocToHTMLOptions.suppress_photos_with_this is specified. */
            needNotSuppressPhoto?: boolean;
            /** For blocks: explicitly specify whether or not this block should get a page-break before it. */
            pageBreakBefore?: string;
            style?: GoodocOverridesStyle[];
            /** For Words only: replace the rendered HTML by this: */
            wordHtml?: string;
        }
        interface GoodocOverridesStyle {
            /** css attribute name: "margin-left", for eg. */
            name?: string;
            /** css attribute vale: "1em", for eg. */
            value?: string;
        }
        interface GoodocParagraph {
            alignment?: number;
            Box?: GoodocBoundingBox;
            droppedcap?: GoodocParagraphDroppedCap;
            FirstLineIndent?: number;
            Label?: GoodocLabel;
            LeftIndent?: number;
            LineSpacing?: number;
            /** Which way is upright for this paragraph and what is the dominant reading order? */
            OrientationLabel?: GoodocOrientationLabel;
            RightIndent?: number;
            /** If RotatedBox is set, Box must be set as well. See RotatedBoundingBox. */
            RotatedBox?: GoodocRotatedBoundingBox;
            route?: GoodocParagraphRoute[];
            SpaceAfter?: number;
            SpaceBefore?: number;
            /**
             * If we merge any paragraphs into this one (through the MergeParagraphWithNext() interface in goodoc-editing.h), then we append the properties of the merged paragraph here, for
             * debugging and to avoid losing any info. Note that the SubsumedParagraphProperties Paragraphs do not contain Routes.
             */
            SubsumedParagraphProperties?: GoodocParagraph[];
            /** Paragraph text recognition confidence. Range depends on the algorithm but should be consistent in a given volume. 0 is bad, 100 is good. */
            TextConfidence?: number;
            Width?: number;
        }
        interface GoodocParagraphDroppedCap {
            Box?: GoodocBoundingBox;
            LettersCount?: number;
        }
        interface GoodocParagraphRoute {
            /** Route end point */
            EndPoint?: GoodocRoutePoint;
            /** Route start point */
            StartPoint?: GoodocRoutePoint;
            /** Route weight, i.e. route */
            Weight?: number;
            /** The array of words on this route */
            Word?: GoodocWord[];
        }
        interface GoodocRotatedBoundingBox {
            /** Angle of rotation of the original non-rotated box around the top left corner of the original non-rotated box, in clockwise degrees from the horizontal. */
            Angle?: number;
            Height?: number;
            /** Coordinates and sizes are expressed in pixels, where the top-left pixel is (0, 0). The coordinates refer to the corner of the top-left vertex of the unrotated version of the box. */
            Left?: number;
            Top?: number;
            Width?: number;
        }
        interface GoodocRoutePoint {
            /** The sequential route number, starts at 0 */
            RouteIndex?: number;
            /** The sequential word number, starts at 0 */
            WordIndex?: number;
        }
        interface GoodocSemanticLabel {
            /**
             * Alternate text for a sequence of the Goodoc, just for the element containing this label, or for a sequence starting from this element to the EndOfSpanningLabel. Typically this is
             * inserted by automatic or manual OCR correction. We use text instead of editing the Goodoc directly since we dont usually have accurate symbol level bboxes for the alternate text.
             * Also the original values from OCR are preserved. It is upto the application to do anything more intelligent like mapping words and finding potential symbol/word bboxes.
             */
            AlternateText?: string;
            appearance?: number;
            /**
             * Page elements can be given Attributes refining meaning/role. We keep this flexible by using strings instead of pre-determined enum values. But it is useful to list all such
             * Attributes in use in ocr/goodoc/goodoc-semantics-attributes.h
             */
            Attribute?: string[];
            /** Blocks that are at the beginning of chapters have this set: */
            ChapterStart?: boolean;
            CleanupAnnotation?: number[];
            columndetails?: GoodocSemanticLabelColumnDetails;
            contentlink?: GoodocSemanticLabelContentLink;
            ContinuesFromPreviousPage?: boolean;
            /** When ContinuesFromPreviousPage=true, this bit can be set to note that the word fragment on the previous page ends in a hyphen. */
            ContinuesFromPreviousPageHyphenated?: boolean;
            /**
             * Paragraphs that span across pages can be identified with the following flags. Note that flows just connect Blocks across pages. These continuation flags imply something more
             * specific -- the case of a single logical paragraph split over pages. Only the last Paragraph in the last Block within a given FlowThread() on a page can have ContinuesOnNextPage
             * set. Similarly, only the first Paragraph in the first Block with a given FlowThread() on a page may have ContinuesFromPreviousPage set.
             */
            ContinuesOnNextPage?: boolean;
            editcorrectioncandidate?: GoodocSemanticLabelEditCorrectionCandidate[];
            /**
             * Normally, a SemanticLabel applies exactly to the goodoc element that it is contained in (usually Block or Paragraph, sometimes Word). Occasionally, we need a SemanticLabel to span
             * across the boundary or end before the boundary. For example, a URL may just be a few words within a Paragraph. In such cases, the SemanticLabel is added to the first element of the
             * span and contains this LogicalEntity pointing to the last element of the span:
             */
            EndOfSpanningLabel?: GoodocLogicalEntity;
            /**
             * Message set for experimental algorithm data. Use case: We keep a set of features that was computed for the unsupervised caption extraction and store it here. Agora question producer
             * will consume this message set to be embedded in a question. The experimental feature set can then be used later to pair up with ground truth labels for designing a supervised
             * algorithm. Currently holding: o ocean/analysis/content/caption_data.proto's TextualElement
             */
            ExperimentalData?: any;
            /**
             * Flow identifies a single sequential unit of text (or other content). It is only set on Blocks -- a flow identifies a sequence of Blocks. The default, main flow is just the empty
             * string. The "FlowThread" of a block is the flow (if non-empty), suffixed with the block appearance. This is computed by GoodocUtils::FlowThread(). Paragraphs may be split over
             * blocks in the same FlowThread, across pages. The following table shows how FlowThread gets computed: ## Flow Appearance FlowThread (empty) UNSPECIFIED "UNSPECIFIED" foo BODY
             * "foo:BODY" Please use lower-case strings for flows (such as article-33-box). One useful way to think of flows is this: A logical unit of interest in a a Document (for example, an
             * article) would be identified by a starting block, an ending block, and a list of flows of interest within the [start, end) span. message Article { (page#, block#): article_start;
             * (page#, block#): article_end; repeated string flows; } The reading order of blocks, paragraphs/etc within this article would be the same order as present in the goodoc itself. Some
             * applications (such as rendering) may want to process the article by running over all the flows together, others (such as indexing) may want to deal with the FlowThreads one after
             * the other.
             */
            Flow?: string;
            /** This field can be used to record the steps by which AlternateText for a sequence of the Goodoc is generated. */
            ModificationRecord?: string;
            /** Structure overrides: typically manual corrections to goodoc renderings. */
            overrides?: GoodocOverrides;
            /** If Appearence is PAGE_NUMBER: */
            PageNumberOrdinal?: GoodocOrdinal;
            snippetfilter?: GoodocSemanticLabelSnippetFilter[];
            tablecelldetails?: GoodocSemanticLabelTableCellDetails;
            tabledetails?: GoodocSemanticLabelTableDetails;
        }
        interface GoodocSemanticLabelColumnDetails {
            Column?: number;
            Columns?: number;
        }
        interface GoodocSemanticLabelContentLink {
            citationtarget?: GoodocSemanticLabelContentLinkCitationTarget;
            involumetarget?: GoodocSemanticLabelContentLinkInVolumeTarget;
            /**
             * For URL labels, we note the url here directly (it's also available by grabbing all text symbols within the labeled span). SCHOLARLY_CITATION labels or even CAPTION labels may
             * occasionally contain URLs.
             */
            UrlTarget?: string;
        }
        interface GoodocSemanticLabelContentLinkCitationTarget {
            /** separated by semicolons */
            Authors?: string;
            BibKey?: string;
            Confidence?: number;
            Title?: string;
            Year?: number;
        }
        interface GoodocSemanticLabelContentLinkInVolumeTarget {
            Confidence?: number;
            /**
             * The CAPTION label typically targets the previous or the next Block. The FOOTNOTE_POINTER label typically targets a paragraph in a FOOTNOTE Block. TOC_ENTRY and INDEX_ENTRY labels
             * are links that point to a different page within the volume. CONTINUATION labels also are links that point to a different page within the volume, or maybe even a particular block or
             * paragraph.
             */
            LogicalEntity?: GoodocLogicalEntity;
        }
        interface GoodocSemanticLabelEditCorrectionCandidate {
            EditedWord?: string;
            Probability?: number;
        }
        interface GoodocSemanticLabelSnippetFilter {
            badwordFraction?: number;
            windowSize?: number;
        }
        interface GoodocSemanticLabelTableCellDetails {
            Column?: number;
            ColumnSpan?: number;
            /** Row and Column are 0-based */
            Row?: number;
            RowSpan?: number;
        }
        interface GoodocSemanticLabelTableDetails {
            Columns?: number;
            Rows?: number;
        }
        interface GoodocSummaryStats {
            /**
             * This flag is set if the histogram above has been derived by estimating font sizes from CharLabel.CharacterHeight; that happens if the FontSize field is constant, as has happened
             * with Abbyy 9.
             */
            estimatedFontSizes?: boolean;
            /** Symbol counts (and other attributes) for each distinct CharLabel.FontId and FontSize; histogram is in decreasing order of symbol count */
            fontSizeHistogram?: GoodocFontSizeStats[];
            meanSymbolsPerBlock?: number;
            meanSymbolsPerLine?: number;
            meanSymbolsPerParagraph?: number;
            meanSymbolsPerWord?: number;
            meanWordsPerBlock?: number;
            meanWordsPerLine?: number;
            meanWordsPerParagraph?: number;
            /** bottom to next top in flow on page */
            medianBlockSpace?: number;
            /** 0,2,4.. */
            medianEvenPrintedBox?: GoodocBoundingBox;
            medianFullEvenPrintedBox?: GoodocBoundingBox;
            medianFullOddPrintedBox?: GoodocBoundingBox;
            /** Each median_full*_printed_box includes page header/footer but still excludes all graphic blocks */
            medianFullPrintedBox?: GoodocBoundingBox;
            medianHeight?: number;
            medianHorizontalDpi?: number;
            /** top to bottom */
            medianLineHeight?: number;
            /** bottom to next top in para */
            medianLineSpace?: number;
            /** top to next top in para */
            medianLineSpan?: number;
            /** 1,3,5.. */
            medianOddPrintedBox?: GoodocBoundingBox;
            /** leading space on first line */
            medianParagraphIndent?: number;
            /** bottom to next top in block */
            medianParagraphSpace?: number;
            /** Each median*_printed_box excludes page header/footer and all graphic blocks */
            medianPrintedBox?: GoodocBoundingBox;
            medianSymbolsPerBlock?: number;
            medianSymbolsPerLine?: number;
            medianSymbolsPerParagraph?: number;
            medianSymbolsPerWord?: number;
            medianVerticalDpi?: number;
            medianWidth?: number;
            medianWordsPerBlock?: number;
            medianWordsPerLine?: number;
            medianWordsPerParagraph?: number;
            /**
             * ------ Block stats Median symbols and words omit junk, header and footer blocks; they are intended to be a measure of the typical "content" block. There can still be substantial
             * differences between means and medians; however, block values will generally exceed paragraph values (not the case when headers and footers are included).
             */
            numBlocks?: number;
            /** blocks that have a successor block within their flow on their page */
            numBlockSpaces?: number;
            /** ------ Line stats "top" corresponds to the highest ascender and "bottom" to the lowest descender. */
            numLines?: number;
            /** Lines (out of num_lines) that have a successor line within their para */
            numLineSpaces?: number;
            numNonGraphicBlocks?: number;
            /** ------ Page stats. */
            numPages?: number;
            /**
             * ------ Paragraph stats Median symbols and words omit junk, header and footer blocks; they are intended to be a measure of the typical "content" paragraph. There can still be
             * substantial differences between means and medians, particularly if a table is present (every cell is a paragraph).
             */
            numParagraphs?: number;
            /** paras that have a successor para within their block */
            numParagraphSpaces?: number;
            /** ------ Symbol stats */
            numSymbols?: number;
            /** ------ Word stats */
            numWords?: number;
        }
        interface GoodocSymbol {
            Box?: GoodocBoundingBox;
            /** The unicode character code in UTF-32 */
            Code?: number;
            Label?: GoodocLabel;
            /** If RotatedBox is set, Box must be set as well. See RotatedBoundingBox. */
            RotatedBox?: GoodocRotatedBoundingBox;
            symbolvariant?: GoodocSymbolSymbolVariant[];
        }
        interface GoodocSymbolSymbolVariant {
            Code?: number;
            Confidence?: number;
        }
        interface GoodocWord {
            alternates?: GoodocWordAlternates;
            /** The baseline's y-axis offset from the bottom of the word's bounding box, given in pixels. (A value of 2, for instance, indicates the baseline is 2px above the bottom of the box.) */
            Baseline?: number;
            Box?: GoodocBoundingBox;
            /** The capline is the y-axis offset from the top of the word bounding box. A positive value n indicates that capline is n-pixels above the top of this word. */
            Capline?: number;
            /**
             * For space efficiency, we sometimes skip the detailed per-symbol bounding boxes in Symbol.Box, and use this coarser representation instead, where we just store Symbol boundaries
             * within the Word box. Most client code should not have to worry directly about this, it should be handled in the deepest layers of writing/reading goodocs (for example, see
             * Compress() and Uncompress() in ocean/goodoc/goovols-bigtable-volume.h). Note(viresh): I experimented with this compression, and here are some numbers for reference. If the
             * zlib-compressed page goodoc string size was 100 to start with, then this compaction makes it 65. As a possible future relaxation to consider: if we add in, for each symbol, a "top"
             * and "bottom" box offset then the size would be 75 (that's with "repeated int32 top/bottom_offset" fields inside BoxPartitions, instead of inside each symbol).
             */
            CompactSymbolBoxes?: GoodocBoxPartitions;
            /** Word recognition confidence. Range depends upon OCR Engine. */
            Confidence?: number;
            /** word. The meaning and range depends on the OCR engine or subsequent processing. Specifies whether the word was found */
            IsFromDictionary?: boolean;
            /** a number True if word represents */
            IsIdentifier?: boolean;
            /**
             * True if the word is the last word in any sub-paragraph unit that functions at the same level of granularity as a sentence. Examples: "She hit the ball." (regular sentence) "Dewey
             * defeats Truman" (heading) "The more, the merrier." (no verb) Note: not currently used. Code to set this was introduced in CL 7038338 and removed in OCL=10678722.
             */
            IsLastInSentence?: boolean;
            /** in the dictionary True if the word represents */
            IsNumeric?: boolean;
            Label?: GoodocLabel;
            /** Penalty for discordance of characters in a */
            Penalty?: number;
            /** If RotatedBox is set, Box must be set as well. See RotatedBoundingBox. */
            RotatedBox?: GoodocRotatedBoundingBox;
            /** Word characters, the text may */
            Symbol?: GoodocSymbol[];
            /**
             * As a shortcut, the content API provides the text of words instead of individual symbols (NOTE: this is experimental). This is UTF8. And the main font for the word is stored in
             * Label.CharLabel.
             */
            text?: string;
            /** Writing direction for this word. */
            writingDirection?: string;
        }
        interface GoodocWordAlternates {
            alternate?: GoodocWordAlternatesAlternate[];
            /** The probability that the main OCR engine (Abbyy) string is incorrect; range is 0 (definitely correct) to 100 (definitely incorrect). */
            ErrorProbability?: number;
        }
        interface GoodocWordAlternatesAlternate {
            /** See Document.Header */
            OcrEngineId?: string;
            /** See Document.Header */
            OcrEngineVersion?: string;
            /** In order to compile, this recursive message needs to be optional, even though it's within an optional group. */
            Word?: GoodocWord;
        }
        interface GoogleAssistantAccessoryV1AudioOutConfig {
            /** Current audio mode on the device while issuing the query. */
            audioMode?: string;
            /** Current audio routing on the device while issuing the query. */
            audioRoutingMode?: string;
            /** *Required* The encoding of audio data to be returned in all `audio_out` messages. */
            encoding?: string;
            /**
             * *Optional* Specifies preferred encoding bitrate (bits-per-second). Currently this is only implemented for OGG_OPUS for bitrates of 12000, 16000, 24000, 32000. If not specified,
             * OGG_OPUS defaults to 32000.
             */
            preferredBitrateBps?: number;
        }
        interface GoogleAssistantAccessoryV1DeviceConfig {
            /** *Required* Identifier for the device which sent the request. */
            deviceBuild?: GoogleAssistantEmbeddedV1DeviceBuild;
            /** Device model capabilities from client to override capabilities in the primary device model. */
            deviceModelCapabilitiesOverride?: GoogleAssistantEmbeddedV1DeviceModelCapabilitiesOverride;
            /** *Optional* An encrypted heterodyne_experiment_token containing the list of experiment_ids (go/ph-server-tokens). */
            heterodyneToken?: string;
        }
        interface GoogleAssistantAccessoryV1DeviceState {
            /**
             * *Optional* Information about on-device alarms. For devices that support alarms, all on-device alarms must be sent up with the DeviceState in order for Assistant Server to be able to
             * perform operations on them.
             */
            alarmState?: GoogleAssistantEmbeddedV1Alarms;
            /** Other context params to be sent to Assistant. This is a assistant.embedded.v1.ContextParams message in serialized binary proto format. */
            contextParams?: string;
            /**
             * A timestamp of the current device time when the request was made. This field is required if your device supports alarms or timers. This ensures that requests are fulfilled relative
             * to the current device time and regardless of any clock skew between the client and the server.
             */
            deviceTime?: string;
            /**
             * The time zone where the device is currently located. This helps the Assistant answer time-related queries relative to the device's time zone. Generally speaking, mobile devices that
             * support alarms or timers should supply device_time_zone. This field is required if your device supports alarms or timers and the device's location cannot reliably be determined.
             * (See the comment above google.assistant.embedded.v1.DeviceLocation for a description of how the device's location is determined.) If the time zone cannot be determined, some queries
             * for creating or modifying timers or alarms may fail with a generic error such as, "Sorry, I don't know how to help with that."
             */
            deviceTimeZone?: GoogleTypeTimeZone;
            /** Indicate whether do not disturb mode is turned on. */
            doNotDisturb?: boolean;
            /**
             * Information about on-device fitness activities. For devices that support fitness activities, all on-device fitness activities must be sent up with the DeviceState in order for
             * Assistant Server to be able to perform operations on them.
             */
            fitnessActivitiesState?: GoogleAssistantEmbeddedV1FitnessActivities;
            /**
             * *Optional* Information about on-device timers. For devices that support timers, all on-device timers must be sent up with the DeviceState in order for Assistant Server to be able to
             * perform operations on them.
             */
            timerState?: GoogleAssistantEmbeddedV1Timers;
        }
        interface GoogleAssistantAccessoryV1ResponseConfig {
            /** Specifies the current audio mode on the device. */
            audioOutConfig?: GoogleAssistantAccessoryV1AudioOutConfig;
            /** Configuration related to a specific device. */
            deviceConfig?: GoogleAssistantAccessoryV1DeviceConfig;
            /** The client interaction to be sent to Assistant. This is a assistant.embedded.v1.DeviceInteraction message in serialized binary proto format. */
            deviceInteraction?: string;
            /** Device state to pass to the Assistant server to use in calculating the response. */
            deviceState?: GoogleAssistantAccessoryV1DeviceState;
            /** Specifies the initial bytes of TTS audio to send. */
            initialAudioBytes?: number;
            /**
             * If true, the server will treat the request as a new conversation and not use state from the prior request. Set this field to true when the conversation should be restarted, such as
             * after a device reboot, or after a significant lapse of time since the prior query.
             */
            isNewConversation?: boolean;
            /** Specifies the desired audio sample rate of the output TTS stream in Hz. */
            outputSampleRateHz?: number;
            /** Specifies the requested response type. */
            responseType?: string;
            /** Specifies the desired format to use when server returns a visual screen response. */
            screenOutConfig?: GoogleAssistantAccessoryV1ScreenOutConfig;
        }
        interface GoogleAssistantAccessoryV1ScreenOutConfig {
            /** Device dimensions. */
            dimensions?: GoogleAssistantAccessoryV1ScreenOutConfigDimensions;
        }
        interface GoogleAssistantAccessoryV1ScreenOutConfigDimensions {
            /** Dots (pixels) per inch of the screen. */
            screenDpi?: number;
            /**
             * Height of the device's screen in pixels. If 0 or not specified, it's assumed to be the same as screen_width_px. For a square or round screen, it's recommended to leave this field
             * empty as a bandwidth optimization.
             */
            screenHeightPx?: number;
            /** The shape of the device's screen */
            screenShape?: string;
            /** Width of the device's screen in pixels. */
            screenWidthPx?: number;
        }
        interface GoogleAssistantEmbeddedV1Alarm {
            /**
             * A string key used as an identifier to this alarm. This key needs to be unique amongst all alarms on the device. The client can choose a mechanism of its choice to ensure this. If
             * the server suggests an alarm_id, the client can either use the suggestion or create a new unique alarm_id of its choosing.
             */
            alarmId?: string;
            /** For single alarms: the one date the alarm should next be scheduled for. */
            datePattern?: GoogleTypeDate;
            /** A user-provided name for this alarm. */
            label?: string;
            /** For recurring alarms: a description of the dates when the alarm should recur. */
            recurrencePattern?: GoogleAssistantEmbeddedV1AlarmRecurrence;
            /**
             * When SCHEDULED or SNOOZED, the absolute time the alarm will fire next. When SNOOZED, this time includes the additional time added by snoozing the alarm. When FIRING, the absolute
             * time the alarm had been scheduled to fire. When DISABLED, this field is undefined and should be ignored.
             */
            scheduledTime?: string;
            /** Describes the part of the lifecycle that an alarm is in. */
            status?: string;
            /**
             * The time of day the alarm should be scheduled for. This value does not change when an alarm enters the SNOOZED state; instead the scheduled_time field should be adjusted to the new
             * alarm time.
             */
            timePattern?: GoogleTypeTimeOfDay;
        }
        interface GoogleAssistantEmbeddedV1AlarmRecurrence {
            /** Specifies a weekly or daily recurrence. Constraint: The date falls on one of these days of the week, in 0...6 (Sunday...Saturday). Should not be empty. */
            dayOfWeek?: string[];
        }
        interface GoogleAssistantEmbeddedV1Alarms {
            /** Information about all on-device alarms. */
            alarms?: GoogleAssistantEmbeddedV1Alarm[];
            /**
             * The amount of time for which alarms should be snoozed. If not specified, the productivity vertical applies a default snooze duration, which may be seen here:
             * http://google3/assistant/verticals/productivity/utils/alarm_utils.cc;l=2734;rcl=415933085
             */
            snoozeDuration?: string;
            /** Indicates if an error occurred while fetching alarm state. If this value is missing, it can be assumed that the state fetch was successful. */
            stateFetchError?: string;
        }
        interface GoogleAssistantEmbeddedV1DeviceBuild {
            /** * Fully formed user agent suffix string. */
            userAgentSuffix?: string;
        }
        interface GoogleAssistantEmbeddedV1DeviceModelCapabilitiesOverride {
            /** Device model capabilities from client. */
            deviceModelCapabilities?: string;
            /**
             * If present, overrides only fields specified in the mask. When doing so, selected message and repeated fields will be replaced rather than merged. Performs a regular proto MergeFrom
             * if no mask is specified.
             */
            updateMask?: string;
        }
        interface GoogleAssistantEmbeddedV1FitnessActivities {
            /** Information about all on-device activities. */
            fitnessActivities?: GoogleAssistantEmbeddedV1FitnessActivity[];
        }
        interface GoogleAssistantEmbeddedV1FitnessActivity {
            /**
             * Required A string key used as an identifier for this activity. This key needs to be unique amongst all activities on the device. The client can choose a mechanism of its choice to
             * ensure this. If the server suggests an activity_id, the client can either use the suggestion or create a new unique activity_id of its choosing.
             */
            activityId?: string;
            /** DEPRECATED: The most recent time this activity was switched to the ACTIVE state. */
            mostRecentStartTime?: string;
            /**
             * DEPRECATED: The total amount of time this activity has spent in the ACTIVE state until the most recent start time. The total time spent active may be computed by summing (now -
             * most_recent_start_time) with previously_accumulated_duration.
             */
            previouslyAccumulatedDuration?: string;
            /** The current state of this activity. */
            state?: string;
            /** The type of activity being done. */
            type?: string;
        }
        interface GoogleAssistantEmbeddedV1Timer {
            /** The time the timer is scheduled to expire. google.protobuf.Timestamp is a Unix epoch time with a granularity of 1 nanosecond. */
            expireTime?: string;
            /** A user-provided name for this timer. */
            label?: string;
            /** The duration of the timer when it was started. For the ADD_TIME action, this field contains the amount of time to add to the timer with the given timer_id. */
            originalDuration?: string;
            /** The remaining duration for the timer. */
            remainingDuration?: string;
            /** Describes the part of the lifecycle a timer is in. */
            status?: string;
            /**
             * A string key used as an identifier to this timer. This key needs to be unique amongst all timers on the device. The client can choose a mechanism of its choice to ensure this. If
             * the server suggests a timer_id, the client can either use the suggestion or create a new unique timer_id of its choosing.
             */
            timerId?: string;
        }
        interface GoogleAssistantEmbeddedV1Timers {
            /** Indicates if an error occurred while fetching timer state. If this value is missing, it can be assumed that the state fetch was successful. */
            stateFetchError?: string;
            /** Information about all on-device timers. */
            timers?: GoogleAssistantEmbeddedV1Timer[];
        }
        interface GoogleCloudContentwarehouseV1AccessControlAction {
            /** Identifies the type of operation. */
            operationType?: string;
            /** Represents the new policy from which bindings are added, removed or replaced based on the type of the operation. the policy is limited to a few 10s of KB. */
            policy?: GoogleIamV1Policy;
        }
        interface GoogleCloudContentwarehouseV1Action {
            /** Action triggering access control operations. */
            accessControl?: GoogleCloudContentwarehouseV1AccessControlAction;
            /** ID of the action. Managed internally. */
            actionId?: string;
            /** Action triggering create document link operation. */
            addToFolder?: GoogleCloudContentwarehouseV1AddToFolderAction;
            /** Action triggering data update operations. */
            dataUpdate?: GoogleCloudContentwarehouseV1DataUpdateAction;
            /** Action triggering data validation operations. */
            dataValidation?: GoogleCloudContentwarehouseV1DataValidationAction;
            /** Action deleting the document. */
            deleteDocumentAction?: GoogleCloudContentwarehouseV1DeleteDocumentAction;
            /** Action publish to Pub/Sub operation. */
            publishToPubSub?: GoogleCloudContentwarehouseV1PublishAction;
            /** Action removing a document from a folder. */
            removeFromFolderAction?: GoogleCloudContentwarehouseV1RemoveFromFolderAction;
        }
        interface GoogleCloudContentwarehouseV1ActionExecutorOutput {
            /** List of rule and corresponding actions result. */
            ruleActionsPairs?: GoogleCloudContentwarehouseV1RuleActionsPair[];
        }
        interface GoogleCloudContentwarehouseV1ActionOutput {
            /** ID of the action. */
            actionId?: string;
            /** State of an action. */
            actionState?: string;
            /** Action execution output message. */
            outputMessage?: string;
        }
        interface GoogleCloudContentwarehouseV1AddToFolderAction {
            /** Names of the folder under which new document is to be added. Format: projects/{project_number}/locations/{location}/documents/{document_id}. */
            folders?: string[];
        }
        // tslint:disable-next-line:no-empty-interface
        interface GoogleCloudContentwarehouseV1beta1CreateDocumentMetadata {
        }
        interface GoogleCloudContentwarehouseV1beta1InitializeProjectResponse {
            /** The message of the project initialization process. */
            message?: string;
            /** The state of the project initialization process. */
            state?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface GoogleCloudContentwarehouseV1beta1UpdateDocumentMetadata {
        }
        interface GoogleCloudContentwarehouseV1CloudAIDocumentOption {
            /** If set, only selected entities will be converted to properties. */
            customizedEntitiesPropertiesConversions?: { [P in string]: string };
            /** Whether to convert all the entities to properties. */
            enableEntitiesConversions?: boolean;
        }
        interface GoogleCloudContentwarehouseV1CreateDocumentLinkRequest {
            /** Required. Document links associated with the source documents (source_document_id). */
            documentLink?: GoogleCloudContentwarehouseV1DocumentLink;
            /** The meta information collected about the document creator, used to enforce access control for the service. */
            requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
        }
        // tslint:disable-next-line:no-empty-interface
        interface GoogleCloudContentwarehouseV1CreateDocumentMetadata {
        }
        interface GoogleCloudContentwarehouseV1CreateDocumentRequest {
            /**
             * Request Option for processing Cloud AI Document in Document Warehouse. This field offers limited support for mapping entities from Cloud AI Document to Warehouse Document. Please
             * consult with product team before using this field and other available options.
             */
            cloudAiDocumentOption?: GoogleCloudContentwarehouseV1CloudAIDocumentOption;
            /**
             * Field mask for creating Document fields. If mask path is empty, it means all fields are masked. For the `FieldMask` definition, see
             * https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#fieldmask.
             */
            createMask?: string;
            /** Required. The document to create. */
            document?: GoogleCloudContentwarehouseV1Document;
            /**
             * Default document policy during creation. This refers to an Identity and Access (IAM) policy, which specifies access controls for the Document. Conditions defined in the policy will
             * be ignored.
             */
            policy?: GoogleIamV1Policy;
            /** The meta information collected about the end user, used to enforce access control for the service. */
            requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
        }
        interface GoogleCloudContentwarehouseV1CreateDocumentResponse {
            /** Document created after executing create request. */
            document?: GoogleCloudContentwarehouseV1Document;
            /** Additional information for the API invocation, such as the request tracking id. */
            metadata?: GoogleCloudContentwarehouseV1ResponseMetadata;
            /** Output from Rule Engine recording the rule evaluator and action executor's output. Refer format in: google/cloud/contentwarehouse/v1/rule_engine.proto */
            ruleEngineOutput?: GoogleCloudContentwarehouseV1RuleEngineOutput;
        }
        interface GoogleCloudContentwarehouseV1DataUpdateAction {
            /**
             * Map of (K, V) -> (valid name of the field, new value of the field) E.g., ("age", "60") entry triggers update of field age with a value of 60. If the field is not present then new
             * entry is added. During update action execution, value strings will be casted to appropriate types.
             */
            entries?: { [P in string]: string };
        }
        interface GoogleCloudContentwarehouseV1DataValidationAction {
            /**
             * Map of (K, V) -> (field, string condition to be evaluated on the field) E.g., ("age", "age > 18 && age < 60") entry triggers validation of field age with the given condition. Map
             * entries will be ANDed during validation.
             */
            conditions?: { [P in string]: string };
        }
        interface GoogleCloudContentwarehouseV1DateTimeArray {
            /** List of datetime values. Both OffsetDateTime and ZonedDateTime are supported. */
            values?: GoogleTypeDateTime[];
        }
        // tslint:disable-next-line:no-empty-interface
        interface GoogleCloudContentwarehouseV1DateTimeTypeOptions {
        }
        interface GoogleCloudContentwarehouseV1DeleteDocumentAction {
            /** Boolean field to select between hard vs soft delete options. Set 'true' for 'hard delete' and 'false' for 'soft delete'. */
            enableHardDelete?: boolean;
        }
        interface GoogleCloudContentwarehouseV1DeleteDocumentLinkRequest {
            /** The meta information collected about the document creator, used to enforce access control for the service. */
            requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
        }
        interface GoogleCloudContentwarehouseV1DeleteDocumentRequest {
            /** The meta information collected about the end user, used to enforce access control for the service. */
            requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
        }
        interface GoogleCloudContentwarehouseV1Document {
            /** Document AI format to save the structured content, including OCR. */
            cloudAiDocument?: GoogleCloudDocumentaiV1Document;
            /** Indicates the category (image, audio, video etc.) of the original content. */
            contentCategory?: string;
            /** Output only. The time when the document is created. */
            createTime?: string;
            /** The user who creates the document. */
            creator?: string;
            /**
             * Required. Display name of the document given by the user. This name will be displayed in the UI. Customer can populate this field with the name of the document. This differs from
             * the 'title' field as 'title' is optional and stores the top heading in the document.
             */
            displayName?: string;
            /** Uri to display the document, for example, in the UI. */
            displayUri?: string;
            /** The Document schema name. Format: projects/{project_number}/locations/{location}/documentSchemas/{document_schema_id}. */
            documentSchemaName?: string;
            /** Raw document content. */
            inlineRawDocument?: string;
            /** The resource name of the document. Format: projects/{project_number}/locations/{location}/documents/{document_id}. The name is ignored when creating a document. */
            name?: string;
            /** Other document format, such as PPTX, XLXS */
            plainText?: string;
            /** List of values that are user supplied metadata. */
            properties?: GoogleCloudContentwarehouseV1Property[];
            /**
             * This is used when DocAI was not used to load the document and parsing/ extracting is needed for the inline_raw_document. For example, if inline_raw_document is the byte
             * representation of a PDF file, then this should be set to: RAW_DOCUMENT_FILE_TYPE_PDF.
             */
            rawDocumentFileType?: string;
            /** Raw document file in Cloud Storage path. */
            rawDocumentPath?: string;
            /** The reference ID set by customers. Must be unique per project and location. */
            referenceId?: string;
            /** If true, text extraction will not be performed. */
            textExtractionDisabled?: boolean;
            /** If true, text extraction will be performed. */
            textExtractionEnabled?: boolean;
            /** Title that describes the document. This can be the top heading or text that describes the document. */
            title?: string;
            /** The user who lastly updates the document. */
            updater?: string;
            /** Output only. The time when the document is last updated. */
            updateTime?: string;
        }
        interface GoogleCloudContentwarehouseV1DocumentLink {
            /** Output only. The time when the documentLink is created. */
            createTime?: string;
            /** Description of this document-link. */
            description?: string;
            /**
             * Name of this document-link. It is required that the parent derived form the name to be consistent with the source document reference. Otherwise an exception will be thrown. Format:
             * projects/{project_number}/locations/{location}/documents/{source_document_id}/documentLinks/{document_link_id}.
             */
            name?: string;
            /** Document references of the source document. */
            sourceDocumentReference?: GoogleCloudContentwarehouseV1DocumentReference;
            /** The state of the documentlink. If target node has been deleted, the link is marked as invalid. Removing a source node will result in removal of all associated links. */
            state?: string;
            /** Document references of the target document. */
            targetDocumentReference?: GoogleCloudContentwarehouseV1DocumentReference;
            /** Output only. The time when the documentLink is last updated. */
            updateTime?: string;
        }
        interface GoogleCloudContentwarehouseV1DocumentQuery {
            /**
             * This filter specifies a structured syntax to match against the [PropertyDefinition].is_filterable marked as `true`. The syntax for this expression is a subset of SQL syntax.
             * Supported operators are: `=`, `!=`, `<`, `<=`, `>`, and `>=` where the left of the operator is a property name and the right of the operator is a number or a quoted string. You must
             * escape backslash (\\) and quote (\") characters. Supported functions are `LOWER([property_name])` to perform a case insensitive match and `EMPTY([property_name])` to filter on the
             * existence of a key. Boolean expressions (AND/OR/NOT) are supported up to 3 levels of nesting (for example, "((A AND B AND C) OR NOT D) AND E"), a maximum of 100 comparisons or
             * functions are allowed in the expression. The expression must be < 6000 bytes in length. Sample Query: `(LOWER(driving_license)="class \"a\"" OR EMPTY(driving_license)) AND
             * driving_years > 10`
             */
            customPropertyFilter?: string;
            /**
             * The exact creator(s) of the documents to search against. If a value isn't specified, documents within the search results are associated with any creator. If multiple values are
             * specified, documents within the search results may be associated with any of the specified creators.
             */
            documentCreatorFilter?: string[];
            /**
             * This filter specifies the exact document schema Document.document_schema_name of the documents to search against. If a value isn't specified, documents within the search results are
             * associated with any schema. If multiple values are specified, documents within the search results may be associated with any of the specified schemas. At most 20 document schema
             * names are allowed.
             */
            documentSchemaNames?: string[];
            /**
             * This filter specifies the types of files to return: ALL, FOLDER, or FILE. If FOLDER or FILE is specified, then only either folders or files will be returned, respectively. If ALL is
             * specified, both folders and files will be returned. If no value is specified, ALL files will be returned.
             */
            fileTypeFilter?: GoogleCloudContentwarehouseV1FileTypeFilter;
            /** Search all the documents under this specified folder. Format: projects/{project_number}/locations/{location}/documents/{document_id}. */
            folderNameFilter?: string;
            /**
             * Experimental, do not use. If the query is a natural language question. False by default. If true, then the question-answering feature will be used instead of search, and
             * `result_count` in SearchDocumentsRequest must be set. In addition, all other input fields related to search (pagination, histograms, etc.) will be ignored.
             */
            isNlQuery?: boolean;
            /** This filter specifies a structured syntax to match against the PropertyDefinition.is_filterable marked as `true`. The relationship between the PropertyFilters is OR. */
            propertyFilter?: GoogleCloudContentwarehouseV1PropertyFilter[];
            /**
             * The query string that matches against the full text of the document and the searchable properties. The query partially supports [Google AIP style
             * syntax](https://google.aip.dev/160). Specifically, the query supports literals, logical operators, negation operators, comparison operators, and functions. Literals: A bare literal
             * value (examples: "42", "Hugo") is a value to be matched against. It searches over the full text of the document and the searchable properties. Logical operators: "AND", "and", "OR",
             * and "or" are binary logical operators (example: "engineer OR developer"). Negation operators: "NOT" and "!" are negation operators (example: "NOT software"). Comparison operators:
             * support the binary comparison operators =, !=, <, >, <= and >= for string, numeric, enum, boolean. Also support like operator `~~` for string. It provides semantic search
             * functionality by parsing, stemming and doing synonyms expansion against the input query. To specify a property in the query, the left hand side expression in the comparison must be
             * the property ID including the parent. The right hand side must be literals. For example: "\"projects/123/locations/us\".property_a < 1" matches results whose "property_a" is less
             * than 1 in project 123 and us location. The literals and comparison expression can be connected in a single query (example: "software engineer \"projects/123/locations/us\".salary >
             * 100"). Functions: supported functions are `LOWER([property_name])` to perform a case insensitive match and `EMPTY([property_name])` to filter on the existence of a key. Support
             * nested expressions connected using parenthesis and logical operators. The default logical operators is `AND` if there is no operators between expressions. The query can be used with
             * other filters e.g. `time_filters` and `folder_name_filter`. They are connected with `AND` operator under the hood. The maximum number of allowed characters is 255.
             */
            query?: string;
            /**
             * For custom synonyms. Customers provide the synonyms based on context. One customer can provide multiple set of synonyms based on different context. The search query will be expanded
             * based on the custom synonyms of the query context set. By default, no custom synonyms wll be applied if no query context is provided. It is not supported for CMEK compliant
             * deployment.
             */
            queryContext?: string[];
            /** Documents created/updated within a range specified by this filter are searched against. */
            timeFilters?: GoogleCloudContentwarehouseV1TimeFilter[];
        }
        interface GoogleCloudContentwarehouseV1DocumentReference {
            /** Output only. The time when the document is created. */
            createTime?: string;
            /** Output only. The time when the document is deleted. */
            deleteTime?: string;
            /** display_name of the referenced document; this name does not need to be consistent to the display_name in the Document proto, depending on the ACL constraint. */
            displayName?: string;
            /** The document type of the document being referenced. */
            documentIsFolder?: boolean;
            /** Required. Name of the referenced document. */
            documentName?: string;
            /** Stores the subset of the referenced document's content. This is useful to allow user peek the information of the referenced document. */
            snippet?: string;
            /** Output only. The time when the document is last updated. */
            updateTime?: string;
        }
        interface GoogleCloudContentwarehouseV1DocumentSchema {
            /** Output only. The time when the document schema is created. */
            createTime?: string;
            /** Schema description. */
            description?: string;
            /** Required. Name of the schema given by the user. Must be unique per project. */
            displayName?: string;
            /** Document Type, true refers the document is a folder, otherwise it is a typical document. */
            documentIsFolder?: boolean;
            /**
             * The resource name of the document schema. Format: projects/{project_number}/locations/{location}/documentSchemas/{document_schema_id}. The name is ignored when creating a document
             * schema.
             */
            name?: string;
            /** Document details. */
            propertyDefinitions?: GoogleCloudContentwarehouseV1PropertyDefinition[];
            /** Output only. The time when the document schema is last updated. */
            updateTime?: string;
        }
        interface GoogleCloudContentwarehouseV1EnumArray {
            /** List of enum values. */
            values?: string[];
        }
        interface GoogleCloudContentwarehouseV1EnumTypeOptions {
            /** Required. List of possible enum values. */
            possibleValues?: string[];
            /** Make sure the Enum property value provided in the document is in the possile value list during document creation. The validation check runs by default. */
            validationCheckDisabled?: boolean;
        }
        interface GoogleCloudContentwarehouseV1EnumValue {
            /** String value of the enum field. This must match defined set of enums in document schema using EnumTypeOptions. */
            value?: string;
        }
        interface GoogleCloudContentwarehouseV1FetchAclRequest {
            /** For Get Project ACL only. Authorization check for end user will be ignored when project_owner=true. */
            projectOwner?: boolean;
            /** The meta information collected about the end user, used to enforce access control for the service. */
            requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
        }
        interface GoogleCloudContentwarehouseV1FetchAclResponse {
            /** Additional information for the API invocation, such as the request tracking id. */
            metadata?: GoogleCloudContentwarehouseV1ResponseMetadata;
            /** The IAM policy. */
            policy?: GoogleIamV1Policy;
        }
        interface GoogleCloudContentwarehouseV1FileTypeFilter {
            /** The type of files to return. */
            fileType?: string;
        }
        interface GoogleCloudContentwarehouseV1FloatArray {
            /** List of float values. */
            values?: number[];
        }
        // tslint:disable-next-line:no-empty-interface
        interface GoogleCloudContentwarehouseV1FloatTypeOptions {
        }
        interface GoogleCloudContentwarehouseV1GetDocumentRequest {
            /** The meta information collected about the end user, used to enforce access control for the service. */
            requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
        }
        interface GoogleCloudContentwarehouseV1HistogramQuery {
            /**
             * Optional. Filter the result of histogram query by the property names. It only works with histogram query count('FilterableProperties'). It is an optional. It will perform histogram
             * on all the property names for all the document schemas. Setting this field will have a better performance.
             */
            filters?: GoogleCloudContentwarehouseV1HistogramQueryPropertyNameFilter;
            /** An expression specifies a histogram request against matching documents for searches. See SearchDocumentsRequest.histogram_queries for details about syntax. */
            histogramQuery?: string;
            /** Controls if the histogram query requires the return of a precise count. Enable this flag may adversely impact performance. Defaults to true. */
            requirePreciseResultSize?: boolean;
        }
        interface GoogleCloudContentwarehouseV1HistogramQueryPropertyNameFilter {
            /**
             * This filter specifies the exact document schema(s) Document.document_schema_name to run histogram query against. It is optional. It will perform histogram for property names for all
             * the document schemas if it is not set. At most 10 document schema names are allowed. Format: projects/{project_number}/locations/{location}/documentSchemas/{document_schema_id}.
             */
            documentSchemas?: string[];
            /**
             * It is optional. It will perform histogram for all the property names if it is not set. The properties need to be defined with the is_filterable flag set to true and the name of the
             * property should be in the format: "schemaId.propertyName". The property needs to be defined in the schema. Example: the schema id is abc. Then the name of property for property
             * MORTGAGE_TYPE will be "abc.MORTGAGE_TYPE".
             */
            propertyNames?: string[];
            /** By default, the y_axis is HISTOGRAM_YAXIS_DOCUMENT if this field is not set. */
            yAxis?: string;
        }
        interface GoogleCloudContentwarehouseV1HistogramQueryResult {
            /**
             * A map from the values of the facet associated with distinct values to the number of matching entries with corresponding value. The key format is: * (for string histogram) string
             * values stored in the field.
             */
            histogram?: { [P in string]: string };
            /** Requested histogram expression. */
            histogramQuery?: string;
        }
        interface GoogleCloudContentwarehouseV1InitializeProjectRequest {
            /** Required. The access control mode for accessing the customer data */
            accessControlMode?: string;
            /** Required. The type of database used to store customer data */
            databaseType?: string;
            /**
             * Optional. The KMS key used for CMEK encryption. It is required that the kms key is in the same region as the endpoint. The same key will be used for all provisioned resources, if
             * encryption is available. If the kms_key is left empty, no encryption will be enforced.
             */
            kmsKey?: string;
        }
        interface GoogleCloudContentwarehouseV1InitializeProjectResponse {
            /** The message of the project initialization process. */
            message?: string;
            /** The state of the project initialization process. */
            state?: string;
        }
        interface GoogleCloudContentwarehouseV1IntegerArray {
            /** List of integer values. */
            values?: number[];
        }
        // tslint:disable-next-line:no-empty-interface
        interface GoogleCloudContentwarehouseV1IntegerTypeOptions {
        }
        interface GoogleCloudContentwarehouseV1InvalidRule {
            /** Validation error on a parsed expression. */
            error?: string;
            /** Triggered rule. */
            rule?: GoogleCloudContentwarehouseV1Rule;
        }
        interface GoogleCloudContentwarehouseV1ListDocumentSchemasResponse {
            /** The document schemas from the specified parent. */
            documentSchemas?: GoogleCloudContentwarehouseV1DocumentSchema[];
            /** A token, which can be sent as `page_token` to retrieve the next page. If this field is omitted, there are no subsequent pages. */
            nextPageToken?: string;
        }
        interface GoogleCloudContentwarehouseV1ListLinkedSourcesRequest {
            /**
             * The maximum number of document-links to return. The service may return fewer than this value. If unspecified, at most 50 document-links will be returned. The maximum value is 1000;
             * values above 1000 will be coerced to 1000.
             */
            pageSize?: number;
            /**
             * A page token, received from a previous `ListLinkedSources` call. Provide this to retrieve the subsequent page. When paginating, all other parameters provided to `ListLinkedSources`
             * must match the call that provided the page token.
             */
            pageToken?: string;
            /** The meta information collected about the document creator, used to enforce access control for the service. */
            requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
        }
        interface GoogleCloudContentwarehouseV1ListLinkedSourcesResponse {
            /** Source document-links. */
            documentLinks?: GoogleCloudContentwarehouseV1DocumentLink[];
            /** A token, which can be sent as `page_token` to retrieve the next page. If this field is omitted, there are no subsequent pages. */
            nextPageToken?: string;
        }
        interface GoogleCloudContentwarehouseV1ListLinkedTargetsRequest {
            /** The meta information collected about the document creator, used to enforce access control for the service. */
            requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
        }
        interface GoogleCloudContentwarehouseV1ListLinkedTargetsResponse {
            /** Target document-links. */
            documentLinks?: GoogleCloudContentwarehouseV1DocumentLink[];
            /** A token, which can be sent as `page_token` to retrieve the next page. If this field is omitted, there are no subsequent pages. */
            nextPageToken?: string;
        }
        interface GoogleCloudContentwarehouseV1ListRuleSetsResponse {
            /** A token, which can be sent as `page_token` to retrieve the next page. If this field is omitted, there are no subsequent pages. */
            nextPageToken?: string;
            /** The rule sets from the specified parent. */
            ruleSets?: GoogleCloudContentwarehouseV1RuleSet[];
        }
        interface GoogleCloudContentwarehouseV1ListSynonymSetsResponse {
            /** A page token, received from a previous `ListSynonymSets` call. Provide this to retrieve the subsequent page. */
            nextPageToken?: string;
            /** The synonymSets from the specified parent. */
            synonymSets?: GoogleCloudContentwarehouseV1SynonymSet[];
        }
        interface GoogleCloudContentwarehouseV1MapProperty {
            /** Unordered map of dynamically typed values. */
            fields?: { [P in string]: GoogleCloudContentwarehouseV1Value };
        }
        // tslint:disable-next-line:no-empty-interface
        interface GoogleCloudContentwarehouseV1MapTypeOptions {
        }
        interface GoogleCloudContentwarehouseV1MergeFieldsOptions {
            /**
             * When merging message fields, the default behavior is to merge the content of two message fields together. If you instead want to use the field from the source message to replace the
             * corresponding field in the destination message, set this flag to true. When this flag is set, specified submessage fields that are missing in source will be cleared in destination.
             */
            replaceMessageFields?: boolean;
            /**
             * When merging repeated fields, the default behavior is to append entries from the source repeated field to the destination repeated field. If you instead want to keep only the
             * entries from the source repeated field, set this flag to true. If you want to replace a repeated field within a message field on the destination message, you must set both
             * replace_repeated_fields and replace_message_fields to true, otherwise the repeated fields will be appended.
             */
            replaceRepeatedFields?: boolean;
        }
        interface GoogleCloudContentwarehouseV1Property {
            /** Date time property values. It is not supported by CMEK compliant deployment. */
            dateTimeValues?: GoogleCloudContentwarehouseV1DateTimeArray;
            /** Enum property values. */
            enumValues?: GoogleCloudContentwarehouseV1EnumArray;
            /** Float property values. */
            floatValues?: GoogleCloudContentwarehouseV1FloatArray;
            /** Integer property values. */
            integerValues?: GoogleCloudContentwarehouseV1IntegerArray;
            /** Map property values. */
            mapProperty?: GoogleCloudContentwarehouseV1MapProperty;
            /** Required. Must match the name of a PropertyDefinition in the DocumentSchema. */
            name?: string;
            /** Nested structured data property values. */
            propertyValues?: GoogleCloudContentwarehouseV1PropertyArray;
            /** String/text property values. */
            textValues?: GoogleCloudContentwarehouseV1TextArray;
            /** Timestamp property values. It is not supported by CMEK compliant deployment. */
            timestampValues?: GoogleCloudContentwarehouseV1TimestampArray;
        }
        interface GoogleCloudContentwarehouseV1PropertyArray {
            /** List of property values. */
            properties?: GoogleCloudContentwarehouseV1Property[];
        }
        interface GoogleCloudContentwarehouseV1PropertyDefinition {
            /** Date time property. It is not supported by CMEK compliant deployment. */
            dateTimeTypeOptions?: any;
            /** The display-name for the property, used for front-end. */
            displayName?: string;
            /** Enum/categorical property. */
            enumTypeOptions?: GoogleCloudContentwarehouseV1EnumTypeOptions;
            /** Float property. */
            floatTypeOptions?: any;
            /** Integer property. */
            integerTypeOptions?: any;
            /** Whether the property can be filtered. If this is a sub-property, all the parent properties must be marked filterable. */
            isFilterable?: boolean;
            /**
             * Whether the property is user supplied metadata. This out-of-the box placeholder setting can be used to tag derived properties. Its value and interpretation logic should be
             * implemented by API user.
             */
            isMetadata?: boolean;
            /** Whether the property can have multiple values. */
            isRepeatable?: boolean;
            /** Whether the property is mandatory. Default is 'false', i.e. populating property value can be skipped. If 'true' then user must populate the value for this property. */
            isRequired?: boolean;
            /** Indicates that the property should be included in a global search. */
            isSearchable?: boolean;
            /** Map property. */
            mapTypeOptions?: any;
            /**
             * Required. The name of the metadata property. Must be unique within a document schema and is case insensitive. Names must be non-blank, start with a letter, and can contain
             * alphanumeric characters and: /, :, -, _, and .
             */
            name?: string;
            /** Nested structured data property. */
            propertyTypeOptions?: GoogleCloudContentwarehouseV1PropertyTypeOptions;
            /** Text/string property. */
            textTypeOptions?: any;
            /** Timestamp property. It is not supported by CMEK compliant deployment. */
            timestampTypeOptions?: any;
        }
        interface GoogleCloudContentwarehouseV1PropertyFilter {
            /**
             * The filter condition. The syntax for this expression is a subset of SQL syntax. Supported operators are: `=`, `!=`, `<`, `<=`, `>`, `>=`, and `~~` where the left of the operator is
             * a property name and the right of the operator is a number or a quoted string. You must escape backslash (\\) and quote (\") characters. `~~` is the LIKE operator. The right of the
             * operator must be a string. The only supported property data type for LIKE is text_values. It provides semantic search functionality by parsing, stemming and doing synonyms expansion
             * against the input query. It matches if the property contains semantic similar content to the query. It is not regex matching or wildcard matching. For example, "property.company ~~
             * \"google\"" will match records whose property `property.compnay` have values like "Google Inc.", "Google LLC" or "Google Company". Supported functions are `LOWER([property_name])`
             * to perform a case insensitive match and `EMPTY([property_name])` to filter on the existence of a key. Boolean expressions (AND/OR/NOT) are supported up to 3 levels of nesting (for
             * example, "((A AND B AND C) OR NOT D) AND E"), a maximum of 100 comparisons or functions are allowed in the expression. The expression must be < 6000 bytes in length. Only properties
             * that are marked filterable are allowed (PropertyDefinition.is_filterable). Property names do not need to be prefixed by the document schema id (as is the case with histograms),
             * however property names will need to be prefixed by its parent hierarchy, if any. For example: top_property_name.sub_property_name. Sample Query: `(LOWER(driving_license)="class
             * \"a\"" OR EMPTY(driving_license)) AND driving_years > 10` CMEK compliant deployment only supports: * Operators: `=`, `<`, `<=`, `>`, and `>=`. * Boolean expressions: AND and OR.
             */
            condition?: string;
            /** The Document schema name Document.document_schema_name. Format: projects/{project_number}/locations/{location}/documentSchemas/{document_schema_id}. */
            documentSchemaName?: string;
        }
        interface GoogleCloudContentwarehouseV1PropertyTypeOptions {
            /** Required. List of property definitions. */
            propertyDefinitions?: GoogleCloudContentwarehouseV1PropertyDefinition[];
        }
        interface GoogleCloudContentwarehouseV1PublishAction {
            /** Messages to be published. */
            messages?: string[];
            /** The topic id in the Pub/Sub service for which messages will be published to. */
            topicId?: string;
        }
        interface GoogleCloudContentwarehouseV1QAResult {
            /**
             * The calibrated confidence score for this document, in the range [0., 1.]. This represents the confidence level for whether the returned document and snippet answers the user's
             * query.
             */
            confidenceScore?: number;
            /** Highlighted sections in the snippet. */
            highlights?: GoogleCloudContentwarehouseV1QAResultHighlight[];
        }
        interface GoogleCloudContentwarehouseV1QAResultHighlight {
            /** End index of the highlight, exclusive. */
            endIndex?: number;
            /** Start index of the highlight. */
            startIndex?: number;
        }
        interface GoogleCloudContentwarehouseV1RemoveFromFolderAction {
            /** Condition of the action to be executed. */
            condition?: string;
            /** Name of the folder under which new document is to be added. Format: projects/{project_number}/locations/{location}/documents/{document_id}. */
            folder?: string;
        }
        interface GoogleCloudContentwarehouseV1RequestMetadata {
            /** Provides user unique identification and groups information. */
            userInfo?: GoogleCloudContentwarehouseV1UserInfo;
        }
        interface GoogleCloudContentwarehouseV1ResponseMetadata {
            /** A unique id associated with this call. This id is logged for tracking purpose. */
            requestId?: string;
        }
        interface GoogleCloudContentwarehouseV1Rule {
            /** List of actions that are executed when the rule is satisfied. */
            actions?: GoogleCloudContentwarehouseV1Action[];
            /**
             * Represents the conditional expression to be evaluated. Expression should evaluate to a boolean result. When the condition is true actions are executed. Example: user_role =
             * "hsbc_role_1" AND doc.salary > 20000
             */
            condition?: string;
            /** Short description of the rule and its context. */
            description?: string;
            /** ID of the rule. It has to be unique across all the examples. This is managed internally. */
            ruleId?: string;
            /** Identifies the trigger type for running the policy. */
            triggerType?: string;
        }
        interface GoogleCloudContentwarehouseV1RuleActionsPair {
            /** Outputs of executing the actions associated with the above rule. */
            actionOutputs?: GoogleCloudContentwarehouseV1ActionOutput[];
            /** Represents the rule. */
            rule?: GoogleCloudContentwarehouseV1Rule;
        }
        interface GoogleCloudContentwarehouseV1RuleEngineOutput {
            /** Output from Action Executor containing rule and corresponding actions execution result. */
            actionExecutorOutput?: GoogleCloudContentwarehouseV1ActionExecutorOutput;
            /** Name of the document against which the rules and actions were evaluated. */
            documentName?: string;
            /** Output from Rule Evaluator containing matched, unmatched and invalid rules. */
            ruleEvaluatorOutput?: GoogleCloudContentwarehouseV1RuleEvaluatorOutput;
        }
        interface GoogleCloudContentwarehouseV1RuleEvaluatorOutput {
            /** A subset of triggered rules that failed the validation check(s) after parsing. */
            invalidRules?: GoogleCloudContentwarehouseV1InvalidRule[];
            /** A subset of triggered rules that are evaluated true for a given request. */
            matchedRules?: GoogleCloudContentwarehouseV1Rule[];
            /** List of rules fetched from database for the given request trigger type. */
            triggeredRules?: GoogleCloudContentwarehouseV1Rule[];
        }
        interface GoogleCloudContentwarehouseV1RuleSet {
            /** Short description of the rule-set. */
            description?: string;
            /** The resource name of the rule set. Managed internally. Format: projects/{project_number}/locations/{location}/ruleSet/{rule_set_id}. The name is ignored when creating a rule set. */
            name?: string;
            /** List of rules given by the customer. */
            rules?: GoogleCloudContentwarehouseV1Rule[];
            /** Source of the rules i.e., customer name. */
            source?: string;
        }
        interface GoogleCloudContentwarehouseV1SearchDocumentsRequest {
            /** Query used to search against documents (keyword, filters, etc.). */
            documentQuery?: GoogleCloudContentwarehouseV1DocumentQuery;
            /**
             * An expression specifying a histogram request against matching documents. Expression syntax is an aggregation function call with histogram facets and other options. The following
             * aggregation functions are supported: * `count(string_histogram_facet)`: Count the number of matching entities for each distinct attribute value. Data types: * Histogram facet (aka
             * filterable properties): Facet names with format <schema id>.<facet>. Facets will have the format of: `a-zA-Z`. If the facet is a child facet, then the parent hierarchy needs to be
             * specified separated by dots in the prefix after the schema id. Thus, the format for a multi- level facet is: <schema id>.<parent facet name>. <child facet name>. Example:
             * schema123.root_parent_facet.middle_facet.child_facet * DocumentSchemaId: (with no schema id prefix) to get histograms for each document type (returns the schema id path, e.g.
             * projects/12345/locations/us-west/documentSchemas/abc123). Example expression: * Document type counts: count('DocumentSchemaId') * For schema id, abc123, get the counts for
             * MORTGAGE_TYPE: count('abc123.MORTGAGE_TYPE')
             */
            histogramQueries?: GoogleCloudContentwarehouseV1HistogramQuery[];
            /**
             * An integer that specifies the current offset (that is, starting result location, amongst the documents deemed by the API as relevant) in search results. This field is only
             * considered if page_token is unset. The maximum allowed value is 5000. Otherwise an error is thrown. For example, 0 means to return results starting from the first matching document,
             * and 10 means to return from the 11th document. This can be used for pagination, (for example, pageSize = 10 and offset = 10 means to return from the second page).
             */
            offset?: number;
            /**
             * The criteria determining how search results are sorted. For non-empty query, default is `"relevance desc"`. For empty query, default is `"upload_date desc"`. Supported options are:
             * * `"relevance desc"`: By relevance descending, as determined by the API algorithms. * `"upload_date desc"`: By upload date descending. * `"upload_date"`: By upload date ascending. *
             * `"update_date desc"`: By last updated date descending. * `"update_date"`: By last updated date ascending. * `"retrieval_importance desc"`: By retrieval importance of properties
             * descending. This feature is still under development, please do not use unless otherwise instructed to do so.
             */
            orderBy?: string;
            /**
             * A limit on the number of documents returned in the search results. Increasing this value above the default value of 10 can increase search response time. The value can be between 1
             * and 100.
             */
            pageSize?: number;
            /** The token specifying the current offset within search results. See SearchDocumentsResponse.next_page_token for an explanation of how to obtain the next set of query results. */
            pageToken?: string;
            /**
             * Experimental, do not use. The limit on the number of documents returned for the question-answering feature. To enable the question-answering feature, set [DocumentQuery].is_nl_query
             * to true.
             */
            qaSizeLimit?: number;
            /** The meta information collected about the end user, used to enforce access control and improve the search quality of the service. */
            requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
            /**
             * Controls if the search document request requires the return of a total size of matched documents. See SearchDocumentsResponse.total_size. Enabling this flag may adversely impact
             * performance. Hint: If this is used with pagination, set this flag on the initial query but set this to false on subsequent page calls (keep the total count locally). Defaults to
             * false.
             */
            requireTotalSize?: boolean;
            /** Controls if the search document request requires the return of a total size of matched documents. See SearchDocumentsResponse.total_size. */
            totalResultSize?: string;
        }
        interface GoogleCloudContentwarehouseV1SearchDocumentsResponse {
            /** The histogram results that match with the specified SearchDocumentsRequest.histogram_queries. */
            histogramQueryResults?: GoogleCloudContentwarehouseV1HistogramQueryResult[];
            /** The document entities that match the specified SearchDocumentsRequest. */
            matchingDocuments?: GoogleCloudContentwarehouseV1SearchDocumentsResponseMatchingDocument[];
            /** Additional information for the API invocation, such as the request tracking id. */
            metadata?: GoogleCloudContentwarehouseV1ResponseMetadata;
            /** The token that specifies the starting position of the next page of results. This field is empty if there are no more results. */
            nextPageToken?: string;
            /**
             * The total number of matched documents which is available only if the client set SearchDocumentsRequest.require_total_size to `true` or set SearchDocumentsRequest.total_result_size
             * to `ESTIMATED_SIZE` or `ACTUAL_SIZE`. Otherwise, the value will be `-1`. Typically a UI would handle this condition by displaying "of many", for example: "Displaying 10 of many".
             */
            totalSize?: number;
        }
        interface GoogleCloudContentwarehouseV1SearchDocumentsResponseMatchingDocument {
            /** Document that matches the specified SearchDocumentsRequest. This document only contains indexed metadata information. */
            document?: GoogleCloudContentwarehouseV1Document;
            /** Experimental. Additional result info if the question-answering feature is enabled. */
            qaResult?: GoogleCloudContentwarehouseV1QAResult;
            /**
             * Contains snippets of text from the document full raw text that most closely match a search query's keywords, if available. All HTML tags in the original fields are stripped when
             * returned in this field, and matching query keywords are enclosed in HTML bold tags. If the question-answering feature is enabled, this field will instead contain a snippet that
             * answers the user's natural-language query. No HTML bold tags will be present, and highlights in the answer snippet can be found in QAResult.highlights.
             */
            searchTextSnippet?: string;
        }
        interface GoogleCloudContentwarehouseV1SetAclRequest {
            /**
             * Required. REQUIRED: The complete policy to be applied to the `resource`. The size of the policy is limited to a few 10s of KB. This refers to an Identity and Access (IAM) policy,
             * which specifies access controls for the Document.
             */
            policy?: GoogleIamV1Policy;
            /** For Set Project ACL only. Authorization check for end user will be ignored when project_owner=true. */
            projectOwner?: boolean;
            /** The meta information collected about the end user, used to enforce access control for the service. */
            requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
        }
        interface GoogleCloudContentwarehouseV1SetAclResponse {
            /** Additional information for the API invocation, such as the request tracking id. */
            metadata?: GoogleCloudContentwarehouseV1ResponseMetadata;
            /** The policy will be attached to a resource (e.g. projecct, document). */
            policy?: GoogleIamV1Policy;
        }
        interface GoogleCloudContentwarehouseV1SynonymSet {
            /** This is a freeform field. Example contexts can be "sales," "engineering," "real estate," "accounting," etc. The context can be supplied during search requests. */
            context?: string;
            /** The resource name of the SynonymSet This is mandatory for google.api.resource. Format: projects/{project_number}/locations/{location}/synonymSets/{context}. */
            name?: string;
            /** List of Synonyms for the context. */
            synonyms?: GoogleCloudContentwarehouseV1SynonymSetSynonym[];
        }
        interface GoogleCloudContentwarehouseV1SynonymSetSynonym {
            /** For example: sale, invoice, bill, order */
            words?: string[];
        }
        interface GoogleCloudContentwarehouseV1TextArray {
            /** List of text values. */
            values?: string[];
        }
        // tslint:disable-next-line:no-empty-interface
        interface GoogleCloudContentwarehouseV1TextTypeOptions {
        }
        interface GoogleCloudContentwarehouseV1TimeFilter {
            /** Specifies which time field to filter documents on. Defaults to TimeField.UPLOAD_TIME. */
            timeField?: string;
            timeRange?: GoogleTypeInterval;
        }
        interface GoogleCloudContentwarehouseV1TimestampArray {
            /** List of timestamp values. */
            values?: GoogleCloudContentwarehouseV1TimestampValue[];
        }
        // tslint:disable-next-line:no-empty-interface
        interface GoogleCloudContentwarehouseV1TimestampTypeOptions {
        }
        interface GoogleCloudContentwarehouseV1TimestampValue {
            /** The string must represent a valid instant in UTC and is parsed using java.time.format.DateTimeFormatter.ISO_INSTANT. e.g. "2013-09-29T18:46:19Z" */
            textValue?: string;
            /** Timestamp value */
            timestampValue?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface GoogleCloudContentwarehouseV1UpdateDocumentMetadata {
        }
        interface GoogleCloudContentwarehouseV1UpdateDocumentRequest {
            /**
             * Request Option for processing Cloud AI Document in Document Warehouse. This field offers limited support for mapping entities from Cloud AI Document to Warehouse Document. Please
             * consult with product team before using this field and other available options.
             */
            cloudAiDocumentOption?: GoogleCloudContentwarehouseV1CloudAIDocumentOption;
            /** Required. The document to update. */
            document?: GoogleCloudContentwarehouseV1Document;
            /** The meta information collected about the end user, used to enforce access control for the service. */
            requestMetadata?: GoogleCloudContentwarehouseV1RequestMetadata;
            /** Options for the update operation. */
            updateOptions?: GoogleCloudContentwarehouseV1UpdateOptions;
        }
        interface GoogleCloudContentwarehouseV1UpdateDocumentResponse {
            /** Updated document after executing update request. */
            document?: GoogleCloudContentwarehouseV1Document;
            /** Additional information for the API invocation, such as the request tracking id. */
            metadata?: GoogleCloudContentwarehouseV1ResponseMetadata;
            /** Output from Rule Engine recording the rule evaluator and action executor's output. Refer format in: google/cloud/contentwarehouse/v1/rule_engine.proto */
            ruleEngineOutput?: GoogleCloudContentwarehouseV1RuleEngineOutput;
        }
        interface GoogleCloudContentwarehouseV1UpdateDocumentSchemaRequest {
            /** Required. The document schema to update with. */
            documentSchema?: GoogleCloudContentwarehouseV1DocumentSchema;
        }
        interface GoogleCloudContentwarehouseV1UpdateOptions {
            /** Options for merging. */
            mergeFieldsOptions?: GoogleCloudContentwarehouseV1MergeFieldsOptions;
            /** Field mask for merging Document fields. For the `FieldMask` definition, see https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#fieldmask */
            updateMask?: string;
            /** Type for update. */
            updateType?: string;
        }
        interface GoogleCloudContentwarehouseV1UpdateRuleSetRequest {
            /** Required. The rule set to update. */
            ruleSet?: GoogleCloudContentwarehouseV1RuleSet;
        }
        interface GoogleCloudContentwarehouseV1UserInfo {
            /** The unique group identifications which the user is belong to. The format is "group:yyyy@example.com"; */
            groupIds?: string[];
            /**
             * A unique user identification string, as determined by the client. The maximum number of allowed characters is 255. Allowed characters include numbers 0 to 9, uppercase and lowercase
             * letters, and restricted special symbols (:, @, +, -, _, ~) The format is "user:xxxx@example.com";
             */
            id?: string;
        }
        interface GoogleCloudContentwarehouseV1Value {
            /** Represents a boolean value. */
            booleanValue?: boolean;
            /** Represents a datetime value. */
            datetimeValue?: GoogleTypeDateTime;
            /** Represents an enum value. */
            enumValue?: GoogleCloudContentwarehouseV1EnumValue;
            /** Represents a float value. */
            floatValue?: number;
            /** Represents a integer value. */
            intValue?: number;
            /** Represents a string value. */
            stringValue?: string;
            /** Represents a timestamp value. */
            timestampValue?: GoogleCloudContentwarehouseV1TimestampValue;
        }
        interface GoogleCloudDocumentaiV1Barcode {
            /**
             * Format of a barcode. The supported formats are: - `CODE_128`: Code 128 type. - `CODE_39`: Code 39 type. - `CODE_93`: Code 93 type. - `CODABAR`: Codabar type. - `DATA_MATRIX`: 2D
             * Data Matrix type. - `ITF`: ITF type. - `EAN_13`: EAN-13 type. - `EAN_8`: EAN-8 type. - `QR_CODE`: 2D QR code type. - `UPC_A`: UPC-A type. - `UPC_E`: UPC-E type. - `PDF417`: PDF417
             * type. - `AZTEC`: 2D Aztec code type. - `DATABAR`: GS1 DataBar code type.
             */
            format?: string;
            /** Raw value encoded in the barcode. For example: `'MEBKM:TITLE:Google;URL:https://www.google.com;;'`. */
            rawValue?: string;
            /**
             * Value format describes the format of the value that a barcode encodes. The supported formats are: - `CONTACT_INFO`: Contact information. - `EMAIL`: Email address. - `ISBN`: ISBN
             * identifier. - `PHONE`: Phone number. - `PRODUCT`: Product. - `SMS`: SMS message. - `TEXT`: Text string. - `URL`: URL address. - `WIFI`: Wifi information. - `GEO`: Geo-localization.
             * - `CALENDAR_EVENT`: Calendar event. - `DRIVER_LICENSE`: Driver's license.
             */
            valueFormat?: string;
        }
        interface GoogleCloudDocumentaiV1BoundingPoly {
            /** The bounding polygon normalized vertices. */
            normalizedVertices?: GoogleCloudDocumentaiV1NormalizedVertex[];
            /** The bounding polygon vertices. */
            vertices?: GoogleCloudDocumentaiV1Vertex[];
        }
        interface GoogleCloudDocumentaiV1Document {
            /**
             * Optional. Inline document content, represented as a stream of bytes. Note: As with all `bytes` fields, protobuffers use a pure binary representation, whereas JSON representations
             * use base64.
             */
            content?: string;
            /** A list of entities detected on Document.text. For document shards, entities in this list may cross shard boundaries. */
            entities?: GoogleCloudDocumentaiV1DocumentEntity[];
            /** Placeholder. Relationship among Document.entities. */
            entityRelations?: GoogleCloudDocumentaiV1DocumentEntityRelation[];
            /** Any error that occurred while processing this document. */
            error?: GoogleRpcStatus;
            /** An IANA published MIME type (also referred to as media type). For more information, see https://www.iana.org/assignments/media-types/media-types.xhtml. */
            mimeType?: string;
            /** Visual page layout for the Document. */
            pages?: GoogleCloudDocumentaiV1DocumentPage[];
            /** Placeholder. Revision history of this document. */
            revisions?: GoogleCloudDocumentaiV1DocumentRevision[];
            /** Information about the sharding if this document is sharded part of a larger document. If the document is not sharded, this message is not specified. */
            shardInfo?: GoogleCloudDocumentaiV1DocumentShardInfo;
            /** Optional. UTF-8 encoded text in reading order from the document. */
            text?: string;
            /**
             * Placeholder. A list of text corrections made to Document.text. This is usually used for annotating corrections to OCR mistakes. Text changes for a given revision may not overlap
             * with each other.
             */
            textChanges?: GoogleCloudDocumentaiV1DocumentTextChange[];
            /** Styles for the Document.text. */
            textStyles?: GoogleCloudDocumentaiV1DocumentStyle[];
            /**
             * Optional. Currently supports Google Cloud Storage URI of the form `gs://bucket_name/object_name`. Object versioning is not supported. See [Google Cloud Storage Request
             * URIs](https://cloud.google.com/storage/docs/reference-uris) for more info.
             */
            uri?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentEntity {
            /** Optional. Confidence of detected Schema entity. Range `[0, 1]`. */
            confidence?: number;
            /** Optional. Canonical id. This will be a unique value in the entity list for this document. */
            id?: string;
            /** Optional. Deprecated. Use `id` field instead. */
            mentionId?: string;
            /** Optional. Text value of the entity e.g. `1600 Amphitheatre Pkwy`. */
            mentionText?: string;
            /**
             * Optional. Normalized entity value. Absent if the extracted value could not be converted or the type (e.g. address) is not supported for certain parsers. This field is also only
             * populated for certain supported document types.
             */
            normalizedValue?: GoogleCloudDocumentaiV1DocumentEntityNormalizedValue;
            /** Optional. Represents the provenance of this entity wrt. the location on the page where it was found. */
            pageAnchor?: GoogleCloudDocumentaiV1DocumentPageAnchor;
            /** Optional. Entities can be nested to form a hierarchical data structure representing the content in the document. */
            properties?: GoogleCloudDocumentaiV1DocumentEntity[];
            /** Optional. The history of this annotation. */
            provenance?: GoogleCloudDocumentaiV1DocumentProvenance;
            /** Optional. Whether the entity will be redacted for de-identification purposes. */
            redacted?: boolean;
            /** Optional. Provenance of the entity. Text anchor indexing into the Document.text. */
            textAnchor?: GoogleCloudDocumentaiV1DocumentTextAnchor;
            /** Required. Entity type from a schema e.g. `Address`. */
            type?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentEntityNormalizedValue {
            /** Postal address. See also: https://github.com/googleapis/googleapis/blob/master/google/type/postal_address.proto */
            addressValue?: GoogleTypePostalAddress;
            /** Boolean value. Can be used for entities with binary values, or for checkboxes. */
            booleanValue?: boolean;
            /** DateTime value. Includes date, time, and timezone. See also: https://github.com/googleapis/googleapis/blob/master/google/type/datetime.proto */
            datetimeValue?: GoogleTypeDateTime;
            /** Date value. Includes year, month, day. See also: https://github.com/googleapis/googleapis/blob/master/google/type/date.proto */
            dateValue?: GoogleTypeDate;
            /** Float value. */
            floatValue?: number;
            /** Integer value. */
            integerValue?: number;
            /** Money value. See also: https://github.com/googleapis/googleapis/blob/master/google/type/money.proto */
            moneyValue?: GoogleTypeMoney;
            /**
             * Optional. An optional field to store a normalized string. For some entity types, one of respective `structured_value` fields may also be populated. Also not all the types of
             * `structured_value` will be normalized. For example, some processors may not generate `float` or `integer` normalized text by default. Below are sample formats mapped to structured
             * values. - Money/Currency type (`money_value`) is in the ISO 4217 text format. - Date type (`date_value`) is in the ISO 8601 text format. - Datetime type (`datetime_value`) is in the
             * ISO 8601 text format.
             */
            text?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentEntityRelation {
            /** Object entity id. */
            objectId?: string;
            /** Relationship description. */
            relation?: string;
            /** Subject entity id. */
            subjectId?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentPage {
            /** A list of visually detected text blocks on the page. A block has a set of lines (collected into paragraphs) that have a common line-spacing and orientation. */
            blocks?: GoogleCloudDocumentaiV1DocumentPageBlock[];
            /** A list of detected barcodes. */
            detectedBarcodes?: GoogleCloudDocumentaiV1DocumentPageDetectedBarcode[];
            /** A list of detected languages together with confidence. */
            detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
            /** Physical dimension of the page. */
            dimension?: GoogleCloudDocumentaiV1DocumentPageDimension;
            /** A list of visually detected form fields on the page. */
            formFields?: GoogleCloudDocumentaiV1DocumentPageFormField[];
            /** Rendered image for this page. This image is preprocessed to remove any skew, rotation, and distortions such that the annotation bounding boxes can be upright and axis-aligned. */
            image?: GoogleCloudDocumentaiV1DocumentPageImage;
            /** Image Quality Scores. */
            imageQualityScores?: GoogleCloudDocumentaiV1DocumentPageImageQualityScores;
            /** Layout for the page. */
            layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
            /** A list of visually detected text lines on the page. A collection of tokens that a human would perceive as a line. */
            lines?: GoogleCloudDocumentaiV1DocumentPageLine[];
            /** 1-based index for current Page in a parent Document. Useful when a page is taken out of a Document for individual processing. */
            pageNumber?: number;
            /** A list of visually detected text paragraphs on the page. A collection of lines that a human would perceive as a paragraph. */
            paragraphs?: GoogleCloudDocumentaiV1DocumentPageParagraph[];
            /** The history of this page. */
            provenance?: GoogleCloudDocumentaiV1DocumentProvenance;
            /** A list of visually detected symbols on the page. */
            symbols?: GoogleCloudDocumentaiV1DocumentPageSymbol[];
            /** A list of visually detected tables on the page. */
            tables?: GoogleCloudDocumentaiV1DocumentPageTable[];
            /** A list of visually detected tokens on the page. */
            tokens?: GoogleCloudDocumentaiV1DocumentPageToken[];
            /** Transformation matrices that were applied to the original document image to produce Page.image. */
            transforms?: GoogleCloudDocumentaiV1DocumentPageMatrix[];
            /** A list of detected non-text visual elements e.g. checkbox, signature etc. on the page. */
            visualElements?: GoogleCloudDocumentaiV1DocumentPageVisualElement[];
        }
        interface GoogleCloudDocumentaiV1DocumentPageAnchor {
            /** One or more references to visual page elements */
            pageRefs?: GoogleCloudDocumentaiV1DocumentPageAnchorPageRef[];
        }
        interface GoogleCloudDocumentaiV1DocumentPageAnchorPageRef {
            /** Optional. Identifies the bounding polygon of a layout element on the page. */
            boundingPoly?: GoogleCloudDocumentaiV1BoundingPoly;
            /** Optional. Confidence of detected page element, if applicable. Range `[0, 1]`. */
            confidence?: number;
            /** Optional. Deprecated. Use PageRef.bounding_poly instead. */
            layoutId?: string;
            /** Optional. The type of the layout element that is being referenced if any. */
            layoutType?: string;
            /**
             * Required. Index into the Document.pages element, for example using `Document.pages` to locate the related page element. This field is skipped when its value is the default `0`. See
             * https://developers.google.com/protocol-buffers/docs/proto3#json.
             */
            page?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentPageBlock {
            /** A list of detected languages together with confidence. */
            detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
            /** Layout for Block. */
            layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
            /** The history of this annotation. */
            provenance?: GoogleCloudDocumentaiV1DocumentProvenance;
        }
        interface GoogleCloudDocumentaiV1DocumentPageDetectedBarcode {
            /** Detailed barcode information of the DetectedBarcode. */
            barcode?: GoogleCloudDocumentaiV1Barcode;
            /** Layout for DetectedBarcode. */
            layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
        }
        interface GoogleCloudDocumentaiV1DocumentPageDetectedLanguage {
            /** Confidence of detected language. Range `[0, 1]`. */
            confidence?: number;
            /** The BCP-47 language code, such as `en-US` or `sr-Latn`. For more information, see https://www.unicode.org/reports/tr35/#Unicode_locale_identifier. */
            languageCode?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentPageDimension {
            /** Page height. */
            height?: number;
            /** Dimension unit. */
            unit?: string;
            /** Page width. */
            width?: number;
        }
        interface GoogleCloudDocumentaiV1DocumentPageFormField {
            /** Created for Labeling UI to export key text. If corrections were made to the text identified by the `field_name.text_anchor`, this field will contain the correction. */
            correctedKeyText?: string;
            /** Created for Labeling UI to export value text. If corrections were made to the text identified by the `field_value.text_anchor`, this field will contain the correction. */
            correctedValueText?: string;
            /** Layout for the FormField name. e.g. `Address`, `Email`, `Grand total`, `Phone number`, etc. */
            fieldName?: GoogleCloudDocumentaiV1DocumentPageLayout;
            /** Layout for the FormField value. */
            fieldValue?: GoogleCloudDocumentaiV1DocumentPageLayout;
            /** A list of detected languages for name together with confidence. */
            nameDetectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
            /** The history of this annotation. */
            provenance?: GoogleCloudDocumentaiV1DocumentProvenance;
            /** A list of detected languages for value together with confidence. */
            valueDetectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
            /**
             * If the value is non-textual, this field represents the type. Current valid values are: - blank (this indicates the `field_value` is normal text) - `unfilled_checkbox` -
             * `filled_checkbox`
             */
            valueType?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentPageImage {
            /** Raw byte content of the image. */
            content?: string;
            /** Height of the image in pixels. */
            height?: number;
            /** Encoding mime type for the image. */
            mimeType?: string;
            /** Width of the image in pixels. */
            width?: number;
        }
        interface GoogleCloudDocumentaiV1DocumentPageImageQualityScores {
            /** A list of detected defects. */
            detectedDefects?: GoogleCloudDocumentaiV1DocumentPageImageQualityScoresDetectedDefect[];
            /** The overall quality score. Range `[0, 1]` where 1 is perfect quality. */
            qualityScore?: number;
        }
        interface GoogleCloudDocumentaiV1DocumentPageImageQualityScoresDetectedDefect {
            /** Confidence of detected defect. Range `[0, 1]` where 1 indicates strong confidence of that the defect exists. */
            confidence?: number;
            /**
             * Name of the defect type. Supported values are: - `quality/defect_blurry` - `quality/defect_noisy` - `quality/defect_dark` - `quality/defect_faint` - `quality/defect_text_too_small`
             * - `quality/defect_document_cutoff` - `quality/defect_text_cutoff` - `quality/defect_glare`
             */
            type?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentPageLayout {
            /** The bounding polygon for the Layout. */
            boundingPoly?: GoogleCloudDocumentaiV1BoundingPoly;
            /**
             * Confidence of the current Layout within context of the object this layout is for. e.g. confidence can be for a single token, a table, a visual element, etc. depending on context.
             * Range `[0, 1]`.
             */
            confidence?: number;
            /** Detected orientation for the Layout. */
            orientation?: string;
            /** Text anchor indexing into the Document.text. */
            textAnchor?: GoogleCloudDocumentaiV1DocumentTextAnchor;
        }
        interface GoogleCloudDocumentaiV1DocumentPageLine {
            /** A list of detected languages together with confidence. */
            detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
            /** Layout for Line. */
            layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
            /** The history of this annotation. */
            provenance?: GoogleCloudDocumentaiV1DocumentProvenance;
        }
        interface GoogleCloudDocumentaiV1DocumentPageMatrix {
            /** Number of columns in the matrix. */
            cols?: number;
            /** The matrix data. */
            data?: string;
            /** Number of rows in the matrix. */
            rows?: number;
            /**
             * This encodes information about what data type the matrix uses. For example, 0 (CV_8U) is an unsigned 8-bit image. For the full list of OpenCV primitive data types, please refer to
             * https://docs.opencv.org/4.3.0/d1/d1b/group__core__hal__interface.html
             */
            type?: number;
        }
        interface GoogleCloudDocumentaiV1DocumentPageParagraph {
            /** A list of detected languages together with confidence. */
            detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
            /** Layout for Paragraph. */
            layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
            /** The history of this annotation. */
            provenance?: GoogleCloudDocumentaiV1DocumentProvenance;
        }
        interface GoogleCloudDocumentaiV1DocumentPageSymbol {
            /** A list of detected languages together with confidence. */
            detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
            /** Layout for Symbol. */
            layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
        }
        interface GoogleCloudDocumentaiV1DocumentPageTable {
            /** Body rows of the table. */
            bodyRows?: GoogleCloudDocumentaiV1DocumentPageTableTableRow[];
            /** A list of detected languages together with confidence. */
            detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
            /** Header rows of the table. */
            headerRows?: GoogleCloudDocumentaiV1DocumentPageTableTableRow[];
            /** Layout for Table. */
            layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
            /** The history of this table. */
            provenance?: GoogleCloudDocumentaiV1DocumentProvenance;
        }
        interface GoogleCloudDocumentaiV1DocumentPageTableTableCell {
            /** How many columns this cell spans. */
            colSpan?: number;
            /** A list of detected languages together with confidence. */
            detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
            /** Layout for TableCell. */
            layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
            /** How many rows this cell spans. */
            rowSpan?: number;
        }
        interface GoogleCloudDocumentaiV1DocumentPageTableTableRow {
            /** Cells that make up this row. */
            cells?: GoogleCloudDocumentaiV1DocumentPageTableTableCell[];
        }
        interface GoogleCloudDocumentaiV1DocumentPageToken {
            /** Detected break at the end of a Token. */
            detectedBreak?: GoogleCloudDocumentaiV1DocumentPageTokenDetectedBreak;
            /** A list of detected languages together with confidence. */
            detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
            /** Layout for Token. */
            layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
            /** The history of this annotation. */
            provenance?: GoogleCloudDocumentaiV1DocumentProvenance;
        }
        interface GoogleCloudDocumentaiV1DocumentPageTokenDetectedBreak {
            /** Detected break type. */
            type?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentPageVisualElement {
            /** A list of detected languages together with confidence. */
            detectedLanguages?: GoogleCloudDocumentaiV1DocumentPageDetectedLanguage[];
            /** Layout for VisualElement. */
            layout?: GoogleCloudDocumentaiV1DocumentPageLayout;
            /** Type of the VisualElement. */
            type?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentProvenance {
            /** The Id of this operation. Needs to be unique within the scope of the revision. */
            id?: number;
            /** References to the original elements that are replaced. */
            parents?: GoogleCloudDocumentaiV1DocumentProvenanceParent[];
            /** The index of the revision that produced this element. */
            revision?: number;
            /** The type of provenance operation. */
            type?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentProvenanceParent {
            /** The id of the parent provenance. */
            id?: number;
            /** The index of the parent item in the corresponding item list (eg. list of entities, properties within entities, etc.) in the parent revision. */
            index?: number;
            /** The index of the index into current revision's parent_ids list. */
            revision?: number;
        }
        interface GoogleCloudDocumentaiV1DocumentRevision {
            /** If the change was made by a person specify the name or id of that person. */
            agent?: string;
            /** The time that the revision was created. */
            createTime?: string;
            /** Human Review information of this revision. */
            humanReview?: GoogleCloudDocumentaiV1DocumentRevisionHumanReview;
            /** Id of the revision. Unique within the context of the document. */
            id?: string;
            /** The revisions that this revision is based on. This can include one or more parent (when documents are merged.) This field represents the index into the `revisions` field. */
            parent?: number[];
            /**
             * The revisions that this revision is based on. Must include all the ids that have anything to do with this revision - eg. there are `provenance.parent.revision` fields that index
             * into this field.
             */
            parentIds?: string[];
            /** If the annotation was made by processor identify the processor by its resource name. */
            processor?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentRevisionHumanReview {
            /** Human review state. e.g. `requested`, `succeeded`, `rejected`. */
            state?: string;
            /** A message providing more details about the current state of processing. For example, the rejection reason when the state is `rejected`. */
            stateMessage?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentShardInfo {
            /** Total number of shards. */
            shardCount?: string;
            /** The 0-based index of this shard. */
            shardIndex?: string;
            /** The index of the first character in Document.text in the overall document global text. */
            textOffset?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentStyle {
            /** Text background color. */
            backgroundColor?: GoogleTypeColor;
            /** Text color. */
            color?: GoogleTypeColor;
            /** Font family such as `Arial`, `Times New Roman`. https://www.w3schools.com/cssref/pr_font_font-family.asp */
            fontFamily?: string;
            /** Font size. */
            fontSize?: GoogleCloudDocumentaiV1DocumentStyleFontSize;
            /** Font weight. Possible values are normal, bold, bolder, and lighter. https://www.w3schools.com/cssref/pr_font_weight.asp */
            fontWeight?: string;
            /** Text anchor indexing into the Document.text. */
            textAnchor?: GoogleCloudDocumentaiV1DocumentTextAnchor;
            /** Text decoration. Follows CSS standard. https://www.w3schools.com/cssref/pr_text_text-decoration.asp */
            textDecoration?: string;
            /** Text style. Possible values are normal, italic, and oblique. https://www.w3schools.com/cssref/pr_font_font-style.asp */
            textStyle?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentStyleFontSize {
            /** Font size for the text. */
            size?: number;
            /** Unit for the font size. Follows CSS naming (in, px, pt, etc.). */
            unit?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentTextAnchor {
            /** Contains the content of the text span so that users do not have to look it up in the text_segments. It is always populated for formFields. */
            content?: string;
            /** The text segments from the Document.text. */
            textSegments?: GoogleCloudDocumentaiV1DocumentTextAnchorTextSegment[];
        }
        interface GoogleCloudDocumentaiV1DocumentTextAnchorTextSegment {
            /** TextSegment half open end UTF-8 char index in the Document.text. */
            endIndex?: string;
            /** TextSegment start UTF-8 char index in the Document.text. */
            startIndex?: string;
        }
        interface GoogleCloudDocumentaiV1DocumentTextChange {
            /** The text that replaces the text identified in the `text_anchor`. */
            changedText?: string;
            /** The history of this annotation. */
            provenance?: GoogleCloudDocumentaiV1DocumentProvenance[];
            /**
             * Provenance of the correction. Text anchor indexing into the Document.text. There can only be a single `TextAnchor.text_segments` element. If the start and end index of the text
             * segment are the same, the text change is inserted before that index.
             */
            textAnchor?: GoogleCloudDocumentaiV1DocumentTextAnchor;
        }
        interface GoogleCloudDocumentaiV1NormalizedVertex {
            /** X coordinate. */
            x?: number;
            /** Y coordinate (starts from the top of the image). */
            y?: number;
        }
        interface GoogleCloudDocumentaiV1Vertex {
            /** X coordinate. */
            x?: number;
            /** Y coordinate (starts from the top of the image). */
            y?: number;
        }
        interface GoogleIamV1AuditConfig {
            /** The configuration for logging of each type of permission. */
            auditLogConfigs?: GoogleIamV1AuditLogConfig[];
            /**
             * Specifies a service that will be enabled for audit logging. For example, `storage.googleapis.com`, `cloudsql.googleapis.com`. `allServices` is a special value that covers all
             * services.
             */
            service?: string;
        }
        interface GoogleIamV1AuditLogConfig {
            /** Specifies the identities that do not cause logging for this type of permission. Follows the same format of Binding.members. */
            exemptedMembers?: string[];
            /** The log type that this config enables. */
            logType?: string;
        }
        interface GoogleIamV1Binding {
            /**
             * The condition that is associated with this binding. If the condition evaluates to `true`, then this binding applies to the current request. If the condition evaluates to `false`,
             * then this binding does not apply to the current request. However, a different role binding might grant the same role to one or more of the principals in this binding. To learn which
             * resources support conditions in their IAM policies, see the [IAM documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
             */
            condition?: GoogleTypeExpr;
            /**
             * Specifies the principals requesting access for a Google Cloud resource. `members` can have the following values: * `allUsers`: A special identifier that represents anyone who is on
             * the internet; with or without a Google account. * `allAuthenticatedUsers`: A special identifier that represents anyone who is authenticated with a Google account or a service
             * account. Does not include identities that come from external identity providers (IdPs) through identity federation. * `user:{emailid}`: An email address that represents a specific
             * Google account. For example, `alice@example.com` . * `serviceAccount:{emailid}`: An email address that represents a Google service account. For example,
             * `my-other-app@appspot.gserviceaccount.com`. * `serviceAccount:{projectid}.svc.id.goog[{namespace}/{kubernetes-sa}]`: An identifier for a [Kubernetes service
             * account](https://cloud.google.com/kubernetes-engine/docs/how-to/kubernetes-service-accounts). For example, `my-project.svc.id.goog[my-namespace/my-kubernetes-sa]`. *
             * `group:{emailid}`: An email address that represents a Google group. For example, `admins@example.com`. * `deleted:user:{emailid}?uid={uniqueid}`: An email address (plus unique
             * identifier) representing a user that has been recently deleted. For example, `alice@example.com?uid=123456789012345678901`. If the user is recovered, this value reverts to
             * `user:{emailid}` and the recovered user retains the role in the binding. * `deleted:serviceAccount:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing
             * a service account that has been recently deleted. For example, `my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901`. If the service account is undeleted, this value
             * reverts to `serviceAccount:{emailid}` and the undeleted service account retains the role in the binding. * `deleted:group:{emailid}?uid={uniqueid}`: An email address (plus unique
             * identifier) representing a Google group that has been recently deleted. For example, `admins@example.com?uid=123456789012345678901`. If the group is recovered, this value reverts to
             * `group:{emailid}` and the recovered group retains the role in the binding. * `domain:{domain}`: The G Suite domain (primary) that represents all the users of that domain. For
             * example, `google.com` or `example.com`.
             */
            members?: string[];
            /** Role that is assigned to the list of `members`, or principals. For example, `roles/viewer`, `roles/editor`, or `roles/owner`. */
            role?: string;
        }
        interface GoogleIamV1Policy {
            /** Specifies cloud audit logging configuration for this policy. */
            auditConfigs?: GoogleIamV1AuditConfig[];
            /**
             * Associates a list of `members`, or principals, with a `role`. Optionally, may specify a `condition` that determines how and when the `bindings` are applied. Each of the `bindings`
             * must contain at least one principal. The `bindings` in a `Policy` can refer to up to 1,500 principals; up to 250 of these principals can be Google groups. Each occurrence of a
             * principal counts towards these limits. For example, if the `bindings` grant 50 different roles to `user:alice@example.com`, and not to any other principal, then you can add another
             * 1,450 principals to the `bindings` in the `Policy`.
             */
            bindings?: GoogleIamV1Binding[];
            /**
             * `etag` is used for optimistic concurrency control as a way to help prevent simultaneous updates of a policy from overwriting each other. It is strongly suggested that systems make
             * use of the `etag` in the read-modify-write cycle to perform policy updates in order to avoid race conditions: An `etag` is returned in the response to `getIamPolicy`, and systems
             * are expected to put that etag in the request to `setIamPolicy` to ensure that their change will be applied to the same version of the policy. **Important:** If you use IAM
             * Conditions, you must include the `etag` field whenever you call `setIamPolicy`. If you omit this field, then IAM allows you to overwrite a version `3` policy with a version `1`
             * policy, and all of the conditions in the version `3` policy are lost.
             */
            etag?: string;
            /**
             * Specifies the format of the policy. Valid values are `0`, `1`, and `3`. Requests that specify an invalid value are rejected. Any operation that affects conditional role bindings
             * must specify version `3`. This requirement applies to the following operations: * Getting a policy that includes a conditional role binding * Adding a conditional role binding to a
             * policy * Changing a conditional role binding in a policy * Removing any role binding, with or without a condition, from a policy that includes conditions **Important:** If you use
             * IAM Conditions, you must include the `etag` field whenever you call `setIamPolicy`. If you omit this field, then IAM allows you to overwrite a version `3` policy with a version `1`
             * policy, and all of the conditions in the version `3` policy are lost. If a policy does not include any conditions, operations on that policy may specify any valid version or leave
             * the field unset. To learn which resources support conditions in their IAM policies, see the [IAM documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
             */
            version?: number;
        }
        interface GoogleInternalAppsWaldoV1alphaAvailabilityPeriod {
            /** Day of week, 0 for Sunday, 1 for Monday, ... */
            dayOfWeek?: number;
            /** Period end, in minutes from the start of the day, exclusive. */
            periodEndMinutes?: number;
            /** Period start, in minutes from the start of the day, inclusive. */
            periodStartMinutes?: number;
        }
        interface GoogleInternalAppsWaldoV1alphaCalendarBusy {
            /**
             * The time when the user will stop being committed, i.e., when their status will be neither of InMeeting, DoNotDisturb, Busy or OutOfOffice < Xh. Note that the goal of this field is
             * to provide information to help users decide how to communicate with a user (see also http://shortn/_wXYXtZScgh).
             */
            committedUntil?: string;
            /** Whether the status of the user from this status's start to committed_until has more than one status type (e.g. DoNotDisturb + InMeeting). */
            committedUntilIsMixed?: boolean;
            /** The summary of the corresponding event in Calendar. */
            eventSummary?: string;
            /** The next time when the user will be available, i.e., when their status will be neither InMeeting, CalendarBusy, DoNotDisturb, OutsideWorkingHours, nor OutOfOffice. */
            nextAvailable?: string;
            /** The time when the user will stop being occupied, i.e., when their status will be neither inMeeting, Busy nor DoNotDisturb. */
            occupiedUntil?: string;
        }
        interface GoogleInternalAppsWaldoV1alphaCustomLocation {
            /** Geographic location as geo coordinates. */
            geoCoordinates?: GoogleTypeLatLng;
            /** The custom location label as a string entered manually by the user. */
            label?: string;
            /** Geographic location as free-form text. */
            location?: string;
        }
        interface GoogleInternalAppsWaldoV1alphaDoNotDisturb {
            /** The time when the user will stop being committed, i.e., when their status will be neither of InMeeting, DoNotDisturb, Busy or OutOfOffice < Xh. */
            committedUntil?: string;
            /** Whether the status of the user from this status's start to committed_until has more than one status type (e.g. DoNotDisturb + InMeeting). */
            committedUntilIsMixed?: boolean;
            /** The next time when the user will be available, i.e., when their status will be neither InMeeting, CalendarBusy, DoNotDisturb, OutsideWorkingHours, nor OutOfOffice. */
            nextAvailable?: string;
            /** The time when the user will stop being occupied, i.e., when their status will be neither inMeeting, Busy nor DoNotDisturb. */
            occupiedUntil?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface GoogleInternalAppsWaldoV1alphaHomeLocation {
        }
        // tslint:disable-next-line:no-empty-interface
        interface GoogleInternalAppsWaldoV1alphaInactive {
        }
        interface GoogleInternalAppsWaldoV1alphaInMeeting {
            /**
             * The time when the user will stop being committed, i.e., when their status will be neither of InMeeting, DoNotDisturb, Busy or OutOfOffice < Xh. Note that the goal of this field is
             * to provide information to help users decide how to communicate with a user (see also http://shortn/_wXYXtZScgh).
             */
            committedUntil?: string;
            /** Whether the status of the user from this status's start to committed_until has more than one status type (e.g. DoNotDisturb + InMeeting). */
            committedUntilIsMixed?: boolean;
            /** The summary of the corresponding event in Calendar. */
            eventSummary?: string;
            /** The time when the user will stop being in a meeting. */
            inMeetingsUntil?: string;
            /** The next time when the user will be available, i.e., when their status will be neither InMeeting, CalendarBusy, DoNotDisturb, OutsideWorkingHours, nor OutOfOffice. */
            nextAvailable?: string;
            /** The time when the user will stop being occupied, i.e., when their status will be neither InMeeting, Busy nor DoNotDisturb. */
            occupiedUntil?: string;
        }
        interface GoogleInternalAppsWaldoV1alphaLocalTimeContext {
            /** The current time zone of the user. Represented as a valid time zone ID from Olson database, like "Europe/Zurich" (see http://google3/i18n/identifiers/data/timezones.txt). */
            timeZone?: string;
        }
        interface GoogleInternalAppsWaldoV1alphaOfficeLocation {
            /**
             * Experimental. Can change or disappear without warning or notice. References a building from http://google3/ccc/hosted/api/rosy/resources/calendar/building.proto For example
             * "US-NYC-9TH".
             */
            experimentalBuildingId?: string;
            /** Experimental. Can change or disappear without warning or notice. The desk id. For example "11E358K". */
            experimentalDeskId?: string;
            /** Experimental. Can change or disappear without warning or notice. The floor id. For example "11". */
            experimentalFloorId?: string;
        }
        interface GoogleInternalAppsWaldoV1alphaOutOfOffice {
            /**
             * The closest time when the user will be available after this OOO block. This might be different from the end of the OOO block in Calendar, since the OOO block might end on Friday
             * evening, and then the user is outside working hours.
             */
            comeBackTime?: string;
            /**
             * The time when the user will stop being committed, i.e., when their status will be neither of InMeeting, DoNotDisturb, Busy or OutOfOffice < Xh. Note that if this OOO block is large
             * (>=Xh), committed_until is not set.
             */
            committedUntil?: string;
            /** Whether the status of the user from this status's start to committed_until has more than one status type (e.g. DoNotDisturb + InMeeting). Only set if committed_until is set. */
            committedUntilIsMixed?: boolean;
            /** The summary of the corresponding OOO block in Calendar. This is entered by the user, so we return it "as is" - no i18n. */
            eventSummary?: string;
        }
        interface GoogleInternalAppsWaldoV1alphaOutsideWorkingHours {
            /**
             * The closest time when the user will be available after this block. This might be different from the start of the working hours in Calendar, because the given OutsideWorkingHours
             * interval might be followed by OOO.
             */
            comeBackTime?: string;
        }
        interface GoogleInternalAppsWaldoV1alphaTimeRange {
            /** End point of the range, exclusive. */
            endTime?: string;
            /** Starting point of the range, inclusive. */
            startTime?: string;
        }
        interface GoogleInternalAppsWaldoV1alphaUpcomingCommitmentContext {
            /** The status of the commitment above. */
            nextCommitmentStatus?: GoogleInternalAppsWaldoV1alphaUserStatus;
            /**
             * The most relevant upcoming commitment (InMeeting, DoNotDisturb, CalendarBusy or OutOfOffice). This context is set only if there is an upcoming commitment to show, and only on non
             * commitments. Priority is given to the next closest commitment if its start is close enough to this event, otherwise the next large OOO if there is one.
             */
            nextCommitmentTime?: string;
        }
        interface GoogleInternalAppsWaldoV1alphaUpcomingOooContext {
            /**
             * The future period of absence. The start of this timerange is the start of the future Out of Office event. The end of this timerange represents the come back time of the user from
             * that future OOO event. Note that the come back time might be different (greater) than the end of the corresponding future OOO event due to other non-working user status intervals
             * that it may be followed by.
             */
            timeRange?: GoogleInternalAppsWaldoV1alphaTimeRange;
        }
        interface GoogleInternalAppsWaldoV1alphaUserAvailabilities {
            /**
             * A list of user availabilities having contiguous time ranges which are ordered chronologically. The first one starts at the time of the request or before, and is guaranteed to
             * contain the request time. That means the first element always indicates the current status of a user. A client that wants to display a user's availability in real time should
             * display the availability whose time range contains the current time.
             */
            availabilities?: GoogleInternalAppsWaldoV1alphaUserAvailability[];
            /**
             * The time at which the client should issue the next availability query for this user. This field should only be used to control the polling frequency. This time is always before the
             * end of the time range of the last availability so that the client always knows the current availability.
             */
            nextPollTime?: string;
            /** Information about the user's working hours. This will only be set in case working hours are enabled in their calendar settings. */
            workingHours?: GoogleInternalAppsWaldoV1alphaWorkingHours;
        }
        interface GoogleInternalAppsWaldoV1alphaUserAvailability {
            /**
             * The contexts contain additional information about the current user's availability or its upcoming changes. The client doesn't need to extract certain bits to visualize the status or
             * apply custom logic based on the content of this field: the status field should contain everything needed for the correct visualization.
             */
            contexts?: GoogleInternalAppsWaldoV1alphaUserContext;
            /** The user status during the time range. */
            status?: GoogleInternalAppsWaldoV1alphaUserStatus;
            /** The time range when this availability should be displayed. */
            timeRange?: GoogleInternalAppsWaldoV1alphaTimeRange;
        }
        interface GoogleInternalAppsWaldoV1alphaUserContext {
            /** Helps to determine the user's local time by providing their current time zone. */
            localTime?: GoogleInternalAppsWaldoV1alphaLocalTimeContext;
            /** Information about upcoming events. */
            upcomingCommitmentContext?: GoogleInternalAppsWaldoV1alphaUpcomingCommitmentContext;
            /** Set if user has upcoming OOO. */
            upcomingOoo?: GoogleInternalAppsWaldoV1alphaUpcomingOooContext;
            /** Set if the user has a working location. Not just elsewhere (legacy name). */
            workingElsewhere?: GoogleInternalAppsWaldoV1alphaWorkingElsewhereContext;
        }
        interface GoogleInternalAppsWaldoV1alphaUserLocation {
            /** Indicates the user is working from some other location. */
            customLocation?: GoogleInternalAppsWaldoV1alphaCustomLocation;
            /** Indicates the user is working from home. */
            homeLocation?: any;
            /** Indicates the user is working from the office. */
            officeLocation?: GoogleInternalAppsWaldoV1alphaOfficeLocation;
        }
        interface GoogleInternalAppsWaldoV1alphaUserStatus {
            /** Set if the user is temporarily busy and there is not a more specific status derived from calendar that applies (e.g., InMeeting or DoNotDisturb). */
            calendarBusy?: GoogleInternalAppsWaldoV1alphaCalendarBusy;
            /** Set if the user is in a Focus Time block. Note that this is different than Chat's Do not disturb status, but they may coincide, see: go/focus-time-dnd. */
            doNotDisturb?: GoogleInternalAppsWaldoV1alphaDoNotDisturb;
            /** Set if no other statuses apply. */
            inactive?: any;
            /** Set if the user is in a meeting. */
            inMeeting?: GoogleInternalAppsWaldoV1alphaInMeeting;
            /** Set if the user is out of office. */
            outOfOffice?: GoogleInternalAppsWaldoV1alphaOutOfOffice;
            /** Set if the user doesn't work at this time. */
            outsideWorkingHours?: GoogleInternalAppsWaldoV1alphaOutsideWorkingHours;
        }
        interface GoogleInternalAppsWaldoV1alphaWorkingElsewhereContext {
            /** The new location of the user. Might represent home, office, or a custom address on the map. */
            location?: GoogleInternalAppsWaldoV1alphaUserLocation;
        }
        interface GoogleInternalAppsWaldoV1alphaWorkingHours {
            /** A list of availability periods representing the user's working hours as configured in calendar. */
            availableTime?: GoogleInternalAppsWaldoV1alphaAvailabilityPeriod[];
        }
        interface GoogleInternalCommunicationsInstantmessagingV1Id {
            /** app is the tachyon client application that generated or is to receive a message. */
            app?: string;
            /**
             * country_code is the E164_COUNTRY_CODE format country code for this id, used as a hint for its region. E.g, "+1" will be used for North America, "+86" will be used for China, etc.
             * Should be filled only for RCS group id.
             */
            countryCode?: string;
            /** id is a unique (for this type and app) identifier of a message source or recipient. */
            id?: string;
            /** location_hint is used as a hint for the user's region. */
            locationHint?: GoogleInternalCommunicationsInstantmessagingV1LocationHint;
            /**
             * Raw byte array containing encoded routing information. Clients of Tachyon are expected to include the most recent routing_info_cookie that they have received from the server in the
             * requests that they make. Its format is purposely opaque so that clients do not need to concern themselves with the content of this field. This field is expected to be used primarily
             * by Tachygram clients for go/tachygram-groups to simplify the API contract for group operations while reducing the need for unnecessary lookups.
             */
            routingInfoToken?: string;
            /** type defines what the id field contains, e.g. phone number, Fi-number, Gaia ID etc. */
            type?: string;
        }
        interface GoogleInternalCommunicationsInstantmessagingV1LocationHint {
            /** the format of location. */
            format?: string;
            /** Location is the location, provided in the format specified by format. */
            location?: string;
        }
        interface GoogleLongrunningOperation {
            /** If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available. */
            done?: boolean;
            /** The error result of the operation in case of failure or cancellation. */
            error?: GoogleRpcStatus;
            /**
             * Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such
             * metadata. Any method that returns a long-running operation should document the metadata type, if any.
             */
            metadata?: { [P in string]: any };
            /**
             * The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending
             * with `operations/{unique_id}`.
             */
            name?: string;
            /**
             * The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the
             * original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the
             * original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.
             */
            response?: { [P in string]: any };
        }
        // tslint:disable-next-line:no-empty-interface
        interface GoogleProtobufEmpty {
        }
        interface GoogleRpcStatus {
            /** The status code, which should be an enum value of google.rpc.Code. */
            code?: number;
            /** A list of messages that carry the error details. There is a common set of message types for APIs to use. */
            details?: Array<{ [P in string]: any }>;
            /**
             * A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the
             * client.
             */
            message?: string;
        }
        interface GoogleTypeColor {
            /**
             * The fraction of this color that should be applied to the pixel. That is, the final pixel color is defined by the equation: `pixel color = alpha * (this color) + (1.0 - alpha) *
             * (background color)` This means that a value of 1.0 corresponds to a solid color, whereas a value of 0.0 corresponds to a completely transparent color. This uses a wrapper message
             * rather than a simple float scalar so that it is possible to distinguish between a default value and the value being unset. If omitted, this color object is rendered as a solid color
             * (as if the alpha value had been explicitly given a value of 1.0).
             */
            alpha?: number;
            /** The amount of blue in the color as a value in the interval [0, 1]. */
            blue?: number;
            /** The amount of green in the color as a value in the interval [0, 1]. */
            green?: number;
            /** The amount of red in the color as a value in the interval [0, 1]. */
            red?: number;
        }
        interface GoogleTypeDate {
            /** Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant. */
            day?: number;
            /** Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day. */
            month?: number;
            /** Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year. */
            year?: number;
        }
        interface GoogleTypeDateTime {
            /** Optional. Day of month. Must be from 1 to 31 and valid for the year and month, or 0 if specifying a datetime without a day. */
            day?: number;
            /** Optional. Hours of day in 24 hour format. Should be from 0 to 23, defaults to 0 (midnight). An API may choose to allow the value "24:00:00" for scenarios like business closing time. */
            hours?: number;
            /** Optional. Minutes of hour of day. Must be from 0 to 59, defaults to 0. */
            minutes?: number;
            /** Optional. Month of year. Must be from 1 to 12, or 0 if specifying a datetime without a month. */
            month?: number;
            /** Optional. Fractions of seconds in nanoseconds. Must be from 0 to 999,999,999, defaults to 0. */
            nanos?: number;
            /** Optional. Seconds of minutes of the time. Must normally be from 0 to 59, defaults to 0. An API may allow the value 60 if it allows leap-seconds. */
            seconds?: number;
            /** Time zone. */
            timeZone?: GoogleTypeTimeZone;
            /** UTC offset. Must be whole seconds, between -18 hours and +18 hours. For example, a UTC offset of -4:00 would be represented as { seconds: -14400 }. */
            utcOffset?: string;
            /** Optional. Year of date. Must be from 1 to 9999, or 0 if specifying a datetime without a year. */
            year?: number;
        }
        interface GoogleTypeExpr {
            /** Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI. */
            description?: string;
            /** Textual representation of an expression in Common Expression Language syntax. */
            expression?: string;
            /** Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file. */
            location?: string;
            /** Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression. */
            title?: string;
        }
        interface GoogleTypeInterval {
            /** Optional. Exclusive end of the interval. If specified, a Timestamp matching this interval will have to be before the end. */
            endTime?: string;
            /** Optional. Inclusive start of the interval. If specified, a Timestamp matching this interval will have to be the same or after the start. */
            startTime?: string;
        }
        interface GoogleTypeLatLng {
            /** The latitude in degrees. It must be in the range [-90.0, +90.0]. */
            latitude?: number;
            /** The longitude in degrees. It must be in the range [-180.0, +180.0]. */
            longitude?: number;
        }
        interface GoogleTypeMoney {
            /** The three-letter currency code defined in ISO 4217. */
            currencyCode?: string;
            /**
             * Number of nano (10^-9) units of the amount. The value must be between -999,999,999 and +999,999,999 inclusive. If `units` is positive, `nanos` must be positive or zero. If `units`
             * is zero, `nanos` can be positive, zero, or negative. If `units` is negative, `nanos` must be negative or zero. For example $-1.75 is represented as `units`=-1 and
             * `nanos`=-750,000,000.
             */
            nanos?: number;
            /** The whole units of the amount. For example if `currencyCode` is `"USD"`, then 1 unit is one US dollar. */
            units?: string;
        }
        interface GoogleTypePostalAddress {
            /**
             * Unstructured address lines describing the lower levels of an address. Because values in address_lines do not have type information and may sometimes contain multiple values in a
             * single field (e.g. "Austin, TX"), it is important that the line order is clear. The order of address lines should be "envelope order" for the country/region of the address. In
             * places where this can vary (e.g. Japan), address_language is used to make it explicit (e.g. "ja" for large-to-small ordering and "ja-Latn" or "en" for small-to-large). This way, the
             * most specific line of an address can be selected based on the language. The minimum permitted structural representation of an address consists of a region_code with all remaining
             * information placed in the address_lines. It would be possible to format such an address very approximately without geocoding, but no semantic reasoning could be made about any of
             * the address components until it was at least partially resolved. Creating an address only containing a region_code and address_lines, and then geocoding is the recommended way to
             * handle completely unstructured addresses (as opposed to guessing which parts of the address should be localities or administrative areas).
             */
            addressLines?: string[];
            /**
             * Optional. Highest administrative subdivision which is used for postal addresses of a country or region. For example, this can be a state, a province, an oblast, or a prefecture.
             * Specifically, for Spain this is the province and not the autonomous community (e.g. "Barcelona" and not "Catalonia"). Many countries don't use an administrative area in postal
             * addresses. E.g. in Switzerland this should be left unpopulated.
             */
            administrativeArea?: string;
            /**
             * Optional. BCP-47 language code of the contents of this address (if known). This is often the UI language of the input form or is expected to match one of the languages used in the
             * address' country/region, or their transliterated equivalents. This can affect formatting in certain countries, but is not critical to the correctness of the data and will never
             * affect any validation or other non-formatting related operations. If this value is not known, it should be omitted (rather than specifying a possibly incorrect default). Examples:
             * "zh-Hant", "ja", "ja-Latn", "en".
             */
            languageCode?: string;
            /**
             * Optional. Generally refers to the city/town portion of the address. Examples: US city, IT comune, UK post town. In regions of the world where localities are not well defined or do
             * not fit into this structure well, leave locality empty and use address_lines.
             */
            locality?: string;
            /** Optional. The name of the organization at the address. */
            organization?: string;
            /**
             * Optional. Postal code of the address. Not all countries use or require postal codes to be present, but where they are used, they may trigger additional validation with other parts
             * of the address (e.g. state/zip validation in the U.S.A.).
             */
            postalCode?: string;
            /** Optional. The recipient at the address. This field may, under certain circumstances, contain multiline information. For example, it might contain "care of" information. */
            recipients?: string[];
            /**
             * Required. CLDR region code of the country/region of the address. This is never inferred and it is up to the user to ensure the value is correct. See https://cldr.unicode.org/ and
             * https://www.unicode.org/cldr/charts/30/supplemental/territory_information.html for details. Example: "CH" for Switzerland.
             */
            regionCode?: string;
            /** The schema revision of the `PostalAddress`. This must be set to 0, which is the latest revision. All new revisions **must** be backward compatible with old revisions. */
            revision?: number;
            /**
             * Optional. Additional, country-specific, sorting code. This is not used in most regions. Where it is used, the value is either a string like "CEDEX", optionally followed by a number
             * (e.g. "CEDEX 7"), or just a number alone, representing the "sector code" (Jamaica), "delivery area indicator" (Malawi) or "post office indicator" (e.g. Côte d'Ivoire).
             */
            sortingCode?: string;
            /** Optional. Sublocality of the address. For example, this can be neighborhoods, boroughs, districts. */
            sublocality?: string;
        }
        interface GoogleTypeTimeOfDay {
            /** Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time. */
            hours?: number;
            /** Minutes of hour of day. Must be from 0 to 59. */
            minutes?: number;
            /** Fractions of seconds in nanoseconds. Must be from 0 to 999,999,999. */
            nanos?: number;
            /** Seconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds. */
            seconds?: number;
        }
        interface GoogleTypeTimeZone {
            /** IANA Time Zone Database time zone, e.g. "America/New_York". */
            id?: string;
            /** Optional. IANA Time Zone Database version number, e.g. "2019a". */
            version?: string;
        }
        interface GroupsPerDocData {
            AuthorId?: string;
            GroupGaiaId?: string;
            /** Legacy group mysql id. */
            GroupId?: string;
            ThreadId?: string;
        }
        interface HomeGraphCommonRoute {
            /** The device ID defined by the agent. */
            agentDeviceId?: string;
            /** The agent's ID. Generally it is the agent's Google cloud project id. */
            agentId?: string;
            /**
             * chip endpoint index (if the target is CHIP). Set packed = true to handle error caused by b/32953375 when exporting this data. Note that we should never change this to non-repeated:
             * a packed field will not work properly if you change the field to non-repeated later.
             */
            chipEndpoint?: number[];
            /** Execution routing target. */
            targetType?: string;
        }
        interface HomeGraphCommonRoutingTable {
            /** List of supported execution route. */
            supportedRoutes?: HomeGraphCommonRoute[];
        }
        interface HomeGraphCommonTraitRoutingHints {
            /** Set to true for a non-local trait. */
            cloudFulfillmentOnly?: boolean;
            /**
             * Trait name, e.g., "action.devices.traits.MediaInitiation". See [device traits](https://developers.google.com/assistant/smarthome/traits). See
             * java/com/google/home/graph/common/devices/config/protoconf.pi for the exhaustive list of trait-strings.
             */
            trait?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoAnonTimingStatPair {
            name?: string;
            timeS?: number;
        }
        interface HtmlrenderWebkitHeadlessProtoBox {
            height?: number;
            width?: number;
            /** on horizontal axis */
            x?: number;
            /** on vertical axis */
            y?: number;
        }
        interface HtmlrenderWebkitHeadlessProtoChromiumTrace {
            chromiumTrace?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoConsoleLogEntry {
            /** Line number of the document which caused an error. */
            lineNumber?: number;
            /** Message which indicates the nature of the error. e.g. parse error, reference error (happens when javascript functions or variables are not resolvable) etc. */
            message?: string;
            /** message level */
            messageLevel?: string;
            /** The url of the document which has the error. */
            sourceUrl?: string;
            /** Stack trace which functions were called when generating the console log. The first frame is the innermost one. */
            stackTrace?: HtmlrenderWebkitHeadlessProtoScriptStackFrame[];
            /** Wall time (s) when the log entry was recorded */
            timestamp?: number;
        }
        interface HtmlrenderWebkitHeadlessProtoCookie {
            domain?: string;
            expiration?: number;
            httpOnly?: boolean;
            name?: string;
            path?: string;
            sameSite?: string;
            secure?: boolean;
            value?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoDocument {
            /** Document's base uri. */
            baseUri?: string;
            /** Document's charset. */
            charset?: string;
            contentHeight?: number;
            /** Document's language. */
            contentLanguage?: string;
            /**
             * These fields contain the actual width and height of the document content, which may exceed the size of the rendering viewport. *DEPRECATED* Use rendered_content_area instead. These
             * two fields always assume the content area begins at viewport coordinates (0,0).
             */
            contentWidth?: number;
            /**
             * A flat list of all the DOMTreeNodes in the DOM. A flat list is preferred to a tree to avoid recursion and potential stack overflows. Note that the first node in this list will
             * always be the root node.
             */
            domTreeNode?: HtmlrenderWebkitHeadlessProtoDOMTreeNode[];
            /**
             * A unique identifier for the frame (browser window of iframe) this document is loaded in. This identifier matches the identifiers used in the timeline data to identify frames and
             * therefore only set if the record_timeline field of the RenderRequest message was set to true. frame_id is not supported on Chromium.
             */
            frameId?: string;
            /** The name of the frame (browser window of iframe) this document is loaded in. May not be set if the frame name was empty. */
            frameName?: string;
            /**
             * -------------------------------------------------------------------------- Input context. These fields are copied from RenderRequest so that Document can be a self contained
             * protobuf. We would've liked to place them in a ## nested InputContext message but it's too late now. ## Time specified to RenderRequest.JavaScriptOptions.time_of_day, if any. ## End
             * of input context. Output-only fields below.
             */
            javascriptTimeOfDay?: number;
            /** The chain of redirects (and redirect methods) used to get to the final resource for this Document. Deprecated: Use the redirect events in the render_event field instead. */
            redirectHop?: HtmlrenderWebkitHeadlessProtoRedirectHop[];
            /** Contains a list of Resources which the renderer requested -- both those that were found and those that were not. Resources are returned in the order that they were requested. */
            referencedResource?: HtmlrenderWebkitHeadlessProtoReferencedResource[];
            /** The bounding box which represents the whole area of rendered content, which may exceed the size of the rendering viewport. It doesn't include the body's margin. */
            renderedContentArea?: HtmlrenderWebkitHeadlessProtoBox;
            /**
             * Different types of events which happened during rendering. All events for this document's frame are included, so for example if a confirmation dialog is created before a client
             * redirect to this document the ConfirmationDialogEvent will still be included even though the dialog was created by a different document. See render_event.proto for the types of
             * events which are recorded. Note that this is present regardless of whether record_timeline was set in the RenderRequest.
             */
            renderEvent?: HtmlrenderWebkitHeadlessProtoRenderEvent[];
            /** See htmlrender_webkit_headless_utils::SerializeRenderStyle() if a serialized css string is wanted. */
            renderStyle?: HtmlrenderWebkitHeadlessProtoStyle[];
            /**
             * A flat list of all the RenderTreeNodes from the render tree. A flat list is preferred to a tree to avoid recursion and potential stack overflows. Note that the first node in this
             * list will always be the RenderTreeNode for the #document node (aka root).
             */
            renderTreeNode?: HtmlrenderWebkitHeadlessProtoRenderTreeNode[];
            /**
             * DEPRECATED - This field to be removed mid-2011. If you need this, use the library directly: //google3/htmlrender/webkit_headless/snapshot_quality Indicates how good or bad the
             * rendering is from the perspective of the render tree. This is different from snapshot_quality_score in that the quality analysis examines everything that can be rendered, not just
             * the portion within the document's viewport. It also ignores missing resouces with fixed width/height specified in the tag. A score of 1 (100%) implies the entire document can be
             * rendered at the best quality and a score of 0 implies the entire document is unusable.
             */
            renderTreeQualityScore?: number;
            /**
             * Scroll offset of this document within the frame. Note that if expand_frame_to_content_height or expand_frame_to_content_width is true, this field reflects the final scroll offset
             * after frame expansion.
             */
            scrollX?: number;
            scrollY?: number;
            /**
             * DEPRECATED - This field to be removed mid-2011. If you need this, use the library directly: //google3/htmlrender/webkit_headless/snapshot_quality Indicates how good or bad the
             * rendered snapshot is within the rendered content area within the document's viewport. A score of 1 (100%) implies the snapshot is of best quality and a score of 0 implies the
             * snapshot is unusable.
             */
            snapshotQualityScore?: number;
            /** Document's title. */
            title?: string;
            /**
             * Document uri is the URL that this document was fetched from. The displayed URL and base URL may be different. If this document was not fetched from any URL (e.g. iframe with no src,
             * populated by script) uri will be "about:blank".
             */
            uri?: string;
            /** The page's layout size. */
            viewport?: HtmlrenderWebkitHeadlessProtoBox;
        }
        interface HtmlrenderWebkitHeadlessProtoDOMStorageItem {
            key?: string;
            securityOrigin?: string;
            value?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoDOMTreeNode {
            attribute?: HtmlrenderWebkitHeadlessProtoDOMTreeNodeAttribute[];
            /** An index per child. Indexes can be used to fetch the DOMTreeNodes from the list maintained by the Document. */
            childDomTreeNodeIndex?: number[];
            /** For elements, the actual url that was used to fetch the image. Note that this field is set only if it is different from the 'src' attribute value. */
            currentSourceUrl?: string;
            /** If the node represents an iframe or a frame then document will be set. */
            document?: HtmlrenderWebkitHeadlessProtoDocument;
            /**
             * Identifies the HTML tag type (IMG, P, DIV, etc). Applicable only for DOM nodes that are representative of html elements. For a list of possible types refer HtmlTagEnum defined in
             * webutil/html/htmltagenum.h.
             */
            htmlTagType?: number;
            /**
             * Whether this DOM node responds to mouse clicks. This includes e.g. nodes that have had click event listeners attached via JavaScript as well as e.g. anchor tags that naturally
             * navigate when clicked.
             */
            isClickable?: boolean;
            /** Name of the node (document, text, comment, div, etc). */
            name?: string;
            /** URL of the script, if any, which created or populated this node. */
            originUrl?: string;
            /** List of referenced resource indexes for any resources that this DOM tree node references. */
            referencedResourceIndex?: number[];
            /**
             * RenderTreeNode can be looked up from the list of RenderTreeNodes stored in the Document using render_tree_node_index. RenderTreeNode gives rendering information (bounding box, style
             * that was applied, etc). Note: 1. If a DOMTreeNode does not have a RenderTreeNode then it is safe to assume that the DOMTreeNode has no effect on the rendering. DOMTreeNodes for a ,
             */
            renderTreeNodeIndex?: number[];
            type?: string;
            /**
             * The node value is applicable for TEXT_NODEs, DOCUMENT_TYPE_NODEs, and user input elements such as , and <option>. For DOCUMENT_TYPE_NODEs, the value contains the publicId and
             * SystemId. For input elements, the value reflects the current value in the element at the time the snapshot was taken.
             */
            value?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoDOMTreeNodeAttribute {
            /** Identifies the HTML attribute type (src, width, height, etc). For a list of possible types refer HtmlAttributeEnum defined in webutil/html/htmlattrenum.h. */
            htmlAttributeType?: number;
            name?: string;
            value?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoFrameResizeEvent {
            resizeType?: string;
            visibleRectAfterResize?: HtmlrenderWebkitHeadlessProtoBox;
            visibleRectBeforeResize?: HtmlrenderWebkitHeadlessProtoBox;
        }
        interface HtmlrenderWebkitHeadlessProtoImage {
            /** The binary image data, stored in a format decided by the application and a particular RenderService implementation. */
            data?: string;
            height?: number;
            /** The page number if this is an image of a page from a print-mode rendering. */
            pageNumber?: number;
            /** The viewport from which this image was generated. This is relative to the upper left of the page's document. */
            viewport?: HtmlrenderWebkitHeadlessProtoBox;
            /** The width and height of the image stored in the data field. */
            width?: number;
        }
        interface HtmlrenderWebkitHeadlessProtoInitialLoadEvent {
            url?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoModalDialogEvent {
            /** Whether a confirm() or prompt() dialog was confirmed. Will not be present for an alert() dialog. */
            confirmed?: boolean;
            message?: string;
            /**
             * For a prompt() dialog, the result of the prompt. Will not be present for other types of dialogs. If confirmed == false and the prompt had a default value, result will contain the
             * default value.
             */
            result?: string;
            type?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoOffset {
            unit?: string;
            value?: number;
        }
        interface HtmlrenderWebkitHeadlessProtoPartialRender {
            /** Cookies at the time of snapshot creation. */
            cookie?: HtmlrenderWebkitHeadlessProtoCookie[];
            /** Current url as would appear in the web browser's address bar at the time of snapshot creation. */
            currentClientUrl?: string;
            /** Snapshot of the document DOM + Render trees, if requested */
            document?: HtmlrenderWebkitHeadlessProtoDocument;
            /** ID set by the render extension */
            id?: string;
            /** Image of the render, if requested */
            image?: HtmlrenderWebkitHeadlessProtoImage;
        }
        interface HtmlrenderWebkitHeadlessProtoPdf {
            /** The binary PDF data. */
            data?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoRectangle {
            bottom?: HtmlrenderWebkitHeadlessProtoOffset;
            left?: HtmlrenderWebkitHeadlessProtoOffset;
            right?: HtmlrenderWebkitHeadlessProtoOffset;
            /** A missing value for any field in this message means 'auto'. */
            top?: HtmlrenderWebkitHeadlessProtoOffset;
        }
        interface HtmlrenderWebkitHeadlessProtoRedirectEvent {
            /** The HTTP method of the request for the redirect target. */
            httpMethod?: string;
            /** For HTTP redirects, the HTTP status code returned in the initial HTTP response. */
            httpStatusCode?: number;
            refreshType?: string;
            /** True if the redirect led to a download instead of loading a new page. Note that such redirects can appear anywhere in the list of redirect events. */
            targetContentDownloaded?: boolean;
            targetUrl?: string;
            type?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoRedirectHop {
            type?: string;
            /** The redirect target url. */
            url?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoReferencedResource {
            /** True if this fetch was canceled due to render server policy. e.g. the page exceeded the fetch budget or an extension canceled the fetch. */
            canceled?: boolean;
            /**
             * Content type of this resource (webutil/http/content-type.h). The content type is from guess based on the file extension, any mime type in http headers at the beginning of the
             * content, any content-disposition http header, and the content body itself. Note: the content type defined in webutil/http/content-type.proto is incomplete. If you are interested in
             * missing types, please update the enum and the logic of content type detection.
             */
            contentType?: number;
            /**
             * DOMTreeNode index which has the url as one of its attributes specified using either src, href or background attributes. src attribute applies to img, script, frame and iframe nodes,
             * href applies to link nodes and background applies to body node. It is possible for a url to be referenced by multiple DOM nodes. For e.g. an tag with the same src attribute can
             * occur in multiple places within a document. It is possible for a url to not have any DOM node reference. For example, redirects don't have DOM tree nodes.
             */
            domTreeNodeIndex?: number[];
            /** True when a HTTP request succeeded but the resource was not made accessible to script due to a HTTP Access Control (CORS) failure. This field is not implemented on Chromium. */
            failedHttpAccessControlCheck?: boolean;
            /** Where this resource comes from. */
            fetchSourceInfo?: WirelessTranscoderFetchFetchSourceInfo[];
            /** The FetchStatus returned by the fetcher. Values are taken from wireless_transcoder_fetch.FetchConstants.FetchStatus in fetch_service.proto. The default value is SUCCESS(0). */
            fetchStatus?: string;
            /** HTTP headers from the fetcher. */
            httpHeader?: HtmlrenderWebkitHeadlessProtoReferencedResourceHttpHeader[];
            /** HTTP response code if we had tried to fetch the url. Absence of this field indicates either we have not tried to fetch the url or the fetcher never got back to us with any response. */
            httpResponseCode?: number;
            metadata?: WirelessTranscoderFetchFetchMetadata[];
            /** The post_data field is only valid when the HTTP request method is POST. */
            postData?: string;
            /** If the http_response_code is a HTTP redirect, the redirect target will be stored here. */
            redirectTarget?: string;
            /**
             * Indicates which referenced_resource_content (in RenderResponse) this RefencedResource points to. This field will be set only when there is referenced_resource_content for this
             * RefencedResource in RenderResponse.
             */
            referencedResourceContentIndex?: number;
            /** Only necessary headers are recorded. See google3/htmlrender/webkit_headless/resource_key.cc */
            requestHeader?: HtmlrenderWebkitHeadlessProtoReferencedResourceHttpHeader[];
            /** The HTTP request method (GET, HEAD, POST, etc) used for this request. Values are taken from the HTTPHeaders::Protocol enum in webutil/http/httputils.h. HTTPHeaders::PROTO_GET */
            requestMethod?: number;
            /** style index which has the url specified using either the background-image property or the list-style-image property. */
            styleIndex?: number[];
            /** Whether it is synchronously fetched. */
            synchronouslyFetched?: boolean;
            timing?: HtmlrenderWebkitHeadlessProtoReferencedResourceFetchTiming[];
            /** Does not have a #fragment. */
            url?: string;
            /** Additional information webkit about this resource. e.g. intended usage */
            webkitMetadata?: HtmlrenderWebkitHeadlessProtoWebKitFetchMetadata;
        }
        interface HtmlrenderWebkitHeadlessProtoReferencedResourceFetchTiming {
            finishMsec?: string;
            /** A string identifying the fetcher that added this timing information. */
            name?: string;
            /** UNIX epoch timestamps in milliseconds. */
            startMsec?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoReferencedResourceHttpHeader {
            name?: string;
            value?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoRenderEvent {
            frameResize?: HtmlrenderWebkitHeadlessProtoFrameResizeEvent;
            initialLoad?: HtmlrenderWebkitHeadlessProtoInitialLoadEvent;
            modalDialog?: HtmlrenderWebkitHeadlessProtoModalDialogEvent;
            redirect?: HtmlrenderWebkitHeadlessProtoRedirectEvent;
            /** The URL of the script which caused this event, if any. Analogous to origin_url in DOMTreeNode. */
            scriptOriginUrl?: string;
            /** Virtual time of the event, as an offset from the beginning of the render in seconds. */
            virtualTimeOffset?: number;
            windowOpen?: HtmlrenderWebkitHeadlessProtoWindowOpenEvent;
        }
        interface HtmlrenderWebkitHeadlessProtoRenderExtensionResult {
            /** Log messages and errors generated by extension script. */
            consoleLogEntry?: HtmlrenderWebkitHeadlessProtoConsoleLogEntry[];
            result?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoRenderResponse {
            /** Contains chromium trace generated during page rendering. This is present if a chromium_trace_config was provided in the request. */
            chromiumTrace?: HtmlrenderWebkitHeadlessProtoChromiumTrace;
            /** Contents of the browser's cookie jar. (if cookies_enabled was set to true in the RenderRequest). */
            cookie?: HtmlrenderWebkitHeadlessProtoCookie[];
            /** Contains the DOM tree, render tree and more. For details consult document.proto. */
            document?: HtmlrenderWebkitHeadlessProtoDocument;
            /** Provides extra debugging details when certain exception bits are set. */
            exceptionDetail?: string;
            /** Exceptions (possibly serious conditions) that occurred during this rendering. 0 means none. Bitfield encoding. See the RenderingException enum above for an explanation. */
            exceptions?: string;
            /** Render extension results (if `devtools_script` was provided with the request.) */
            extensionResult?: HtmlrenderWebkitHeadlessProtoRenderExtensionResult;
            /**
             * This field contains the final url as would appear in the web browser's address bar. Note that JavaScript can modify the contents of the location bar so this URL may not appear on
             * the list of referenced resources. If we fail to follow a redirect this field will contain the URL that we failed to redirect to, not the last one we successfully loaded.
             */
            finalClientUrl?: string;
            /**
             * Contains the viewport images rendered by webkit (if generate_image was set to true in the RenderRequest). Will also contain the print-mode images (if generate_print_mode_images was
             * set to true).
             */
            image?: HtmlrenderWebkitHeadlessProtoImage[];
            /** Contents of the browser's local storage. */
            localStorage?: HtmlrenderWebkitHeadlessProtoDOMStorageItem[];
            /** Partial render snapshots (if requested by a render extension) */
            partialRender?: HtmlrenderWebkitHeadlessProtoPartialRender[];
            /** Contains the PDF document (if generate_pdf was set to true in the RenderRequest) */
            pdf?: HtmlrenderWebkitHeadlessProtoPdf;
            /** Contents for all the urls fetched by the render server. This field is present only if generate_referenced_resource_content was set to true in the RenderRequest. */
            referencedResourceContent?: HtmlrenderWebkitHeadlessProtoResource[];
            /** Time to render the url, total size of a document, number of referenced images, etc will be part of RenderStats. */
            renderStats?: HtmlrenderWebkitHeadlessProtoRenderStats;
            /** Contents of the browser's session storage. */
            sessionStorage?: HtmlrenderWebkitHeadlessProtoDOMStorageItem[];
            /** Contains the page title produced by webkit, in the UTF-8 encoding. */
            title?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoRenderStats {
            /** Deliberately non-named fine timing stats. These are all related to each other and unrelated to other timing stats in this message. */
            anonRenderFineTimingStats?: HtmlrenderWebkitHeadlessProtoAnonTimingStatPair[];
            /** Any messages logged by the renderer to the console. Note that we capture a subset of the messages logged by the renderer here to avoid explosion. */
            consoleLogEntry?: HtmlrenderWebkitHeadlessProtoConsoleLogEntry[];
            counter?: HtmlrenderWebkitHeadlessProtoRenderStatsCounter[];
            /** Time to build document and render tree response data. */
            documentBuildTimeMsec?: number;
            /**
             * Number of dropped log messages. Since we capture only a subset of the messages in console_log_entry this field is included just so that the consumers can get an idea of how many
             * actual attempts were made by the renderer.
             */
            droppedLogEntryCount?: number;
            /** Image encoding (e.g. raw -> PNG) time. */
            imageEncodingTimeMsec?: number;
            /** Image scaling time. */
            imageScalingTimeMsec?: number;
            /** Time from starting render to document finished loading. This includes all fetches, parsing, decoding, running JavaScript, etc. */
            layoutTimeMsec?: number;
            /** Time required to paint a document into our buffer. */
            paintTimeMsec?: number;
            /** Total cost this render spent running and RPC cost in milliGCUs. */
            renderCostMgcu?: number;
            /** Render engine used to render this document. */
            renderEngine?: string;
            /** Total CPU time this render spent running in milliseconds. */
            renderRunningTimeMsec?: number;
            /** The CL from which the render engine was built. */
            renderServerBaselineCl?: string;
            /** Total wall time taken to render a document in milliseconds. */
            renderTimeMsec?: number;
            /** Total time spent in the sandbox in milliseconds. This time includes all phases measured individually below. */
            sandboxRenderTimeMsec?: number;
        }
        interface HtmlrenderWebkitHeadlessProtoRenderStatsCounter {
            count?: string;
            /** By convention, counters may contain a "." which we use to separate a metric name from a counter name in streamz. */
            name?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoRenderTreeNode {
            /**
             * Box is set for render blocks ( , , etc). Box for any RenderTreeNode can be found either in the RenderTreeNode itself or by traversing up the ancestors until a RenderTreeNode with a
             * Box is found.
             */
            box?: HtmlrenderWebkitHeadlessProtoBox;
            /**
             * child_render_tree_node_index is an index into the list of RenderTreeNodes stored in the Document. *** WARNING ***: Don't use this field. Applications should not rely on the
             * structure of the render tree. This is an internal browser implementation detail and it changes from time to time. Generally, applications should obtain rendering information by
             * starting with the relevant DOMTreeNode and following pointers from there to the relevant RenderTreeNodes.
             */
            childRenderTreeNodeIndex?: number[];
            /** Index of the DOMTreeNode for which this RenderTreeNode is applicable. This index can be used to lookup a DOMTreeNode from list of DOMTreeNodes stored in the Document. */
            domTreeNodeIndex?: number;
            inlineTextBox?: HtmlrenderWebkitHeadlessProtoRenderTreeNodeInlineTextBox[];
            /** The actual text that was rendered. This is applicable only for text nodes. */
            renderedText?: string;
            /** Style index is set for rendered nodes (text nodes, image nodes, widgets, etc). The style_index can be used to lookup the style from the list of styles stored in the Document. */
            styleIndex?: number;
        }
        interface HtmlrenderWebkitHeadlessProtoRenderTreeNodeInlineTextBox {
            box?: HtmlrenderWebkitHeadlessProtoBox;
            renderedText?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoResource {
            /**
             * content contains a complete HTTP response message including the HTTP status line, headers and body. For example: HTTP/1.1 200 OK\r\n Content-Type: text/html\r\n \r\n ... content ...
             * For inputs (RenderRequest.resource): Any HTTP content encoding (e.g. gzip) and transfer encoding (e.g. chunked) MUST be decoded. HTTP content and transfer encoding headers will be
             * ignored if present. For outputs (RenderResponse.referenced_resource_content): The body will be decoded (no content or transfer encoding) however any content or transfer encoding
             * headers present in the original fetch response will be passed through. Decoding this field requires a correct text encoding. The charset field of Document proto can be a good guess
             * but is not guaranteed to be correct.
             */
            content?: string;
            /** Where this resource comes from. */
            fetchSourceInfo?: WirelessTranscoderFetchFetchSourceInfo[];
            /** The url that contributes the final content. Only existed when metadata contains FetchReplyData. */
            finalContentUrl?: string;
            metadata?: WirelessTranscoderFetchFetchMetadata[];
            /**
             * The HTTP request method (GET, HEAD, POST, etc) used for this request. Values are taken from the HTTPHeaders::Protocol enum in webutil/http/httputils.h. If it's not set, we will
             * infer GET or POST based on the presence of post_data.
             */
            method?: number;
            postData?: string;
            /** Only necessary headers are included in the resource key by default. See google3/htmlrender/webkit_headless/resource_key.cc */
            requestHeader?: HtmlrenderWebkitHeadlessProtoResourceHttpHeader[];
            url?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoResourceHttpHeader {
            name?: string;
            value?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoScriptStackFrame {
            /** The current column number for the stack frame. */
            columnNumber?: number;
            /** The function name of the stack frame. */
            functionName?: string;
            /** The current line number for the stack frame. */
            lineNumber?: number;
            /** The URL of the script being executed. */
            url?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoStyle {
            backgroundAttachment?: string;
            /** Background color encoded as ARGB */
            backgroundColorArgb?: number;
            backgroundGradientColorStopArgb?: number[];
            backgroundGradientRepeat?: boolean;
            backgroundGradientType?: string;
            backgroundImageRepeat?: string;
            /** The url of the background image in the first layer. */
            backgroundImageUrl?: string;
            /** Background image position (x, y). */
            backgroundImageXPos?: HtmlrenderWebkitHeadlessProtoOffset;
            backgroundImageYPos?: HtmlrenderWebkitHeadlessProtoOffset;
            backgroundSize?: string;
            backgroundSizeHeight?: HtmlrenderWebkitHeadlessProtoOffset;
            /** Only present (but may be missing) if background_size == SIZE_LENGTH. */
            backgroundSizeWidth?: HtmlrenderWebkitHeadlessProtoOffset;
            borderColorArgbBottom?: number;
            borderColorArgbLeft?: number;
            borderColorArgbRight?: number;
            borderColorArgbTop?: number;
            borderPixelWidthBottom?: number;
            borderPixelWidthLeft?: number;
            borderPixelWidthRight?: number;
            borderPixelWidthTop?: number;
            borderStyleBottom?: string;
            borderStyleLeft?: string;
            borderStyleRight?: string;
            borderStyleTop?: string;
            /** Default value for clip is "auto", which is represented here as !has_clip(). */
            clip?: HtmlrenderWebkitHeadlessProtoRectangle;
            direction?: string;
            display?: string;
            /** Font and text decorations: */
            fontFamily?: string;
            fontSize?: number;
            fontStyle?: string;
            fontWeight?: number;
            /** Foreground color encoded as ARGB */
            foregroundColorArgb?: number;
            /**
             * Starting from Chromium, has_background is set when there is a non-empty specification for background_image, whether it be a url, gradient or other cases, such as cross-fade. Besides
             * setting this field, We additionally parse url and gradient cases and populate some of the following background fields.
             */
            hasBackground?: boolean;
            listStyleImageUrl?: string;
            listStyleType?: string;
            marginBottom?: HtmlrenderWebkitHeadlessProtoOffset;
            marginLeft?: HtmlrenderWebkitHeadlessProtoOffset;
            marginRight?: HtmlrenderWebkitHeadlessProtoOffset;
            /** Margin */
            marginTop?: HtmlrenderWebkitHeadlessProtoOffset;
            opacity?: number;
            overflowX?: string;
            overflowY?: string;
            paddingBottom?: HtmlrenderWebkitHeadlessProtoOffset;
            paddingLeft?: HtmlrenderWebkitHeadlessProtoOffset;
            paddingRight?: HtmlrenderWebkitHeadlessProtoOffset;
            /** Padding */
            paddingTop?: HtmlrenderWebkitHeadlessProtoOffset;
            position?: string;
            /** List of referenced resource indexes for any resources that this style references. (e.g. background images.) (see document.proto) */
            referencedResourceIndex?: number[];
            textAlign?: string;
            textDecoration?: string;
            textShadowColorArgb?: number;
            visibility?: string;
            /** Default value for z-index is "auto" which means "inherit from parent". */
            zIndex?: number;
        }
        interface HtmlrenderWebkitHeadlessProtoWebKitFetchMetadata {
            /** Chromium DevTools frame ID of the frame that initiated this fetch. Only populated in the streaming render service with FETCH_MODE_CLIENT. */
            devtoolsFrameId?: string;
            targetType?: string;
        }
        interface HtmlrenderWebkitHeadlessProtoWindowOpenEvent {
            /** Whether or not the window was allowed to be opened by the popup blocker. Unless user events are created with a render extension this should be false. */
            allowed?: boolean;
            /** The URL for the new window. Note that this is the URL after it has been processed by WebKit, so, for example, relative links passed to window.create() will have been made absolute. */
            url?: string;
            /** Window features passed to window.open(). */
            windowFeatures?: string;
            /** Window name passed to window.open(). If no name is provided this defaults to "_blank". */
            windowName?: string;
        }
        // tslint:disable-next-line:interface-name
        interface I18nPhonenumbersPhoneNumber {
            /** The country calling code for this number, as defined by the International Telecommunication Union (ITU). For example, this would be 1 for NANPA countries, and 33 for France. */
            countryCode?: number;
            /** The source from which the country_code is derived. */
            countryCodeSource?: string;
            /**
             * Extension is not standardized in ITU recommendations, except for being defined as a series of numbers with a maximum length of 40 digits. It is defined as a string here to
             * accommodate for the possible use of a leading zero in the extension (organizations have complete freedom to do so, as there is no standard defined). Other than digits, some other
             * dialling characters such as "," (indicating a wait) may be stored here.
             */
            extension?: string;
            /**
             * In some countries, the national (significant) number starts with one or more "0"s without this being a national prefix or trunk code of some kind. For example, the leading zero in
             * the national (significant) number of an Italian phone number indicates the number is a fixed-line number. There have been plans to migrate fixed-line numbers to start with the digit
             * two since December 2000, but it has not happened yet. See http://en.wikipedia.org/wiki/%2B39 for more details. These fields can be safely ignored (there is no need to set them) for
             * most countries. Some limited number of countries behave like Italy - for these cases, if the leading zero(s) of a number would be retained even when dialling internationally, set
             * this flag to true, and also set the number of leading zeros. Clients who use the parsing or conversion functionality of the i18n phone number libraries (go/phonenumbers) will have
             * these fields set if necessary automatically.
             */
            italianLeadingZero?: boolean;
            /**
             * The National (significant) Number, as defined in International Telecommunication Union (ITU) Recommendation E.164, without any leading zero. The leading-zero is stored separately if
             * required, since this is an uint64 and hence cannot store such information. Do not use this field directly: if you want the national significant number, call the
             * getNationalSignificantNumber method of PhoneNumberUtil. For countries which have the concept of an "area code" or "national destination code", this is included in the National
             * (significant) Number. Although the ITU says the maximum length should be 15, we have found longer numbers in some countries e.g. Germany. Note that the National (significant) Number
             * does not contain the National (trunk) prefix. Obviously, as a uint64, it will never contain any formatting (hyphens, spaces, parentheses), nor any alphanumeric spellings.
             */
            nationalNumber?: string;
            /** Full description of this field in the comment for italian_leading_zero since this field will only be set when italian_leading_zero is true. */
            numberOfLeadingZeros?: number;
            /**
             * The carrier selection code that is preferred when calling this phone number domestically. This also includes codes that need to be dialed in some countries when calling from
             * landlines to mobiles or vice versa. For example, in Columbia, a "3" needs to be dialed before the phone number itself when calling from a mobile phone to a domestic landline phone
             * and vice versa. Note this is the "preferred" code, which means other codes may work as well.
             */
            preferredDomesticCarrierCode?: string;
            /**
             * This field is used to store the raw input string containing phone numbers before it was canonicalized by the library. For example, it could be used to store alphanumerical numbers
             * such as "1-800-GOOG-411".
             */
            rawInput?: string;
        }
        interface ImageBaseThumbnailMetadata {
            /** the size of the stored thumbnail */
            byteSize?: number;
            /** SmartCrop crop-hints By default, this field is not populated. */
            crops?: ContentAwareCropsIndexing;
            /** DeepCrop crop-hints. Usage in thumbnails could be deprecated in favor or deep_crop_pixels (below). By default, this field is not populated. */
            deepCrop?: DeepCropIndexing;
            /** DeepCrop signal in pixels, equivalent to deep_crop (above) but with pixels instead of percentages. By default, this field is not populated. */
            deepCropPixels?: DeepCropPixels;
            /** the Amarna docid of the thumbnail */
            docid?: string;
            /** encrypted version of docid */
            encryptedDocid?: string;
            /** the fprint of the thumbnail */
            fprint?: string;
            /** the height of the stored thumbnail */
            height?: number;
            /** The mime_type of the thumbnail ("image/jpeg", "image/png", etc.). */
            mimeType?: string;
            originalHeight?: number;
            /** Not populated by Amarna/image pipelines, ever. This was apparently introduced by a customer that wished to extend ThumbnailMetadata with this custom data. */
            originalWidth?: number;
            type?: string;
            /** the width of the stored thumbnail */
            width?: number;
        }
        interface ImageBaseVideoPreviewMetadata {
            /** Size of the stored preview. */
            byteSize?: number;
            /** 64 bit docid of the original video. */
            docid?: string;
            /** TODO (yzliu): consider using duration_ms as field name since it is number of milliseconds. Duration of the preview in ms. */
            duration?: number;
            /** Expiration timestamp of preview in microseconds since epoch. */
            expirationTimestampMicros?: string;
            /** LINT.ThenChange(//depot/google3/video/crawl/indexing/signal_combiner.cc:video_preview) Fingerprint of the preview. */
            fprint?: string;
            /** Height of the stored preview. */
            height?: number;
            /** Mime type of the preview ("video/mp4"). */
            mimeType?: string;
            /** Indicates the state in Venom for this preview type. */
            state?: string;
            /** Timestamp of start of preview in ms. */
            timestamp?: number;
            /** LINT.IfChange */
            type?: string;
            /** Width of the stored preview. */
            width?: number;
        }
        interface ImageContentFlowProtoProd {
            /** Repeated so that multiple versions can exist in prod simultaneously. */
            starburst?: ImageContentStarburstVersionGroup[];
        }
        interface ImageContentQueryBoost {
            queryboost?: ImageContentQueryBoostQueryBoost[];
        }
        interface ImageContentQueryBoostQueryBoost {
            /** Score multiplier (fully normalized 1 is nop). */
            boost?: number;
            /** Canonicalized query string. */
            query?: string;
        }
        interface ImageContentStarburstVersionGroup {
            /** Raw dense float feature vector. */
            descriptorFloat?: number[];
            /**
             * Short descriptor for image content features, e.g. compressed bytes. This is the compressed version of descriptor_float below. It can be can be decompressed to descriptor_float with
             * a tiny bit of compression error (in most cases it should be totally fine).
             */
            descriptorShort?: string;
            enumVersion?: string;
            minorVersion?: string;
            /** Starburst tokens. */
            starburstTokens?: number[];
            /**
             * The following integers are currently used: Starburst V1: 1 Starburst V2: 2 Starburst V3: 3 Starburst V4: 4 Starburst Visual V4: 1004 This field is deprecated. Please try to use the
             * 'enum_version' in future.
             */
            version?: number;
        }
        interface ImageData {
            /** Warning: adaboost_image_feature_porn* and imageFeaturePorn fields are DEPRECATED in favor of brain_porn_scores. Please do not use them. Contact safesearch@ for transition advice. */
            adaboostImageFeaturePorn?: number;
            adaboostImageFeaturePornMinorVersion?: number;
            adaboostImageFeaturePornVersion?: number;
            /** Present for animated images only: additional animatated image perdoc data. */
            animatedImageData?: ImageRepositoryAnimatedImagePerdocData;
            /**
             * A [0..1] SafeSearch scores based on image pixels, using Google Brain: porn, csai, violence, medical, and spoof. For porn only, if available prefer final_porn_score as it should be
             * more precise than brain_porn_scores.porn_score.
             */
            brainPornScores?: ImageSafesearchContentBrainPornAnnotation;
            /** A string that indicates the version of SafeSearch classifier used to compute brain_porn_scores. */
            brainPornScoresVersion?: string;
            /** This is the image docid used in image search. For ImageData protos coming from Alexandria/Freshdocs, this is a 'required' field that MUST be populated. */
            canonicalDocid?: string;
            /** A score in (0, 1] to indicate how likely this image is considered as a click magnet based on clicks received from bad queries. */
            clickMagnetScore?: number;
            /** Image content based classifier scores. */
            clipartDetectorScore?: number;
            clipartDetectorVersion?: number;
            /**
             * Like is_visible, this is a property of the (web-doc, img_url) pair not just the image. A high codomain_strength indicates high confidence based on collected stats that the image is
             * hosted on a companion domain. If not enough stats are available for codomain strength, this field may be absent in ImageData, and hence the CompositeDoc. Do not place negative
             * values here. Permitted values range between 0 and image_quality_codomain::kMaxCodomainStrength defined in //image/quality/codomain/codomain-stats-utils.h.
             */
            codomainStrength?: number;
            /** Fraction of the image that contains pixels over a certain saturation threshold: can be used to determine if the image is grayscale or not. */
            coloredPixelsFrac?: number;
            /**
             * Colorness scores for the image. Each score represents the amount of a particular color in the image. At the current time, there are 12 colors, so there should always be 0 or 12
             * values in this array. The 12 colors are black, blue, brown, gray, green, orange, pink, purple, red, teal, white, yellow. The convention is that the scores are stored in alphabetical
             * order, so the first score is black, and the last score is yellow.
             */
            colorScore?: number[];
            colorScoreVersion?: number;
            /** Earliest known crawl time among all neardups of this image (go/imagecontentage). */
            contentFirstCrawlTime?: number;
            /** Corpus scoring info for images indexed through Amarna. */
            corpusSelectionInfo?: CorpusSelectionInfo[];
            /** The content-aware cropping information. */
            crops?: ContentAwareCropsIndexing;
            /** DeepCrop based cropping information. See go/creatism/deepcrop for details. */
            deepCrop?: DeepCropIndexing;
            /** Productionized Deep Image Engagingness score. */
            deepImageEngagingness?: ImageRepositoryDeepImageEngagingnessOutput;
            /** VSS generated deep tags for shopping images. */
            deepTags?: CommerceDatastoreImageDeepTags;
            /**
             * fingerprint(non-canonicalized absolute image url) This is *not* the image docid. Use canonical_docid instead. For ImageData protos coming from Alexandria/Freshdocs, this is a
             * 'required' field that MUST be populated. But once again, this is very likely NOT something you need. Use canonical_docid instead.
             */
            docid?: string;
            /** the EXIF/IPTC metadata */
            embeddedMetadata?: ImageExifImageEmbeddedMetadata;
            /** The thumbnail is guaranteed to be kept in the serving system until the expiration timestamp has passed, in microseconds. */
            expirationTimestamp?: string;
            /**
             * The EXIF generated by photos backend team's (more specifically FIFE's) thumbnailer library. This exif model is more comprehensive since a dedicated team is constantly improving it
             * and adding new fields over time. This is currently populated by moonshine for selected corpora.
             */
            extendedExif?: PhotosImageMetadata;
            /** Properties used in featured imagesearch project. inspiration_score indicates how well an image is related to products, or how inspirational it is. */
            featuredImageProp?: ImageMonetizationFeaturedImageProperties;
            /** True file format (not extension). */
            fileFormat?: string;
            /** A [0..1] porn score based on some image-level features (like content score, referrer statistics, navboost queries, etc.). See class RiflePornScorer for more details. */
            finalPornScore?: number;
            /** A string that indicates the version of SafeSearch classifier used to compute final_porn_score. */
            finalPornScoreVersion?: string;
            /** Earliest known timestamp about this image. Today, this is the timestamp when the content key was generated for this image. The time is in seconds. */
            firstCrawlTime?: number;
            /** The first time this image URL was seen on the containing web page. Only set during web indexing. */
            firstTimeSeenOnDocSec?: number;
            /** Use image_perdoc.h to read/write 'flags'. */
            flags?: number;
            /**
             * The output of various features generated by the Flow framework, most importantly data from Starburst (go/starburst). Do NOT interact with the internals of this proto since they may
             * change over time. Instead, use the existing interfaces that consume FlowProtoProd's directly, e.g., image/mustang/content/image_content_distance.h For more info, please contact
             * image-content-core@.
             */
            flowOutput?: ImageContentFlowProtoProd;
            h2c?: number;
            /** 'Hovers to Impressions' and 'Hovers to Clicks' ratios for an image. */
            h2i?: number;
            /** Hate logo detections from the VSS logo_recognition module. */
            hateLogoDetection?: ImageUnderstandingIndexingAnnotationGroup;
            /** Height */
            height?: number;
            /** Image Content Scored per query boosts. Currently this is filled by the pamir algorithm and populates the pamir_section. */
            imageContentQueryBoost?: ImageContentQueryBoost;
            /** A set of query fingerprints and confidence scores. There queries are supposed to be relevant to the image with high confidence. */
            imageExactBoost?: ImageExactBoost;
            /** Indicates license info of this image, which will tell image search users how to use this image legally. */
            imageLicenseInfo?: ImageSearchImageLicenseInfo;
            imagerank?: number;
            /**
             * Regions detected within the image (go/images-region-search-edd). Regions contain bounding boxes circumscribing objects of interest in the image, along with object labels. Regions
             * may overlap.
             */
            imageRegions?: ImageRegionsImageRegions;
            /** IIP in scope signal (go/iip). Set to true if the image is annotated with any iip_in_scope entities (go/iukp-trust-v2). */
            isIipInScope?: boolean;
            /** If this image was not selected for indexing by imagesearch, these fields say so and explain why. */
            isIndexedByImagesearch?: boolean;
            /** True if the original image contains multiple frames (e.g., for animated or stereoscopic images). */
            isMultiframe?: boolean;
            /**
             * Field to indicate the image is unwanted for search index. The data is propagated from amarna to alexandria to be annotated in the cdoc. Refer to
             * image/repository/proto/unwanted_content.proto for more info.
             */
            isUnwantedContent?: boolean;
            /** True if the image is inlined on the page (typicially via ) or false if the image is linked to (via an href). */
            isVisible?: boolean;
            /** Fraction of image covered by the largest face (should match largestFaceFraction, but without scaling). In perdocs, is set only if numberFaces > 0. */
            largestFaceFrac?: number;
            /** Fraction of image covered by the largest face, scaled by 1000. Warning: Is DEPRECATED in favor of largest_face_frac. Do not use. */
            largestFaceFraction?: number;
            /** Most recent timestamp in seconds when this URL was crawled. */
            lastCrawlTime?: number;
            /** Indicates the web-master opt-in state of this image, and will be used for Google products to decide usage rights like showing large previews. */
            licensedWebImagesOptInState?: string;
            lineartDetectorScore?: number;
            lineartDetectorVersion?: number;
            multibangKgEntities?: ImageDataMultibangEntities;
            nearDupFeatures?: string;
            nearDupFeaturesSmall?: string[];
            /**
             * The following fields contain information about a smaller and less powerful version of the hash, needed for neardup retrieval. A compressed and an encoded version of the small hash
             * are stored below. The smaller hash may have a few variants to increase recall. NOTE: This hash is generated by V2 hash computation. A compressed version of the small hash.
             * Currently, a 4-byte fingerprint.
             */
            nearDupFeaturesSmallVersion?: number;
            /** Image content derived data used for finding image near dups. NOTE: This hash is generated by V1 hash computation. */
            nearDupFeaturesVersion?: number;
            /**
             * Productionized Nima AVA score. Both this field and nima_vq were added on the top of nima_ava_score and nima_vq_score because the signals are already integrated with Batch Amarna in
             * image/repository/schema/global_output_tags.h using NimaOutput.
             */
            nimaAva?: ImageRepositoryNimaOutput;
            /** Productionized Nima VQ score. */
            nimaVq?: ImageRepositoryNimaOutput;
            noIndexReason?: string[];
            /** Number of faces detected in the image */
            numberFaces?: number;
            /** Pruned OCR Goodoc see vss_aksara_ocr_util.h for the fields copied. */
            ocrGoodoc?: GoodocDocument;
            /** Ocr detected by ocr_taser module. */
            ocrTaser?: GoodocDocument;
            /** Text lines detected by OCR engine. */
            ocrTextboxes?: OcrPhotoTextBox[];
            /** For an image not explicitly visible on this page, the following url is the one which most closely matches it. */
            onPageAlternateUrl?: string;
            /** Encodes face number and largest face frac into a small package for storage in mustang. This is calculated directly from FaceDetectionResult. */
            packedFullFaceInfo?: FaceIndexing;
            /** Contains person attributes from the LookNet-Person model and the Style AI Iconic Person Scorer for the most iconic person in a style image. */
            personAttributes?: LensDiscoveryStylePersonAttributes;
            /** Contains person detection result. */
            personDetectionSignals?: LensDiscoveryStylePersonDetectionSignals;
            photoDetectorScore?: number;
            photoDetectorVersion?: number;
            /** Used by the segindexer for combined www+image indices. */
            pornFlagData?: PornFlagData;
            /** Restricts computed before building a Mustang index. */
            precomputedRestricts?: PrecomputedRestricts;
            /** Rank in near-dup cluster (go/image-rank-in-neardup-cluster). The rank is 1-indexed: rank 1 is the best. */
            rankInNeardupCluster?: number;
            /** A string representation of all the restricts associated with this image. */
            restrictStrings?: string[];
            /**
             * CSV list of user agents for which this image should be considered roboted. Note: All images are crawled using googlebot-images, this exists for clients that require additional
             * restrictions beyond googlebot-images such as news.
             */
            robotedAgents?: string;
            /** The Shoppable Images product information to be annotated in the Cdoc. All fields will be populated except the product location bounding box. */
            shoppingProductInformation?: ImageRepositoryShoppingProductInformation;
            /** Size in bytes of original (non-thumbnail) */
            size?: number;
            /** Web docids that correspond to high ranked smeared landing pages for this image. Used for conditional retrieval of actionable landing pages for image search. */
            smearedTopWebLandingPageDocids?: string[];
            smearedTopWebLandingPages?: SmearedWebLandingPageEntry[];
            /** Aesthetics score of a style image. */
            styleAestheticsScore?: LensDiscoveryStyleAestheticsScoreSignals;
            /** Prediction of a style image type: Stage, Stock, Street or Outfits. */
            styleImageType?: LensDiscoveryStyleStyleImageTypeSignals;
            /** This field is for testing purposes, more information in go/media-dirt-2022. */
            testingScore?: number;
            thumbHeight?: number;
            thumbnail?: ImageDataThumbnail[];
            thumbSize?: number;
            /** Thumbnail width. */
            thumbWidth?: number;
            /** Time in seconds since epoch after which this image should be considered unavailable. */
            unavailableAfterSecs?: string;
            /** Canonicalized absolute image url. */
            url?: string;
            whiteBackgroundScore?: number;
            /** Image is likely an object on a white background (value on [0,1]). */
            whiteBackgroundScoreVersion?: number;
            width?: number;
        }
        interface ImageDataMultibangEntities {
            entity?: ImageDataMultibangEntitiesMultibangEntity[];
        }
        interface ImageDataMultibangEntitiesMultibangEntity {
            /** Entity ID. */
            entityId?: string;
            /** Multibang score. */
            score?: number;
        }
        interface ImageDataThumbnail {
            /** The thumbnail is guaranteed to be kept in the serving system until the expiration timestamp has passed, in microseconds. */
            expirationTimestampMicros?: string;
            height?: number;
            mimeType?: string;
            size?: number;
            type?: string;
            width?: number;
        }
        interface ImageExactBoost {
            navquery?: ImageExactBoostNavQuery[];
        }
        interface ImageExactBoostNavQuery {
            /** Associated confidence scores for the image for the query. */
            confidence?: number;
            /** Click-based rank of the image for this query. */
            imageClickRank?: number;
            /** Query fingerprint. */
            navFp?: string;
            /** The normalized raw query text. */
            navQuery?: string;
            /** List of all referrers, sorted by their rank (stored in Moosedog). */
            referrerDocid?: string[];
            /** Rank of the current web doc referrer (stored in docjoins). */
            referrerRank?: number;
        }
        interface ImageExifImageEmbeddedMetadata {
            altitude?: number;
            aperture?: number;
            /** Text fields EXIF_TAG_ARTIST */
            author?: string;
            /** EXIF_TAG_XP_AUTHOR */
            author2?: string;
            brightness?: number;
            /** Device - Camera raw text without normalization */
            cameraMaker?: string;
            /** raw text without normalization */
            cameraModel?: string;
            /** This is the extracted serial number from EXIF (the source depends on camera, most of the cameras store it in makers note tag). */
            cameraSerialNumber?: string;
            /** Capturing settings in time_t */
            captureTime?: string;
            colorSpace?: number;
            /** EXIF_TAG_USER_COMMENT */
            comments?: string;
            /** EXIF_TAG_XP_COMMENT */
            comments2?: string;
            continousDriveMode?: boolean;
            /** EXIF_TAG_COPYRIGHT */
            copyright?: string;
            /** Location from IPTC @deprecated: Use iptc.location instead. */
            deprecatedCity?: string;
            deprecatedCountry?: string;
            deprecatedState?: string;
            /** EXIF_TAG_IMAGE_DESCRIPTION */
            description?: string;
            destBearing?: number;
            /** Bearing and distance to destination point. */
            destBearingRef?: number;
            destDistance?: number;
            /** GPS location of destination point. */
            destLatitude?: number;
            destLongitude?: number;
            digitalZoomRatio?: number;
            exposureBias?: number;
            /** 1-8, see EXIF definition */
            exposureProgram?: number;
            exposureTime?: number;
            flashUsed?: boolean;
            focalLength?: number;
            /** convert to match 35mm film camera */
            focalLength35mm?: number;
            focalPlaneResUnit?: number;
            focalPlaneXres?: number;
            focusMode?: string;
            /** Dilution of precision. HDOP/PDOP depends on measure mode. Find out more at http://en.wikipedia.org/wiki/Dilution_of_precision_(GPS) */
            gpsDop?: number;
            gpsMeasureMode?: string;
            gpsStatus?: string;
            /** in meters */
            hPositioningError?: number;
            imageHeight?: number;
            imageWidth?: number;
            /** GPS Heading 0.00 to 359.99 degrees */
            imgDirection?: number;
            imgDirectionRef?: string;
            iptc?: ImageExifIPTCMetadata;
            iso?: number;
            /** EXIF_TAG_XP_KEYWORDS */
            keywords?: string;
            /** GPS location +/- 90 inclusive */
            latitude?: number;
            /**
             * Device - Lens We use this extended id to identify a lens uniquely. Canon: "%d %d %d"=.. Nikon: "%.2X %.2X %.2X %.2X %.2X %.2X %.2X %.2X" Don't change the format of the internal lens
             * id because we use them to look up the lens names.
             */
            lensId?: string;
            lensMaker?: string;
            lightSource?: number;
            longFocal?: number;
            /** +/- 180 inclusive */
            longitude?: number;
            maxApertureAtLongFocal?: number;
            maxApertureAtShortFocal?: number;
            /** 1-6, see EXIF definition */
            meteringMode?: number;
            /** in time_t */
            modificationTime?: string;
            orientation?: string;
            shortFocal?: number;
            /** EXIF_TAG_SOFTWARE */
            software?: string;
            /** EXIF_TAG_XP_SUBJECT */
            subject?: string;
            subjectDistance?: number;
            subjectLocationX?: number;
            subjectLocationY?: number;
            /** EXIF_TAG_XP_TITLE */
            title?: string;
            /** pixels per inch */
            xResolution?: number;
            /** pixels per inch */
            yResolution?: number;
        }
        interface ImageExifIPTCMetadata {
            /** Page URL about how to acquire this licensable image. */
            acquireLicensePage?: string;
            artwork?: ImageExifIPTCMetadataArtwork[];
            contactinfo?: ImageExifIPTCMetadataContactInfo;
            copyrightNotice?: string;
            /** IPTC authorship & copyright related fields. */
            creator?: string[];
            creditLine?: string;
            /** Time (in seconds) */
            dateCreated?: string;
            dateExpired?: string;
            dateReleased?: string;
            description?: string;
            event?: string;
            headline?: string;
            /** PLUS field, not used. */
            imageSupplier?: string;
            instructions?: string;
            keywords?: string[];
            /** License URL about how to distribute the image. */
            licenseUrl?: string;
            location?: ImageExifIPTCMetadataLocation;
            /** Location of the camera */
            locationCreated?: ImageExifIPTCMetadataLocationInfo;
            /** Location shown on the image */
            locationShown?: ImageExifIPTCMetadataLocationInfo[];
            modelReleaseStatus?: string;
            propertyReleaseStatus?: string;
            rightsUsageTerms?: string;
            source?: string;
            supplementalCategories?: string[];
            /** IPTC description related fields. */
            title?: string;
        }
        interface ImageExifIPTCMetadataArtwork {
            /** Other fields omitted. */
            title?: string;
        }
        interface ImageExifIPTCMetadataContactInfo {
            address?: string;
            city?: string;
            country?: string;
            email?: string;
            phone?: string;
            postalCode?: string;
            state?: string;
            webUrl?: string;
        }
        interface ImageExifIPTCMetadataLocation {
            city?: string;
            country?: string;
            countryCode?: string;
            state?: string;
            subLocation?: string;
            worldRegion?: string;
        }
        interface ImageExifIPTCMetadataLocationInfo {
            city?: string;
            country?: string;
            countryCode?: string;
            state?: string;
            subLocation?: string;
            worldRegion?: string;
        }
        interface ImageMonetizationFeaturedImageProperties {
            /** How an image is inspirational, [0, 1]. */
            inspirationScore?: number;
        }
        interface ImageMoosedogCrawlState {
            code?: string;
            /** Each of the above not_crawled_reason will have a set of detailed reason defined in crawler/trawler/trawler_enums.proto. */
            detailedReason?: number;
            /** The status returned when RPCs are used to internally fetch the image (eg. from FIFE). */
            internalStatus?: UtilStatusProto;
            /** Specifies if the current crawl state is terminal. */
            isTerminal?: boolean;
            /** Time in seconds since epoch after which this image should be considered unavailable. */
            noIndexAfterTimestamp?: string;
            notCrawledReason?: string;
            /** When true, it means that a non-terminal state has overwrote a terminal one. */
            overrodeTerminalState?: boolean;
            /** The repid for the urls. This repid is the id given to the dupe cluster this url belongs to. */
            repid?: string;
            /**
             * A comma separated list of user agents for which this image should be considered roboted. All images are crawled using googlebot-images and this exists here purely for informative
             * reasons.
             */
            robotedAgents?: string;
            /**
             * The url at which we crawled this content. With us starting to use repids the crawl table key no longer is suggestive of the url. In addition this is used in Amarna to detect race
             * conditions between a reference changing its crawl directive and the original crawl job finishing.
             */
            url?: string;
            /**
             * Set to true if the url is taken down by clients. This indicates that this crawl state is used to fast remove the crawl result of the url instead of waiting for Multiverse crawl
             * results. For more information, please refer to go/amarna-url-deletion.
             */
            urlDeleted?: boolean;
        }
        interface ImageMustangImageLinkSelectionInfo {
            /** score calculated in image selection phase, higher imagelink_selection_score more relevant the link is related to the web page */
            webRelevanceScore?: number;
        }
        interface ImageMustangShoppingOffer {
            inferredImageTypes?: string[];
            ipsOfferId?: string;
        }
        interface ImagePerDocData {
            /** entropy and color values for thumbnail (4 bytes consisting of R, G, B and entropy values) */
            DEPRECATEDEntropyColor?: number;
            /** about 10 bytes */
            filename?: string;
            /** image_perdoc.h */
            flags?: number;
            height?: number;
            width?: number;
        }
        interface ImagePornDebugInfo {
            info?: string;
        }
        interface ImageRegionsImageRegion {
            /** The bounding box of the region. */
            boundingBox?: PhotosVisionGroundtruthdbNormalizedBoundingBox;
            /** The confidence score associated with the bounding box. */
            boundingBoxScore?: number;
            /** A unique identifier for the region within the image. The id is unique only among other regions in the image. */
            id?: string;
            /** Set true if the region represents a product, i.e., if any of its labels are on a product labels whitelist. See ImageRegionsConfig for details on the product whitelist. */
            isProduct?: boolean;
            /** The score for this region based on how visually similar its neighbors are. */
            knnScore?: number;
            /** The label group corresponding to the first LabelParams listed in ImageRegionsConfig. */
            labelGroup?: ImageUnderstandingIndexingLabelGroup;
            /** The version string of the labels with which the region was processed. */
            labelVersion?: string;
            /** The primary label associated with the region. Specifically, the highest-scored whitelisted label associated with the region. See ImageRegionsConfig for details on the whitelist. */
            primaryLabel?: ImageUnderstandingIndexingLabel;
            renderType?: string;
            /** The starburst v4 features and tokens for the region. */
            starburstV4?: ImageUnderstandingIndexingFeature;
        }
        interface ImageRegionsImageRegions {
            /** The final_porn_score for the image. */
            finalPornScore?: number;
            /** The final_violence_score for the image. */
            finalViolenceScore?: number;
            /** The output of various features generated by the Flow framework, most importantly data from Starburst (go/starburst). */
            flowOutput?: ImageContentFlowProtoProd;
            /** True if the image has a 300k thumb. */
            has300kThumb?: boolean;
            /** True if the image has navboost. */
            hasNavboost?: boolean;
            /** True if the image is iu-inappropriate. */
            isIuInappropriate?: boolean;
            /** The pedo_score of the image. */
            pedoScore?: number;
            /** The precomputed restricts for the image. */
            precomputedRestricts?: PrecomputedRestricts;
            /** The racy_score of the image. */
            racyScore?: number;
            /** The list of regions. */
            region?: ImageRegionsImageRegion[];
        }
        interface ImageRepositoryAmarnaCloudSpeechSignals {
            /**
             * If this field is set to true, it means that Youtube already processed the ASR from S3 for the langID. Please find the ASR result from transcript_asr in
             * google3/image/repository/proto/video_search.proto instead.
             */
            duplicateOfYtS3Asr?: boolean;
            /**
             * The language id input for creating this ASR without regional info. Same format as in go/ytlangid. This field is populated in Kronos Amarna Cloud Speech operator and passed to
             * Amarna, but it is cleared before stored in Amarna's metadata table.
             */
            langWithoutLocale?: string;
            /** Identifying which ASR models are used for the result */
            modelIdentifier?: string;
            /** Raw results from Cloud Speech API */
            results?: ImageRepositorySpeechRecognitionResult[];
            /**
             * This field contains full (stitched) transcription, word-level time offset , and word-level byte offset. The value of this field is derived from the SpeechRecognitionResult field
             * above.
             */
            transcriptAsr?: PseudoVideoData;
        }
        interface ImageRepositoryAmarnaSignalsBlob {
            frameFeatures?: DrishtiFeatureSetDataSequence;
        }
        interface ImageRepositoryAmarnaSignalsBlobInfo {
            /** Blob id for AmarnaSignalsBlob (see `Blob proto` section of go/revisit-frame-level-signals-amarna). */
            signalsBlobId?: string;
            /**
             * Additional timestamp field for when the blob is written/updated, serving as the dirty field to help checksum-based update push (see `Dirty field` section in
             * go/revisit-frame-level-signals-amarna).
             */
            signalsBlobUpdateTimestamp?: string;
        }
        interface ImageRepositoryAmarnaStatus {
            reason?: string;
            status?: string;
        }
        interface ImageRepositoryAnimatedImagePerdocData {
            /**
             * Aggregated porn scores for animated images. Aggregated using max sampling rate / max duration. Note the plan is to fold these scores into existing summarized scores, for cases where
             * these scores are available. See tracking bug b/63580795.
             */
            aggregatedPornScores?: ImageSafesearchContentBrainPornAnnotation;
            /** Total duration of animation, in ms. */
            durationMs?: number;
        }
        interface ImageRepositoryApiItagSpecificMetadata {
            /** Timestamp (measured in seconds since epoch) after which Amarna will delete the serving transcode. */
            expirationTimestampSec?: string;
            /** The Venom Genus that this transcode was produced for. */
            genus?: string;
            /** Indicates the state in Venom for this transcode type. */
            state?: string;
            /** transcode type which are available for the video. */
            transcodeItag?: number;
            /** The Venom ID that this transcode was produced for. */
            videoId?: VideoAssetsVenomVideoId;
            /**
             * Indicates xtags if present. Xtag makes the different transcode. For transcode "MP4_AVCBASE640_AAC/af=sq" (itag 18 with xtag), "af=sq" is the xtag part. This is a different transcode
             * than "MP4_AVCBASE640_AAC" (itag 18).
             */
            xtagsList?: ImageRepositoryApiXtagList;
        }
        interface ImageRepositoryApiXtag {
            /** Names are all stored case-sensitive, and no case-folding is done for comparisons. */
            name?: string;
            /** The value associated with this Xtag. Values are all stored case-sensitive, and no case-folding is done for comparisons. */
            value?: string;
        }
        interface ImageRepositoryApiXtagList {
            xtags?: ImageRepositoryApiXtag[];
        }
        interface ImageRepositoryContentBasedVideoMetadata {
            /** A hash of the video bytes used as a key to Amarna's video_metadata table. */
            amarnaDocid?: string;
            /** Timestamp of the last successful Ares classification request. */
            aresClassificationRequestTimestamp?: string;
            /**
             * Both audio- and audio-video-files are treated as videos during indexing (whether they share a container format, like .mp4, or not, like .mp3). This bool indicates that there's no
             * video track, just an audio track.
             */
            audioOnly?: boolean;
            /** Transcript generated from Cloud Speech API */
            cloudSpeechSignals?: ImageRepositoryAmarnaCloudSpeechSignals;
            /**
             * Video Understanding Golden features. (go/amarna-video-signals#golden-signals) Note: Golden6 features (names matching "video_*") are DEPRECATED. Please migrate to Golden7
             * ("VideoFeatures.*"). For more context, see go/golden7/migrating-from-golden6 and go/amarna-golden-feature-tracker. Signals popluated in Raffia cdoc.doc_videos are configured in
             * cs/symbol:AMARNA_EXPORTED_GOLDEN7_FEATURES.
             */
            featureSetData?: DrishtiFeatureSetData;
            /** Golden7 video-level people features. (go/ypf-video-features) */
            golden7SoapboxSummary?: DrishtiFeatureSetData;
            /** Metadata related to Inline playback on the Interest Feed. This field is filled by Hamilton. */
            inlinePlayback?: VideoCrawlVideoInlinePlaybackMetadata;
            languageIdentification?: VideoTimedtextS4ALIResults;
            /** Legos results */
            legosAnnotationData?: VideoLegosLegosAnnotationsSets;
            /** LMS preview frame perdocs. Timestamps of the frame perdocs are from the original video, not from the preview. */
            lmsPreviewFramePerdocs?: ImageRepositoryFramePerdocs;
            /**
             * When Transcode itag 140 is requested, MediaAnalyzer (as the part of Viper graph) generates audio info including loudness_data, which is then published to Streamer. For Audio news
             * client, we extract this loudness data from Streamer to this field.
             */
            loudnessData?: VideoStorageLoudnessData;
            /** Information about the media file, such as duration, resolution, and detail about each audio/video stream. Note that it contains no PII. */
            mediaInfo?: VideoMediaInfo;
            representativeFrameData?: ImageData;
            s3LanguageIdentification?: ImageRepositoryS3LangIdSignals;
            /** Contains SafeSearch video classification outputs which are vertical_name/float pairs. */
            safesearchVideoContentSignals?: SafesearchVideoContentSignals;
            /** 64 bit docid used for retrieving video previews. */
            searchDocid?: string;
            /** Amarna signals blob that contains large-size signals like VCA frame-level signals. */
            signalsBlob?: ImageRepositoryAmarnaSignalsBlob;
            /** Information for the amarna signals blob. */
            signalsBlobInfo?: ImageRepositoryAmarnaSignalsBlobInfo;
            speechProperties?: IndexingSpeechSpeechPropertiesProto;
            thumbnailerData?: VideoPipelineViperThumbnailerColumnData;
            /**
             * Thumbnail quality score predict how visual pleasing a thumbnail is, based on the model trained with deep neural networks.(go/thumb_features_dd) Note the signal currently only
             * available for Youtube videos.
             */
            thumbnailQualityScore?: VideoThumbnailsThumbnailScore;
            /** Metadata about each transcode requested. */
            transcodeMetadata?: ImageRepositoryApiItagSpecificMetadata[];
            /** Speech related metadata */
            transcriptAsr?: PseudoVideoData;
            /** Data about whether or not the video was truncated. */
            truncationInfo?: ImageRepositoryFileTruncationInfo;
            /** If set, video has been deleted using the deletion service (MediaDeletionService). */
            unwantedContent?: ImageRepositoryUnwantedContent;
            /**
             * The video id in the venom pipeline for STAMP purposes. DEPRECATED: Use transcode_metadata or venom_processing_info instead, which includes the ID and contains information for all
             * clients.
             */
            venomId?: string;
            /** Information about the video's status in Venom, including IDs and processing times. */
            venomProcessingInfo?: ImageRepositoryVenomProcessingInfo;
            /** Video anchor sets hold set of anchors with multiple anchor types and sequence of VideoAnchor which contains metadata about the anchor, such as thumbnail, perdoc data. */
            videoAnchorSet?: VideoContentSearchVideoAnchorSets;
            /** Set from the video header if truncated, or is the verified length if completely crawled. */
            videoDurationSec?: number;
            /** The video porn confidence score extracted from Whisper featureSet: "video_labels:whisper_v3", with CR2 label: "/cr2/1". */
            videoPornScore?: number;
            /** The video porn confidence score extracted from WhisperV4 featureSet: "VideoFeatures.whisper_v4_labels", with CR2 label: "/tns/porn". */
            videoPornScoreV4?: number;
            /** video_preview_bytes is only exported as virtual dataset by IE VideoUnderstanding and should not be persisted. It will be used by downstream IE functions to push for serving. */
            videoPreviewBytes?: ImageRepositoryVideoPreviewsVideoPreview[];
            /** video_previews contain the preview metadata but no bytes. It exits for IE and non-IE cases. */
            videoPreviews?: ImageBaseVideoPreviewMetadata[];
            /** Deprecated, please use media_info. */
            videoStreamInfo?: VideoPipelineViperVSIColumnData;
            /**
             * VideoTranscriptAnnotations holds sentence segmented text and timing information to be used for VideoAnswers (go/video-answers). Note that only punctuated_transcript, timing_info,
             * and lang field are filled, and other fields will be filled in the later stage.
             */
            videoTranscriptAnnotations?: QualityWebanswersVideoTranscriptAnnotations;
            /** Contains lists of reasons why YT videos were filtered from specific processing. */
            youtubeProcessingFilter?: ImageRepositoryYoutubeProcessingFilter;
        }
        interface ImageRepositoryCrawlStatusInfo {
            code?: string;
            notCrawledReason?: string;
        }
        interface ImageRepositoryDeepImageEngagingnessOutput {
            /** DeepImageEngagingness score. */
            score?: number;
        }
        interface ImageRepositoryFileTruncationInfo {
            /** A lower bound on the original file's size. */
            originalFileSizeLowerBoundBytes?: string;
            /** Indicates whether the stored file is equal to the original file (COMPLETE), is only a prefix (TRUNCATED), or that we don't know (UNKNOWN, the default). */
            truncationState?: string;
        }
        interface ImageRepositoryFrameIdentifier {
            previewFrameZeroVariant?: ImageRepositoryFrameIdentifierPreviewFrameZeroVariant;
            thumbnailVariant?: any;
            /** Offset of the frame from the beginning of the video (in milliseconds). */
            timestampMs?: number;
        }
        interface ImageRepositoryFrameIdentifierPreviewFrameZeroVariant {
            previewLength?: string;
            /**
             * All xtags used in the generation of the preview. The same frame generated from the same preview with different xtags will likely have different bytes (such as, for example,
             * resulting from a different aspect ratio).
             */
            xtagList?: ImageRepositoryApiXtagList;
        }
        // tslint:disable-next-line:no-empty-interface
        interface ImageRepositoryFrameIdentifierThumbnailVariant {
        }
        interface ImageRepositoryFramePerdoc {
            frameIdentifier?: ImageRepositoryFrameIdentifier;
            perdoc?: ImageData;
            /** Timestamp (in msec) of the frame from the original video DEPRECATED: Use the timestamp_ms field in frame_identifier instead. */
            timestampMsec?: number;
        }
        interface ImageRepositoryFramePerdocs {
            framePerdoc?: ImageRepositoryFramePerdoc[];
        }
        interface ImageRepositoryNimaOutput {
            /** NIMA score. */
            score?: number;
        }
        interface ImageRepositoryS3LangIdSignals {
            /** Whether this audio chunk has speech or not. */
            containsSpeech?: boolean;
            endSec?: string;
            /** S3 langID result. We keep langid_result even if contains_speech = false. */
            langidResult?: SpeechS3LanguageIdentificationResult;
            /** Converted version of the langid_result field, so that we have the YT compatible version of the langID result. */
            languageIdentification?: VideoTimedtextS4ALIResults;
            /** The version of the model used for S3 LangID service. */
            modelVersion?: string;
            speechFrameCount?: number;
            /** The audio chunk which corresponds to this langID result expressed as a start_sec and end_sec. */
            startSec?: string;
            /** Count the number of total frames in the audio chunk as well as the number of speech frames. */
            totalFrameCount?: number;
        }
        interface ImageRepositoryShoppingProductInformation {
            /**
             * Information about versioned product sets found. There will be at most two versions present. The results from the current version of the models used in VSS and the results from the
             * previous version of the models used. Note that not all products may have two version since the model might detect the product in one version and not the other.
             */
            productSets?: ImageRepositoryShoppingProductInformationVersionedProductInformationSet[];
        }
        interface ImageRepositoryShoppingProductInformationBoundingBox {
            /** The vertical height of the bounding box (ymax - ymin + 1), normalized by image height with range [0,1]. */
            h?: number;
            /** The horizontal width of the bound box (xmax - xmin + 1), normalized by image width with range [0,1]. */
            w?: number;
            /** The x coordinate (xmin), normalized by image width with range [0,1). */
            x?: number;
            /** The y coordinate (ymin), normalized by image height with range [0,1). */
            y?: number;
        }
        interface ImageRepositoryShoppingProductInformationEntity {
            id?: string;
            /** The normalized recognition score between 0 and 1. */
            score?: number;
        }
        interface ImageRepositoryShoppingProductInformationProductInformation {
            /**
             * The possible Merlot ids for the item. There may be more than one if the product detector result corresponds to a collection of merlot ids, which can't be easily grouped up to a
             * common ancestor, for which the detector would still make sense for all the children. E.g. a detected "chair" can be either an indoor chair or an outdoor one, however in Merlot the
             * common ancestor of the two is furniture.
             */
            categoryId?: number[];
            /**
             * The k-d tree clusters for retrieval. Will be deprecated, use the token_groups instead. To add tokens/cluster_ids from new tokenization model in the future, add it to the
             * token_groups.
             */
            clusterIds?: number[];
            /** The localization detection score. */
            detectionScore?: number;
            /** The serialized embedding values. */
            embedding?: string;
            /** The recognized entities and scores. */
            entities?: ImageRepositoryShoppingProductInformationEntity[];
            /** Feature type (different detectors and embedders) requested. */
            featureType?: string;
            /** The bounding box. */
            productLocation?: ImageRepositoryShoppingProductInformationBoundingBox;
            tokenGroups?: ImageRepositoryShoppingProductInformationProductInformationTokenGroup[];
        }
        interface ImageRepositoryShoppingProductInformationProductInformationTokenGroup {
            model?: string;
            tokens?: number[];
        }
        interface ImageRepositoryShoppingProductInformationVersionedProductInformationSet {
            /** The type of the model. */
            modelType?: string;
            /** List of ProductInformation for this version. */
            products?: ImageRepositoryShoppingProductInformationProductInformation[];
            /** The version of the models used in VSS. Newer version will have a higher version number. */
            version?: number;
        }
        interface ImageRepositorySpeechRecognitionAlternative {
            /**
             * The confidence estimate between 0.0 and 1.0. A higher number indicates an estimated greater likelihood that the recognized words are correct. This field is set only for the top
             * alternative of a non-streaming result or, of a streaming result where `is_final=true`. This field is not guaranteed to be accurate and users should not rely on it to be always
             * provided. The default of 0.0 is a sentinel value indicating `confidence` was not set.
             */
            confidence?: number;
            /** Transcript text representing the words that the user spoke. */
            transcript?: string;
            /** A list of word-specific information for each recognized word. Note: When `enable_speaker_diarization` is true, you will see all the words from the beginning of the audio. */
            words?: ImageRepositoryWordInfo[];
        }
        interface ImageRepositorySpeechRecognitionResult {
            /**
             * May contain one or more recognition hypotheses (up to the maximum specified in `max_alternatives`). These alternatives are ordered in terms of accuracy, with the top (first)
             * alternative being the most probable, as ranked by the recognizer.
             */
            alternatives?: ImageRepositorySpeechRecognitionAlternative[];
            /**
             * For multi-channel audio, this is the channel number corresponding to the recognized result for the audio from that channel. For audio_channel_count = N, its output values can range
             * from '1' to 'N'.
             */
            channelTag?: number;
            /**
             * The [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag of the language in this result. This language code was detected to have the most likelihood of being spoken
             * in the audio.
             */
            languageCode?: string;
            /** Time offset of the end of this result relative to the beginning of the audio. This field is internal-only and is used to order results based on their timestamps. */
            resultEndTime?: string;
        }
        interface ImageRepositoryUnwantedContent {
            deletionReason?: string;
            hideReason?: string;
        }
        interface ImageRepositoryVenomProcessingInfo {
            /**
             * Contains one status for each Genus that this video belongs to in Venom. For example, a video that is both 1) Found on the web, and 2) Opted-in by an Interest Feed partner would have
             * two entries, one for GENUS_CRAWL and one for GENUS_VIDEO_INTEREST_FEED
             */
            venomStatus?: ImageRepositoryVenomStatus[];
        }
        interface ImageRepositoryVenomStatus {
            /** Venom ACL of the video. Used to check if other systems, such as Ares, are able to process the video. */
            acl?: VideoAssetsVenomACL;
            deletionTimestampUsec?: string;
            /** The Genus (Venom's client ID) that this media belongs to. */
            genus?: string;
            /** Time that VideoNotification result was received from Venom. */
            insertionResponseTimestampUsec?: string;
            insertionTimestampUsec?: string;
            /**
             * Record the attempts num of previous insertion. It's only updated when either the insertion succeeds or fails with reason INSERTION_ATTEMPTS_EXCEEDED, but it's always set so that we
             * can easily construct venom_id with this attempts num for future insertions.
             */
            lastInsertionAttemptsNum?: number;
            reason?: string;
            /** The Settings that were used to customize the Venom request for this media. */
            settings?: any[];
            state?: string;
            /** Transition contains the Objective and Outcome of the latest Venom run. */
            transition?: VideoAssetsVenomTransition;
            /** The media's unique identifier within Venom. */
            venomId?: VideoAssetsVenomVideoId;
            /** The generation number returned by Venom. */
            venomMutationGeneration?: string;
        }
        interface ImageRepositoryVideoIndexingInfo {
            notIndexedVideoLink?: ImageRepositoryVideoLinkIndexingInfo[];
        }
        interface ImageRepositoryVideoLinkIndexingInfo {
            /** Fields for crawl-status-related debugging information. */
            crawlStatusInfo?: ImageRepositoryCrawlStatusInfo;
            /** The video URL. */
            url?: string;
        }
        interface ImageRepositoryVideoPreviewsDebuggingInfo {
            /** Last Amarna processing timestamp. */
            lastAmarnaProcessingTime?: string;
            /** The underlying processing engine, like 'viper' or 'kronos'. */
            processingEngine?: string;
        }
        interface ImageRepositoryVideoPreviewsVideoPreview {
            /** The actual video preview bytes generated for the video. */
            content?: string;
            /** Used for debugging only. */
            debuggingInfo?: ImageRepositoryVideoPreviewsDebuggingInfo;
            /** The metadata associated with the preview (i.e. the type: 8k, 90k, etc.) */
            metadata?: ImageBaseVideoPreviewMetadata;
            /**
             * 0th frame image of the preview. This frame has the same resolution as the associated preview video bytes, as it is taken directly from the preview bytes in Venom/Viper processing.
             * Right now, we only populate preview_frame_zero only for the VPREVIEW_TYPE_540K_ORIGINAL_HQ_LICENSED preview type. Note that preview_frame_zero.thumbnails(0).timestamp_ms() is the
             * timestamp from the full video, not from the preview.
             */
            previewFrameZero?: DrishtiVesperVideoThumbnail;
        }
        interface ImageRepositoryVideoProperties {
            /**
             * Both audio- and audio-video-files are treated as videos during indexing (whether they share a container format, like .mp4, or not, like .mp3). This bool indicates that there's no
             * video track, just an audio track.
             */
            audioOnly?: boolean;
            /** Information derived from fetched video bytes. */
            contentBasedMetadata?: ImageRepositoryContentBasedVideoMetadata;
            /** The raw crawl state. */
            crawlState?: ImageMoosedogCrawlState;
            /** Timestamp of the first time that the video was successfully crawled. */
            firstCrawlTimestampSec?: string;
            /** Timestamp when this video's videoProperties is populated for the first time, measured in seconds since epoch. */
            firstProcessingTimestampSec?: string;
            /** DEPRECATED: please use content_based_metadata.inline_playback. Metadata related to Inline playback on the Interest Feed */
            inlinePlayback?: VideoCrawlVideoInlinePlaybackMetadata;
            /** Timestamp when this video's last crawling is requested, measured in seconds since epoch. */
            lastCrawlRequestTimestampSec?: string;
            /** Last timestamp when this video's videoProperties is populated, measured in seconds since epoch. */
            lastProcessingTimestampSec?: string;
            /** This is the video url taken from the key of the Amarna references table row corresponding to this message. */
            url?: string;
        }
        interface ImageRepositoryWordInfo {
            /**
             * The confidence estimate between 0.0 and 1.0. A higher number indicates an estimated greater likelihood that the recognized words are correct. This field is set only for the top
             * alternative of a non-streaming result or, of a streaming result where `is_final=true`. This field is not guaranteed to be accurate and users should not rely on it to be always
             * provided. The default of 0.0 is a sentinel value indicating `confidence` was not set.
             */
            confidence?: number;
            /**
             * Time offset relative to the beginning of the audio, and corresponding to the end of the spoken word. This field is only set if `enable_word_time_offsets=true` and only in the top
             * hypothesis. This is an experimental feature and the accuracy of the time offset can vary.
             */
            endTime?: string;
            /**
             * A distinct integer value is assigned for every speaker within the audio. This field specifies which one of those speakers was detected to have spoken this word. Value ranges from
             * '1' to diarization_speaker_count. speaker_tag is set if enable_speaker_diarization = 'true' and only in the top alternative.
             */
            speakerTag?: number;
            /**
             * Time offset relative to the beginning of the audio, and corresponding to the start of the spoken word. This field is only set if `enable_word_time_offsets=true` and only in the top
             * hypothesis. This is an experimental feature and the accuracy of the time offset can vary.
             */
            startTime?: string;
            /** The word corresponding to this set of information. */
            word?: string;
        }
        interface ImageRepositoryYoutubeProcessingFilter {
            previewsFilteredReason?: string[];
        }
        interface ImageSafesearchContentBrainPornAnnotation {
            /** The probability that the youngest person in the image is a child. */
            childScore?: number;
            /** This score correlates with potential child abuse. Google confidential! */
            csaiScore?: number;
            /** This field contains the probability that an image is inappropriate for Images Universal, according to this policy: go/iupolicy. */
            iuInappropriateScore?: number;
            medicalScore?: number;
            pedoScore?: number;
            pornScore?: number;
            /** This score is related to an image being sexually suggestive. */
            racyScore?: number;
            spoofScore?: number;
            /**
             * This field is an experimental one with a quite vague meaning. Please contact safesearch@ before any meaningful use of it. There is no guarantee it will preserve its behavior in the
             * future.
             */
            version?: string;
            violenceScore?: number;
            /** Deprecated, use porn_score instead. The most recent model version does not produce this anymore. */
            ytPornScore?: number;
        }
        interface ImageSafesearchContentOCRAnnotation {
            /** The score produced by Aksara geometry and spoof score. Describes the 'visibility' or 'importance' of the text on the image [0, 1] */
            ocrProminenceScore?: number;
            /** Image OCR racyness/pornyness, computed by porn query classifier. */
            pornScore?: number;
            /** Same as offensive_score, but weighted by prominence. */
            prominentOffensiveScore?: number;
            /** Same as vulgar_score, but weighted by prominence. */
            prominentVulgarScore?: number;
            /** The score produced by offensive salient terms model. */
            qbstOffensiveScore?: number;
            /** Presence of i18n-recognized vulgar term in the OCR. */
            vulgarI18nBit?: boolean;
            /** Image OCR vulgarity, computed by vulgar query classifier. */
            vulgarScore?: number;
        }
        interface ImageSafesearchContentOffensiveSymbolDetection {
            matches?: ImageSafesearchContentOffensiveSymbolMatch[];
        }
        interface ImageSafesearchContentOffensiveSymbolMatch {
            /** Confidence score of the match. The higher, the more likely to match the symbol. */
            score?: number;
            type?: string;
        }
        interface ImageSearchImageIndexingInfo {
            /** Image Selection Info */
            imageLinkSelectionInfo?: ImageSearchImageSelectionInfo[];
            /**
             * URLs and Amarna status of images on the page for which image data is not yet available and weren't selected for indexing in image search. Used by consumers of docjoins that need a
             * complete view of image urls on the page (i.e. Digdug).
             */
            rejectedNotIndexedImageLink?: ImageSearchUnindexedImageLink[];
            /**
             * URLs and Amarna status of images on the page for which image data is not yet available and were otherwise selected for indexing in image search. Used by consumers of docjoins that
             * need a complete view of selected image urls on the page (i.e. Hearse, the index selection testbed).
             */
            selectedNotIndexedImageLink?: ImageSearchUnindexedImageLink[];
        }
        interface ImageSearchImageLicenseInfo {
            /** Records web page url about how to use the licensed image. */
            acquireLicensePage?: string;
            /** Provides copyright info. */
            copyrightNotice?: string;
            /** Source type for copyright_notice field. */
            copyrightNoticeSourceType?: string;
            /** creator, authors. */
            creator?: string[];
            /** Source type for creator field. */
            creatorSourceType?: string;
            /** Text for crediting persons or organizations. */
            creditText?: string;
            /** Source type for credit_text field. */
            creditTextSourceType?: string;
            /** Whether this license url is in retired license list, which is from: https://creativecommons.org/retiredlicenses/ */
            isRetiredCcUrl?: boolean;
            licenseType?: string;
            /** Records license URL. */
            licenseUrl?: string;
            /**
             * A bitwise-OR of SafeSearch filtering flags. If present, the flags will be a bitwise-AND between this value and all the classifier_porn::query::Vertical enums. If the value is -1, it
             * indicates there is some error with SafeSearch classifier. The default value 0 means no filtering flags are set.
             */
            safesearchFlags?: number;
            sourceType?: string;
        }
        interface ImageSearchImageSelectionInfo {
            /** Image Selection Info. */
            imageLinkSelectionInfo?: ImageMustangImageLinkSelectionInfo;
            /** The image URL. */
            url?: string;
        }
        interface ImageSearchUnindexedImageLink {
            /** Insight on why we do not have data for this imagelink. */
            amarnaStatus?: ImageRepositoryAmarnaStatus;
            /** Fields for crawl-status-related debugging information. */
            crawlStatusInfo?: ImageRepositoryCrawlStatusInfo;
            /** The image URL. */
            url?: string;
        }
        interface ImageUnderstandingIndexingAnnotation {
            /** Multiple feature embeddings for this bounding box. */
            feature?: ImageUnderstandingIndexingFeature[];
            /** Multiple label annotations for this bounding box. */
            labelGroup?: ImageUnderstandingIndexingLabelGroup[];
            /** Detected bounding box. Leave it not set for whole image annotation. */
            roi?: ImageUnderstandingIndexingImageRegion;
        }
        interface ImageUnderstandingIndexingAnnotationGroup {
            annotation?: ImageUnderstandingIndexingAnnotation[];
        }
        interface ImageUnderstandingIndexingFeature {
            /** Multiple fields can be set. For example for Starburst V3, they can be used to store compressed byte, raw float feature, and tokens, respectively. */
            bytesValue?: string;
            floatValue?: number[];
            /** Local features. */
            imageTemplate?: PhotosVisionObjectrecImageTemplate;
            int32Value?: number[];
            version?: string;
        }
        interface ImageUnderstandingIndexingImageRegion {
            /**
             * Bounding box normalized to [0,1] scale independent on the image size. For example if the original image has the size 1600x1200, the rectangle [200, 200, 800, 600] from the image
             * would have a normalized bounding box [1/8, 1/6, 1/2, 1/2].
             */
            box?: PhotosVisionGroundtruthdbNormalizedBoundingBox;
            /**
             * Box confidence score. This is used to store the confidence of the box proposal, not the score associated with any specific labels. The box proposal confidence score is a float
             * number per region between [0, 1] indicating how likely a box contains an "object".
             */
            score?: number;
            version?: string;
        }
        interface ImageUnderstandingIndexingLabel {
            /** Human readable text. */
            canonicalText?: string;
            /** KG entity id. */
            entityId?: string;
            /** Meta data for topicality, visible labels, attribute, etc. */
            metaData?: ImageUnderstandingIndexingMetaData[];
            /** Confidence score. */
            score?: number;
        }
        interface ImageUnderstandingIndexingLabelGroup {
            label?: ImageUnderstandingIndexingLabel[];
            version?: string;
        }
        interface ImageUnderstandingIndexingMetaData {
            floatValue?: number;
            name?: string;
            stringValue?: string;
        }
        interface IndexingBadSSLCertificate {
            badSslCertificate?: TrawlerSSLCertificateInfo;
            /** The URL where the bad SSL certificate really comes from. Present iff it is different from the source URL, i.e. a redirect target of the source URL). */
            urlWithBadSslCertificate?: string;
        }
        interface IndexingConverterLocalizedAlternateName {
            annotationSource?: string;
            /** Device match info calculated only by URL pattern. */
            deviceMatchInfo?: string;
            /** Fp96 of webmirror ECN as of the last time the canonical was processed. */
            ecnFp?: string;
            /** Populated if annotation_source is SITEMAP. */
            feedUrl?: string;
            language?: string;
            /** Parsed language and region code from language field. */
            parsedLanguage?: string;
            parsedRegion?: number;
            url?: string;
            /** see webutil/urlencoding */
            urlEncoding?: number;
        }
        interface IndexingConverterRawRedirectInfo {
            /**
             * Final redirect target found from rendering. It is the same as the last element of raw_redirect_chain_from_rendering. It is used as an input source for the indexable fragment
             * detection pipeline and also downstream phases.
             */
            rawFinalTargetFromRendering?: string;
            /**
             * This is with-fragment version of redirect_with_contents. This field is populated only if there was a fragment. This field is used by indexing::mobile::GetRedirectTarget() defined in
             * indexing/mobile/internal/smartphone-util.cc, which extracts the redirect target for smartphone optimized pages. The extracted target in turn is served in search results for
             * smartphone users. We need with-fragment version because with-fragment url can return different content than fragment-stripped url. For example, http://www.example.com/m#article=11
             * and http://www.example.com/m can return different content. These cases are most typical for Ajaxy sites. This fragment does not have to be indexable.
             */
            rawFinalTargetFromTrawler?: string;
            /**
             * Redirect chain generated from redirect events in rendering. At the beginning of it, there could be some redirects from trawler (i.e. could be partial or entire trawler redirect
             * chain), other redirects have their RedirectParams::is_redirect_from_rendering fields set to true. Redirects here have no RedirectChain::Hop::raw_target fields populated, and targets
             * stored in RedirectChain::Hop::target fields are likely cleaned while keeping fragments (also sometimes they could be uncleaned ones because of cleaning failures), fragments could be
             * indexable or non-indexable.
             */
            rawRedirectChainFromRendering?: IndexingConverterRedirectChain;
            /**
             * This is used to describe how many redirect hops from Webkit were kept in the raw_redirect_chain_from_rendering. If it is -1, it means it kept all the hops from Webkit in redirect
             * chain.
             */
            renderingRedirectLimit?: number;
        }
        interface IndexingConverterRedirectChain {
            hop?: IndexingConverterRedirectChainHop[];
        }
        interface IndexingConverterRedirectChainHop {
            params?: IndexingConverterRedirectParams;
            /** Redirect target with fragment. This field is populated only if there was a fragment. */
            rawTarget?: string;
            /** Redirect target URL and params of the current hop in the redirect chain. */
            target?: string;
        }
        interface IndexingConverterRedirectParams {
            /** The time difference between page loading and redirect occurrence. When missing, it means the redirect happens immediately (i.e. delay = 0). In seconds. */
            delay?: number;
            /** Populated for SINGLE_FRAME and SINGLE_IFRAME redirects only and indicates that the target url requested not to be framed, by virtue of using the "X-Frame-Options" HTTP header. */
            frameTargetDeniesFraming?: boolean;
            /**
             * Indicates corresponding redirect is a download. This field is only set when rendering redirect chain is used. This field represents the value of corresponding
             * "RedirectEvent.target_content_downloaded" field.
             */
            isDownload?: boolean;
            /** Indicates corresponding redirect is from rendering if set to true. */
            isRenderingRedirect?: boolean;
            /** If set, it means that the redirect of type META was detected by Trawler (as opposed to the content processor.) Only makes sense when type is META. */
            metaRedirectFromTrawler?: boolean;
            type?: string;
        }
        interface IndexingConverterRichContentData {
            range?: IndexingConverterRichContentDataRange[];
        }
        interface IndexingConverterRichContentDataRange {
            rangeType?: string;
            /** Range size when uncompressed, in bytes. */
            size?: number;
            /**
             * The source of this range of content. Present iff 'type' is PROCESSED_ONLY or INTERMEDIATE_ONLY. Note: 'source_type' is not present for ORIGINAL_AND_PROCESSED, ORIGINAL_ONLY, and
             * ORIGINAL_AND_INTERMEDIATE because for those range types the source of their content is the original crawled content.
             */
            sourceType?: string;
            /** The source URL of this range of content. Present iff 'source_type' is present and 'source_type' is FRAME or FLASH or IFRAME. */
            sourceUrl?: string;
            /**
             * The content of the range, compressed with 'text_compression_method'. Present iff 'type' is ORIGINAL_ONLY or ORIGINAL_AND_INTERMEDIATE or INTERMEDIATE_ONLY. Useful to reconstruct the
             * original content or the intermediate content. Note: 'text' is not present for ORIGINAL_AND_PROCESSED and PROCESSED_ONLY because the processed content is already stored separately
             * (in the contents column, and in CompositeDoc.doc.Content.Representation).
             */
            text?: string;
            /** Method used to compress the 'text' field. May be present only when the 'text' is present. */
            textCompressionMethod?: string;
        }
        interface IndexingConverterRobotsInfo {
            /**
             * time in unix time format after which this content should not be shown in the results. This in inferred from the X-Robots-Tag HTTP header with unavailable_after: Do not use this
             * field directly. There is a column called content_expiration in Alexandria that includes this and other signals.
             */
            contentExpiry?: number;
            convertToRobotedReason?: string;
            disallowedReason?: number;
            /** IMPORTANT: if you add a new field here, update the MergeRobotsInfo() function to merge the new field. */
            indexifembeddedReason?: number;
            /** Max image preview restriction applied to this data. A value of THUMBNAIL_UNSPECIFIED can be treated as though there is no restriction. */
            maxImagePreview?: string;
            /**
             * Max snippet preview restriction applied to this data. If this field is zero, it indicates that no snippet data can be displayed, therefore this field should be checked using
             * has_max_snippet_length to determine if it was set.
             */
            maxSnippetLength?: string;
            noarchiveReason?: number;
            nofollowReason?: number;
            noimageframeoverlayReason?: number;
            noimageindexReason?: number;
            /** Bit map of RobotedReasons values. When set to a non-zero value, the document should not be indexed or archived etc. based on the name of the tag. */
            noindexReason?: number;
            nopreviewReason?: number;
            nosnippetReason?: number;
            notranslateReason?: number;
        }
        interface IndexingConverterShingleFingerprint {
            metadata?: string;
            /** Repeated to allow for fingerprints larger than 64-bits. */
            value?: string[];
        }
        interface IndexingCrawlerIdServingDocumentIdentifier {
            /** Only for double indexing experiments. This field is set for duplicated documents so that docjoin users will not see duplicated docs. */
            doubleIndexingExperimentId?: string;
            /**
             * Only for Experimental clusters, not relevant for production serving data: Index-Dups can run experiments in Quality Clusters where different versions of the same document (e.g. with
             * different signals) are serving in parallel. They are uniquely identified by the dup-experiment-IDs. This is for experimental clusters only. In prod-versions the member will not be
             * set.
             */
            dupExperimentId?: string;
            /**
             * The primary identifier of a production document is the document key, which is the same as the row-key in Alexandria, and represents a URL and its crawling context. The document key
             * is the unique identifier for each document, but multiple document keys can cover the same URL (e.g. crawled with different device types). In your production code, please always
             * assume that the document key is the only way to uniquely identify a document. Link for more background information: http://go/url The document key is populated for all docs in
             * indexing since 2014-03. ## Recommended way of reading: const string& doc_key = cdoc.doc().id().key(); ## CHECK(!doc_key.empty()); Note: For older DocJoins (e.g. historical
             * DocJoins), the field is not populated. In those scenarios it is recommended to use the function 'GetDocumentKeyFromCompositeDoc' in
             * '//indexing/crawler_id/utils/compositedoc/compositedoc_util.h' instead.
             */
            key?: string;
        }
        interface IndexingDocjoinerAnchorPhraseSpamInfo {
            /** How many spam phrases found in the anchors among unique domains. */
            phraseAnchorSpamCount?: number;
            /** Over how many days 80% of these phrases were discovered. */
            phraseAnchorSpamDays?: number;
            /** Total number of demoted anchors. */
            phraseAnchorSpamDemoted?: number;
            /** Time when anchor spam spike ended with padding. */
            phraseAnchorSpamEnd?: number;
            /** Spam phrases fraction of all anchors of the document. */
            phraseAnchorSpamFraq?: number;
            /** Combined penalty for anchor demotion. */
            phraseAnchorSpamPenalty?: number;
            /** Total number of observed anchors. */
            phraseAnchorSpamProcessed?: number;
            /** Average daily rate of spam anchor discovery. */
            phraseAnchorSpamRate?: number;
            /** Time when anchor spam spike started with padding. */
            phraseAnchorSpamStart?: number;
        }
        interface IndexingDocjoinerAnchorSpamInfo {
            /** End date of the last anchor of the document. */
            anchorEnd?: number;
            /** Ratio of spam demoted period to all anchor period. */
            anchorFraq?: number;
            /** Start date of the first anchor of the document. */
            anchorStart?: number;
            /** Following field record details of anchor demotion in action. How many anchors were demoted. */
            demoted?: number;
            /** Demoted all anchors in the period or only anchors classified as spam. */
            demotedAll?: boolean;
            /** End date of the demotion period. */
            demotedEnd?: number;
            /** Start date of the demotion period. */
            demotedStart?: number;
            /** Following fields record signals used in anchor spam classification. How many spam phrases found in the anchors among unique domains. */
            phraseCount?: number;
            /** Over how many days 80% of these phrases were discovered. */
            phraseDays?: number;
            /** Spam phrases fraction of all anchors of the document. */
            phraseFraq?: number;
            /** Average daily rate of spam anchor discovery. */
            phraseRate?: number;
            /** Total number of processed anchors. */
            processed?: number;
            /** True if anchors were sampled during observation phrase. */
            sampled?: boolean;
            /** Detailed information about trusted sources and match computation. Populated only when --anchorspam_penalizer_debug=true. */
            sources?: IndexingDocjoinerAnchorTrustedInfo[];
            /** Additional debug information about computation of spam probability. */
            spamDebugInfo?: string;
            /** Combined penalty for anchor demotion. */
            spamPenalty?: number;
            /** Predicted probability of spam. */
            spamProbability?: number;
            /** Number of trusted anchors used in computation of spam probability. */
            trustedDemoted?: number;
            /** Examples of trusted sources. */
            trustedExamples?: string;
            /** Number of trusted anchors with anchor text matching spam terms. */
            trustedMatching?: number;
            /** Following fields record details about trusted anchors True if is this URL is on trusted source. */
            trustedTarget?: boolean;
            /** Total number of trusted sources for this URL. */
            trustedTotal?: number;
        }
        interface IndexingDocjoinerAnchorStatistics {
            anchorCount?: number;
            /** The number of unique anchor phrases. Capped by the constant kMaxAnchorPhraseCountInStats (=5000) defined in indexing/docjoiner/anchors/anchor-manager.cc. */
            anchorPhraseCount?: number;
            /** This structure contains signals and penalties of AnchorSpamPenalizer. It replaces phrase_anchor_spam_info above, that is deprecated. */
            anchorSpamInfo?: IndexingDocjoinerAnchorSpamInfo;
            /** The number of anchors for which some ImprovAnchors phrases have been removed due to duplication within source org. */
            anchorsWithDedupedImprovanchors?: number;
            /** Whether this doc is penalized by BadBackLinks, in which case we should not use improvanchor score in mustang ascorer. */
            badbacklinksPenalized?: boolean;
            baseAnchorCount?: number;
            baseOffdomainAnchorCount?: number;
            droppedHomepageAnchorCount?: number;
            droppedLocalAnchorCount?: number;
            droppedNonLocalAnchorCount?: number;
            /**
             * Sum of anchors_dropped in the repeated group RedundantAnchorInfo, but can go higher if the latter reaches the cap of kMaxRecordsToKeep.
             * (indexing/docjoiner/anchors/anchor-loader.cc), currently 10,000
             */
            droppedRedundantAnchorCount?: number;
            fakeAnchorCount?: number;
            forwardedAnchorCount?: number;
            forwardedOffdomainAnchorCount?: number;
            /** Metric of number of changed global anchors computed as, size(union(previous, new) - intersection(previous, new)). */
            globalAnchorDelta?: number;
            linkBeforeSitechangeTaggedAnchors?: number;
            localAnchorCount?: number;
            lowCorpusAnchorCount?: number;
            lowCorpusOffdomainAnchorCount?: number;
            mediumCorpusAnchorCount?: number;
            mediumCorpusOffdomainAnchorCount?: number;
            /** Minimum local outdegree of all anchor sources that are domain home pages as well as on the same domain as the current target URL. */
            minDomainHomePageLocalOutdegree?: number;
            /** Minimum local outdegree of all anchor sources that are host home pages as well as on the same host as the current target URL. */
            minHostHomePageLocalOutdegree?: number;
            nonLocalAnchorCount?: number;
            offdomainAnchorCount?: number;
            ondomainAnchorCount?: number;
            onsiteAnchorCount?: number;
            /** Set in SignalPenalizer::FillInAnchorStatistics. */
            pageFromExpiredTaggedAnchors?: number;
            pageMismatchTaggedAnchors?: number;
            /** Doc is protected by goodness of early anchors. */
            penguinEarlyAnchorProtected?: boolean;
            /** BEGIN: Penguin related fields. Timestamp when penguin scores were last updated. Measured in days since Jan. 1st 1995. */
            penguinLastUpdate?: number;
            /** Page-level penguin penalty (0 = good, 1 = bad). */
            penguinPenalty?: number;
            /** Doc not scored because it has too many anchor sources. END: Penguin related fields. */
            penguinTooManySources?: boolean;
            perdupstats?: IndexingDocjoinerAnchorStatisticsPerDupStats[];
            /** Following signals identify spike of spammy anchor phrases. Anchors created during the spike are tagged with LINK_SPAM_PHRASE_SPIKE. */
            phraseAnchorSpamInfo?: IndexingDocjoinerAnchorPhraseSpamInfo;
            /**
             * Total anchor dropped due to exceed per domain phrase cap. Equals to sum of anchors_dropped in the repeated group RedundantAnchorInfoForPhraseCap, but can go higher if the latter
             * reaches the cap of kMaxDomainsToKeepForPhraseCap (indexing/docjoiner/anchors/anchor-loader.h), currently 1000.
             */
            redundantAnchorForPhraseCapCount?: number;
            redundantanchorinfo?: IndexingDocjoinerAnchorStatisticsRedundantAnchorInfo[];
            redundantanchorinfoforphrasecap?: IndexingDocjoinerAnchorStatisticsRedundantAnchorInfoForPhraseCap[];
            /** The total number of anchors being scanned from storage. */
            scannedAnchorCount?: number;
            /** A count of the number of times anchor accumulation has been skipped for this document. Note: Only used when canonical. */
            skippedAccumulate?: number;
            /** Reason to skip accumulate, when skipped, or Reason for reprocessing when not skipped. */
            skippedOrReusedReason?: string;
            /** The log base 10 odds that this set of anchors exhibits spammy behavior. Computed in the AnchorLocalizer. */
            spamLog10Odds?: number;
            /** Walltime of when anchors were accumulated last. */
            timestamp?: number;
            topPrOffdomainAnchorCount?: number;
            topPrOndomainAnchorCount?: number;
            /** According to anchor quality bucket, anchor with pagrank > 51000 is the best anchor. anchors with pagerank < 47000 are all same. */
            topPrOnsiteAnchorCount?: number;
            /** The following should be equal to the size of the following repeated group, except that it can go higher than 10,000. */
            totalDomainPhrasePairsAboveLimit?: number;
            /**
             * Number of domain/phrase pairs in total -- i.e. how many anchors we would have if the domain/phrase cutoff was set to 1 instead of 200. This is "approx" for large anchor clusters
             * because there can be double counting when the LRU cache forgets about rare domain/phrase pairs.
             */
            totalDomainPhrasePairsSeenApprox?: number;
            /** Number of domains above per domain phrase cap. We see too many phrases in the domains. */
            totalDomainsAbovePhraseCap?: number;
            /** Number of domains seen in total. */
            totalDomainsSeen?: number;
        }
        interface IndexingDocjoinerAnchorStatisticsPerDupStats {
            /** Count of anchors kept from forwarding. */
            anchorCount?: number;
            /**
             * This is EcnCollectType in anchor-ecn-matcher.h for the latest ECN of this dup: - kCollectNormal = 0, // Normal collection. - kCollectUnforwarded = 1, // Forwarding leader docid
             * match only. - kCollectWhitelisted = 2, // Collected anchors matching whitelist. - kCollectNone = 4 // Skipped ECN anchor cluster.
             */
            collectType?: number;
            /** If missing, the same as the canonical. */
            dupUrl?: string;
            /** Count of offdomain anchors. */
            offdomainAnchorCount?: number;
            /** Count of redundant anchors. */
            redundantAnchorCount?: number;
            /** The number of anchors being scanned from storage per dupforwarding. */
            scannedAnchorCount?: number;
            /** Walltime when this was scanned last. */
            timestamp?: number;
        }
        interface IndexingDocjoinerAnchorStatisticsRedundantAnchorInfo {
            anchorsDropped?: string;
            domain?: string;
            text?: string;
        }
        interface IndexingDocjoinerAnchorStatisticsRedundantAnchorInfoForPhraseCap {
            anchorsDropped?: number;
            domain?: string;
        }
        interface IndexingDocjoinerAnchorTrustedInfo {
            /**
             * Difference in KL-divergence from spam and non-spam anchors. Value >0 indicate that anchor text from this trusted source is similar to anchors classified as spam which means that
             * spammy anchors are legitimate.
             */
            matchedScore?: number;
            /** Detailed debug information about computation of trusted anchors match. Populated only when --anchorspam_penalizer_debug=true */
            matchedScoreInfo?: string[];
            /** Count of anchors classified as spam using anchor text. */
            phrasesScore?: number;
            /** Site name from anchor.source().site(). */
            site?: string;
            /** Tokenized text of all anchors from the site. */
            text?: string[];
            /** Fraction of pages with newsy anchors on the site, >0 for trusted sites. */
            trustedScore?: number;
        }
        interface IndexingDocjoinerCDocBuildInfo {
            extraMessage?: any;
        }
        interface IndexingDocjoinerDataVersion {
            acceleratedShoppingSignal?: IndexingDocjoinerDataVersionVersionInfo;
            chromeCounts?: IndexingDocjoinerDataVersionVersionInfo;
            /** LINT.ThenChange(//depot/google3/indexing/ames/spanner/schema/websearch_main.sdl) */
            instantNavboost?: IndexingDocjoinerDataVersionVersionInfo;
            localyp?: IndexingDocjoinerDataVersionVersionInfo;
            localypVersion?: string;
            modernFormatContent?: IndexingDocjoinerDataVersionVersionInfo;
            modernFormatContentVersion?: string;
            /** LINT.IfChange */
            navboost?: IndexingDocjoinerDataVersionVersionInfo;
            /** DEPRECATED */
            navboostVersion?: string;
            rankembed?: IndexingDocjoinerDataVersionVersionInfo;
            universalFacts?: IndexingDocjoinerDataVersionVersionInfo;
            videoScoringSignal?: IndexingDocjoinerDataVersionVersionInfo;
            videoScoringSignalVersion?: string;
            volt?: IndexingDocjoinerDataVersionVersionInfo;
            voltVersion?: string;
        }
        interface IndexingDocjoinerDataVersionVersionInfo {
            humanReadableVersion?: string;
            timestampMicros?: string;
        }
        interface IndexingDocjoinerServingTimeClusterId {
            /**
             * The unique id to distinguish members in cluster. It could be generated in different ways according to reason, e.g. LINK_REL_NEXT_PREVIOUS: it is the fingerprint of the URL of index
             * 0; PAGE_PARAMETER_INFO: it is the fingerprint of pagination pattern (pagination_pattern_fp field in PageParamInfo message).
             */
            clusterId?: string;
            /**
             * The member index of this document in cluster. Starts from "0". Note that indices of pages in a cluster may not be consistent with each other, because we may update them at different
             * points in time. Currently only used for debugging.
             */
            indexForDebugging?: number;
            /** The reason why this document is clustered into this cluster. */
            reason?: string;
        }
        interface IndexingDocjoinerServingTimeClusterIds {
            /** The exact cluster metadata for each individual cluster if any. */
            clusterId?: IndexingDocjoinerServingTimeClusterId[];
        }
        interface IndexingDupsComputedLocalizedAlternateNamesLocaleEntry {
            /**
             * Cluster-ID of that locale entry. Not Populated if the message is part of a Cluster-Proto (e.g. when loaded as a signal). The data is being populated when the proto is used outside
             * of the cluster context. For instance, when being used as a dups-computed-localized-alternate-name.
             */
            clusterId?: string;
            /** Device match info calculated only by URL pattern. */
            deviceMatchInfo?: string;
            /** Language/Region code. E.g. "en-US" or "de". Allowed values are language-region codes based on the W3C recommendation http://www.w3.org/TR/html401/struct/dirlang.html#langcodes */
            language?: string;
            /** The alternate url representing the content for a specific language and region (or language only). */
            url?: string;
            /** see webutil/urlencoding */
            urlEncoding?: number;
            /**
             * The region code that was extracted from the URL, either by the TLD or via a pattern (like 'en-ca' as a path element).. Always filled in if known, unlike the sometimes left out
             * region part of the language field. Unknown Region Code
             */
            urlRegionCode?: number;
        }
        interface IndexingDupsLocalizedLocalizedCluster {
            /**
             * Defined as a source-blocker, a result which can be a boost target but should itself not be boosted (e.g. roboted documents). For more details on source and target blocking, please
             * read through the code for quality/twiddler/impls/PROTECTED/local_result_twiddler_v2.cc
             */
            boostSourceBlocker?: boolean;
            cluster?: IndexingDupsLocalizedLocalizedClusterCluster[];
            /**
             * Since July 2014 those two fiels are no longer populated, the data is stored in the TargetLinkSets instead. The deprecated fields contain values only for docs which have not been
             * processed since July 2014.
             */
            deprecatedHreflangInfo?: IndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfo;
            deprecatedOutlinksInfo?: IndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfo;
            /** The language of this document (as detected by on-page language detection, not influenced by external anchor signals or other indirect conclusions). */
            documentLanguage?: string;
            hreflangTargetLink?: IndexingDupsLocalizedLocalizedClusterTargetLinkSets;
            inbodyTargetLink?: IndexingDupsLocalizedLocalizedClusterTargetLinkSets;
            outlinksTargetLink?: IndexingDupsLocalizedLocalizedClusterTargetLinkSets;
            /**
             * The list of Sitedup rule IDs for this specific URL. The value is only populated if the URL has at least one localized cluster fulfilling the following conditions: - spans more than
             * one host - does not have filtering enabled due to other input (e.g. due to being a hreflang cluster).
             */
            sitedupRuleId?: string[];
            /** A warning indicator that a problem has occurred, e.g. cross-domain links being filtered early. The warning is just presented for debugging purposes. */
            warningMessage?: string[];
        }
        interface IndexingDupsLocalizedLocalizedClusterCluster {
            /** The cluster id, a unique int64 id for the cluster. */
            clusterId?: string;
            clusterType?: string;
            /** Debug Info being attached to each cluster, to understand how it was created. That info is stored in Alexandria, but not available during serving. */
            deprecatedDebugInfo?: string[];
            /** Indicates that filtering can be applied on the category (if many results of one cluster show up on the SERP, only one should be kept). */
            filteringEnabled?: boolean;
            /** The language as represented by the URL, e.g. 'use this document on the cluster for German queries'. */
            language?: string;
            /**
             * Same as language, except for the country. This is the Stable Region Code. This value may be UNKNOWN even though the URL region code is known, namely when the known region code was
             * the main region for the language and for that language no other region is specified (e.g. de-DE being the only german variation). Unknown Region Code
             */
            regionCode?: number;
            /** Similar to region_code, but always has the value filled in if known. Unknown Region Code */
            urlRegionCode?: number;
        }
        interface IndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfo {
            /** A fingerprint of all outlink-URLs of this document that have been used as algorithmic input. */
            fpOutlinks?: string;
            /** The last time the set of outgoing links of this document was modified. This is the input for our calculation. */
            lastModifiedInputTimestampMs?: string;
            /** The last time the cross-validation of the links was done. Between that last timestamp and now, only cached results have been used. */
            lastProcessedOutputTimestampMs?: string;
            /** All verified members of the cluster (including recursive inclusions). */
            linkMember?: IndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfoLinkMember[];
            unvalidatedOutlink?: IndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfoLinkData[];
        }
        interface IndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfoLinkData {
            annotationSource?: string;
            /** If set, represents the crawl timestamp. If not set, there is no known crawl timestamp for that url. */
            crawlTimestamp?: number;
            url?: string;
        }
        interface IndexingDupsLocalizedLocalizedClusterLinkBasedClusterInfoLinkMember {
            annotationSource?: string;
            languageCode?: string[];
            url?: string;
        }
        interface IndexingDupsLocalizedLocalizedClusterTargetLink {
            linkData?: IndexingDupsLocalizedLocalizedClusterTargetLinkLink;
            metaData?: IndexingDupsLocalizedLocalizedClusterTargetLinkMetadata;
            targetDocData?: IndexingDupsLocalizedLocalizedClusterTargetLinkTargetDocData;
            validationStatus?: string;
        }
        interface IndexingDupsLocalizedLocalizedClusterTargetLinkLink {
            annotationSourceInfo?: IndexingDupsLocalizedLocalizedClusterTargetLinkLinkAnnotationSourceInfo[];
            /** For a link A->B where B is represented by this proto, cross_domain := Host(A) != Host(B). */
            crossDomain?: boolean;
            /** The URL the information in TargetLink refers to. */
            url?: string;
        }
        interface IndexingDupsLocalizedLocalizedClusterTargetLinkLinkAnnotationSourceInfo {
            /** Optional field for storing the anchor text the language code was extracted from. Applies to outlinks only. */
            anchorText?: string;
            /** Information about where the language code was extracted from. */
            annotationSource?: string;
            /** Language code extracted from the URL (hreflang or outlink). One URL can represent multiple language codes, like e.g. de-at and de-ch */
            languageCode?: string;
            /** Optional field that stores the feed URL where a Sitemap annotation was discovered. Only populated if annotation_source is SITEMAP. */
            sourceFeedUrl?: string;
        }
        interface IndexingDupsLocalizedLocalizedClusterTargetLinkMetadata {
            /** When was the first time a link seen. Defaults to last crawled timestamp. */
            firstSeenMs?: string;
            /**
             * When was the last time a link validated. Validation is the process of (re)reading the relevant information for a linked document from its respective row in the document table. Data
             * needed for understanding the correctness of the cluster is copied over to have it available locally.
             */
            lastVerifiedMs?: string;
        }
        interface IndexingDupsLocalizedLocalizedClusterTargetLinkSets {
            /** Direct links are the simplest scenarios where A simply links to B. */
            directTargetLink?: IndexingDupsLocalizedLocalizedClusterTargetLink[];
            /**
             * Repeated field for URLs that are not directly linking to the document TargetLink refers to. We can encounter the following scenario: A -> Links to B -> links to C (i.e. without (A)
             * linking to (C)). In the context of B, indirect_inclusion would include the link to 'C' but not the link back to 'A'.
             */
            indirectTargetLink?: IndexingDupsLocalizedLocalizedClusterTargetLink[];
        }
        interface IndexingDupsLocalizedLocalizedClusterTargetLinkTargetDocData {
            /** The detected on-page content language of the document. */
            contentLanguage?: string;
            crawlStatus?: string;
            /** The timestamp of the last crawl attempt from crawl_timestamp column. */
            crawlTimestampSeconds?: number;
            /** Whether the URL being validated is canonical at the time of processing. */
            isCanonical?: boolean;
            /** Repeated field for data about the outgoing hreflang links that appear in the document that the currently processed URL refers to. */
            outgoingLinkData?: IndexingDupsLocalizedLocalizedClusterTargetLinkLink[];
        }
        interface IndexingEmbeddedContentEmbeddedContentInfo {
            /**
             * The document's DOM and render tree produced by WebKit as a side effect of rendering the page. It might be compressed or not. Thus, use
             * indexing::embedded_content::UncompressWebkitDocument to decode it.
             */
            compressedDocumentTrees?: string;
            /**
             * The converted contents, as produced by the same DocumentUpdater transaction that generated the render tree. Useful whenever one of our users wants to experiment with deriving an
             * annotation from the render tree.
             */
            convertedContents?: string;
            /** Information about all external resources needed to render this page, a.k.a. embedded links. This includes .css files, images embedded in a page, external javascripts, iframes etc. */
            embeddedLinksInfo?: IndexingEmbeddedContentEmbeddedLinksInfo;
            /** The headless response for rendering the document. */
            headlessResponse?: HtmlrenderWebkitHeadlessProtoRenderResponse;
            /** Indicate if the snapshot is generated from alternate snapshot. If true, the snapshot will be exported even if the snapshot quality score is low. */
            isAlternateSnapshot?: boolean;
            /**
             * The original encoding of the content crawled from trawler. It's the value of enum i18n::encodings::encoding. We put a int32 here instead of encoding proto to maintain the
             * compatibility of "py_api_version = 1"
             */
            originalEncoding?: number;
            /** *** DEPRECATED *** This field is only populated in fresh_doc which is shutting down. */
            rawRedirectInfo?: IndexingConverterRawRedirectInfo;
            /** Information about all external resources used to render this page, a.k.a. embedded links. This includes .css files, images embedded in a page, external javascripts, iframes etc. */
            referencedResource?: HtmlrenderWebkitHeadlessProtoReferencedResource[];
            /** Only exist in dry run mode. */
            renderedSnapshot?: HtmlrenderWebkitHeadlessProtoImage;
            /** Snapshot image of a rendered html document (possibly encoded as png, jpeg, or webp). */
            renderedSnapshotImage?: string;
            /** A collection of values which are needed by the users of the Kodachrome bigtable. */
            renderedSnapshotMetadata?: SnapshotSnapshotMetadata;
            /**
             * The quality of the image, 0.0 is the worst, 1.0 is the best. If all dependencies are successfully crawled, the quality should be 1.0. If one or more of the dependencies are unknown,
             * the quality will be lower.
             */
            renderedSnapshotQualityScore?: number;
            renderingOutputMetadata?: IndexingEmbeddedContentRenderingOutputMetadata;
            /** The rich content data to recover the original contents from the converted_contents. Useful for offline content analysis. */
            richcontentData?: IndexingConverterRichContentData;
        }
        interface IndexingEmbeddedContentEmbeddedLinksInfo {
            /** This field is optional only because we're adding it late and want to support records written before that. For newly produced records, this field should always be set. */
            embedderInfo?: IndexingEmbeddedContentEmbedderInfo;
            link?: IndexingEmbeddedContentLinkInfo[];
            /** Page download size. */
            pageSizeInfo?: IndexingEmbeddedContentPageSizeInfo;
            /**
             * This field is the sum of http_response_length for the embedder and all embedded resources. This is expected to be set only in the docjoins, not in the pinax tables or the exported
             * bigtable.
             */
            sumHttpResponseLength?: number;
            uncrawledLinkUrl?: string[];
        }
        interface IndexingEmbeddedContentEmbedderInfo {
            importanceAsEmbedder?: number;
            linkInfo?: IndexingEmbeddedContentLinkInfo;
        }
        interface IndexingEmbeddedContentFetchHostCount {
            counter?: IndexingEmbeddedContentFetchHostCountCounter[];
            host?: string;
            num?: number;
        }
        interface IndexingEmbeddedContentFetchHostCountCounter {
            name?: string;
            num?: number;
        }
        interface IndexingEmbeddedContentFetchUrlResponseMetadata {
            adsResourceType?: string;
            /** The field always exists, and has four options: UNKNOWN, CONTENT, ROBOTED and ERROR, which are defined in indexing.converter.CrawlStatus. */
            crawlStatus?: number;
            criticalResourceType?: string;
            /** True if the response is fetched with SMARTPHONE user agent. */
            fetchWithSmartphoneUa?: boolean;
            isAdsResource?: boolean;
            isCriticalResource?: boolean;
            isTrivialResource?: boolean;
            /** Number of trawler fetches while fetching this URL. In most cases, this number will be 0 or 1. */
            numTrawlerFetches?: number;
            /** Used for logging purposes only here. */
            rewriteMethod?: string;
            /** Note that this robots_info should only be used for noindex_reason and will only be present for TARGET_MAIN_FRAME / TARGET_SUBFRAME fetches. */
            robotsInfo?: IndexingConverterRobotsInfo;
        }
        interface IndexingEmbeddedContentLinkInfo {
            /**
             * Size of the HTTP body (payload of the HTTP response, excluding headers), pre-decompression. Equal to the value of the Content-Length header if any. NOTE: if this proto is converted
             * to from ReferencedResource, we have to use the size of the full HTTP response (i.e. http_response_length) as an approximation, as we could not get the size of HTTP headers.
             */
            contentLength?: number;
            contentType?: number;
            /** Time spent downloading this resource, in milliseconds. Not a timestamp! */
            crawlDuration?: number;
            /** Enum values for crawl_status are defined in indexing/converter/proto/converter.proto */
            crawlStatus?: number;
            crawlTimestamp?: number;
            deprecatedRedirect?: string[];
            /** Where this resource comes from. */
            fetchSourceInfo?: WirelessTranscoderFetchFetchSourceInfo[];
            /** Fetch status from trawler. */
            fetchStatus?: TrawlerFetchStatus;
            /** Populated from embedded-content fetch server. */
            fetchUrlResponseMetadata?: IndexingEmbeddedContentFetchUrlResponseMetadata;
            /** FetchReplyData from trawler. */
            frd?: TrawlerFetchReplyData;
            /** Size of the full HTTP response (headers and body pre-decompression). Semantically equal to content_length plus size of the HTTP headers. */
            httpResponseLength?: number;
            isCacheable?: boolean;
            isRobotedContentFromFastnet?: boolean;
            /**
             * Size of the HTTP body (payload of the HTTP response, excluding headers), post-decompression. Equal to content_length if the body was not compressed to begin with. NOTE: if this
             * proto is converted to from ReferencedResource, we have to use the size of the full HTTP response as an approximation, as we could not get the size of HTTP headers.
             */
            uncompressedContentLength?: number;
            url?: string;
            webkitFetchMetadata?: HtmlrenderWebkitHeadlessProtoWebKitFetchMetadata;
        }
        interface IndexingEmbeddedContentOutputGenerationTimestamps {
            documentData?: number;
            renderedSnapshot?: number;
        }
        interface IndexingEmbeddedContentPageSizeInfo {
            /** Images are also resources. num_images <= num_resources. */
            numImages?: number;
            /** Number of images whose crawl status is CONTENT. */
            numImagesWithContent?: number;
            /** Numbers below don't include embedder. */
            numResources?: number;
            /** Number of resources whose crawl status is CONTENT. */
            numResourcesWithContent?: number;
            /** Sum of embedder and all referenced resources. */
            sumHttpResponseLength?: number;
        }
        interface IndexingEmbeddedContentRenderCacheStats {
            /** When the rendered content would expire from the cache in microseconds. */
            cacheExpireTimestampUsec?: string;
            crawledSimhashDistance?: number;
            /** The last time the document was rendered, in microseconds. Does not update in case of cache use. */
            lastRenderedTimestampUsec?: string;
            renderCache?: string;
            renderedSimhashDistance?: number;
        }
        interface IndexingEmbeddedContentRenderingFetchStats {
            /** A host->count mapping to log how many embedded_links in each host finally goes to trawler during rendering. */
            fetchHostCount?: IndexingEmbeddedContentFetchHostCount[];
        }
        interface IndexingEmbeddedContentRenderingOutputMetadata {
            configParams?: IndexingEmbeddedContentRenderRequestConfigConfigParams;
            /** The exceptions observed during the rendering. In bit-field encoding of enum values of RenderResponse.RenderingException. */
            exceptions?: string;
            /**
             * Total GCU time for rendering the document in millisecond. This data is from render_stats.render_cost_mgcu in RenderResponse proto. Note that this is *experimental* field. Please
             * check with rendering-infra@ if you want to use.
             */
            experimentalRenderTimeMsec?: number;
            generationTimestamps?: IndexingEmbeddedContentOutputGenerationTimestamps;
            /** The importance value of the rendered document. */
            importance?: number;
            /** The timestamp of last new content probing. */
            lastNewContentProbingTimestamp?: number;
            /** Percentage of new tokens in the rendered the document content. */
            newTokensPercentageAfterRendering?: number;
            numNewTokensFoundInRendering?: number;
            refresh?: boolean;
            /** A collection of fields to track stats on cache use in the Rendering microservice. */
            renderCacheStats?: IndexingEmbeddedContentRenderCacheStats;
            /**
             * Short signature (usually less than 1 KB) which captures a perceptual hash on the rendered image. This is used to determine whether successive renderings should be output. See the
             * library in googlen/snapshot/shared/similarity.* for more info about how this value is interpreted and used.
             */
            renderedSnapshotSignature?: string;
            /**
             * Current time in microseconds the document is going through rendering system. This field is set regardless of whether the document is being rendered or if we are skipping rendering
             * by using a cache.
             */
            renderedTimeUsec?: string;
            renderEngine?: string;
            /** Different types of events which happened during rendering. */
            renderEvent?: HtmlrenderWebkitHeadlessProtoRenderEvent[];
            renderingFetchStats?: IndexingEmbeddedContentRenderingFetchStats;
            /** The CL from which the render engine was built. */
            renderServerCl?: string;
            renderTreeQualityScore?: number;
            /** The corpus selection result. Can be used for offline analysis. */
            selectionResult?: IndexingEmbeddedContentSelectionResult;
            /** These scores are copied from htmlrender_webkit_headless_proto.Document. */
            snapshotQualityScore?: number;
            /** True if there were any missing resources during the rendering. */
            withMissingResources?: boolean;
        }
        interface IndexingEmbeddedContentRenderRequestConfigConfigParams {
            virtualTime?: number;
        }
        interface IndexingEmbeddedContentSelectionResult {
            renderEffort?: string;
            /** Indicate which selector has made the decision. */
            selectorId?: string;
        }
        interface IndexingMlVerticalVerticalItem {
            /** Unique ID. */
            id?: number;
            /** The description name. */
            name?: string;
            /** The corresponding Petacat ID. */
            petacatId?: number;
            /** The probability of the vertical, whose value is in [0.0, 1.0]. */
            probability?: number;
        }
        interface IndexingMobileInterstitialsProtoDesktopInterstitials {
            details?: IndexingMobileInterstitialsProtoDesktopInterstitialsDetails[];
            /** Epoch of the interstitial offline pipeline generating this signal. */
            pipelineEpoch?: string;
            /** If present, pipeline_pattern identifies the cluster of URLs for which the signal value was smeared. */
            pipelinePattern?: string;
            /**
             * URL tree of interstitial patterns belong to the host, to be used as site-level signal in Index Signals. A pattern may contain a payload InterstitialPatternPayload, which will
             * indicate the violated interstitial types of this pattern.
             */
            urlTree?: IndexingUrlPatternUrlTreeUrlTree;
            /** Overall policy violation status. If this is true, at least one of the InterstitialSignal below indicates a violation. */
            violatesDesktopInterstitialPolicy?: boolean;
        }
        interface IndexingMobileInterstitialsProtoDesktopInterstitialsDetails {
            basicInfo?: IndexingMobileInterstitialsProtoInterstitialBasicInfo;
            /** Indicates whether the signal value is "smeared", e.g. extrapolated from other URLs. */
            isSmearedSignal?: boolean;
        }
        interface IndexingMobileInterstitialsProtoInterstitialBasicInfo {
            /** Stores the geometry of detected interstitial in absolute page pixels. */
            absoluteBox?: HtmlrenderWebkitHeadlessProtoBox;
            contentType?: string;
            detectionMode?: string;
            layoutType?: string;
        }
        interface IndexingMobileVoltCoreWebVitals {
            /** Cumulative Layout Shift. */
            cls?: string;
            /** First Input Delay. */
            fid?: string;
            inp?: string;
            /** Largest Contentful Paint. */
            lcp?: string;
        }
        interface IndexingMobileVoltVoltPerDocData {
            /** Desktop Core Wev Vital metrics. NOTE(yunchengz): This field will not be populated in Muppet. */
            desktopCwv?: IndexingMobileVoltCoreWebVitals;
            desktopDisplayUrlIsHttps?: boolean;
            displayUrlIsHttps?: boolean;
            /** Mobile Core Web Vital metrics. NOTE(yunchengz): This field will not be populated in Muppet. */
            mobileCwv?: IndexingMobileVoltCoreWebVitals;
        }
        interface IndexingPrivacyAccessAccessRequirements {
            restrictionCategories?: string[];
        }
        interface IndexingSignalAggregatorAdaptiveIntervalData {
            clicksGoodInterval?: number;
            clicksGoodPriorWeight?: number;
            clicksTotalInterval?: number;
            clicksTotalPriorWeight?: number;
            ctrwiInterval?: number;
            ctrwiPriorWeight?: number;
            dwellsInterval?: number;
            dwellsPriorWeight?: number;
            luDwellsInterval?: number;
            luDwellsPriorWeight?: number;
        }
        interface IndexingSignalAggregatorAgeWeightedCoverageData {
            /** Weighted averged timestamps of the decayed chances. */
            averageChanceTime?: number;
            /** Numbers below are all total in the decayed manner. To get rate of impression/clicks, divide by chances. */
            chances?: number;
            clicksBad?: number;
            clicksGood?: number;
            clicksImage?: number;
            clicksTotal?: number;
            clicksUnclassified?: number;
            /** Epoch seconds at which this weighted coverage data was calculated. */
            coverageTimestamp?: string;
            ctrWeightedImpressions?: number;
            /** Dwells from KnowledgePanel and WebAnswers. */
            dwells?: number;
            /** Epoch seconds at which this url first gets coverage in BASE. */
            firstBaseCoverageTimestamp?: string;
            /** The pagerank when the url was serving for the first time. */
            firstCoveragePagerankNs?: number;
            /** Epoch seconds at which this url first gets coverage data. */
            firstCoverageTimestamp?: string;
            firstseen?: string;
            impressions?: number;
            /** Interval Data to track the average time between clicks_total, clicks_good, and ctr_weighted_impression. */
            intervalData?: IndexingSignalAggregatorAdaptiveIntervalData;
            language?: number;
            /** Indicates the date when this document received the last KnowledgePanel or WebAnswer dwell. Note: The date is identified in terms of number of days since Epoch. */
            lastDwellDateInDays?: number;
            /** Indicates the date when this document received the last good click. Note: The date is identified in terms of number of days since Epoch. */
            lastGoodClickDateInDays?: number;
            /** Indicates the date when this document received the last impression. Note: The date is identified in terms of number of days since Epoch. */
            lastImpressionDateInDays?: number;
            /** Indicates the date when this document received the last LocalUniversal dwell. Note: The date is identified in terms of number of days since Epoch. */
            lastLuDwellDateInDays?: number;
            /**
             * Indicates the date when this document received the last pseudo-impression. I.e., when it was retrieved as a result but GWS would not show it because of the document's age in the
             * index. Note: The date is identified in terms of number of days since Epoch.
             */
            lastPseudoImpressionsDateInDays?: number;
            /** Dwells from LocalUniversal. */
            luDwells?: number;
            /** Repid in Alexandria pipeline. */
            repid?: string;
            /** Total number of chances on this urls (not decayed). */
            totalChances?: string;
            url?: string;
            /** Temporary variable, only used during mapreduce. */
            urlfp?: string;
        }
        interface IndexingSignalAggregatorAggregatedScore {
            /** A number reflecting the deviation of Url scores. */
            deviation?: number;
            /** State variables for West & Chan variance algorithm used to be stored here directly. Now they are stored inside RunningMeanAndVarianceInternalState. */
            m2?: number;
            /** Input UrlScore with max score. */
            maxScoreUrl?: IndexingSignalAggregatorUrlScore;
            mean?: number;
            /** Overall stats that are only available in final aggregation results. The aggregated score. */
            meanScore?: number;
            /** Input UrlScore with min score. */
            minScoreUrl?: IndexingSignalAggregatorUrlScore;
            numImportantUrls?: string;
            /** Final Stats that are also available in intermediate output. Number of Urls matching the class. */
            numUrlsMatched?: string;
            /** Not every matching url has a signal. */
            numUrlsWithSignal?: string;
            /** Experimental layer of the corresponding pattern. */
            patternLayer?: string;
            /** Optionally populated in mediators. A list of patterns that actually contributed to the final mediated signal. */
            patternsUsedInMediation?: string[];
            /**
             * Score percentile of matching urls. If present, it has N entries for buckets of roughly equal number of urls. N is specified the aggregation. The value is the min score in that
             * bucket.
             */
            percentile?: number[];
            runningMeanAndVarianceInternalState?: IndexingSignalAggregatorRunningMeanAndVarianceInternalState;
            /** Random samples. */
            samples?: IndexingSignalAggregatorUrlScore[];
            /** for calculating percentile */
            scores?: number[];
            /** For debugging purposes, this is an id of the signal associated with this AggregatedScore. For pattern score, this may be the length of the pattern. */
            signalId?: number;
            /** If this field presents, it is for a single url. No other field should appear. */
            singleUrlScore?: IndexingSignalAggregatorUrlScore;
            /** summation varaible used to get mean */
            totalScore?: number;
            /** low-order part of total_score */
            totalScoreLow?: number;
            /** summation variable for calculating deviation note, these are now only used for legacy and debugging purposes */
            totalScoreSqr?: number;
            /** low order part of total_score_sq */
            totalScoreSqrLow?: number;
            /** for calculating weighted mean/dev */
            totalWeight?: number;
            /** low order part of total_weight */
            totalWeightLow?: number;
        }
        interface IndexingSignalAggregatorRunningMeanAndVarianceInternalState {
            /**
             * The variable which in the Wikipedia page is referred to as M_2: m2 = w_1 * (x_1 - mean)^2 + ... + w_n * (x_n - mean)^2. The algorithm implemented in RunningMeanAndVarianceUtil
             * provides a way to update m2 in a numerically stable way when the data set grows. If total_weight = 0, then m2 is meaningless, and its value is unspecified, except that it must be
             * finite and >= 0.
             */
            m2?: number;
            /**
             * Mean of the data set, mean = (w_1 * x_1 + ... + w_n * x_n) / total_weight. The algorithm implemented in RunningMeanAndVarianceUtil provides a way to update this mean in a
             * numerically stable way when the data set grows. If total_weight = 0, then mean is meaningless, and its value is unspecified, except that it must be finite.
             */
            mean?: number;
            /** Total weight of the data set, total_weight = w_1 + ... + w_n. */
            totalWeight?: number;
        }
        interface IndexingSignalAggregatorSccData {
            parentPattern?: IndexingSignalAggregatorSccSignal;
            /** The most immediate pattern data. */
            pattern?: IndexingSignalAggregatorSccSignal;
        }
        interface IndexingSignalAggregatorSccSignal {
            clicksBad?: number;
            clicksImage?: number;
            clicksTotal?: number;
            /** For debugging purpose only. */
            debugInfo?: string[];
            /**
             * This represents the number of urls with image clicks. A url can have both image and non-image clicks, in which case we set num_image_urls to be the ratio of image_clicks vs total
             * clicks. For example, if a url has 10 total clicks and 7 image clicks, num_image_urls will be set to 0.7.
             */
            numImageUrls?: number;
            numUrls?: string;
            /** For debugging purpose only. */
            pattern?: string;
        }
        interface IndexingSignalAggregatorUrlPatternSignals {
            coverage?: IndexingSignalAggregatorAgeWeightedCoverageData;
            pagerankScore?: IndexingSignalAggregatorAggregatedScore;
            patternScore?: IndexingSignalAggregatorAggregatedScore;
            priorSignal?: IndexingSignalAggregatorUrlPatternSignalsPriorSignal[];
            regexpPatternScore?: IndexingSignalAggregatorAggregatedScore;
            sccData?: IndexingSignalAggregatorSccData;
        }
        interface IndexingSignalAggregatorUrlPatternSignalsPriorSignal {
            aggregatedScore?: IndexingSignalAggregatorAggregatedScore;
            priorSignalId?: string;
        }
        interface IndexingSignalAggregatorUrlScore {
            /**
             * The number of weekly performance records if the UrlScore is extracted from the DSAC data. It should be used in case a URL is no longer served. As of 2014-10-14, this field is for
             * the evaluation purpose only.
             */
            dsacNumWeeklyPerfRecords?: number;
            /** If this field is set, it indicates the url is eligible to be aggregated to one of the experimental layers. */
            eligibleExperimentalLayer?: string;
            /** The timestamp of the first time this document is served anywhere. */
            firstServedTimestamp?: string;
            /** Whether this url has important signal. Used for keeping patterns that match too few URLs but some of them have good clicks. */
            isImportant?: boolean;
            /** score might be missing if the url does not have signal. */
            score?: number;
            /** url might be missing if we can get it from sstable key. */
            url?: string;
            /** weight for this url. */
            weight?: number;
        }
        interface IndexingSpeechSpeechPropertiesProto {
            /** Duration of audio in processed fragment (including non-speech), in seconds. */
            audioDuration?: number;
            /** If true, the media file is audio-only. If false, also has video track(s). */
            audioOnly?: boolean;
            /**
             * Estimated duration of audio in the whole file (including non-speech), in seconds. If this is greater than 0, then it will either be equal to audio_duration (when truncated_file is
             * false), or to the length of the content (audio or video) according to the file header (when truncated_file is true).
             */
            estimatedAudioDuration?: number;
            /** Our confidence in the duration estimate, on a scale from 0 (not confident) to 1 (very confident). An estimate should have a confidence of at least 0.5 if it is to be shown to users. */
            estimatedAudioDurationConfidence?: number;
            /** The spoken language, see i18n/identifiers/languagecode.h and go/gl2014. This may or may not match the language of the written page. (Examples: "en", "sv", "zh-CN"). */
            languageCode?: string;
            /** Total number of recognized words in processed fragment. */
            numWords?: number;
            /** Measure of the estimated output accuracy from the speech recognition code, from 0 to 1. Based on word-level confidence and possibly other factors. */
            recognizerAccuracy?: number;
            /** Duration of speech in processed fragment, in seconds. */
            speechDuration?: number;
            /**
             * If true, we may have processed a truncated file (most likely due to a size-cutoff when crawling). As a result, the audio duration is a lower bound and the other fields reflect only
             * the processed prefix of the file.
             */
            truncatedFile?: boolean;
        }
        interface IndexingUrlPatternUrlTreeBigTreeBranch {
            features?: IndexingUrlPatternUrlTreeUrlFeatures;
            /** The fingerprint of the features string. */
            patternId?: string;
            payload?: any;
        }
        interface IndexingUrlPatternUrlTreeUrlFeature {
            fingerprint?: string;
            /** If consider position when calculating fingerprint of url feature. */
            fingerprintWithGroupInType?: boolean;
            /** Used together w/ type field to group features, for finding features with too many possible values. */
            groupInType?: string;
            type?: string;
            value?: string;
        }
        interface IndexingUrlPatternUrlTreeUrlFeatures {
            feature?: IndexingUrlPatternUrlTreeUrlFeature[];
        }
        interface IndexingUrlPatternUrlTreeUrlTree {
            /** Keeping information for dominating branches separately, to prevent docs on smaller branches from being dropping during sampling. */
            bigBranch?: IndexingUrlPatternUrlTreeBigTreeBranch[];
            debugInfo?: IndexingUrlPatternUrlTreeUrlTreeDebugInfo;
            key?: IndexingUrlPatternUrlTreeUrlTreeKey;
            /** node(0) is root. */
            node?: IndexingUrlPatternUrlTreeUrlTreeNode[];
            /** Used in url pattern matcher for cache invalidation. */
            retrievalTimestamp?: number;
            /**
             * The key for this UrlTree, also will be the key in sstable. The old format is site, while the new format will be UrlTreeKey. Only one field can be set in the same time for site and
             * key.
             */
            site?: string;
            /** The time when this UrlTree is built, encoded as seconds past the epoch (Jan 1, 1970). */
            timestamp?: number;
            /** Any additional information. */
            treeInfo?: any;
        }
        interface IndexingUrlPatternUrlTreeUrlTreeDebugInfo {
            innerSimilarity?: number;
        }
        interface IndexingUrlPatternUrlTreeUrlTreeKey {
            crawlerId?: string;
            domain?: string;
            hostname?: string;
        }
        interface IndexingUrlPatternUrlTreeUrlTreeNode {
            indexOfSubTreeWithoutSplittingFeature?: number;
            indexOfSubTreeWithSplittingFeature?: number;
            parent?: number;
            /** The path from root to current node. This is only used for debugging. */
            pathFromRoot?: string;
            /** This is only used in leaf nodes which represents a url pattern. It is the fingerprint of the splitting url features from root to the leaf. */
            patternId?: string;
            payload?: any;
            splittingFeature?: IndexingUrlPatternUrlTreeUrlFeature;
            /** The information gain of content features when selecting this splitting feature to split the node. */
            splittingFeatureScore?: number;
        }
        interface KaltixPerDocData {
            /** approx. 2 bytes for top 1B */
            KaltixRank?: number;
            /** empty for now */
            LocalKaltixRank?: number;
            /** empty for now */
            SiteKaltixRank?: number;
        }
        interface KeGovernanceTypedRegions {
            /**
             * Values are go/iii RegionCode in capital case. It is a good practice to keep elements in this list unique, although not enforced. In case of duplicated entries, they'll be treated as
             * if there were only one entry of the same value.
             */
            regions?: string[];
            /** The particular type of region should be explicitly set to disambiguate. */
            regionType?: string;
        }
        interface KnowledgeAnswersAnyType {
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
        }
        interface KnowledgeAnswersAttributeType {
            /** Use in parsing: the value filled with must be in the list of this. If no attribute ids are specified, this value can be filled with any attribute. */
            attribute?: string[];
            /** If exist, the attribute will be applied on the given pivot slot. This helps type checking when qrewrite constructs function calls with an attribute-typed slot. */
            pivotEntitySlot?: string;
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
        }
        interface KnowledgeAnswersBooleanType {
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
        }
        interface KnowledgeAnswersCollectionType {
            /**
             * The collection this value is filled with must be one of these collections (denoted by a /collection/* id). If no collections are specified, this value can be filled with any
             * collection.
             */
            collection?: string[];
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
        }
        interface KnowledgeAnswersCompoundType {
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
        }
        interface KnowledgeAnswersContainerType {
            slotNames?: string[];
        }
        interface KnowledgeAnswersDateType {
            /** If true, will allow all resolutions that are ranges. */
            allowAllRangeResolutions?: boolean;
            /** If true, overrides all other options in this message and allows any kind of DateTime annotation. */
            allowAllResolutions?: boolean;
            /** If true, will allow all resolutions except holidays. */
            allowAllResolutionsExceptHolidays?: boolean;
            /** If true, will allow resolutions that aren't contiguous sequences of 4 digits annotated as 24-hr times. These are often mis-interpreted years or postcodes. */
            allowAllResolutionsWithout4digit24hrTime?: boolean;
            /**
             * If true, will allow resolutions without an explicit hour. Symbolic ranges such as [this evening] are not considered as explicit hour, but the range [1-3pm] is considered as
             * explicit.
             */
            allowAllResolutionsWithoutTime?: boolean;
            /** If true, will parse a mention to DateTime of resolution day. This allows parsing strings like "August 30th", "2012-12-25"; */
            allowDayResolution?: boolean;
            /** If true, will allow day resolutions except holidays or ordinal numbers, such as "today", "December 13", but "Christmas", "first" are not allowed. */
            allowDayResolutionExceptHolidaysOrOrdinal?: boolean;
            /** If true, will allow resolutions with an explicit hour such as "8am", "5pm". */
            allowHourResolution?: boolean;
            /** If true, will parse a mention to DateTime of resolution month. This allows parsing strings like "this August", "2012-12"; */
            allowMonthResolution?: boolean;
            /** If true, will allow "now" resolutions, but not any other time */
            allowNowResolution?: boolean;
            /** If true, will allow symbolic time resolutions such as "tonight". */
            allowSymbolicTime?: boolean;
            /** If true, will allow time resolutions without an explicit timezone. */
            allowTimeResolutionsWithoutExplicitTimezone?: boolean;
            /** If true, will parse a mention to DateTime of resolution year. This allows parsing strings like "Next year ", "2010"; */
            allowYearResolution?: boolean;
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
            subType?: string;
        }
        interface KnowledgeAnswersDependencyType {
            containerType?: KnowledgeAnswersContainerType;
            intersectType?: KnowledgeAnswersIntersectType;
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
            sameType?: KnowledgeAnswersSameType;
            unionType?: KnowledgeAnswersUnionType;
        }
        interface KnowledgeAnswersDialogReferentialResolution {
            /** True iff this ReferentialResolution is part of an intent and refers to the full MRF subtree (rather than just the intent). */
            refersToFullMrf?: boolean;
            resolutionType?: string;
        }
        interface KnowledgeAnswersDurationType {
            /** Range constraint limits the set of durations accepted. The values of the range are in milliseconds. Currently, this constraint is only enforced in Loose Parser. */
            rangeConstraint?: KnowledgeAnswersRangeConstraint;
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
        }
        interface KnowledgeAnswersEntityType {
            /**
             * This field specifies that containing entity must be: - in *any* 'collection' if 'in_all_collections' is false (default) - in *every* 'collection' if 'in_all_collections' is true.
             * The collection field contains strings of the form '/collection/'. If no collections are specified, this value can be filled with any entity. A collection specified as an empty
             * string has a special meaning for Aqua induction, which is that the type includes all entities.
             */
            collection?: string[];
            /**
             * The entity that this value is filled with must not be any of these collections (denoted by a /collection/* id). This restriction does not affect parsing; it is used only to filter
             * attributes in the extraction flow.
             */
            excludedCollection?: string[];
            /** The entity that this value is filled with must be one of the following explicitly specified KG-ids. */
            id?: string[];
            /**
             * The entity that this value is filled with must be of the explicit type and/or contain the explicitly specified id. This field can not be used for kg mids, which should directly use
             * the id field above.
             */
            identifier?: KnowledgeAnswersIntentQueryIdentifier[];
            inAllCollections?: boolean;
            /**
             * If this is set to true for a slot and the entity is a location, the latitude and longitude will be available in variables $SlotName_Latitude and $SlotName_Longitude, respectively.
             * The latitude and longitude data comes from KG.
             */
            includeGeolocationData?: boolean;
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
            /** This field is deprecated. It is not removed completely since this proto was saved with this field in proto text files used by the Grammy tool. */
            stbrDomain?: string[];
        }
        interface KnowledgeAnswersIntentModifiers {
            /**
             * Language of all of the non-annotation tokens of the query interpretation, if it is different than |language|. This can happen with English smearing, e.g. [height rousseau] will
             * trigger as "fr" when issued in fr/FR, but really the language is "en". This can also happen when we have extra information about the language model, e.g. language="zh",
             * alternate_language="zh-Hant".
             */
            alternateLanguage?: string;
            definiteness?: string;
            /** Language of parsed query. */
            language?: string;
            /** Since there's only IMPERATIVE, consider using Marker.command instead. */
            mood?: string;
            plurality?: string;
            /** Whether or not the question is a polar (yes/no) question. */
            polarQuestion?: boolean;
            /** Sentiment analysis attached to an intent implies the sentiment user expressed behind that query. This is generated by the Empathetic Servlet in the QRewrite. */
            sentiment?: SentimentSentiment;
            tense?: string;
        }
        interface KnowledgeAnswersIntentQueryAnnotationLayerSignals {
            customVehicleActionArgumentAnnotatorSignals?: KnowledgeAnswersIntentQueryCustomVehicleActionArgumentAnnotatorSignals;
            freetextAnnotationSignals?: any;
            nimbleAnnotationSignals?: KnowledgeAnswersIntentQueryNimbleAnnotationSignals;
            ntprAnnotationSignals?: any;
            qrefAnnotationSignals?: KnowledgeAnswersIntentQueryQrefAnnotationSignals;
            semanticAnnotationSignals?: KnowledgeAnswersIntentQuerySemanticAnnotationSignals;
            teleportArgumentAnnotatorSignals?: any;
        }
        interface KnowledgeAnswersIntentQueryArgPath {
            components?: KnowledgeAnswersIntentQueryArgPathComponent[];
        }
        interface KnowledgeAnswersIntentQueryArgPathComponent {
            argName?: string;
            index?: number;
        }
        interface KnowledgeAnswersIntentQueryArgument {
            /** This field is used inside Aqua and outside Aqua for identifying the token indices and/or byte offsets of this argument */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /**
             * Eval_data was not derived at parsing time (i.e. is not expected to be produced by the IG), but heuristically determined by matching the ArgumentValue to an annotation/query
             * fragment.
             */
            heuristicEvalData?: NlpSemanticParsingAnnotationEvalData;
            /**
             * Slot schema key for this Argument. Note: This is still under development and not available for general use. Contact meaning-platform-eng@ for questions. Note: Currently
             * MeaningSchemaSlotKey proto has both mid and unique_id. In future, only mid will be present in it. We are in the process of moving "unique_id" out of it. See (b/168907943). Note: The
             * logged version of intent_query will only have "mid" populated in it to save space and avoid data duplication.
             */
            key?: KnowledgeAnswersMeaningSchemaSlotKey;
            /** A flattened representation of all intent modifiers that apply to this argument. */
            modifiers?: KnowledgeAnswersIntentModifiers;
            /**
             * Name of this argument. If this Argument is part of a FunctionCall, it must have a name or it is not well-formed. If this Argument is from an Annotator, the name field should be
             * empty.
             */
            name?: string;
            /** Signals associated with this argument. */
            signals?: KnowledgeAnswersIntentQueryArgumentSignals;
            /** The value of this argument. */
            value?: KnowledgeAnswersIntentQueryArgumentValue;
        }
        interface KnowledgeAnswersIntentQueryArgumentProvenance {
            /**
             * If populated, the current query contains an anaphor that refers to the value. For example: U: Weather in Paris. [Weather(location=paris)] G: 65 degrees and sunny. U: How many people
             * live there? [Population(city=paris)] The "there" in the current query would have the "anaphor" field set. NOTE: after a string rewrite this field will not be populated anymore if
             * the rewrite replaced the anaphor with the corresponding value. For example, if we rewrite [How many people there] to [How many people in Paris], the CurrentQuerySignals for "paris"
             * will not contain an "anaphor" message anymore in the following turns. It will only contain an eval_data for the span that corresponds to "paris" in the query.
             */
            anaphor?: KnowledgeAnswersIntentQueryArgumentProvenanceQueryAnaphor;
            attentionalEntity?: KnowledgeAnswersIntentQueryArgumentProvenanceAttentionalEntity;
            /**
             * NOTE: PreviousQuery is used for values that originate directly from QRef entities annotated in the user query. AttentionalEntity is used for values that come from the system
             * (entities published by a dialog). These values could also originate from an entity annotated by QRef in the query, but this is not necessarily the case. SearchAnswerValue is used
             * for values that come from the system as part of the answer of the user query. For example: U: Wife of Barack Obama G: Barack Obama's wife is Michelle Obama Here "Barack Obama" can
             * have an ArgumentProvenance of PreviousQuery, or AttentionalEntity if a dialog publishes that entity and the interpretation pulls the value from it. "Michelle Obama" can have an
             * ArgumentProvenance of SearchAnswerValue, or AttentionalEntity if the dialog publishes that entity and the interpretation pulls the value it.
             */
            currentQuery?: KnowledgeAnswersIntentQueryArgumentProvenanceCurrentQuery;
            injectedContextualSchema?: any;
            previousQuery?: KnowledgeAnswersIntentQueryArgumentProvenancePreviousQuery;
            previousResponseMeaning?: any;
            previousTaskState?: KnowledgeAnswersIntentQueryArgumentProvenancePreviousTaskState;
            searchAnswerValue?: KnowledgeAnswersIntentQueryArgumentProvenanceSearchAnswerValue;
        }
        interface KnowledgeAnswersIntentQueryArgumentProvenanceAttentionalEntity {
            /** This key can be used to recover the attentional entity from the corresponding attentional_entities::EntityCache. */
            attentionalEntityKey?: string;
            /** Source information from the AttentionalEntityReader. */
            mentionProperties?: AttentionalEntitiesMentionProperties;
        }
        interface KnowledgeAnswersIntentQueryArgumentProvenanceCurrentQuery {
            /**
             * The span(s) in the query where the value comes from. Note that if the argument is split across the current and previous query, this message should *NOT* be populated. Please use
             * PreviousQuery below, populating it's eval-data fields accordingly.
             */
            evalData?: NlpSemanticParsingAnnotationEvalData[];
            neuralLocationAnnotator?: any;
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersIntentQueryArgumentProvenanceInjectedContextualSchema {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersIntentQueryArgumentProvenanceNeuralLocationAnnotator {
        }
        interface KnowledgeAnswersIntentQueryArgumentProvenancePreviousQuery {
            /**
             * The span(s) in the current query where the value comes from. This is used when the argument spans both the current and previous query. Eg jfk death -> [death, when] spans both
             * queries.
             */
            currentQueryEvalData?: NlpSemanticParsingAnnotationEvalData[];
            /** The span(s) in the query where the value comes from. */
            evalData?: NlpSemanticParsingAnnotationEvalData[];
            /** The event ID of the query where this value was pulled from. */
            eventId?: EventIdMessage;
            neuralLocationAnnotator?: any;
            role?: KnowledgeAnswersIntentQueryArgumentProvenancePreviousQueryRole;
            source?: string;
        }
        interface KnowledgeAnswersIntentQueryArgumentProvenancePreviousQueryRole {
            intentId?: string;
            slotName?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersIntentQueryArgumentProvenancePreviousResponseMeaning {
        }
        interface KnowledgeAnswersIntentQueryArgumentProvenancePreviousTaskState {
            /**
             * Argument names in the DialogIntentState that the argument corresponds to. This is repeated so it can handle complex argument update paths. (ordered from outermost argument to
             * innermost argument)
             */
            argumentName?: string[];
            /**
             * The span(s) in the current query (if any) used to resolve the previous query's DIS. Example: U: Barack Obama G: Do you want his age or his height? U: The first one. G: Age(/m/obama)
             * In this example, the intent is derived from the previous query's DIS, but also needs to be resolved in the current query since the user was presented with multiple options.
             */
            currentQueryEvalData?: NlpSemanticParsingAnnotationEvalData[];
            /** The id of the specific DialogIntentState instance that the argument corresponds to. */
            dialogIntentStateId?: string;
            /** Intent name of the DialogIntentState that the argument corresponds to. */
            intentName?: string;
            listCandidate?: KnowledgeAnswersIntentQueryArgumentProvenancePreviousTaskStateListCandidate;
            previousFunctionCall?: any;
        }
        interface KnowledgeAnswersIntentQueryArgumentProvenancePreviousTaskStateListCandidate {
            /** The presented_index of the field_candidate in the DialogIntentState field_signals that the argument corresponds to. */
            candidateIndex?: number;
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersIntentQueryArgumentProvenancePreviousTaskStatePreviousFunctionCall {
        }
        interface KnowledgeAnswersIntentQueryArgumentProvenanceQueryAnaphor {
            /**
             * If populated, the spans in the current query where this value was annotated. This is a repeated field because some values can be annotated from a set of discontiguous spans (e.g.
             * some intent phrases), but in most cases this field will contain only one item or it will be empty (for values inferred from context without the use of anaphora).
             */
            evalData?: NlpSemanticParsingAnnotationEvalData[];
        }
        interface KnowledgeAnswersIntentQueryArgumentProvenanceSearchAnswerValue {
            /** This identifies the SearchAnswerValues where this value was pulled from. */
            eventId?: EventIdMessage;
            /**
             * Each SearchAnswerValue can have a primary value and a list of metadata values. If this index is set, this value was pulled from the metadata value at this index, otherwise it was
             * pulled from the primary value.
             */
            metadataValueIndex?: number;
            /** The display text of this answer value. It's taken from the search answer value display text if present, or the canonical name if it's an entity. */
            text?: string;
            /** The index of the SearchAnswerValue where this value was pulled from. */
            valueIndex?: number;
        }
        interface KnowledgeAnswersIntentQueryArgumentSignals {
            /** Whether this argument was added by CloseAnswers in Postref. This bit is used to mark the corresponding interpretation/intent query as such by setting is_close_interpretation bit. */
            addedByCloseAnswers?: boolean;
            /** For this argument, backend performed fuzzy match. */
            allowedFuzzyMatch?: boolean;
            /** Relationships between entities */
            annotatedRelationship?: LogsSemanticInterpretationIntentQueryWebrefEntityRelationship[];
            /** Signals to facilitate orchestration of TUIG annotations. */
            annotationLayerSignals?: KnowledgeAnswersIntentQueryAnnotationLayerSignals;
            /**
             * One or more ChainIds from a ChainAnnotation whose "organization_mid" matches the MID. As of 2021-01 multiple chain_ids may be specified if the organization for MID controls multiple
             * chains. See go/chains-lckp-robust-triggering for motivation.
             */
            chainId?: LocalsearchChainId[];
            /** If the literal.obj_type of the argument value is ID (Entity), this stores cluster scoring information for that entity, if the entity belongs to a cluster. */
            clusterInfo?: QualityViewsExtractionClusterInfo;
            /** If the literal.obj_type of the argument value is ID (Entity), this represents the collection that the entity in this argument is a member of. */
            collectionMembership?: KnowledgeAnswersIntentQueryCollectionMembership[];
            /**
             * How this argument was resolved through context from a previous query. Examples: obama -> "he" is resolved from the Obama entity starbucks -> Q2 is resolved from the list of shops
             * (Attentional Entities)
             */
            contextResolution?: string;
            /** If the literal.obj_type of the argument value is ID (Entity), this represents freebase types of the entity in this argument. */
            deprecatedFreebaseType?: string[];
            /**
             * A list of mids that "support" this argument in voting, i.e, results that support these mids will be treated as if they support the argument. This field has been deprecated in favor
             * of related_entity. b/27363861
             */
            deprecatedSupportingMid?: string[];
            /**
             * Signals about what other entities this entity implies / is implied by. This is useful for grounding. Example: b/138388207: suppressing song intents if the artist entity doesn't link
             * to the song title. This value specifies the order of annotations in a QRef annotation chain so they can refer to each other.
             */
            entityNumber?: number;
            /**
             * Signals about what other entities this entity implies / is implied by. This is useful for grounding. Example: b/138388207: suppressing song intents if the artist entity doesn't link
             * to the song title.
             */
            entityRelationship?: NlpSemanticParsingQRefAnnotationEntityRelationship[];
            /** Status indicating whether the user has completely expressed the semantics of the argument. */
            expressionStatus?: NlpSemanticParsingExpressionStatus;
            /** Whether the argument entity comes from a manual graphic symbol annotation. This is later used as a heuristic for poor web result quality. */
            fromManualSymbolAnnotation?: boolean;
            /** Whether the argument entity comes from a graphic symbol annotation. This is later used as a heuristic for poor web result quality. */
            fromSymbolAnnotation?: boolean;
            /** The gaia id for the entity (person or plus page). */
            gaiaId?: string;
            groundingSignals?: KnowledgeAnswersIntentQueryGroundingSignals;
            /** If the argument is entity, the ungrounded type the entity is. For example, the entity argument is /m/0p83l (Jasmine), the value of this field should be "Plant" if it is present. */
            isAUngroundedTypeOf?: string;
            /**
             * If true, the value of the argument is populated with the default value specified by the system if the value can't be inferred from the input query. In IntentConfig case, the default
             * value is specified by using IntentConfig.slot.default_value.
             */
            isDefaultValue?: boolean;
            /** Set when the argument has an enum value - a normalized_string_type from the intent catalog. */
            isEnum?: boolean;
            /** Set when the eval_data was not derived at parsing time, but heuristically determined by matching the ArgumentValue to an annotation/query fragment. */
            isEvalDataHeuristic?: boolean;
            /** Whether this annotation was propagated as part of a Genie rewrite (go/genie-aqua). */
            isGenieAnnotation?: boolean;
            /** Whether this argument was annotated by Intentgen QUIK model (go/intentgen-quik) */
            isIntentgenAnnotation?: boolean;
            /** Whether this argument was annotated by nimble (go/nimble-annotator) */
            isNimbleAnnotation?: boolean;
            /** Entity location information (latitude/longitude) from freebase. */
            location?: GeostorePointProto;
            /** The usual semantic role associated with the signal from lightweight tokens attached to this argument span. */
            locationMarkersSignals?: KnowledgeAnswersIntentQueryLocationMarkersSignals;
            /** Signals about the media entity for this argument. */
            mediaEntitySignals?: KnowledgeAnswersIntentQueryMediaEntitySignals;
            /** List of QRef implied entities merged into this entity during parsing. Clients should not rely on the order, as it is derivation-dependent. */
            mergedImpliedEntity?: KnowledgeAnswersIntentQueryImpliedEntity[];
            /**
             * For collection arguments, it is useful to save what was the original mid that qref annotated. For example, if the collection is /collection/films, we'll have the mid for /en/film
             * here (/m/02vxn).
             */
            midEquivalentToCollection?: string;
            /** Whether there were multiple equally good matches from horizontal_list_selection. */
            multipleHorizontalListSelectionMatches?: boolean;
            /** Signals derived from Munin Function call annotations. */
            muninSignals?: KnowledgeAnswersIntentQueryMuninSignals;
            /** Additional signals for on-device annotations. */
            onDeviceAnnotationSignals?: KnowledgeAnswersIntentQueryOnDeviceAnnotationSignals;
            /** The oyster feature id. NOTE: As of Mar 2017, the cell ID field of the feature ID might not be set. See http://b/35447230#comment10 */
            oysterId?: GeostoreFeatureIdProto;
            /** Experiment ID for experiments that were used to parse this FunctionCall. Empty indicates no experiments used. */
            parsedDueToExperiment?: string[];
            /**
             * Personal entities are compound entities made up of entities and their attributes, where the entities can be compound too. E.g., "my father's mother" can have a summary node
             * annotation of "Mother(Father(Myself))"
             */
            personalEntity?: KnowledgeAnswersIntentQueryPersonalEntity[];
            /**
             * Information about where the value of this argument came from. For example, it could have been explicitly provided in the query, pulled in from the previous state, or pulled from
             * attentional entities.
             */
            provenance?: KnowledgeAnswersIntentQueryArgumentProvenance[];
            /** The QRef confidence score for an entity argument. */
            qrefConfidenceScore?: number;
            /**
             * The index of the QueryJoin interpretation from which this annotation is taken. We copy over the value given by nlp.semantic_parsing.annotators.QrefAnnotator. The value will be "-1"
             * if the annotation is coming from low confidence Qref annotations. NOTE - this is generated from as QRef's interetation_number.
             */
            qrefInterpretationIndex?: number;
            /** A copy of the span of canonical (raw) parser input text corresponding to this annotation. */
            rawQueryText?: string;
            /** List of entities that are semantically related to the argument as well as details of the relationship. */
            relatedEntity?: NlpSemanticParsingRelatedEntity[];
            /** Relatedness Matrix signals about this argument, e.g., query_popularity. */
            relatednessSignals?: KnowledgeAnswersIntentQueryRelatednessSignals;
            /**
             * Whether this argument was resolved through context from a previous query. Examples: obama -> "he" is resolved from the Obama entity starbucks -> Q2 is resolved from the list of
             * shops
             */
            resolvedFromContext?: boolean;
            /** Whether this argument was resolved from a pronoun mention in the query. Eg: [how old was obama when *he* became president] */
            resolvedFromPronoun?: boolean;
            /** The list of result supports for this Argument. */
            resultSupport?: UniversalsearchNewPackerKnowledgeResultSupport[];
            /** Signals derived from SAFT. */
            saftSignals?: KnowledgeAnswersIntentQuerySaftSignals;
            /** Equivalent shopping ids for the argument. */
            shoppingIds?: KnowledgeAnswersIntentQueryShoppingIds;
            /** go/stbr supportthis is an */
            supportTransferRules?: LogsSemanticInterpretationIntentQuerySupportTransferRule[];
            /** Support Transfer signals for this entity. */
            supportTransferSignals?: KnowledgeAnswersIntentQuerySupportTransferSignals;
            /** Type of ungrounded argument. It is exclusively used when simple_value.ungrounded_value is populated. */
            ungroundedValueType?: KnowledgeAnswersValueType;
            /**
             * Webref entity index for this argument, necessary for interpreting the relationship structure, and the list to index into. Specifically we need this to understand qref implications
             * since they edges are represented with entity indexes.
             */
            webrefEntitiesIndex?: number;
            /** This represents which list entities index refers to. */
            webrefListSource?: string;
        }
        interface KnowledgeAnswersIntentQueryArgumentValue {
            /** Custom type used by actions-on-google in-dialog queries. See go/3p-custom-intents-wrt-meaning-catalog */
            aogSlot?: NlpSemanticParsingProtoActionsOnGoogleAogSlot;
            /** Device actions custom types. */
            appAnnotation?: NlpSemanticParsingAppAnnotation;
            audio?: NlpSemanticParsingModelsMediaAudio;
            /** Calendar custom types. Details in go/cal-ref. */
            calendarEvent?: AssistantApiCoreTypesCalendarEvent;
            /** Details in go/multi-account-event-representation. */
            calendarEventWrapper?: any;
            calendarReference?: QualityQrewriteCalendarReference;
            /** Custom type used by Complex Queries. This is populated based on the output of the RPC to the Complex Queries Boq node. */
            complexQueriesRewrite?: QualityGenieComplexQueriesComplexQueriesOutputRewrite;
            /**
             * Component reference between WebrefEntity and Mention. This should only ever be set in argument values in WebrefEntities (e.g. in a QueryJoin). The processing expectation is that the
             * value including the component reference is discarded altogether and replaced by reference target. Use QueryJoinToMeaningStructConverter to perform the replacement. An example value
             * parallel to this reference may exist, but it's meant purely for human consumption and should not be used.
             */
            componentReference?: RepositoryWebrefComponentReference;
            /** A value that is a coreference or variable binding to some other part of the tree. See go/mrf-variables. */
            coreference?: KnowledgeAnswersIntentQueryCoreference;
            /** *** Opaque types that are likely to become fully supported: *** Represents: date and time expressions. Annotated by: datetime subgrammar. */
            dateTime?: NlpSemanticParsingDatetimeDateTime;
            /** Media custom types. For example use, see go/valyrian-media-dd. */
            device?: NlpSemanticParsingModelsMediaCastDeviceAnnotation;
            /** DeviceId custom types. Details in go/reply-broadcast */
            deviceId?: AssistantApiCoreTypesDeviceId;
            /** DeviceUserIdentity custom types. Details in go/reply-broadcast */
            deviceUserIdentity?: AssistantApiCoreTypesDeviceUserIdentity;
            /** Represents: duration expressions (e.g. 5 minutes). Annotated by: datetime subgrammar. */
            duration?: NlpSemanticParsingDatetimeDuration;
            /** *** Fully supported types *** An argument can also be a function call. */
            funcall?: KnowledgeAnswersIntentQueryFunctionCall;
            /** HomeAutomation custom types. Details in go/smarthome_with_monastery. */
            homeAutomationDevice?: AssistantVerticalsHomeautomationProtoHomeAutomationDevice;
            /** Represents: location expressions. Annotated by: location subgrammar. */
            location?: NlpSemanticParsingLocalLocation;
            media?: NlpSemanticParsingModelsMediaMediaAnnotation;
            /** Custom type used by tap-to-read for embedding a MessageNotification message in a GetMessageContent intent. */
            messageNotification?: AssistantApiCoreTypesMessageNotification;
            /** Represents: money expressions (e.g. 25$). Annotated by: number subgrammar. */
            money?: NlpSemanticParsingModelsMoneyMoney;
            /**
             * Custom type used by NarrativeNews. This is populated by the narrative news provider annotator, and it differs semantically from a mid for a news brand in that it doesn't refer to
             * the field of widely known news brands but rather but to the specific audio news RSS feeds that the narrative news feature serves. (There is of course substantial overlap between
             * those two concepts)
             */
            narrativeNewsProvider?: NlpSemanticParsingModelsNarrativeNewsNewsProvider;
            /** Represents: number expressions. Annotated by: number subgrammar. */
            number?: NlpSemanticParsingNumberNumber;
            /**
             * OnDevice custom types. Device on which an intent should be fulfilled. Differs semantically from device fields used by Media and HomeAutomation: this is annotated by the on_device
             * subgrammar, and will not output any metadata beyond what the subgrammar outputs. See go/on_device_induction_quality.
             */
            onDevice?: NlpSemanticParsingModelsOnDevice;
            /** Represents: structured person names, including common names and personal contacts. Annotated by: go/person-subgrammar. */
            person?: NlpSemanticParsingModelsPersonPerson;
            /** Entity parsed from manual grammar interpretation in the Personal Intelligence domain. */
            personalIntelligenceEntity?: NlpSemanticParsingPersonalIntelligenceEntity;
            productivityListItem?: AssistantProductivityListItem;
            /** Represents: intervals of recurrence for repeated tasks. See go/recurrence-subgrammar Annotated by: recurrence subgrammar. */
            recurrence?: NlpSemanticParsingModelsRecurrence;
            reminder?: QualityActionsReminder;
            /** Sensitive value, see go/sensitive-intents and go/a4w-multi-turn-dialog */
            sensitiveValue?: KnowledgeAnswersIntentQuerySensitiveArgumentValueGuard;
            /**
             * Argument level query sensitivities. 1) Statically defined Sensitivity is copied from IntentSlot at serving time so it can be propagated along with FunctionCall to places where the
             * Intent Catalog is not available. See go/sensitive-intents for details. 2) For the same reason, contextual sensitivites (eg., from AttentionalEntity mentions) are populated here too.
             * See go/tagging-sensitive-ae for details.
             */
            sensitivity?: KnowledgeAnswersSensitivitySensitivity[];
            shoppingMerchant?: NlpSemanticParsingModelsShoppingAssistantMerchant;
            /** Shopping custom types. See go/sopa-attentional. */
            shoppingOffer?: NlpSemanticParsingModelsShoppingAssistantOffer;
            shoppingProduct?: NlpSemanticParsingModelsShoppingAssistantProduct;
            shoppingProductExpression?: NlpSemanticParsingModelsShoppingAssistantProductExpression;
            shoppingStore?: NlpSemanticParsingModelsShoppingAssistantStore;
            /**
             * When literal is a datetime, it's really just an ISO 8601 datetime string. This case will eventually be replaced with the date_time field, which is more expressive and can also
             * represent recurrences, ranges, etc. Likewise, simple_value will replace the other types of simple values that literal is currently being used to represent.
             */
            simpleValue?: KnowledgeAnswersIntentQuerySimpleValue;
            /** Productivity custom types. Team: go/productivity-assistance. */
            timer?: QualityActionsTimer;
            /** Represents: timezone expressions (e.g. Eastern Daylight Time). Annotated by: datetime subgrammar. */
            timezone?: NlpSemanticParsingDatetimeTimeZone;
        }
        interface KnowledgeAnswersIntentQueryAttributeSignal {
            attributeId?: string;
            score?: number;
        }
        interface KnowledgeAnswersIntentQueryCollectionMembership {
            /** Human readable id of the collection. */
            collectionId?: string;
            /** Identifier of the collection, usually a MID (/m/xyz or /g/zyw). */
            collectionMid?: string;
            /** The collection score for a entity. */
            collectionScore?: number;
            /** Different types of scores for the collection. Each score type has at most one score. */
            score?: KnowledgeAnswersIntentQueryCollectionScore[];
        }
        interface KnowledgeAnswersIntentQueryCollectionScore {
            scoreType?: string;
            scoreValue?: number;
        }
        interface KnowledgeAnswersIntentQueryCoreference {
            /** A coreference is represented by an argument path starting from the root of the whole tree to the referenced value. */
            argPath?: KnowledgeAnswersIntentQueryArgPath;
        }
        interface KnowledgeAnswersIntentQueryCustomVehicleActionArgumentAnnotatorSignals {
            /** Stores any additional data which is required only at the intent fulfilment phase. */
            additionalAnnotationData?: { [P in string]: string };
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersIntentQueryFreetextAnnotationSignals {
        }
        interface KnowledgeAnswersIntentQueryFunctionCall {
            /** A list of arguments of this function call. */
            argument?: KnowledgeAnswersIntentQueryArgument[];
            /** The corresponding meaning catalog version that was used to generate this FunctionCall. */
            catalogVersion?: string;
            /**
             * Contextual Sensitivity (go/contextual-sensitivity) metadata indicating that a policy- or privacy- sensitive conversation context (previous queries, rewritten user queries, and
             * previous system responses, like attentional entities) is used to generate this FunctionCall. This needs propagation (1) from Interp to DialogIntentState (DIS) (see b/148479837) and
             * (2) from QRewrite/QUS down to Assistant Server's memory finalizer. One can use knowledge/answers/sensitivity/sensitivity_reader.h to parse this proto. NOTE(b/149091449): This is
             * part of the migration of contextual sensitivity protos from Interp sensitivity extension. (nlp::semantic_parsing::sensitivity) to this proto field. See the bug to track the
             * migration progress and for more details.
             */
            contextualSensitivity?: KnowledgeAnswersSensitivitySensitivity[];
            /** Contains data about which remodelings are being used for this funcall. For more information see go/meaning-remodeling-framework. */
            enabledRemodelings?: NlpMeaningMeaningRemodelingControl;
            /**
             * A list of token lists that were ignored during parsing because they are known context phrases for this interpretation. For example, for query [tell me how tall height of Obama
             * really], assuming "tell me", "tall", "of", "really" are explained and thus ignored, with corresponding prior 0.9, 0.8, 0.7, 0.6, following ignored tokens will be populated: {
             * ignored_tokens { token { ngram: "tell me", prior: 0.9} score: 0.9 } ignored_tokens { token { ngram: "tall", prior: 0.8} token { ngram: "of", prior: 0.7} score: 0.56 // currently
             * score = prior1 * prior2 * ... * prior N } ignored_tokens { token { ngram: "really", prior: 0.6} score: 0.6 } } These tokens can serve two purpose: 1) debug info to show why an
             * interpretation is generated; 2) carry the signals for downstream usage. Note: This field is under active development, and significant changes could happen. Please contact porky-pig@
             * if you want to use it.
             */
            ignoredTokens?: KnowledgeAnswersIntentQueryTokens[];
            /** The primary key for this FunctionCall. Note: This is still under development and not available for general use. Contact meaning-platform-eng@ for questions. */
            key?: KnowledgeAnswersMeaningSchemaKey;
            /**
             * The marker specifies the purpose of this meaning struct / function call: Is it asking a question, and if yes, for which slot(s)? Is it a command, statement, etc? This corresponds to
             * a (very coarse) notion of dialog acts. In the absence of this field, it will be inferred using the following algorithm (subject to marker applicability rules specified in
             * marker.proto, see also go/requested-slots): 1) Use the underlying Meaning Schema's default marker, if applicable. 2) Assume that the Meaning Struct is polar or a statement. The
             * presence of a marker will affect the value type of this function call.
             */
            marker?: KnowledgeAnswersMarker;
            /** A flattened representation of all intent modifiers that apply to this function call. */
            modifiers?: KnowledgeAnswersIntentModifiers;
            /** Name of this function call. The name must be present. If it is omitted, the FunctionCall is not well-formed. */
            name?: string;
            /**
             * Intent level query sensitivity (go/sensitive-intents). This metadata comes directly from Intent Catalog, indicating a single-shot query sensitivity without putting context into
             * considerations. Therefore, this requires a one-to-one match with each intent registered in Intent Catalog.
             */
            sensitivity?: KnowledgeAnswersSensitivitySensitivity;
            /** Signals at the function call level */
            signals?: KnowledgeAnswersIntentQueryFunctionCallSignals;
            /** A list of tokens that were ignored during parsing that cannot be explained by context phrases. */
            unexplainedTokens?: KnowledgeAnswersIntentQueryTokens[];
        }
        interface KnowledgeAnswersIntentQueryFunctionCallSignals {
            /** The argument mid that was used to compose the entity for a concept interpretation, along with the intent_composing_mid (one of the intent's equivalent MIDs). */
            argumentComposingMid?: string;
            /** The attributes from which this intent was generated during execution of AttributeSignalsProvider. |attribute_signals| is only populated for single entity funcalls. */
            attributeSignals?: KnowledgeAnswersIntentQueryAttributeSignal[];
            /** An entity that represents the concept of an entity-attribute intent by being composed of an intent equivalent MID and the argument MID. */
            conceptEntityMid?: string;
            confidenceLevel?: string;
            /** FunctionCall-s that this funcall was deduped against. */
            dedupedFuncalls?: KnowledgeAnswersIntentQueryFunctionCall[];
            /** Status indicating whether the user has completely expressed their intended semantics. (See go/streaming-nlu-fulfilment-protocol-v1 for more info. ) */
            expressionStatus?: NlpSemanticParsingExpressionStatus;
            freefolksTrigger?: string;
            /** Grounding signals for ranking/filtering, as well as whether to use Grounding Box and PGRP in AnswersRewriter. See comment on GroundingSignals for details. */
            groundingSignals?: KnowledgeAnswersIntentQueryGroundingSignals;
            /**
             * Used to indicate that an interpretation is high confidence and triggers different voting behavior. This bit should only be set for verticals. DEPRECATED. Use confidence_level
             * instead.
             */
            highConfidence?: boolean;
            intentAnnotationSources?: string[];
            /** An intent_relevant_mid that was used to compose the entity for a concept interpretation, along with argument_composing_mid (the question's argument MID). */
            intentComposingMid?: string;
            /**
             * Information about where the value of this intent came from. For example, it could have been explicitly provided in the query, pulled in from the previous dialog state, or pulled
             * from previous queries.
             */
            intentProvenance?: KnowledgeAnswersIntentQueryArgumentProvenance[];
            /** KG mids of entities that represent this intent. These entities are seen as equivalent to the Intent definition, and are specified in the Intent Catalog as relevant_mid. */
            intentRelevantMid?: string[];
            /** Whether the interpretation was generated using similar queries in POSTREF. In case POSTREF_AQUA generated the same entity-attribute interpretation, this is still set to true. */
            isCloseInterpretation?: boolean;
            /** Denotes whether this is an intent being fulfilled from user tapping a disambiguation card. More info in go/cardea-deck. */
            isDisambiguationCardIntent?: boolean;
            /** Denotes whether this is a sub-intent of an ambiguous SystemUncertain intent go/intent-disambiguation. */
            isDisambiguationIntent?: boolean;
            /** Whether the interpretation was generated from the neural categorical parser. */
            isNeuralCategoricalInterpretation?: boolean;
            /**
             * Denotes this is a sub-intent used for composing an Assistant UI response. The assistant dialog should output ui_composition_shelf in the SystemResponse if it can fulfill the intent.
             * More info in go/davinci-design and go/davinci-di-fulfillment
             */
            isUiCompositionIntent?: boolean;
            /** Information about Local results to be used in the Packer for Local Categorical derived intent deduplication and conformance. */
            localSignals?: KnowledgeAnswersIntentQueryLocalSignals;
            /**
             * A tag to annotate user's journey (e.g., JourneyFollowCampusUpdates). This will be used for Journey OSRP demo (go/josrp-sprint). !!NOTE!! This field is reserved for Journey OSRP
             * demo, and will be deprecated shortly after its completion. DO NOT USE.
             */
            osrpJourneyTag?: string;
            /** Experiments that caused this FunctionCall to parse, without which this would not have parsed. */
            parsedDueToExperiment?: string[];
            /** Parsing signals for ranking/filtering. */
            parsingSignals?: KnowledgeAnswersIntentQueryParsingSignals;
            /** Identifies a score, determined before fulfillment but after grounding. Written by the Prefulfillment Ranker, and used as a signal for ACE Ranking. */
            prefulfillmentRankingScore?: number;
            /** All the input signals to the Prefulfillment Ranker. */
            prefulfillmentSignals?: AssistantPrefulfillmentRankerPrefulfillmentSignals;
            /** Describes how this intent was resolved via external data (either elsewhere in the query, or in a previous query). */
            referentialResolution?: KnowledgeAnswersDialogReferentialResolution;
            /** The id of the summary node if this funcall represents an mdvc interpretation */
            refxSummaryNodeId?: string;
            /** The list of result supports for this FunctionCall. */
            resultSupport?: UniversalsearchNewPackerKnowledgeResultSupport[];
            role?: string;
            /**
             * Identifies whether the Prefulfillment Ranker selected this intent for emission. This is needed temporarily while migrating intent emitters from ACE to QUS/PFR. See
             * go/pfr-intent-emitter for more info
             */
            selectedByPrefulfillmentRanking?: boolean;
            /** Equivalent shopping ids for the function call. */
            shoppingIds?: KnowledgeAnswersIntentQueryShoppingIds;
            /**
             * Additional intents to be used for intent scoring. This field must only be populated when we cannot find a single unified intent. For example, when we compute signals for a
             * LocalEntities function call, this means we could not find a unified intent to capture all the local results. In this case, we add a fallback intent for each local result (e.g.
             * GeoSchool, GeoRestaurant, and GeoBank if those are the results we show).
             */
            signalsFallbackIntents?: KnowledgeAnswersIntentQuerySignalComputationFallbackIntent[];
        }
        interface KnowledgeAnswersIntentQueryGroundingSignals {
            /**
             * True if the argument was added during grounding. This signal is intended to be used with ArgumentSignals. Note that the added argument's value must be a FunctionCall that only
             * contains resolutions, i.e. grounding cannot add/modify/delete any ungrounded values.
             */
            addedByGrounding?: boolean;
            /** Score indicating how grounded the intent is, populated by the Grounding Box, used by the pre-fulfillment ranker, see http://go/prefulfillment-ranker. */
            groundabilityScore?: number;
            /** Sum of the number of constraints used by the Grounding Box to ground each variable. */
            numConstraints?: number;
            /** Sum of the number of constraints satisfied for each variable. Depending on the match score for a constraint, this number can be fractional and is in the range [0, num_constraints]. */
            numConstraintsSatisfied?: number;
            /** Number of groundable arguments in the parsed intent. */
            numGroundableArgs?: number;
            /** Number of arguments that got actually grounded. */
            numGroundedArgs?: number;
            /** Number of arguments, possibly nested, that the Grounding Box tried to ground. */
            numVariables?: number;
            /** Number of arguments, possibly nested, that the Grounding Box was able to ground. This includes ambiguously grounded arguments. */
            numVariablesGrounded?: number;
            /**
             * PGRP outputs PROD_INTENT_FACTORY intent format by default. See go/intent-conversion-locations-in-sage. Experimental flags can change or make PGRP output additional intents formatted
             * for PORTMON_FULFILLMENT (e.g. with RDs). This is used by the PortMon/ARM dark launch (go/arm-dark-launch-infra). Longer term, this will be replaced by DGS system-internal
             * transformations (go/if-dgs).
             */
            pgrpOutputFormat?: string;
            /**
             * If true, then GroundingBox and PGRP are used in AnswersRewriter to process the intent. Other post-processing steps, including IGDP, are adjusted accordingly. Note this will be
             * removed once GroundingBox is fully launched and all prod traffic goes through it. Before that happens, each IG that needs to go through GB and PGRP (post GB ranking pruning) will
             * need to explicitly set this field to true. See http://go/gb-impl and http://go/gb-post-ranker-pruner for details.
             */
            usesGroundingBox?: boolean;
        }
        interface KnowledgeAnswersIntentQueryIdentifier {
            id?: string;
            idType?: string;
        }
        interface KnowledgeAnswersIntentQueryImpliedEntity {
            /** A copy of the span of canonical (raw) parser input text corresponding to this annotation. Copied from QRefAnnotation.annotated_span. */
            annotatedSpan?: string;
            /** This field is used inside Aqua for evaluation purposes. */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** TODO (b/143536264): Create a new ImpliedTokens message and remove this. Whether the implied entity is ungrounded value, set to true when the entity doesn't have a KG mid. */
            isUngroundedValue?: boolean;
            /** The KG mid of the implied entity. */
            mid?: string;
            /** The QRef confidence (in [0, 1]) of the entity being correctly annotated. */
            qrefConfidenceScore?: number;
            /**
             * All ShoppingIds for this implied entity that need to be copied to IntentQuery (FunctionCall) if this implied entity is used in intent generation. See go/iql-shopping-ids for
             * details.
             */
            shoppingIds?: KnowledgeAnswersIntentQueryShoppingIds;
        }
        interface KnowledgeAnswersIntentQueryIndexingIQLAttachment {
            /**
             * The version of encoder for the IQL FunctionCalls. We bump up the version when, but not limited to, we change how an IQL is converted to a byte array, or the change of byte
             * compression algorithm.
             */
            iqlEncodingVersion?: number;
            /**
             * A compressed byte array that represents IQL FunctionCalls. A list of IQL FunctionCalls are first encoded as a byte array. The byte array is then compressed. For more details on the
             * encoding, see go/iql-in-wma.
             */
            iqlFuncalls?: string;
            /**
             * The Pianno confidence scores of all intents of the IQL FunctionCalls. For space reasons this is stored as a [0, 100] integer that represents the confidence up to two decimal points
             * (fixed point). Convert it to confidence_score using the following formula: float pianno_confidence_score = pianno_confidence_score_e2 / 100.0f It should have the same number of
             * elements as the IQL expressions after decoding. For non-Pianno top level intents, this score is 0.
             */
            piannoConfidenceScoreE2?: number[];
            /**
             * A bit map indicating if the intents in the IQL FunctionCalls are top level intents for Pianno (go/pianno). This is a repeated field. In the event of more than 32 intents, the first
             * uint32/ represents the 1st to the 32nd intents, and the second uint32 represents/ the 33rd to the 64th intents, and so on. Within each uint32, the bits are in reversed order, i.e.
             * the right-most bit of the first uint32 indicating if the first intent in IQL expressions is a top level intent for Pianno. The prevailing (unused) bits of the last uint32 are filled
             * with 0s.
             */
            piannoIqlBitmap?: number[];
        }
        interface KnowledgeAnswersIntentQueryLocalResultSignals {
            /** Geo intents corresponding to the gcids obtained from the Local result. */
            gcidIntent?: string[];
            /** Salient terms associated with this Local result based on the result gcids. */
            salientTermSet?: QualitySalientTermsSalientTermSet;
        }
        interface KnowledgeAnswersIntentQueryLocalSignals {
            /** Signals relating to each Local result. */
            localResultSignals?: KnowledgeAnswersIntentQueryLocalResultSignals[];
            /** Minimum salient term similarity between Local results. */
            minSalientTermSimilarity?: number;
        }
        interface KnowledgeAnswersIntentQueryLocationMarkersSignals {
            /** The type of the lightweight token match. */
            type?: string;
        }
        interface KnowledgeAnswersIntentQueryMediaEntitySignals {
            /** For songs, this is the name of the primary artist, i.e. "Shallow" would "Lady Gaga" set. */
            artistTitle?: string;
            /** Name of the media entity, i.e. "Lady Gaga". */
            name?: string;
        }
        interface KnowledgeAnswersIntentQueryMuninSignals {
            /** If the modifier is only a good soft modifier by itself, then we would trigger only if it's the only modifier */
            isIsolated?: boolean;
            /** Signals for $ListQueryRuleWithSoftModifier. Collections allowed by the soft modifier. */
            softModifierCollection?: string[];
            /** If true, the text for this argument did not come from the query, but was generated somehow else. */
            textIsGenerated?: boolean;
        }
        interface KnowledgeAnswersIntentQueryNimbleAnnotationSignals {
            /** Where the annotation has been read from. */
            annotationSource?: string;
            /** A client-controlled identifier that the client can use to distinguish between different sets of annotations. */
            type?: string;
            /**
             * Version identifier used to isolate different clients from each other. A client should intersect this list of versions with the ones the client is interested in, and use the
             * annotation if the intersection is non-empty.
             */
            version?: string[];
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersIntentQueryNTPRAnnotationSignals {
        }
        interface KnowledgeAnswersIntentQueryOnDeviceAnnotationSignals {
            /**
             * Provenance of the annotator. Equivalent to the `provenance` field in OnDeviceParserInput::AnnotationInfo. This is used to map from AnnotationInfo to nlp_sage.ScoredAnnotation, since
             * nlp_sage.ScoredAnnotation doesn't have a native `provenance` field. Note in the (very) long term, we'd like to replace ScoredAnnotation with Argument altogether.
             */
            provenance?: string;
        }
        interface KnowledgeAnswersIntentQueryParsingSignals {
            /** A parsing score that is independently calibrated by each parser/IG, used by pre-fulfillment ranker, see http://go/prefulfillment-ranker. */
            calibratedParsingScore?: number;
            /**
             * This proto holds the complete call path info of the QRewrite client (e.g. the QUS's phase like "RBT","QBT"; the QUS's candidate type like "Identity"; and the ACE's candidate type
             * like "FuzzyMatcher").
             */
            qrewriteCallPathInfo?: NlpLoggingQRewriteClientCallPathInfo;
            /**
             * This proto holds the fingerprint of the call path info of QRewrite client (e.g. the QUS's phase like "RBT","QBT"; the QUS's candidate type like "Identity"; and the ACE's candidate
             * type like "FuzzyMatcher").
             */
            qrewriteCallPathInfoFingerprint?: string;
            /** The parser that calibrated the parsing score below. */
            source?: string;
        }
        interface KnowledgeAnswersIntentQueryPersonalEntity {
            /** Attribute ID of a personal_summary_node_child. */
            attributeId?: string;
            entityRelationship?: KnowledgeAnswersIntentQueryPersonalEntityEntityRelationship[];
            /** The mid of the entity in freebase associated with this span. */
            freebaseMid?: string;
            /**
             * Every PersonalEntity might itself rescursively contain related Personal Entities, e.g. for, "my father's mother" a parent Personal Entity for 'Mother()' contains a child Personal
             * Entity of the form 'Mother(Myself)'.
             */
            personalEntityChild?: KnowledgeAnswersIntentQueryPersonalEntity[];
        }
        interface KnowledgeAnswersIntentQueryPersonalEntityEntityRelationship {
            /** The index of the other entity in the relationship. */
            entityIndex?: number;
            /** Names of the relationship links. */
            linkPropertyName?: string[];
        }
        interface KnowledgeAnswersIntentQueryQrefAnnotationSignals {
            /** Numeric value associated with each annotation within the Qref servlet output. */
            score?: number;
            /** Trusted name confidence signal https://g3doc.corp.google.com/repository/webref/preprocessing/names/tnc_classifier/README.md */
            trustedNameConfidence?: number;
        }
        interface KnowledgeAnswersIntentQueryRelatednessSignals {
            queryPopularity?: number;
            youtubeViews?: string;
        }
        interface KnowledgeAnswersIntentQuerySaftSignals {
            entityType?: string;
            isHeadOfIntent?: boolean;
            /** Saft often marks verbs as head of intent and we may want to ignore those. */
            isVerb?: boolean;
            number?: string;
        }
        interface KnowledgeAnswersIntentQuerySemanticAnnotationSignals {
            /** Name of the subgrammar category this annotation is associated with. */
            category?: string;
            /** Name of the subgrammar domain. */
            domain?: string;
            features?: KnowledgeAnswersIntentQuerySemanticAnnotationSignalsFeature[];
            /**
             * Numeric value associated with each subgrammar annotation. Used for in-domain ranking inside the Aqua Analyzer. This field is not guaranteed to be in any range. Furthermore, this
             * field should never be compared for annotations with differing 'domain' value. The field is included here for making the Aqua Analyzer work with subgrammar annotations that have been
             * generated in a different Aqua Analyzer (typically by TUIG SemanticAnnotationServlet). TL;DR: Consumers of this message are STRONGLY DISCOURAGED from using this field.
             */
            score?: number;
        }
        interface KnowledgeAnswersIntentQuerySemanticAnnotationSignalsFeature {
            name?: string;
            value?: number;
        }
        interface KnowledgeAnswersIntentQuerySensitiveArgumentValueGuard {
            /**
             * Decrypted and deserialized contents of |encrypted_value|. This field should never be populated in prod. This is only provided for easier human inspection when using dev builds (dev
             * keys are public).
             */
            doNotUseDebugOnlyDecryptedValue?: KnowledgeAnswersIntentQueryArgumentValue;
            /** Encrypted protobuffer of type ArgumentValue. */
            encryptedValue?: string;
        }
        interface KnowledgeAnswersIntentQueryShoppingIds {
            /** A shopping aspect cluster id. These are attributes mined from mentions in web articles. */
            aspectClusterIds?: string[];
            /** Brand entity id. Brands are fully reconciled with KG entities so there should never be ambiguity as to which brand applies (those would be separate MIDs). */
            brandEntityId?: string;
            /**
             * A category in the shopping browseonomy, a taxonomy of product types that can be found at go/bx. This field is expected to contain the deepest node in the browseonomy that the intent
             * or argument pertains to, which may be an internal node. It does not contain the entire path of categories.
             */
            bxCategoryIds?: number[];
            measures?: KnowledgeAnswersIntentQueryShoppingIdsMeasureValue[];
            /** List of merchant customer account IDs associated with a merchant entity in KG. NOTE: Soon to be deprecated, see go/merchant_mids_in_indexer design */
            merchantIds?: string[];
            /**
             * A shopping merchant source id, i.e. the key used to identify Shopping Merchants as they are imported into KG. For reference, these IDs are populated in: * CommerceDB under
             * BusinessIdentification.knowledge_graph.source_id * KG using the /shopping/merchant/id predicate
             */
            merchantSourceIds?: string[];
            /**
             * Moka attributes of a product. This includes color tags but currently not brand. We allow the possibility for multiple tag ids, as multiple Moka tag ids may map to the same mid, and
             * we may not be able to find a single matching Moka tag. Also, cross-category Moka colors intentionally map a single color mentioned in the query to an expansion of many tags
             * representing points in LAB color space (although this representation is expected to change).
             */
            tagIds?: string[];
        }
        interface KnowledgeAnswersIntentQueryShoppingIdsMeasureValue {
            facetId?: string;
            value?: number;
        }
        interface KnowledgeAnswersIntentQuerySignalComputationFallbackIntent {
            /** The intent name of the fallback intent. */
            intent?: string;
        }
        interface KnowledgeAnswersIntentQuerySimpleValue {
            boolValue?: boolean;
            doubleValue?: number;
            identifier?: KnowledgeAnswersIntentQueryIdentifier;
            intValue?: string;
            stringValue?: string;
            /**
             * Ungrounded value contains the part of the query (or web snippet, etc.) that was not understood. For more information on this field, see the "Ungrounded value" item in the table of
             * contents of go/iql-v1
             */
            ungroundedValue?: string;
        }
        interface KnowledgeAnswersIntentQuerySupportTransferSignals {
            /** Entities that transferred support to this entity (mids). */
            supportTransferSource?: string[];
            /** Entities that received support from this entity (mids). */
            supportTransferTarget?: string[];
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersIntentQueryTeleportArgumentAnnotatorSignals {
        }
        interface KnowledgeAnswersIntentQueryToken {
            /** This field is used inside Aqua and outside Aqua for identifying the token indices and/or byte offsets of this Token. */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /**
             * |ngram| should be populated with a string from the raw query, not the normalized tokens. E.g. The ngram in the ignored token for the Height intent on the query [Height of barack
             * obama], will be "Height". The ngram in the ignored token for the Videos intent on the query [vidéos] will be "vidéos".
             */
            ngram?: string;
            /** Experiments that caused this Token to parse, without which this would not have parsed. */
            parsedDueToExperiment?: string[];
            prior?: number;
            provenance?: string;
            /** Unique identifiers for the provenance of this token, for example, NLP Repository Example IDs. */
            provenanceId?: string[];
            provenanceLanguage?: string;
            synonyms?: KnowledgeAnswersIntentQueryTokenSynonym[];
        }
        interface KnowledgeAnswersIntentQueryTokens {
            /** Score for this group of tokens is currently product of priors. */
            score?: number;
            token?: KnowledgeAnswersIntentQueryToken[];
        }
        interface KnowledgeAnswersIntentQueryTokenSynonym {
            source?: string;
            synonymNgram?: string;
        }
        interface KnowledgeAnswersIntersectType {
            slotNames?: string[];
        }
        interface KnowledgeAnswersMarker {
            command?: any;
            openQuestion?: KnowledgeAnswersMarkerOpenQuestion;
            polarQuestion?: any;
            stateOfAffairs?: any;
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersMarkerCommand {
        }
        interface KnowledgeAnswersMarkerOpenQuestion {
            /** Note: This is still under development and not available for general use. Contact meaning-platform-eng@ for questions. */
            slotKey?: KnowledgeAnswersMeaningSchemaSlotKey;
            /** One or multiple slots may be requested by the marker. See go/mrf-multiple-output-slots for details on requesting multiple output slots. */
            slotName?: string[];
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersMarkerPolarQuestion {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersMarkerStateOfAffairs {
        }
        interface KnowledgeAnswersMeaningSchemaKey {
            /** The version has been changed to be defined as a horizontal version on the entire meaning catalog instead of per-schema. */
            deprecatedVersion?: string;
            /** The minted MID for an intent. */
            mid?: string;
        }
        interface KnowledgeAnswersMeaningSchemaSlotKey {
            /** The minted MID for the slot. This ID uniquely identifies the slot globally. */
            mid?: string;
            /**
             * A stable unique ID for this intent minted from go/uniqueid. NOTE: This is considered a private field used only for internal Intent Catalog purposes (i.e. as a source ID for
             * generating this intent's associated MID). Additionally, this field is only populated on the schema. TODO (b/168907943): Move "unique_id" out of MeaningSchemaSlotKey proto message.
             * Note: Please do not use this field. It is going to be moved out of this proto message.
             */
            uniqueId?: string;
        }
        interface KnowledgeAnswersMeasurementType {
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
        }
        interface KnowledgeAnswersNormalizedStringType {
            normalizedValue?: string[];
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
        }
        interface KnowledgeAnswersNumberType {
            /**
             * If true, the semantics of the NumberType argument are retained as a string, rather than being converted to a float-type object. This option is particularly useful in cases where
             * leading 0s in the user input are meaningful, e.g. for zip codes or sports jersey numbers. For the user- specified value "01", for instance, the PathQuery semantics will be: def
             * $Slot "01"
             */
            keepAsString?: boolean;
            /** Range constraint limits the set of numbers accepted by this type. The constraint applies to all subtypes. Currently, this constraint is only enforced in Loose Parser. */
            rangeConstraint?: KnowledgeAnswersRangeConstraint;
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
            /**
             * sub_type is a list of the NumberSubTypes which are accepted. If the list is empty, that means all numeric or ordinal values are accepted. If multiple values are specified, then this
             * value accepts any of the sub_types in the list.
             */
            subType?: string[];
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueAogType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueAppAnnotationType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueAudioType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueCalendarEventType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueCalendarEventWrapperType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueCalendarReferenceType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueComplexQueriesRewriteType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueComponentReferenceIndexType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueDeviceIdType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueDeviceType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueDeviceUserIdentityType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueHomeAutomationDeviceType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueLocationType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueMediaType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueMessageNotificationType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueMoneyType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueNewsProviderType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueOnDeviceType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaquePersonalIntelligenceEntityType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaquePersonType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueProductivityListItemType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueRecurrenceType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueReminderType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueShoppingMerchantType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueShoppingOfferType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueShoppingProductExpressionType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueShoppingProductType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueShoppingStoreType {
        }
        // tslint:disable-next-line:no-empty-interface
        interface KnowledgeAnswersOpaqueTimerType {
        }
        interface KnowledgeAnswersOpaqueType {
            aogType?: any;
            appAnnotationType?: any;
            audioType?: any;
            calendarEventType?: any;
            calendarEventWrapperType?: any;
            calendarReferenceType?: any;
            complexQueriesRewriteType?: any;
            componentReferenceType?: any;
            deviceIdType?: any;
            deviceType?: any;
            deviceUserIdentityType?: any;
            homeAutomationDeviceType?: any;
            locationType?: any;
            mediaType?: any;
            messageNotificationType?: any;
            moneyType?: any;
            narrativeNewsProviderType?: any;
            onDeviceType?: any;
            personalIntelligenceEntityType?: any;
            personType?: any;
            productivityListItemType?: any;
            recurrenceType?: any;
            reminderType?: any;
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
            shoppingMerchantType?: any;
            shoppingOfferType?: any;
            shoppingProductExpressionType?: any;
            shoppingProductType?: any;
            shoppingStoreType?: any;
            timerType?: any;
        }
        interface KnowledgeAnswersPlexityRequirement {
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
            /** Simple plexity: the slot's filler must allow the specified plexity value, for example it must contain multiple individuals if the plexity is MULTIPLEX. */
            simplePlexity?: string;
        }
        interface KnowledgeAnswersPolarQuestionType {
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
        }
        interface KnowledgeAnswersRangeConstraint {
            max?: KnowledgeAnswersRangeConstraintRangeEndpoint;
            min?: KnowledgeAnswersRangeConstraintRangeEndpoint;
        }
        interface KnowledgeAnswersRangeConstraintRangeEndpoint {
            /** If true, then this endpoint's value is not included in the range. */
            isExclusive?: boolean;
            /** The value of this endpoint */
            value?: number;
        }
        interface KnowledgeAnswersSameType {
            slotName?: string;
        }
        interface KnowledgeAnswersSemanticType {
            /**
             * Determines whether or not the meaning schema that contains this semantic_type conforms to a function call with the name and arguments taken from the meaning schema. As it refers to
             * the "containing_intent", this field should only be set in a semantic_type declared in an intent's type_members field. The behavior of this field is undefined in other cases, for
             * example, declaring the type of an intent slot. On Assistant, we use meaning schemas for argument types to represent both function call values as well as a reusable tool to host
             * other argument values (opaque types, normalized strings, subsets of entities) across intents. Teams need this information to run conformance checks and annotate new data. Example:
             * If the intents below are in the intent catalog, then: - Intent(slot="some string") is conformant, because Type has string_type{} in its type_members. - Intent(slot=Type()) is not
             * conformant, because Type has set semantic_type.includes_containing_intent to false. - Intent(slot=SubType()) is conformant, because type_members is not inherited. { id: "Intent"
             * slot: { name: "slot" type: { semantic_type { name: "Type" }} } } { id: "Type" type_members { string_type{} semantic_type { includes_containing_intent: false } } } { id: "SubType"
             * parent { id: "Type" relationship_type: SUBTYPE } }
             */
            includesContainingIntent?: boolean;
            /** Names of valid sources of the semantics (for example: a frame or an intent). */
            name?: string[];
            /**
             * Contains data about current schema remodelings at the SemanticType name level. The "name" field contains all possible semantic type names and "semantic_type_name_remodelings" acts
             * as an overlay to determine which ones to surface based on which schema remodeling IDs are requested. For more information see go/meaning-remodeling-framework.
             */
            nameRemodelings?: NlpMeaningSemanticTypeNameMeaningRemodelings[];
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
        }
        interface KnowledgeAnswersSensitivityArgumentEvalPolicy {
            /**
             * Optional cannery policy name. If it presents then Intent Scrubber will use the corresponding Cannery rule for argument scrubbing and redaction instead. It should only be used for
             * existing complex argment value types such as HomeAutomationDevice.
             */
            policyName?: string;
            /** Redact corresponding span of the string query. */
            redactQuerySpan?: boolean;
            /** Customized replacement phrase, if missing ${ArgumentName}_REDACTED is used as default. */
            replacement?: string;
            /**
             * Scrub argument value and signals before saving to eval storage. If not set, 1) inherit the policy from the outer argument if there is one (for nested intents); 2) finally default to
             * type based scrubbing: see go/argument-type-scrubbing.
             */
            scrubArgumentValue?: boolean;
        }
        interface KnowledgeAnswersSensitivityInstruction {
            argument?: KnowledgeAnswersSensitivityInstructionArgument;
            intent?: KnowledgeAnswersSensitivityInstructionIntent;
            /** This field is for backward compatibility. */
            legacyAssistantSensitivity?: SearchPolicyRankableSensitivity;
            /**
             * Controls whether a top-level intent is multi-account approved. NLU will do go/cross-account-understanding only for intents with this bit on. Also, this bit should be propagated to
             * user turn Attentionl Entities to extend protection of cross-account data to next turns. In principle fulfillment services (e.g., Monastery) should only dispatch such intents to
             * multi-account approved fulfillers (schemas), at least when the user has a linked dasher account. The Assistant runtime policy engine should treat a query as dasher data if 1) this
             * bit is true in the string redaction, and 2) the user has a linked dasher account, and apply a more restrictive rule for whitelisting, regardless of the actual account provenance in
             * Sensitivity. Example: [User logged in to their personal gmail account.] Q1: "Schedule a meeting tiltled okr review at 3pm". Assistant: "Should I scheduled it on your xyz@gmail.com
             * account?" Q2: "No, add it to my xyz@bigcorp.com account." We don't know Q1 is dasher data until Q2. To prevent leaking of Q1 to non-dasher approved binaries, this bit should be used
             * as a proactive measure. It might introduce some over-triggering (e.g., user says "Yes" in Q2), but is much better than blindly treating every query as dasher, not considering
             * whether it actually triggers any multi-account capable intents or not (see b/164420114 for example).
             */
            multiAccountAllowed?: boolean;
            previousQuery?: KnowledgeAnswersSensitivityInstructionPreviousQuery;
        }
        interface KnowledgeAnswersSensitivityInstructionArgument {
            eval?: KnowledgeAnswersSensitivityArgumentEvalPolicy;
            logging?: KnowledgeAnswersSensitivityLoggingPolicy;
            serving?: KnowledgeAnswersSensitivityServingPolicy;
            storage?: KnowledgeAnswersSensitivityStoragePolicy;
        }
        interface KnowledgeAnswersSensitivityInstructionIntent {
            eval?: KnowledgeAnswersSensitivityIntentEvalPolicy;
            footprints?: KnowledgeAnswersSensitivityMyActivityPolicy;
            logging?: KnowledgeAnswersSensitivityLoggingPolicy;
            serving?: KnowledgeAnswersSensitivityServingPolicy;
            storage?: KnowledgeAnswersSensitivityStoragePolicy;
        }
        interface KnowledgeAnswersSensitivityInstructionPreviousQuery {
            logging?: KnowledgeAnswersSensitivityLoggingPolicy;
            serving?: KnowledgeAnswersSensitivityServingPolicy;
            storage?: KnowledgeAnswersSensitivityStoragePolicy;
        }
        interface KnowledgeAnswersSensitivityIntentEvalPolicy {
            /** Policy for all arguments, so no need to repeat on every argument. */
            allArguments?: KnowledgeAnswersSensitivityArgumentEvalPolicy;
            /** Controls whether to enabled limited logging (rpc whitelisting + GWS log query redaction) if the intent wins post-fulfillment ranking. */
            enabled?: boolean;
            /** The eval policy won't apply if the annotated intent is a root. This check is majorly to prevent calling IntentScrubber halfway from InterpretationScrubber via nested intents. */
            nestedIntentOnly?: boolean;
            /** Scrub entire intent before saving to eval storage, leaving only intent name and sensitivity info. */
            scrubEntireIntent?: boolean;
        }
        interface KnowledgeAnswersSensitivityLoggingPolicy {
            /** The contents of the argument value should be scrubbed before being written to logs. */
            scrubArgumentValue?: boolean;
            /** If this is set to true, this Sensitivity's presence will result in QRewrite to enable AS logging to scrub any discourse context. */
            scrubContext?: boolean;
        }
        interface KnowledgeAnswersSensitivityMyActivityPolicy {
            myActivityRedactedAction?: string;
            /** This field will be translated by footprints and is used to describe the content that was redacted that will be displayed to the user in MyActivity. */
            myActivityRedactionKey?: string;
        }
        interface KnowledgeAnswersSensitivitySensitivity {
            /**
             * Used to annotate the provenace of cross-account personal data. See go/cross-account-understanding. Sensitivity could be annotated at query, intent, and argument levels. Query and
             * intent could have data from multiple accounts, so this field is repeated. A sensitive knowledge_context.PreviousQuery might be dropped to prevent leaking cross-account data via
             * Genie rewrite. For arguments, the best practice is to not blend multi-account data, and this field should be treated as singular to make ownership clear. When publishing attentional
             * entities, contextual NLU might drop an argument that contains data from a different account for data protection. Mixing multi-account data in one argument will cause data from the
             * primary account to be dropped altogether, which is an unnecessary quality loss.
             */
            accountProvenance?: QualityQrewriteAccountProvenance[];
            /** Instruction of handling sensitive intent/argument data. Can be specified in Intent Catalog. */
            instruction?: KnowledgeAnswersSensitivityInstruction;
            /**
             * This should be systematically added without requiring the feature developers to add a source. This is for debug purpose as to whether the Sensitivity's trace/path included any of
             * landmark code path helpful for tracing back the sensitivity sources. One should add a new source when one sees fits. It's chronological order as to which source is added first. One
             * should not manually add a source. The same source can be repeated if the Sensitivity object went through the same code path twice.
             */
            source?: string[];
            /** Sensitivity type. See the enum definition below. */
            type?: string;
        }
        interface KnowledgeAnswersSensitivityServingPolicy {
            /** If this is set to true, QRewrite will enable RPC Whitelist to be applied in Assistant Server and Genie Rewriter. */
            enableRpcWhitelist?: boolean;
        }
        interface KnowledgeAnswersSensitivityStoragePolicy {
            /**
             * The contents of the argument value should be encrypted before being written to a persistent storage (even if the storage has short time-to-live). No-op when specified at intent
             * level.
             */
            encryptArgumentValue?: boolean;
            /** If this is set true, we encrypt QueryAnnotationDataProto prior to writing it to Footprint ASSISTANT_EPHEMERAL corpus. This enables restricting ACL to the data. */
            encryptQueryAnnotationData?: boolean;
            /** If this is set to true, the following fields in ConversationSnapshot are scrubbed: * circulated_state.squery * spoken_query * All client_op arguments |from_assistant| interactions */
            scrubAuxiliaryFieldsInConversationSnapshot?: boolean;
        }
        interface KnowledgeAnswersStateOfAffairsType {
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
        }
        interface KnowledgeAnswersStringType {
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
            /** If true, this value will match a single token. If false, this value will match any nonzero number of tokens. */
            singleToken?: boolean;
        }
        interface KnowledgeAnswersTimeZoneType {
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
        }
        interface KnowledgeAnswersTrackingNumberType {
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
        }
        interface KnowledgeAnswersTypeTrait {
            /** Contains data about current schema remodelings at this ValueType level. For more information see go/meaning-remodeling-framework. */
            remodelings?: NlpMeaningMeaningRemodelings;
            traitId?: string[];
        }
        interface KnowledgeAnswersUnionType {
            slotNames?: string[];
        }
        interface KnowledgeAnswersValueType {
            /**
             * This type is meant to accept "any" type and allow any and all composition. As such, it should not be used for any composition algorithms, e.g. in Loose Parser. See more detailed
             * discussion at go/any-type-in-mrf. This type may appear on an answer_type, implying that the output of that Meaning Schema is allowed to nest in any other slot. However, support for
             * this is NOT implemented in Loose Parser due to risk of overcomposition, but the MRF Conformance checker allows for this. If you are thinking of using this, please contact mrf-team@.
             */
            anyType?: KnowledgeAnswersAnyType;
            attributeType?: KnowledgeAnswersAttributeType;
            booleanType?: KnowledgeAnswersBooleanType;
            collectionType?: KnowledgeAnswersCollectionType;
            compoundType?: KnowledgeAnswersCompoundType;
            dateType?: KnowledgeAnswersDateType;
            /** Work in progress: Used for configuring dynamic types to allow for type transparency. See: go/type-dependencies */
            dependencyType?: KnowledgeAnswersDependencyType;
            durationType?: KnowledgeAnswersDurationType;
            entityType?: KnowledgeAnswersEntityType;
            /** When specified on a slot's type, restricts composition based on the enum value. This does not mean anything when the value type is to be interpreted as an output_type. */
            inputCompositionConfig?: string;
            measurementType?: KnowledgeAnswersMeasurementType;
            /** Note that normalized_string_type is NOT supported in the loose parser. A slot with this type will cause the intent to not be parsed. */
            normalizedStringType?: KnowledgeAnswersNormalizedStringType;
            numberType?: KnowledgeAnswersNumberType;
            opaqueType?: KnowledgeAnswersOpaqueType;
            plexityRequirement?: KnowledgeAnswersPlexityRequirement;
            pluralityType?: string;
            polarQuestionType?: KnowledgeAnswersPolarQuestionType;
            semanticType?: KnowledgeAnswersSemanticType;
            /** DEPRECATED: see go/type-dependencies. Please reach out to suwu@, dqwang@ if usage is required. */
            slotName?: string;
            stateOfAffairsType?: KnowledgeAnswersStateOfAffairsType;
            stringType?: KnowledgeAnswersStringType;
            timezoneType?: KnowledgeAnswersTimeZoneType;
            trackingNumberType?: KnowledgeAnswersTrackingNumberType;
            /**
             * Extra trait information for compound value types. Note: currently the semantics of having both the data type (e.g. "entity_type") and "with_trait" is an OR operation. Eg.
             * HorizontalDateRestrict has a SetToModify slot that accepts some collections like /collection/films. And also intent queries with_trait date, start_date, etc.
             */
            withTrait?: KnowledgeAnswersTypeTrait;
        }
        interface KnowledgeGraphDateTimeProto {
            /** A day of month, 1-31. If present, year and month must be present as well, and must form a valid date. */
            days?: number;
            /** Hour of the day, 0-23 */
            hours?: number;
            /** Microsecond, in the interval [0, 999999]. If present, seconds have to be present as well. */
            microseconds?: number;
            /** Minute, 0-59. If present, hours have to be present as well. */
            minutes?: number;
            /** A month, 1-12. If present, year must be present as well. */
            months?: number;
            /** Second, in the interval [0, 60], where 60 is an exceptional value reserved for leap seconds. If present, minutes have to be present as well. */
            seconds?: number;
            /**
             * Timezone offset in seconds (can be positive/negative). If present, hours have to be present as well If absent, we expect the time above to be in local time (a.k.a. civil time,
             * go/httat#civil_time).
             */
            tzOffset?: string;
            /** A year. */
            years?: number;
        }
        interface KnowledgeGraphNestedStruct {
            /** predicate_objs.pred should be unique within the list. */
            predicateObjs?: KnowledgeGraphNestedStructPredicateObjs[];
        }
        interface KnowledgeGraphNestedStructPredicateObjs {
            objs?: KnowledgeGraphTripleObj[];
            pred?: string;
        }
        interface KnowledgeGraphQualifier {
            /** The qualifier pred must be a qualifier property defined in KG schema as applying to the predicate of the triple this qualifier is attached to. */
            pred?: string;
            value?: KnowledgeGraphTripleObj;
        }
        interface KnowledgeGraphQualifierSet {
            qualifiers?: KnowledgeGraphQualifier[];
        }
        interface KnowledgeGraphTriple {
            /**
             * If is_negation is set to true then this triple is considered a statement that the fact is false. This allows for the storage of both what we know to be true and what we know to be
             * false.
             */
            isNegation?: boolean;
            /** obj is the value of a relationship. */
            obj?: KnowledgeGraphTripleObj;
            /** pred is an arbitrary node id representing the predicate (name) of a graph relationship. */
            pred?: string;
            provenance?: KnowledgeGraphTripleProvenance[];
            /**
             * WARNING: This is currently defined for experimentation purposes only. Please do not set. Data set in this field will not be published to any systems downstream of Livegraph.
             * Together with the SPO of this triple, each qualifier set here represents a different logical assertion/fact.
             */
            qualifierSets?: KnowledgeGraphQualifierSet[];
            /** sub is an arbitrary node id representing the source entity of a graph relationship. */
            sub?: string;
        }
        interface KnowledgeGraphTripleObj {
            boolValue?: boolean;
            datetimeValue?: KnowledgeGraphDateTimeProto;
            doubleValue?: number;
            /** seconds */
            durationValue?: string;
            /** An id representing an entity (mid or hrid) */
            idValue?: string;
            int64Value?: string;
            /** The language code for the object value. It must be a BCP 47-compliant language tag (b/10005172). See also go/kg-data-l10n. */
            locale?: string;
            nestedStructValue?: KnowledgeGraphNestedStruct;
            protoValue?: KnowledgeGraphTripleObjProto;
            s2cellId?: string;
            /** A UTF-8 string value to be used for the following expected schema types: - /type/rawstring - /type/text - /type/key */
            stringValue?: string;
            uint64Value?: string;
            /** A UTF-8 string value to be used for expected type /type/uri - b/68760994. */
            uriValue?: string;
        }
        interface KnowledgeGraphTripleObjProto {
            /** The encoded proto data. */
            data?: string;
            /** The full name of the proto descriptor, such as 'music.AlbumSummary'. */
            descriptorFullName?: string;
        }
        interface KnowledgeGraphTripleProvenance {
            /**
             * Specifies the contract or legal visibility required to see the Triple. See go/kg-triple-level-access-controls for details and background. Note that we use an int32 here so that we
             * won't lose values when decoding on a stale binary. The int32 references to the enum storage_graph_bfg.Triple.Provenance.AccessRequirement.
             */
            accessRequired?: number;
            /**
             * Historically, this field was used to encode the Freebase User ID, Google username, or Google MDB group that was responsible for the pipeline that is producing this data. However,
             * there is currently no horizontal validation in place, and as of Q3 2018, this field is used essentially as a free-form string by multiple data providers. NOTE: Do not use this field
             * in new pipelines without first consulting with the OWNERS of this proto.
             */
            creator?: string;
            /** The dataset which asserted this data. Must be a valid mid. See go/kg-provenance */
            datasetMid?: string;
            /**
             * Indicates that the corresponding data is supporting evidence for reconciliation only, and is *not* an assertion that should be visible to other systems or to external users. Note
             * that this also means that no provenances indicating supporting data will be visible in the composed graph. Please see go/supporting-kg-triples-design-doc for additional details and
             * background.
             */
            isSupportingData?: boolean;
            /**
             * Internal metadata used by Livegraph and possibly other horizontal KG infra systems. This is not part of the logical triple or its provenance, and contents may not be visible
             * downstream of LG.
             */
            lgMetadata?: StorageGraphBfgLivegraphProvenanceMetadata;
            /**
             * Metadata specifying data governance policies. This information will be processed and enforced in KE systems. For more context, see go/ke-triple-dg-policy-and-metadata. WARNING: This
             * field is WIP and please do not populate it without consulting ke-data-governance@.
             */
            policyMetadata?: StorageGraphBfgPolicyMetadata;
            /** An identifier for the process that asserted this triple. */
            process?: string;
            restrictions?: string[];
            /** Used to measure impact of 3P contributions. See go/ke-metrics. */
            sourceCategory?: string;
            /** The websearch doc_id of the source_url. Used in conjunction with source_category for measuring 3P contributions. */
            sourceDocId?: string;
            /** If the triple was extracted from the web, the source URL where the assertion was found. Used for citation if needed (see restrictions field below). */
            sourceUrl?: string;
            /** A fact about potentially sensitive personal info (http://what/SPII) can be "certified" iff it meets specific requirements. See go/kg-spii-certification for details. */
            spiiCertification?: StorageGraphBfgSpiiCertification;
        }
        interface KnowledgeVerticalsWeatherProtoUserSpecifiedLocation {
            /** (Mandatory) Oyster ID. */
            featureId?: GeostoreFeatureIdProto;
            /** (Mandatory) Coordinates of the location for which weather is requested. */
            latLng?: GoogleTypeLatLng;
            /** The name to display. If specified it will override the formatted address of "feature_id". */
            locationName?: string;
            /** MID corresponding to the location from feature_id. */
            mid?: string;
            /** The timezone to display the current conditions observation time. Optional and will override the timezone of "feature_id". */
            timezone?: string;
        }
        interface LegalCitation {
            /** For Courts, the country the court is in. For Statues,? 3 leter country code ISO 3166 alpha2 */
            CountryCode?: string;
            courtdocument?: LegalCitationCourtDocument;
            law?: LegalCitationLaw;
            ParseType?: number;
            /** State or province of the court or statue (if applicable) What standard? */
            State?: string;
            /** DocType */
            Type?: number;
        }
        interface LegalCitationCourtDocument {
            /** One entry per judge who listened to the case in this court */
            ArguedBefore?: LegalPerson[];
            ArguedDate?: LegalDate;
            /** For an appeal, the name of the lower court that sent this up Abbreviation form? Verbose form? */
            CertiorariCourtName?: string;
            CertiorariRelationship?: number;
            court?: LegalCitationCourtDocumentCourt;
            /** Usually the name of a month. Not sure really what it means. */
            CourtTerm?: string;
            /** Various dates related to the generation of document most of these are opinion-centric */
            DecidedDate?: LegalDate;
            FiledDate?: LegalDate;
            /** Not sure what this is. But I've seen it. */
            MemoID?: string;
            ModifiedDate?: LegalDate;
            opinioninfo?: LegalCitationCourtDocumentOpinionInfo[];
            perdocketinfo?: LegalCitationCourtDocumentPerDocketInfo[];
            pub?: LegalCitationCourtDocumentPub[];
            /** A summary of the document or a syllabus for this document */
            Syllabus?: string;
            unknowndate?: LegalCitationCourtDocumentUnknownDate[];
        }
        interface LegalCitationCourtDocumentCourt {
            /** The name of the court to be displayed to users. */
            DisplayName?: string;
            /** Maybe be redundant with the Name. We can remove this later if we don't find it useful. Court Level */
            Level?: number;
            /** Court id for matching records; "name" is a historic misnomer. */
            Name?: string;
            namecomponent?: LegalCitationCourtDocumentCourtNameComponent[];
            /** The name of the court as taken directly from the source document */
            OriginalName?: string;
        }
        interface LegalCitationCourtDocumentCourtNameComponent {
            Text?: string;
            Type?: number;
        }
        interface LegalCitationCourtDocumentOpinionInfo {
            Bench?: number;
            /** if Type == PER_CURIAM, then DeliveredBy is unnecessary since it is delivered by the full court. Who delivered the opinion? */
            DeliveredBy?: LegalPerson;
            /** Who agrees with the opinion */
            JoinedBy?: LegalPerson;
            /** OpinionType */
            Type?: number;
        }
        interface LegalCitationCourtDocumentPerDocketInfo {
            /** An alpha-numeric (usually, mostly numeric) string used to identify the case by the court */
            DocketID?: string;
            /** Who is bringing the action? (X in X vs. Y) */
            Petitioner?: LegalPerson[];
            /** Who represents the petitioner? */
            PetitionerCounsel?: LegalPerson[];
            /** Who is responding to the action? (Y in X vs. Y) */
            Respondent?: LegalPerson[];
            /** Who represents the respondent? */
            RespondentCounsel?: LegalPerson[];
            /** The "in re" or "matter of" field. */
            Topic?: string;
        }
        interface LegalCitationCourtDocumentPub {
            /** Page number */
            Page?: string;
            /** Paragraph number */
            Paragraph?: string;
            /** The publisher of the opinion. For example, 'U.S.' - United States Reports 'S. Ct.' - Supreme Court Reporter 'L. Ed. 2d' - Lawyers Edition Second Series */
            Reporter?: string;
            /** For documents published by a court reporter. Vendor/Media neutral citations will probably not have this. */
            Volume?: number;
            /**
             * This is the publication year. In many citations, there is one year listed and it is typically the year the opinion was handed down. For example: Roe v. Wade, 410 U.S. 113 (1973)
             * Occasionally, the publication year of the reporter is included. This happens typically when the law reporter volume numbers are numbered within a calendar year. For example, Swiss
             * Bank Corp. v. Air Canada, [1988] 1 F.C. 71. It some (most?) areas, publication date is denoted by [] while opinion date is denoted by ().
             */
            Year?: number;
        }
        interface LegalCitationCourtDocumentUnknownDate {
            Date?: LegalDate;
            Description?: string;
        }
        interface LegalCitationLaw {
            collectionname?: LegalCitationLawCollectionName;
            level?: LegalCitationLawLevel[];
            RevisionDate?: LegalDate;
            /** LawStatus */
            Status?: number;
            /** LawType */
            Type?: number;
        }
        interface LegalCitationLawCollectionName {
            Normalized?: string;
            Source?: string;
        }
        interface LegalCitationLawLevel {
            /** A counter that specifies the depth of the level in the parse */
            Depth?: number;
            /** "SECTION, TITLE, PART, etc." */
            LevelTypeNormalized?: string;
            /** "Section, Sect., §, etc" */
            LevelTypeSourceText?: string;
            /** deprecated */
            LevelTypeString?: string;
            /** The name of the chapter/section/etc. */
            Name?: string;
            /** deprecated */
            Type?: number;
            /** "3", "42(a)", etc */
            Value?: string;
        }
        interface LegalDate {
            Day?: number;
            Month?: number;
            Year?: number;
        }
        interface LegalPerson {
            Description?: string;
            LastName?: string;
            OtherNames?: string;
        }
        interface LensDiscoveryStyleAestheticsScoreSignals {
            /** Aesthetics score discretized into range [0, 100]. */
            discretizedAestheticsScore?: number;
            version?: string;
        }
        interface LensDiscoveryStyleBoundingBox {
            x1?: number;
            x2?: number;
            y1?: number;
            y2?: number;
        }
        interface LensDiscoveryStylePersonAttributes {
            /** The visibility of the face of the most iconic person in the image discretized into range [0, 100]. */
            discretizedFaceVisibilityScore?: number;
            discretizedFemaleConfidence?: number;
            /** Male and female confidence scores are discretized into the [0, 100] range. */
            discretizedMaleConfidence?: number;
            /** Age prediction is rounded to the first decimal place and multiplied by 10 (e.g. 12.3 -> 123). *** Not populated in Amarna for legal reasons. *** */
            discretizedPredictedAge?: number;
            /** The area ratio of the most iconic person to the whole image discretized into range [0, 100]. */
            discretizedVisualSaliencyScore?: number;
            /** Bounding box of the most iconic person in the image. */
            personBoundingBox?: LensDiscoveryStyleBoundingBox;
            personVisibilityScores?: LensDiscoveryStylePersonAttributesPersonVisibilityScores;
            /** Bucketed version of the predicted age. */
            predictedAgeBucket?: string;
            version?: string;
        }
        interface LensDiscoveryStylePersonAttributesPersonVisibilityScores {
            /**
             * A measure of the visibility of the most iconic person between [0, 100], derived by combining all label predictions by the Person Visibility model according to
             * go/person-visibility-formula. Higher values indicate greater visibility while lower values indicate lesser visibility.
             */
            discretizedPersonVisibilityScore?: number;
            /** Repeated for # of PersonVisibility types. */
            personVisibilityPredictions?: LensDiscoveryStylePersonAttributesPersonVisibilityScoresPersonVisibilityPrediction[];
        }
        interface LensDiscoveryStylePersonAttributesPersonVisibilityScoresPersonVisibilityPrediction {
            /** Confidence score of the visibility type prediction discretized into range [0, 100]. */
            discretizedIconicPersonVisibilityConfidence?: number;
            /** Classification of how much of the body of the most iconic person in the image is visible. */
            iconicPersonVisibilityType?: string;
        }
        interface LensDiscoveryStylePersonDetectionSignals {
            /** Information of all detected people in the image, sorted by decreasing size of the bounding box. We store a maximum of 10 detected people. */
            detectedPersons?: LensDiscoveryStylePersonDetectionSignalsDetectedPerson[];
            version?: string;
        }
        interface LensDiscoveryStylePersonDetectionSignalsDetectedPerson {
            /** Bounding box of the detected person. */
            boundingBox?: LensDiscoveryStyleBoundingBox;
        }
        interface LensDiscoveryStyleStyleImageTypeSignals {
            /** Repeated for # of StyleImageType types. */
            styleImageTypePredictions?: LensDiscoveryStyleStyleImageTypeSignalsStyleImageTypePrediction[];
            version?: string;
        }
        interface LensDiscoveryStyleStyleImageTypeSignalsStyleImageTypePrediction {
            /** Style image type confidence discretized into range [0, 100]. */
            discretizedStyleImageTypeConfidence?: number;
            /** Predicted style image type. */
            styleImageType?: string;
        }
        interface ListSnippetResponse {
            header?: ListSnippetResponseRow;
            /** Should list be formatted as a table? */
            isTable?: boolean;
            row?: ListSnippetResponseRow[];
            /** The number of rows annotated in the doc, of which 'row' is a subset. */
            totalRows?: number;
        }
        interface ListSnippetResponseRow {
            column?: string[];
        }
        interface LocalsearchChainId {
            /** The category associated with this chain, currently only used for subchains. */
            category?: string;
            /** The Knowledge Graph (KG) entity of the chain, found and used in chain mining. */
            prominentEntityId?: string;
            /** The website sitechunk/domain that is owned by the chain. */
            sitechunk?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface LocalsearchDocInfo {
        }
        interface LocalsearchProtoInternalFoodOrderingActionMetadata {
            /** The action type of this action metadata. */
            actionType?: string;
            /**
             * If true, it indicates that the merchant has a primarily food intent. This field will only be set when enable_food_gcid_strict_check in FoodOrderingRestrictionProto is true, see
             * go/togo-unified:overlapping-for-le. See go/togo-unified-gcid for how this is calculated.
             */
            hasPrimarilyFoodIntent?: boolean;
            /**
             * If set, indicates that the food ordering service is out of operational hours. This could only be populated if the request explicitly asks for ignore_operational_hours in request
             * (universalsearch/rpc/geo/food_ordering_restriction.proto). Design doc: go/fo-persistent-v1.
             */
            isOutOfOperationalHours?: boolean;
            /**
             * When true, indicates that this is a whitelisted restaurant from a first party (but non FO) partner, i.e. a merchant from the orderig app, who is Google owned first party food
             * ordering platform. Design doc: go/onboard-mavn-to-fo. Tracking bug: b/150331855
             */
            isWhitelistedExternalRestaurant?: boolean;
            /** Next opening time when the food ordering service will be available. This is only present if the unavailability reason is OUT_OF_OPERATIONAL_HOURS. */
            nextOpeningTime?: string;
            /** Indicates whether only order ahead services are available. Order ahead services allow only to place order for future and ASAP order can not be placed via them. */
            onlyOrderAheadServicesAvailable?: boolean;
            /** Aggregated service information by service type. Each service type would only have one ServiceInfo. Optional. */
            serviceInfo?: LocalsearchProtoInternalFoodOrderingActionMetadataServiceInfo[];
            /** Food ordering service type. */
            supportedServiceType?: string;
            /**
             * Reason for unavailability of internal food ordering action. This is only present when FOPA is unavailable for a particular restaurant. When this is set, all other fields in this
             * proto will not be populated. Note(fo-search): If there are log only partners and this particular restaurant is only supported because of log only partners, this field will not be
             * set to NOT_INTEGRATED_WITH_FOPA.
             */
            unavailabilityReason?: string;
        }
        interface LocalsearchProtoInternalFoodOrderingActionMetadataAvailablePartnerInfo {
            /** Available partner's id. */
            availablePartnerId?: string;
            /** Indicates whether the partner is log only. */
            logOnly?: boolean;
        }
        interface LocalsearchProtoInternalFoodOrderingActionMetadataServiceInfo {
            /** Information about Food Ordering partner, which is used for whitelisting the partner in Food Ordering entry points such as Placesheet. */
            availablePartnerInfo?: LocalsearchProtoInternalFoodOrderingActionMetadataAvailablePartnerInfo[];
            /** Maximum max_wait_time in second. */
            maxWaitTimeSec?: string;
            /** Only present for delivery case, service fee is not included. */
            minDeliveryFee?: GoogleTypeMoney;
            /** Minimum min_wait_time in second. */
            minWaitTimeSec?: string;
            /** Food ordering service type. Please note that only ServiceType.PICKUP and ServiceType.DELIVERY are valid values for this field. */
            serviceType?: string;
        }
        interface LocalWWWInfo {
            address?: LocalWWWInfoAddress[];
            brickAndMortarStrength?: number;
            cluster?: LocalWWWInfoCluster[];
            docid?: string;
            /** Information about geo locations, rather than individual businesses. */
            geotopicality?: RepositoryAnnotationsGeoTopicality;
            hours?: LocalWWWInfoOpeningHours[];
            /** Does this LocalWWWInfo represent a widely-distributed chain? */
            isLargeChain?: boolean;
            isLargeLocalwwwinfo?: boolean;
            phone?: LocalWWWInfoPhone[];
            /** These are per-document signals independent of any particular address. */
            siteSiblings?: number;
            /** These are for convenience during intermediate data processing, and should be cleared before the data gets into doc-joins. */
            url?: string;
            wrapptorItem?: LocalWWWInfoWrapptorItem[];
        }
        interface LocalWWWInfoAddress {
            address?: GeostoreAddressProto;
            addrFprint?: string;
            latE7?: number;
            lngE7?: number;
        }
        interface LocalWWWInfoCluster {
            addrFprint?: string;
            /** Confidence score for business mention annotations which is copied from LocalEntityAnnotations::location_confidence. */
            annotationConfidence?: number;
            clusterdocid?: string;
            clusterid?: string;
            /** Probability that this is the authority page of the business. Same as LocalListing.authority_page_probability, only set for pages with page_type_flags & AUTHORITY. */
            confidence?: number;
            /**
             * Feature type for this listing, from LocalListing::info::related_feature. A geostore::FeatureProto::TypeCategory. Intended primarily to indicate POI-ness (i.e.,
             * TYPE_ESTABLISHMENT_POI).
             */
            featureType?: number;
            /** Opening hours for the business, from Local attributes and/or extracted annotations. */
            hours?: GeostoreTimeScheduleProto;
            hoursSource?: string;
            includeInIndex?: boolean;
            /** TODO(local-universal) Consider deleting is_plusbox once the new scheme that uses make_plusbox_visible rolled out. */
            isPlusbox?: boolean;
            latitudeE6?: number;
            /** DEPRECATED / NO LONGER WRITTEN. URL path level from actual references to this webpage. */
            level?: number;
            longitudeE6?: number;
            /** A hint for frontend to decide whether this plusbox should be visible or not. */
            makePlusboxVisible?: boolean;
            /** Menu link for the business. Currently only comes from Local attributes. */
            menuUrl?: string[];
            /** Type of the web reference. */
            pageTypeFlags?: number;
            phoneFprint?: string;
            phoneNumber?: TelephoneNumber;
            postalAddress?: PostalAddress;
            /**
             * DEPRECATED / NO LONGER WRITTEN. How relevant the webpage is to the business (clustering distance). Same as LocalListing::Reference.relevance. Typically only set for pages with
             * (page_type_flags & WEB_EXTRACTION && !AUTHORITY).
             */
            relevance?: number;
            showInSnippets?: boolean;
            source?: string[];
            title?: string;
        }
        interface LocalWWWInfoOpeningHours {
            hours?: GeostoreTimeScheduleProto;
            hoursFprint?: string;
        }
        interface LocalWWWInfoPhone {
            phoneFprint?: string;
            phoneNumber?: TelephoneNumber;
        }
        interface LocalWWWInfoWrapptorItem {
            addrFprint?: string;
            bizName?: string;
            phoneFprint?: string;
        }
        interface LogsProtoIndexingCrawlerIdCrawlerIdProto {
            /**
             * The country to crawl the country from, defaults to the default non-specified crawling node (which is interpreted by most web-servers as USA). When specified, the crawling will fetch
             * the document from a node in that country instead.
             */
            country?: string;
            /** The device type, which maps into the useragent to be set when initiating the fetch-request, e.g. desktop-googlebot vs. smartphone-googlebot. */
            deviceType?: string;
            /** Specifies whether the document is a duplicated document from the index growth experiment, detailed at go/indexsize_exp, defaults to not in any experiment. */
            indexGrowthExptType?: string;
            /**
             * The language being set by the crawler. Defaults to UNKNOWN_LANGUAGE which indicates to not apply an accept-language header on the FetchRequest. When a language is specified, on
             * crawling this language is converted into an accept-language header (e.g. GERMAN -> "Accept-language: de"). Script variations, e.g. ZH-HANS vs. ZH-HANT, are handled as different enum
             * values (e.g. CHINESE vs. CHINESE_T).
             */
            language?: string;
            /**
             * Language-code used for identifying the locale of the document. 'language' and 'country' above are used for web-based documents, representing the detected language of the document
             * and the country it was crawled from. The language code here, however, rather represents an artifical language_code applied to manually translated webpages (e.g. feeds), for instance
             * for the pidgin-usecase. They are limited to the set of III-codes being supported by the client, yet are beyond the enum in 'language', e.g. to support variants of English across
             * different countries.
             */
            languageCode?: string;
        }
        interface LogsSemanticInterpretationIntentQueryEntityLinkMetadata {
            aggregateFlags?: LogsSemanticInterpretationIntentQueryLinkKindFlags;
            kindInfo?: LogsSemanticInterpretationIntentQueryLinkKindInfo[];
        }
        interface LogsSemanticInterpretationIntentQueryLinkKindFlags {
            cluster?: string;
            geoContainment?: string;
            implication?: string;
            latentEntity?: string;
            mdvc?: string;
            property?: string;
            resolution?: string;
        }
        interface LogsSemanticInterpretationIntentQueryLinkKindInfo {
            flags?: LogsSemanticInterpretationIntentQueryLinkKindFlags;
            kcLinkName?: string;
            topicPropertyName?: string;
        }
        interface LogsSemanticInterpretationIntentQuerySupportTransferRule {
            allowWildcardIntents?: boolean;
            domain?: string;
            isReverseLink?: boolean;
            mentionsOnly?: boolean;
            supportShare?: boolean;
            targetCollection?: string;
            userCountry?: string;
            userLanguage?: string;
        }
        interface LogsSemanticInterpretationIntentQueryWebrefEntityRelationship {
            entityIndex?: number;
            linkMetadata?: LogsSemanticInterpretationIntentQueryEntityLinkMetadata;
            linkWeight?: number;
        }
        interface LongStructuredSnippet {
            entry?: LongStructuredSnippetEntry[];
        }
        interface LongStructuredSnippetEntry {
            /** Is this a header or normal paragraph? */
            header?: boolean;
            /** The text of the header or paragraph. */
            text?: string;
        }
        interface MajelContactInformationShortcutInformation {
            shortcutContactType?: string;
        }
        interface MapsQualitySpecialWordsFlags {
            /**
             * An affix that indicates an alley. Alleys are unnamed, numbered routes that are always linked to a "parent street". As these parent streets can be named e.g. "7th street" and alleys
             * might be referred to as "7th alley", we need to be able to distinguish those affixes. For more details about alleys see go/vn-alley-geocoding.
             */
            isAlleyAffix?: boolean;
            /** Common words E.g.: center, park, etc. */
            isCommonWord?: boolean;
            /** Whether this special word is part of a name without a separator (like e.g. suffix "strasse" in Freigutstrasse). */
            isDeconstructible?: boolean;
            /** Directional modifier. E.g.: north, south, etc. */
            isDirectionalModifier?: boolean;
            /** An affix that indicates distance marker on a route, e.g., 'km'. */
            isDistanceMarker?: boolean;
            /** Whether geo paths are forbidden to contain this word. */
            isForbiddenWord?: boolean;
            /** A keyword for a house id. */
            isHouseIdIdentifier?: boolean;
            /** Intersection. E.g.: and, at, corner. */
            isIntersectionConnector?: boolean;
            /** An affix that indicates a landmark, e.g. "opposite", "near" etc. */
            isLandmarkIdentifier?: boolean;
            /** Language indicator. E.g.: platz in German, straat in Dutch. */
            isLanguageIndicator?: boolean;
            /** Whether this is a name synonym and should be allowed to be matched on when searching (that is, added to the retrieval query with the name/ prefix). */
            isNameSynonym?: boolean;
            /** Terms which are not allowed to be used by the legacy street number detection. */
            isNotForLegacyStreetNumberDetection?: boolean;
            /** Terms which are not allowed to be treated as optional. */
            isNotOptionalizable?: boolean;
            /** Numbers. E.g.: 1, one, 2, two. */
            isNumber?: boolean;
            /** E.g. suffixes in French: bis, ter. */
            isNumberSuffix?: boolean;
            /** Is this special word optional? */
            isOptional?: boolean;
            /** E.g.: 1st, first. */
            isOrdinalNumber?: boolean;
            /** Optional terms that should not geocode by themselves. */
            isPenalizedIfMissing?: boolean;
            /** Personal titles (e.g. doctor, professor, general, etc.) */
            isPersonalTitle?: boolean;
            /** E.g.: the, in, near, where. */
            isStopWord?: boolean;
            /** A keyword that denotes a street number, e.g. "number", "unit" etc. */
            isStreetNumberIdentifier?: boolean;
        }
        interface MapsQualitySpecialWordsProto {
            /**
             * Alternate versions of this canonical form. This is mainly abbreviations of the canonical form e.g. "St", "NE", etc. This should be present as it is used in the specified language
             * with the correct capitalization, accents, etc. in UTF-8.
             */
            alternate?: string[];
            /**
             * Canonical versions: the version which is in oyster. This should be present as it is used in the specified language with the correct capitalization, accents, etc. in UTF-8. The
             * canonical can be a single or a multi-token string. There can be several canonicals, e.g. "center" and "centre" in English.
             */
            canonical?: string[];
            /** If empty, apply this rule to any country. Otherwise, a list of ISO 3166-1 alpha-2 (2-letter uppercase) country codes that this description applies to. */
            country?: string[];
            /** Boolean flags indicating what type of special word this is. */
            flags?: MapsQualitySpecialWordsFlags;
            /**
             * The III language code of the language that this description applies to. No language means that this applies worldwide. This could be useful for codes like country codes or airport
             * codes or for displayed language neutral icons. A special word with a language code here also applies to the regional variants of that language (e.g. "en" applies to "en-GB" and
             * "en-US" as well).
             */
            language?: string[];
            position?: string;
            /** visible_type_id from VisibleTypeProto for visible types converted to the special words. For original special words this field is empty. */
            visibleTypeId?: string[];
        }
        interface MediaIndexBoundingbox {
            /** The area of the region as a fraction of the image. The value is in the range (0, 1). */
            areaFraction?: number;
            xmax?: number;
            xmin?: number;
            ymax?: number;
            ymin?: number;
        }
        interface MediaIndexEntityField {
            /** The custom source should only be a-z[0-9] dashes, underscores, and colons. Special characters should be avoided. */
            customSource?: string;
            entityId?: string;
            quantizedScore?: string;
            source?: string;
        }
        interface MediaIndexFrameIdentifier {
            previewFrameZeroVariant?: MediaIndexFrameIdentifierPreviewFrameZeroVariant;
            /** Offset of the frame from the beginning of the video (in milliseconds). */
            timestampMs?: number;
        }
        interface MediaIndexFrameIdentifierPreviewFrameZeroVariant {
            previewLength?: string;
            /**
             * All xtags used in the generation of the preview. The same frame generated from the same preview with different xtags will likely have different bytes (such as, for example,
             * resulting from a different aspect ratio).
             */
            xtagList?: MediaIndexXtagList;
        }
        interface MediaIndexRegion {
            /** The bounding box corresponding to the region. */
            boundingBox?: MediaIndexBoundingbox;
            /** Detected Entities found within this region. */
            entityFields?: MediaIndexEntityField[];
            /**
             * The labels associated with the region encoded as a SparseFloatVector to facilitate dot product computation during sorting. The columns are the fingerprints of the labels and the
             * values are the corresponding confidence scores. The vector is L2 normalized.
             */
            labels?: MediaIndexSparseFloatVector;
            /** PRIMI Apparel Features v2 embedding and tokens. */
            primiApparelFeaturesV2?: string;
            primiApparelTokensV2?: string[];
            /** PRIMI Generic Features v2.5 embedding and tokens. */
            primiGenericFeaturesV25?: string;
            primiGenericTokensV25?: string[];
            /** Starburst v4 embedding and tokens. */
            starburstFeaturesV4?: string;
            /** Starburst v5 embedding and tokens. */
            starburstFeaturesV5?: string;
            starburstTokensV4?: string[];
            starburstTokensV5?: string[];
            starburstV4?: ImageContentStarburstVersionGroup;
        }
        interface MediaIndexSparseFloatVector {
            /** Parallel arrays of column / value. Exactly one of those columns vector should be set. Columns must be in monotonically increasing order. */
            columns?: string[];
            columnsInt16?: string;
            columnsInt32?: number[];
            /** Columns are fixed integers, used for accelerated parse. */
            columnsInt64?: string[];
            columnsInt8?: string;
            values?: number[];
        }
        interface MediaIndexVideoCentroid {
            domainScores?: MediaIndexVideoCentroidDomainScore[];
        }
        interface MediaIndexVideoCentroidDomainScore {
            /** The domain this score was generated for. */
            domain?: string;
            /** Number of pages from the domain used to generate this DomainScore. */
            numDocs?: number;
            /** In general, lower scores indicate the video is appearing on more diverse pages. */
            score?: number;
        }
        interface MediaIndexVideoCoreSignals {
            centroid?: MediaIndexVideoCentroid;
            videoFrames?: MediaIndexVideoFrame[];
        }
        interface MediaIndexVideoFrame {
            /** The canonical docid of the frame. */
            docid?: string;
            frameIdentifier?: MediaIndexFrameIdentifier;
            /** Metadata associated with regions within this frame. */
            regions?: MediaIndexRegion[];
            /** Starburst v4 embedding and tokens. */
            starburstFeaturesV4?: string;
            /**
             * Note: due to the migration to Golden7-source Starburst v4 embedding, no starburst_tokens_v4 will be provided in video content corpus (go/video-content-corpus). But this field is
             * kept in case other purposes may still use it in the proto.
             */
            starburstTokensV4?: string[];
            /** Set of available thumbnail types for this frame. Should be valid image_base.ThumbnailType values (enumerated at http://google3/image/base/thumbnail-type.proto). */
            thumbnailType?: string[];
        }
        interface MediaIndexVideoFrames {
            videoFrames?: MediaIndexVideoFrame[];
        }
        interface MediaIndexXtag {
            /** Names are all stored case-sensitive, and no case-folding is done for comparisons. */
            name?: string;
            /** The value associated with this Xtag. Values are all stored case-sensitive, and no case-folding is done for comparisons. */
            value?: string;
        }
        interface MediaIndexXtagList {
            xtags?: MediaIndexXtag[];
        }
        interface MobilePerDocData {
            flags?: number;
            /** DEPRECATED: Url of the mobile version of the document. This is set during canonicalization if we do not know that the Web url also serves the mobile version. */
            mobileurl?: string;
            /** DEPRECATED: The transcoded page quality repesented in 7-bits range from 0 to 127. */
            transcodedPageScore?: number;
        }
        interface MultiscaleFieldPresence {
            /** Whether the field (data field or pointer) is defined. */
            present?: boolean;
            wellDefined?: string;
        }
        interface MultiscaleLayerPresence {
            /** If the layer is not materialized but things point into it, this gives the effective length. */
            implicitLength?: number;
            /** Whether the layer is present. */
            present?: boolean;
        }
        interface MultiscalePointerIndex {
            /** The index of the node that this pointer points to. */
            index?: number;
        }
        interface MultiscalePointerSpan {
            /**
             * The exclusive end index for the span of nodes that this pointer points to -- i.e., one plus the index of the last node in the span. Must be greater than or equal to `start`. If
             * equal to `start`, then the target span is empty.
             */
            limit?: number;
            /** The inclusive start index for the span of nodes that this pointer points to -- i.e., the index of the first node in the span. */
            start?: number;
        }
        interface MustangReposWwwSnippetsCandidateFeature {
            /** Name corresponds to the names in WebChooserScorer::FeatureNames. */
            name?: string;
            score?: number;
        }
        interface MustangReposWwwSnippetsOrganicListSnippetResponse {
            /** The texts of header and listing items. */
            header?: string;
            /** The ratio of header tokens covered by title. */
            headerTitleRedundancy?: number;
            /** If the header being used in organic snippet. */
            headerUsedInSnippet?: boolean;
            items?: string[];
            /** The number of items in the original list. */
            originalTotalItems?: number;
            /** The score of the radish signal. */
            radishScore?: number;
        }
        interface MustangReposWwwSnippetsSnippetCandidate {
            /** data_source_type corresponds to the ChosenSnippet::SnippetType enum. */
            dataSourceType?: number;
            features?: MustangReposWwwSnippetsCandidateFeature[];
            text?: string;
        }
        interface MustangReposWwwSnippetsSnippetsRanklabFeatures {
            /** Browser width. */
            browserWidth?: number;
            /** Features for snippets candidates, generated by both old and new scorer. Currently only features for chosen candidate is generated. */
            candidates?: MustangReposWwwSnippetsSnippetCandidate[];
            /** Snippet features for the final chosen snippet. This field is firstly populated by Muppet, and then overwriten by Superroot if SnippetBrain is triggered. */
            displaySnippet?: QualityPreviewRanklabSnippet;
            /** locale of the document. */
            documentLanguage?: string;
            /** Original query term coverage in titles and / or snippets. */
            originalQueryTermCoverages?: QualityPreviewSnippetQueryTermCoverageFeatures;
            /** locale of the query, */
            queryLanguage?: string;
            /** Snippet data source. */
            snippetDataSourceType?: number;
            /** Query term coverage in snippets. */
            snippetQueryTermCoverage?: number;
            /** Snippet features for Muppet snippet candidates. In production, only the data for chosen snippet will be recorded. */
            snippets?: QualityPreviewRanklabSnippet[];
            /** Title data source. */
            titleDataSourceType?: number;
            /** Query term coverage in titles. */
            titleQueryTermCoverage?: number;
            /** Per-candidate title features for ranklab models, sorted from the best candidate to the worst candidate (i.e., the first element is the actually selected title). */
            titles?: QualityPreviewRanklabTitle[];
            /** Query term coverage in titles and snippets. */
            titleSnippetQueryTermCoverage?: number;
        }
        interface MustangSnippetsRenderedToken {
            /** Is the rendered token bolded (insided ) */
            bolded?: boolean;
            /** Byte offset range in the rendered text that corresponds to this token. [byte_offset_begin, byte_offset_end) inclusive */
            byteOffsetBegin?: number;
            /** exclusive */
            byteOffsetEnd?: number;
            /** Section and TokenPos of the token. */
            section?: string;
            tokenPos?: string;
        }
        interface NetFabricRpcVirtualNetworkId {
            /** required */
            id?: number;
        }
        interface NlpLoggingQRewriteClientCallPathInfo {
            /**
             * Indicates the type of candidate rewritten by QRewrite. This field is filled within QRewrite instead of QRewrite clients, and we add this here so this proto is able to hold all tags
             * to form the identifier.
             */
            qrewriteCandidateId?: QualityQrewriteCandidateId;
            /** QUS tags Indicates the type of the candidate in QUS that sends the QRewrite request. */
            qusCandidateId?: QualityQrewriteCandidateId;
            /** Upstream call path before QUS. */
            qusClientCallPathInfo?: NlpLoggingQusClientCallPathInfo;
            /**
             * Indicates which QUS phase sends the QRewrite request. Note if the QRewrite response is reused in succeeding phases, this field should not be overridden and it is always the phase
             * that initially sends the RPC.
             */
            qusPhase?: string;
        }
        interface NlpLoggingQusClientCallPathInfo {
            /**
             * rewriter_type forms part of a unique key to be used to label QUS Requests from ACE. The need to distinguish between the variety of calls from AS into QUS is for two reasons: (a)
             * currently, assistant eval can do NLU Eval only on certain rewrites (b) later AS Hermetic and NLU Eval can be integrated In the furure, the unique key will be expanded to add
             * intent_generator_type or something similar. There are ongoing discussions to confirm these plans
             */
            rewriterType?: string;
            /** The timestamp when QUS request is built in ACE. For now we don't care about the actual meaning of this tag, and only want to guarantee its uniqueness per QUS call. */
            temporaryAceTag?: string;
        }
        interface NlpMeaningMeaningRemodeling {
            /** This field can be set to true to indicate that the associated part of the schema is being deleted as part of the remodeling. */
            deletion?: boolean;
            /** The remodeling ID. Each remodeling has a unique ID that is used to associate changes with that remodeling. */
            id?: string;
        }
        interface NlpMeaningMeaningRemodelingControl {
            remodelingId?: string[];
        }
        interface NlpMeaningMeaningRemodelings {
            remodeling?: NlpMeaningMeaningRemodeling[];
        }
        interface NlpMeaningSemanticTypeNameMeaningRemodelings {
            /** Semantic type name. */
            name?: string;
            remodelings?: NlpMeaningMeaningRemodelings;
        }
        interface NlpSaftAnnotatedPhrase {
            /** Annotation for this phrase. */
            info?: any;
            /** Contains start and end pointers to the token array for this span. */
            phrase?: NlpSaftPhrase;
        }
        interface NlpSaftConstituencyNode {
            /** An arbitrary number of children, ordered from left to right; empty for preterminals. Represented via indices into Document.constituency_node. */
            child?: number[];
            /** The label of the current node. */
            label?: string;
            /** A phrase that contains information about the span and the (optional) head token. For terminal nodes the head of the phrase holds the word. */
            phrase?: NlpSaftPhrase;
        }
        interface NlpSaftDocument {
            /** Annotated phrases in the document that are not semantically well-defined mentions of entities. */
            annotatedPhrase?: NlpSaftAnnotatedPhrase[];
            /** Generic annotations. */
            annotations?: any;
            /** Document author(s). */
            author?: string[];
            /**
             * Document's byline date, if available: this is the date that will be shown in the snippets in web search results. It is stored as the number of seconds since epoch. See
             * segindexer/compositedoc.proto
             */
            bylineDate?: string;
            /** Constituency parse tree nodes for the sentences in this document. */
            constituencyNode?: NlpSaftConstituencyNode[];
            /**
             * The root node of the constituency tree for each sentence. If non-empty, the list of roots will be aligned with the sentences in the document. Note that some sentences may not have
             * been parsed for various reasons; these sentences will be annotated with placeholder "stub parses". For details, see //nlp/saft/components/constituents/util/stub-parse.h.
             */
            constituencyRoot?: number[];
            /**
             * Age of the content of the document. For details, see: quality/historical/shingle/signals/contentage.proto The format has been translated to a canonical timestamp (seconds since
             * epoch).
             */
            contentage?: string;
            /**
             * Stores minimum of first time google successfully crawled a document, or indexed the document with contents (i.e, not roboted). It is stored as the number of seconds since epoch. See
             * quality/historical/signals/firstseen/firstseen.proto
             */
            contentFirstseen?: string;
            /**
             * Optional document content_type (from webutil/http/content-type.proto). Used for setting the content_type when converting the SAFT Document to a CompositeDoc. Will be inferred if not
             * given here.
             */
            contentType?: number;
            /** Document anchor date in YYYYMMDDhhmmss format. */
            date?: string;
            /** Identifier for document. */
            docid?: string;
            /** Entities in the document. */
            entity?: NlpSaftEntity[];
            /**
             * Entity labels used in this document. This field is used to define labels for the Entity::entity_type_probability field, which contains corresponding probabilities. WARNING: This
             * field is deprecated. go/saft-replace-deprecated-entity-type
             */
            entityLabel?: string[];
            /** Focus entity. For lexicon articles, like Wikipedia pages, a document is often about a certain entity. This is the local entity id of the focus entity for the document. */
            focusEntity?: number;
            /**
             * Flag for indicating that the document is a gold-standard document. This can be used for putting additional weight on human-labeled documents in contrast to automatically labeled
             * annotations.
             */
            golden?: boolean;
            /**
             * HTTP header for document. If the HTTP headers field is set it should be the complete header including the HTTP status line and the trailing cr/nl. HTTP headers are not required to
             * be valid UTF-8. Per the HTTP/1.1 Syntax (RFC7230) standard, non-ASCII octets should be treated as opaque data.
             */
            httpHeaders?: string;
            /** The hyperlinks in the document. Multiple hyperlinks are sorted in left-to-right order. */
            hyperlink?: NlpSaftHyperlink[];
            /**
             * Generic labeled spans (produced by the span labeling framework, go/saft-span-labeling). The map key identifies spans of the same type. By convention, it should be of the form
             * "team_name/span_type_name".
             */
            labeledSpans?: { [P in string]: NlpSaftLabeledSpans };
            /** Document language (default is English). This field's value maps cleanly to the i18n.languages.Language proto enum (i18n::languages::Language in C++). */
            language?: number;
            /**
             * Last significant update of the page content, in the same format as the contentage field, and also derived from ContentAge.last_significant_update in
             * quality/historical/shingle/signals/contentage.proto.
             */
            lastSignificantUpdate?: string;
            /** Measures in the documents. This covers both time expressions as well as physical quantities. */
            measure?: NlpSaftMeasure[];
            /** True if this document contains privacy sensitive data. When the document is transferred in RPC calls the RPC should use SSL_PRIVACY_AND_INTEGRITY security level. */
            privacySensitive?: boolean;
            /** Relations between entities in the document. */
            relation?: NlpSaftRelation[];
            /** True if some RPC which touched this document had an error. */
            rpcError?: boolean;
            /**
             * The semantic nodes for the document represent arbitrary types of higher-level abstractions beyond entity mention coreference and binary relations between entities. These may
             * include: n-ary relations, semantic frames or events. The semantic nodes for a document are the nodes in a directed acyclic graph, with an adjacency list representation.
             */
            semanticNode?: NlpSaftSemanticNode[];
            /** Sub-sections for document for dividing a document into volumes, parts, chapters, sections, etc. */
            subsection?: NlpSaftDocument[];
            /**
             * Document's syntactic date (e.g. date explicitly mentioned in the URL of the document or in the document title). It is stored as the number of seconds since epoch. See
             * quality/timebased/syntacticdate/proto/syntactic-date.proto
             */
            syntacticDate?: string;
            /** Raw text contents of document. (In docjoin attachments from the SAFT goldmine annotator this field will be empty.) */
            text?: string;
            /** Optional document title. */
            title?: string;
            /** Tokenization of the document. */
            token?: NlpSaftToken[];
            topic?: NlpSaftDocumentTopic[];
            /** Whether to enable component tracing during analysis of this document. See http://go/saft-tracing for details. */
            trace?: boolean;
            /** Source document URL. */
            url?: string;
        }
        interface NlpSaftDocumentTopic {
            /** Topic name or identifier. */
            name?: string;
            /** Topic score. */
            score?: number;
        }
        interface NlpSaftEntity {
            /** Antecedent for entity. This is used to make coreference chains before the mentions in the document are grouped by entity. */
            antecedent?: number;
            /** Entity type (e.g. PER, ORG, LOC). WARNING: This field is deprecated. go/saft-replace-deprecated-entity-type */
            entityType?: string;
            /**
             * Probability distribution over entity types. These values correspond to Document.entity_label values: doc.entity[e].entity_type_probability[n] is the probability that the correct
             * label for doc.entity[e] is doc.entity_label[n]. These probabilities sum to 1.0 (with possible rounding error). WARNING: This field is deprecated.
             * go/saft-replace-deprecated-entity-type
             */
            entityTypeProbability?: number[];
            /** Gender for entity. */
            gender?: string;
            /** Application-specific information about this entity. */
            info?: any;
            /** Mentions of the entity in the document. */
            mention?: NlpSaftMention[];
            /** Representative entity name. */
            name?: string;
            /** Profile for entity. */
            profile?: NlpSaftEntityProfile;
            /**
             * Referent information for discourse context entities that are not mentioned in the document. These can be merged with mentioned entities during analysis if they are deemed to be
             * coreferent. Entities with referents should not have any mentions if they do not corefer with anything. For example, when adding context entities to an input document prior to SAFT
             * analysis, those entities should have a referent and no mentions.
             */
            referent?: NlpSaftReferent;
            /** Representative mention, as an index into mention. */
            representativeMention?: number;
            /** Score indicating the saliency (centrality) of this entity to the document. */
            salience?: number;
            /**
             * Entity types of the entity. These can include SAFT types (/saft/location, /saft/art, /saft/other/living_thing, etc), collections types (/collection/tv_personalities,
             * /collection/statistical_regions, etc), and more. This refers to the type of the entity itself: in "She is on TV", "She" refers to a specific actor, with type
             * "/collection/tv_personalities". Cf. Mention.Type, which is the type of the referring mention.
             */
            type?: NlpSaftEntityType[];
        }
        interface NlpSaftEntityProfile {
            alternate?: NlpSaftEntityProfileAlternate[];
            /** Generic annotations. */
            annotations?: any;
            /** List of attributes for the entity. */
            attribute?: NlpSaftEntityProfileAttribute[];
            /** Canonical entity name. */
            canonicalName?: string;
            collectionScoreType?: string;
            /** Disambiguation phrase. The combination of entity name and disambiguation phrase should be unique within the corpus. */
            disambiguation?: string;
            /** Entity embeding vector, representing the entity in a dense low-dimensional embedding space. */
            embedding?: number[];
            /** Profile frame in binary SLING encoding. */
            frame?: string;
            /** Gender of the entity. */
            gender?: string;
            /** Unique global id for entity. */
            id?: string;
            /** External identifiers for entity. */
            identifier?: NlpSaftIdentifier[];
            keyword?: NlpSaftEntityProfileKeyword[];
            /** Freebase MID for entity. This field should be the same as FREEBASE_MID identifier for the entity profile. */
            mid?: string;
            /** Representative name for entity. */
            name?: string;
            /** Language for the name and disambiguation. */
            nameLanguage?: number;
            /** Nature of the entity. */
            nature?: string;
            reference?: NlpSaftEntityProfileReference[];
            related?: NlpSaftEntityProfileRelated[];
            /** Entity type. */
            type?: string;
        }
        interface NlpSaftEntityProfileAlternate {
            count?: number;
            /** see nlp/saft/resolution/name-form.h for values */
            form?: number;
            /** frame in SLING encoding */
            frame?: string;
            language?: number;
            name?: string;
            /** (1 << SRC_DEFAULT) */
            sources?: number;
        }
        interface NlpSaftEntityProfileAttribute {
            /** Boolean attribute value, e.g. for IsDeceased. */
            boolValue?: boolean;
            /** Double attribute value, e.g. for height/weight. */
            floatValue?: number;
            /** Integer attribute value, e.g. IntId("April"). */
            intValue?: string;
            /** Language, in case the attribute value is a string. */
            language?: number;
            /** String name of the type of attribute, e.g. /birth/date */
            type?: string;
            /** Any id of the type of the attribute, e.g. IntId(/birth/date) */
            typeId?: number;
            /** String attribute value, e.g. "April 2010" or "3,235,121". */
            value?: string;
            /** The type of the value. */
            valueType?: string;
        }
        interface NlpSaftEntityProfileKeyword {
            count?: number;
            language?: number;
            /** Score associated with the keyword. For fine-grained types this is a probability. */
            score?: number;
            term?: string;
            type?: string;
        }
        interface NlpSaftEntityProfileReference {
            docid?: string;
            entity?: number;
        }
        interface NlpSaftEntityProfileRelated {
            /** Number of occurrences. */
            count?: number;
            /** Inverse relations can be marked in a bidirectional graph. */
            inverse?: boolean;
            /** Optional integer id for the relation. */
            relationId?: number;
            /** Optional external identifier for the relation. */
            relationIdentifier?: NlpSaftIdentifier;
            /** Score for related entity, i.e. p(e->r | e). */
            score?: number;
            /** Profile id of related entity. */
            targetId?: string;
            /** Optional external identifier for the target entity. */
            targetIdentifier?: NlpSaftIdentifier;
            /** Name of related entity. */
            targetName?: string;
            /** Type of relation. */
            type?: string;
        }
        interface NlpSaftEntityType {
            /**
             * This field can be used to specify if the entity type has been annotated or predicted from a specific mention of the entity. However, the entity type does still apply to the entity
             * as a whole, and not just a specific mention.
             */
            basedOnMention?: number;
            /** A domain name for the set that this particular type belongs to. */
            domain?: string;
            /** Application-specific information about this entity type. */
            info?: any;
            /** The type name, like "/saft/person". See README.entity-types for the inventory of SAFT type tags. */
            name?: string;
            /** A score for this type. */
            score?: number;
        }
        interface NlpSaftHyperlink {
            /** Clean anchor text (no HTML markup). */
            anchorText?: string;
            /** note: inclusive */
            byteEnd?: number;
            /**
             * begin/end options are for goldmine AnnotationsFinder to locate the offsets of saft tokens. Start is inclusive by default and end is marked. The indices of the first and last byte
             * covered by the hyperlink.
             */
            byteStart?: number;
            /** The indices of the first and last token covered by the hyperlink. */
            phrase?: NlpSaftPhrase;
            /** (Absolute) URL that the links to. */
            url?: string;
        }
        interface NlpSaftIdentifier {
            /** Domain for the identifier. */
            domain?: string;
            /** Identifier within domain. */
            id?: string;
        }
        interface NlpSaftLabeledSpan {
            /** note: inclusive */
            byteEnd?: number;
            /** The indices of the first and last byte covered by the span. */
            byteStart?: number;
            /** The label associated with the span. */
            label?: string;
            /** Optionally stores alternative labels with associated scores for the span. */
            labelScores?: { [P in string]: number };
            /** A score associated with the span. */
            score?: number;
            /** note: inclusive */
            tokenEnd?: number;
            /** The indices of the first and last token covered by the span. */
            tokenStart?: number;
        }
        interface NlpSaftLabeledSpans {
            labeledSpan?: NlpSaftLabeledSpan[];
        }
        interface NlpSaftMeasure {
            /** Canonical value for measurement. */
            canonical?: number;
            /** Granularity for measurement. */
            granularity?: number;
            /** Application-specific information about this measure. */
            info?: any;
            /** Phrase containing the measure. */
            phrase?: NlpSaftPhrase;
            type?: string;
            unit?: string;
            /** Measurement value and unit. */
            value?: string;
        }
        interface NlpSaftMention {
            /**
             * Estimate of the confidence that this mention is in the correct cluster. Zero means this mention is probably in the wrong cluster, 1 means this mention is probably in the correct
             * cluster. See nlp/saft/components/coreference/coreference-confidence.h for details about what "correct cluster" might mean.
             */
            confidence?: number;
            /** Application-specific information about this mention. */
            info?: any;
            kind?: string;
            nestingRelation?: string;
            /** Phrase for the mention. */
            phrase?: NlpSaftPhrase;
            /**
             * Mention-level resolution. This is used for encoding the meaning of the mention rather than the entity. For example, definite references and appositions are resolved to the mid for
             * the concept rather than the entity.
             */
            resolution?: NlpSaftMentionResolution;
            role?: string;
            type?: string;
        }
        interface NlpSaftMentionResolution {
            /** Profile for mention information. */
            profile?: NlpSaftEntityProfile;
            type?: string;
        }
        interface NlpSaftMorphology {
            /** A list of morphology attribute-value pairs. */
            attrValue?: string[];
        }
        interface NlpSaftPhrase {
            end?: number;
            facet?: string;
            /**
             * The head token in the phrase is the id of the top-most token within the phrase. It either has an arc from outside the phrase going to it, or it is a root token of the sentence. A
             * value of -1 indicates that the head has not yet been computed for the phrase (not the same semantics as the head of a token!). Note that even when it is uniquely defined, there is
             * no guarantee that the head is set for entities and measurements within a document: you may need to explicitly compute it.
             */
            head?: number;
            /** First and last token in the phrase. The phrase goes from start to end (inclusive). */
            start?: number;
        }
        interface NlpSaftReferent {
            /**
             * Distance of this referent from the markables in the Document. Smaller values imply that the referent is more accessible to be an antecedent for a markable in the Document. The
             * expectation is that this field would increase with every new Document in which this referent is not mentioned.
             */
            distance?: number;
            explicitness?: string;
            /** Application-specific information about this referent. */
            info?: any;
            /**
             * Entity name phrase. The phrase indices are relative to the token array above. The phrase should normally cover all the tokens in the name and the head must be set to be the head
             * token of the name.
             */
            phrase?: NlpSaftPhrase;
            /** Prominence score for referent. This is roughly equivalent to the number of previous mentions of the referent. */
            prominence?: number;
            role?: string;
            /** Tokenized representation for the canonical name of the referent entity. */
            token?: NlpSaftToken[];
        }
        interface NlpSaftRelation {
            /** External identifier for relation. */
            identifier?: NlpSaftIdentifier;
            /** Application-specific information about this relation. */
            info?: any;
            kind?: string;
            /** Mentions of the relation in the document. */
            mention?: NlpSaftRelationMention[];
            /** Relation score. */
            score?: number;
            /** Source and target entity indices. These are indices into the entity array in the document. If this is an attribute relation the target is the index of a measure in the document. */
            source?: number;
            target?: number;
            /** Relation type. */
            type?: string;
            /** Relation type id. */
            typeId?: number;
        }
        interface NlpSaftRelationMention {
            /** Application-specific information about this relation mention. */
            info?: any;
            /** Phrase in the document that indicates the relation mention. */
            phrase?: NlpSaftPhrase;
            /** Source and target mention indices. These are indices into the mention arrays for their respective entities. The target is not used for attributes. */
            source?: number;
            /** The info of the source models or systems of the relation mention. */
            sourceInfo?: string[];
            target?: number;
        }
        interface NlpSaftSemanticNode {
            /**
             * The arcs from this node. For example, if this node is the root of a subgraph representing a predicate-argument structure, this node will typically refer to the predicate, and there
             * will typically be one arc per argument.
             */
            arc?: NlpSaftSemanticNodeArc[];
            /** Confidence score for the annotation. */
            confidence?: number;
            /** Human-readable description of the information in the subgraph represented by this node. This field is only meant for display purposes. */
            description?: string;
            /** The entity and mention fields specify a unique entity mention referred to by this semantic node. */
            entity?: number;
            /**
             * Indicates whether the semantic node is not explicit (grounded) in the text (e.g. pro-drop for a text author or an implicit predicate node for interpreting a compound noun), rather
             * than any explicit phrase or text inside the document.
             */
            implicit?: boolean;
            /** Application-specific information about this node. */
            info?: any;
            /**
             * Encodes the kind of this node and, possibly, the entire subgraph rooted at this node. For example, if this node represents a predicate-argument structure in PropBank, then this
             * node's kind will be PROPBANK, its phrase field will be set to correspond to the span of tokens corresponding to the predicate (such as a verb) and it will have one arc per argument.
             * If the kind is MONOTONIC this node corresponds to a semantic graph node, and arcs correspond to semantic graph edges outgoing from the node. If the kind field is not set, then this
             * node is not directly connected to any type system. In such a case, this node may still optionally have a concrete "payload" in the form of references to an entity mention, measure
             * or span of tokens (Phrase) in a SAFT document. The values or existence of the kind field need not be identical in any subgraph. For example, even if this node's kind field is not
             * set, it may still be the destination node of an arc from some other node whose kind field is set.
             */
            kind?: string;
            /** The index of the measure referred to by this semantic node. */
            measure?: number;
            mention?: number;
            /**
             * Phrase (span of text) for this node. This field does not need to be set, but if it is, this node has a textual "payload" corresponding to the specified token span. For example, if
             * this node is the root of a subgraph corresponding to a predicate-argument structure, then the phrase field will be set to be the span of tokens corresponding to the predicate (e.g.,
             * a verb).
             */
            phrase?: NlpSaftPhrase;
            /**
             * Arbitrary type string for this semantic node, or for the subgraph rooted at this node. This type string might come from an external resource, type system or ontology that contains a
             * predefined set of types.
             */
            type?: string;
            /** Arbitrary value string for this semantic node. */
            value?: string;
        }
        interface NlpSaftSemanticNodeArc {
            /** Human-readable description of this arc's type (for display purposes). */
            description?: string;
            /** Indicates the arc is for an implicit semantic relation between nodes, for example one that does not correspond to a grammatical relation in the text. */
            implicit?: boolean;
            /** Application-specific information about this arc. */
            info?: any;
            /** Index of the semantic node pointed to by this arc. */
            semanticNode?: number;
            /** Arc type (akin to an edge label, or semantic operator). */
            type?: string;
        }
        interface NlpSaftToken {
            breakLevel?: string;
            /** Whether the break skipped over non-tag text (excluding script/style). */
            breakSkippedText?: boolean;
            /** Coarse-grained word category for token. See README.categories for category inventory. */
            category?: string;
            end?: number;
            /** Head of this token in the dependency tree: the id of the token which has an arc going to this one. If it is the root token of a sentence, then it is set to -1. */
            head?: number;
            /** Annotation for this token. */
            info?: any;
            /** Label for dependency relation between this token and its head. See README.labels for label inventory. */
            label?: string;
            /** Word lemma. This is only filled if the lemma is different from the word form. */
            lemma?: string;
            /** Morphology information. */
            morph?: NlpSaftMorphology;
            /**
             * A string representation (typically four letters, sometimes longer) of the token's Unicode script code, based on BCP 47/CLDR, capitalized according to ISO 15924. See
             * i18n/identifiers/scriptcode.h for details.
             */
            scriptCode?: string;
            /**
             * [start, end] describe the inclusive byte range of the UTF-8 encoded token in document.text. End gives the index of the last byte, which may be a UTF-8 continuation byte, and the
             * length in bytes is end - start + 1. begin/end options are for goldmine AnnotationsFinder to locate the offsets of saft tokens. Start is inclusive by default and end is marked.
             */
            start?: number;
            /** Part-of-speech tag for token. See README.tags for tag inventory. */
            tag?: string;
            /** Confidence score for the tag prediction -- should be interpreted as a probability estimate that the tag is correct. */
            tagConfidence?: number;
            textProperties?: number;
            /**
             * Token word form. This may not be identical to the original. For example, in goldmine annotation we do UTF-8 normalization and punctuation normalization. The punctuation
             * normalization includes inferring the directionality of straight doublequotes -- that is, we map " to open quote (``) or close quote (''), and sometimes we get it wrong. SAFT
             * processing in other contexts (such as queries in qrewrite) involves different normalizations.
             */
            word?: string;
        }
        interface NlpSciencelitArticleData {
            /** All the text in this article, separated into Sections and Paragraphs. See nlp_sciencelit.ScaleSetExtensions for the extensions to ScaleSet used. */
            analyzedText?: NlxDataSchemaScaleSet;
            articleId?: NlpSciencelitArticleId[];
            /** All references from this article (Bibliography). */
            citation?: NlpSciencelitCitationData[];
            /** The result of selecting the earliest date from various metadata (PMC, PubMed Metadata, scholar citations). */
            earliestPubDate?: string;
            metadata?: NlpSciencelitArticleMetadata;
            nonAbstractWordCount?: string;
            /** Path of the source document from which this was parsed. */
            parsedFrom?: string;
            /** All dates from the PMC article metadata Year/Mon/Day. */
            pubDate?: NlpSciencelitPubDate[];
            /** All figure captions within this article. */
            referencedBlock?: NlpSciencelitReferencedBlock[];
            /** Citation for this article. */
            scholarCitation?: ScienceCitation;
            /** DocJoins with full text article. */
            scholarDocument?: CompositeDoc[];
            /** May also add the Scholar index signal information: */
            scholarSignal?: ScienceIndexSignal;
            /** Source of this article data (e.g., PubMed, scholar index, other source.). */
            source?: string;
            title?: string;
            /** Number of words in the entire article and everywhere outside of abstract sections. */
            wordCount?: string;
        }
        interface NlpSciencelitArticleId {
            id?: string;
            idType?: string;
        }
        interface NlpSciencelitArticleMetadata {
            /** Abstract of article from metadata. */
            abstract?: NlpSciencelitTokenizedText;
            articleId?: NlpSciencelitArticleId[];
            /** Author of article. */
            author?: NlpSciencelitAuthor[];
            /** Datasets referenced from this article. */
            dataset?: NlpSciencelitDataset[];
            /** Most recent date YYYY-MM-DD. */
            dateStr?: string;
            /** Citation for flagged for deletion by source. */
            deleted?: boolean;
            /** Mesh Terms. */
            heading?: NlpSciencelitMeshHeading[];
            issue?: string;
            /** Title of journal. For books: Journal = Publisher Volume = Collection */
            journal?: string;
            language?: string;
            /** Last entry revision date YYYY-MM-DD. */
            lastRevisedDateStr?: string;
            metadataSource?: string[];
            /** Source Pubmed/Medline XML file. */
            parsedFrom?: string;
            /** PMID of article (for non-pubmed data, this is the docid). */
            pmid?: string;
            publicationType?: NlpSciencelitPublicationType[];
            /** Optional ScaM restrict tokens to be added to all GFVs generated from this article's data. */
            scamRestrictTokens?: ResearchScamV3Restrict;
            /** Title of article. */
            title?: string;
            /** URL(s) for the document. If possible, order by decreasing desirability. */
            url?: string[];
            volume?: string;
        }
        interface NlpSciencelitAuthor {
            firstName?: string;
            lastName?: string;
        }
        interface NlpSciencelitCitationData {
            articleId?: NlpSciencelitArticleId[];
            author?: NlpSciencelitAuthor[];
            externalLink?: string;
            fullText?: string;
            /** Reference used in text (e.g., PMC rid). */
            reference?: string;
            /** Scholar citation information from scholar index. */
            scholarCitation?: ScienceCitation;
            /** Optional information about the publication. */
            title?: string;
        }
        interface NlpSciencelitDataset {
            association?: string;
            datasetMetadata?: ResearchScienceSearchReconciledMetadata;
        }
        interface NlpSciencelitMeshHeading {
            meshDescriptor?: NlpSciencelitSubjectHeading;
            meshQualifier?: NlpSciencelitSubjectHeading[];
        }
        interface NlpSciencelitPubDate {
            dateStr?: string;
            /** "ppub" for a print ISSN and "epub" for an electronic ISSN. */
            pubType?: string;
        }
        interface NlpSciencelitPublicationType {
            /** Display name for the publication type, e.g. "Journal Article" */
            name?: string;
            /** MeSH unique identifiers for publication types, e.g. "D016428" */
            ui?: string;
        }
        interface NlpSciencelitReferencedBlock {
            /** Caption tokens - all text in the caption other than the block. */
            caption?: NlpSciencelitTokenizedText;
            /** Reference used from the text to point to this figure. */
            reference?: string;
            /** Title tokens - these come from a block within a caption. */
            title?: NlpSciencelitTokenizedText;
            /** Type of figure (table, figure, etc.). */
            type?: string;
        }
        interface NlpSciencelitRetrievalQueryEncodingDebugInfo {
            /** The query encoding sent to scam for retrieval. */
            scamQueryEncoding?: ResearchScamGenericFeatureVector;
        }
        interface NlpSciencelitRetrievalSearchResultDebugInfo {
            /** Only set if RequestOptions.debug_return_article_data is true. */
            articleData?: NlpSciencelitArticleData;
            goldDocid?: string[];
            goldSnippets?: string[];
            /** Not set by server; only used by evals. */
            isGold?: boolean;
            /** See SearchResultInternal.reranking_score. */
            rerankingScore?: number;
            /** See SearchResultInternal.reverse_reranking_order. */
            reverseRerankingOrder?: number;
            /** See SearchResultInternal.section_ir_score. */
            sectionIrScore?: { [P in string]: number };
        }
        interface NlpSciencelitRetrievalSearchResultSetDebugInfo {
            queryEncoding?: NlpSciencelitRetrievalQueryEncodingDebugInfo;
            scamResponse?: ResearchScamQueryResponse;
        }
        interface NlpSciencelitRetrievalSnippetDebugInfo {
            /** Which highlights have sentence overlap with gold snippets. Not ordered. Might only be set for the first gold highlight. */
            goldHighlightSentenceIndices?: number[];
            /** Map of highlight index to best overlap with any gold snippet [0,1]. */
            highlightIdxToOverlap?: { [P in string]: number };
            /** Map of highlight index to best overlap with any gold sentence [0,1]. */
            highlightIdxToSentenceOverlap?: { [P in string]: number };
            /** Not set by server; only used by certain evals. Might only be set for the first gold snippet. */
            isGold?: boolean;
            /** Byte index of text within the full section text (or within title). */
            offsetWithinSection?: number;
            /** Section within the document. -1 if title. */
            sectionIndex?: number;
            /** IR score of the section the snippet is coming from. */
            sectionIrScore?: number;
            /** BLEU score for the entire snippet. */
            snippetBleuScore?: number;
        }
        interface NlpSciencelitSubjectHeading {
            id?: string;
            majorTopic?: boolean;
            term?: string;
        }
        interface NlpSciencelitTokenizedText {
            text?: string;
            token?: string[];
        }
        interface NlpSemanticParsingAnnotationEvalData {
            /** Additional spans after the first. Empty in all additional_spans. */
            additionalSpans?: NlpSemanticParsingAnnotationEvalData[];
            numBytes?: number;
            numTokens?: number;
            /** Byte position within the utterance. Safe to use across different components of the NLU stack as long as said components have access to the same query. */
            startByte?: number;
            /**
             * Token position. This is cleared when normalizing examples for storage because tokenization changes over time. DO NOT use these two fields across components that use different
             * tokenizations.
             */
            startToken?: number;
        }
        interface NlpSemanticParsingAppAnnotation {
            /** The app_info is to store specific information about installed/uninstalled apps annotated by app annotator servlet. It contains app name, package name, confidence, and source. */
            appInfo?: QualityActionsAppInfo[];
        }
        interface NlpSemanticParsingDatetimeAbsoluteDateTime {
            /**
             * allow_personal determines if personal datetimes are allowed to be used in the resolution of the personal datetime. If allow_personal is false and a personal date exists, the entire
             * parse will be thrown out.
             */
            allowPersonal?: boolean;
            day?: number;
            /** Deprecated fields. Do NOT use. */
            deleted11?: string;
            /** season, quarters and holidays will be soon handled as fetched relative datetimes and will be removed from the AbsoluteDateTime message. */
            holiday?: NlpSemanticParsingDatetimeHoliday;
            /** Time is 24-hour military time. */
            hour?: number;
            /**
             * Note: This is marked as deprecated as we are moving into explicit parses using the `meridiem` field, and leave the inference over implicit parses to the grounding/resolution
             * libraries.
             */
            hourState?: string;
            /**
             * |is_bc| is true if and only the date is Before Christ/Common Era. If |is_bc| is true, only year is meaningful in this proto, as Gregorian calendar is only meaningful for A.D.
             * date/times.
             */
            isBc?: boolean;
            /**
             * For expressions such as "am", "pm". Note: the name "meridiem" has been taken by a field in message ResolutionProperties. Examples: * "9 am": point { hour: 9 meridiem: AM hour_state:
             * UNAMBIGUOUS }
             */
            meridiem?: string;
            minute?: number;
            /** For expressions such as "around 2 pm". */
            modifier?: string;
            month?: string;
            /**
             * If present then: 1) the incoming non-Gregorian datetime will be converted to Gregorian. 2) exported DateTimeProperty fields will contain the converted Gregorian datetime. 3)
             * DateTimeProperty.source_calendar will be set to the calendar-system that was used to specify the non-Gregorian date.
             */
            nonGregorianDate?: NlpSemanticParsingDatetimeNonGregorianDate;
            partialSecond?: number;
            properties?: NlpSemanticParsingDatetimeDateTimeProperty;
            quarter?: string;
            /**
             * Modifier that return the appropriate subrange. For more information, see the description of RangeOfDateTimeModifier. Example: * *early* 2020 * *early* on March 20th When a point
             * have a range_modifier field, the resolution library will expand the point into the widest range in contains. For example, in the case of a single date point like "April 22nd, 2022",
             * the point will be transformed into a range with: - "begin: April 22nd 2022 00:00:00h" - "end: April 22nd 2022 23:59:59h" The modifier will then be applied over that range.
             */
            rangeModifier?: string;
            season?: string;
            second?: number;
            /** A string representation of the timezone information, see i18n/identifiers/timezones.{h,cc}. */
            timezone?: string;
            /**
             * The |weekday| field is populated to indicate that a day-of-the-week is explicitly mentioned in an absolute date utterance, such as [Tuesday, July 6th, 2021]. Note that when a
             * day-of-the-week is included in other, non-absolute-date expressions, such as [on Tuesday], then this this field is not populated (and in fact an AbsoluteDateTime is not used at
             * all.) Note: This field is populated only when the original expression contains a day-of-the-week. It is not populated by the grounding library to indicate that the date happens to
             * be a Tuesday. Examples: * "Tuesday, July 6th 2021" --> the day of the week is part of an absolute date expression, so this field is populated: point { year: 2021 month: JULY day: 6
             * weekday: TUESDAY } * "on Tuesday" --> the day of the week is not part of an absolute date expression, so it is interpreted as a relative datetime: relative { fetched { target {
             * weekday: TUESDAY } } }
             */
            weekday?: string;
            /** Date. */
            year?: number;
        }
        interface NlpSemanticParsingDateTimeAnnotation {
            dateType?: string;
            endDate?: string[];
            endTime?: string[];
            endWeekday?: string;
            rawText?: string;
            /**
             * NOTE: None of these are co-indexed. If the query is 'morning', there could be multiple start_time's, start_date's, end_date's, and end_time's, and they do not correspond to one
             * another in any structured way.
             */
            startDate?: string[];
            startTime?: string[];
            startWeekday?: string;
            timeType?: string;
        }
        interface NlpSemanticParsingDatetimeDateTime {
            /**
             * For temporal expressions that consist of components with different types, the elements in the composition are nested according to the order they should be grounded/resolved. For
             * example, "tomorrow at 8am" has a relative component [tomorrow] and an absolute datetime component [8am] so the annotation will be represented in the following way, indicating that
             * the relative datetime for tomorrow should be grounded first, and then resolve the actual 8am point for that given date: point { hour: 8 hour_state: UNAMBIGUOUS properties {
             * time_format: AM_PM_TOKEN } } composition_element { relative { fetched { ordinal: 1 target { unit: DAY } base_type: CURRENT_DATETIME } } grounding_stage: UNGROUNDED }
             * grounding_stage: UNGROUNDED_COMPOSITION The composition_element field will be populated only when the grounding_stage is set to UNGROUNDED_COMPOSITION and it will hold the nested
             * DateTime value for the rest the compositional expression. More details in: go/datetime-resolution-decoupling.
             */
            compositionElement?: NlpSemanticParsingDatetimeDateTime;
            /** Deprecated fields. Do NOT use. */
            deleted7?: boolean;
            deleted8?: boolean;
            /**
             * This field of the DateTime message should not in general be used by outside clients of the grammar. It is intended to be used internally in Aqua for evaluation purposes. The
             * rationale is that token counts depend on the particular tokenization used in Aqua which may be different from the one used by the client and may change from time to time. Outside
             * clients should not create a dependency on the current tokenization used in Aqua.
             */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            groundingStage?: string;
            point?: NlpSemanticParsingDatetimeAbsoluteDateTime[];
            properties?: NlpSemanticParsingDatetimeResolutionProperties;
            /**
             * Note that there is a difference between this scenario and an ambiguous date/time expression. The latter is resolved to multiple proto messages, not multiple values within one proto
             * message. To be concrete, consider "Monday" in "Monday football". It is ambiguous and can be reasonably resolved to "Monday last week," "Monday this week" and "Monday next week." The
             * 3 values are represented as 3 separate DateTime messages, not 3 values within one DateTime message.
             */
            range?: NlpSemanticParsingDatetimeRange[];
            recurrent?: NlpSemanticParsingDatetimeRecurrent;
            relative?: NlpSemanticParsingDatetimeRelativeDateTime;
            /** See comments of Span. */
            span?: NlpSemanticParsingDatetimeSpan;
        }
        interface NlpSemanticParsingDatetimeDateTimeProperty {
            dateFormat?: string;
            expandYearToCurrent?: boolean;
            hourStatus?: string;
            inferredDateValue?: string;
            /** Note: this may be changed to a repeated field in the future. */
            metadata?: string;
            /** Metadata about the personal reference if the date was generated from a personal reference. */
            personalReferenceMetadata?: CopleyPersonalReferenceMetadata;
            relationToReference?: string;
            /** Expresses the relative DateTime query that gave rise to these grounded semantics. */
            relative?: NlpSemanticParsingDatetimeRelativeDateTime;
            sourceCalendar?: string;
            /** If the annotation was created by using personal data, we record the provenance for that data here. */
            sourceTypeList?: CopleySourceTypeList;
            timeFormat?: string[];
            /**
             * True iff the timezone value in AbsoluteDateTime is explicit in the annotated text or not. In the following examples the timezone is explicit: Query Timezone
             * -------------------------- -------- 10pst Pacific Standard Time 10 utc UTC 10 sydney time Australia Eastern Time
             */
            timezoneIsExplicit?: boolean;
        }
        interface NlpSemanticParsingDatetimeDuration {
            /**
             * This field of the Duration message should not in general be used by outside clients of the grammar. It is intended to be used internally in Aqua for evaluation purposes. The
             * rationale is that token counts depend on the particular tokenization used in Aqua which may be different from the one used by the client and may change from time to time. Outside
             * clients should not create a dependency on the current tokenization used in Aqua.
             */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** For expressions such as "about 2 hrs". */
            modifier?: string;
            quantity?: NlpSemanticParsingDatetimeQuantity;
            /** See comments of Span. */
            span?: NlpSemanticParsingDatetimeSpan;
        }
        interface NlpSemanticParsingDatetimeEvent {
            holiday?: string;
            moonEvent?: NlpSemanticParsingDatetimeMoonEventInfo;
            sunEvent?: string;
            type?: string;
        }
        interface NlpSemanticParsingDatetimeFetchedRelativeDateTime {
            baseType?: string;
            /** How many to fetch (e.g. [next weekend] vs. [next two weeks]) */
            count?: number;
            /** Can be used to tag relative datetime expressions with metadata information in the grammar. */
            metadata?: string;
            /** Encodes expressions like next (+1), last (-1), after next (+2), this (0). */
            ordinal?: number[];
            /**
             * The restriction range on which fetching is operated, e.g., "April" in "first Tuesday in/of April." If this field is missing, the operation is done relative to the base_type (or if
             * not given, to the query's reference datetime). When the fetching operation is performed relative to a reference time point, positive ordinal values represent upcoming instances from
             * the reference point, negative ordinal values represent previous instances from the reference point. Similarly, ordinal=0 represents a reference to the "current instance", which may
             * vary depending on the target. E.g. "this week" is simply defined as the week range that contains the current reference time point, but "this " can be ambiguous and its resolution
             * will depend on language/locale conventions ("this monday" in some languages refers to the closest upcoming instance of Monday, while in other languages it represents the Monday
             * instance within the current week).
             */
            range?: NlpSemanticParsingDatetimeRange;
            /** Modifier that return the appropriate subrange. For more information, see the description of RangeOfDateTimeModifier. Example: * *early* next week * *late* next Monday */
            rangeModifier?: string;
            /** If the underlying range comes from a relative datetime expression, encode the expression here instead. */
            relativeRange?: NlpSemanticParsingDatetimeResolutionProperties;
            /** The target to be fetched. This could be a named day-of-week or month (e.g., "Monday", "April"), or a date/time unit (e.g., "day", "week", "month"). */
            target?: NlpSemanticParsingDatetimeTargetToFetch;
        }
        interface NlpSemanticParsingDatetimeHoliday {
            /**
             * There are 3 types of holidays supported by the datetime subgrammar: 1) NonFixedHolidayEnum: e.g., "easter", "chinese new year". 2) FetchedRelativeDateTime: e.g., "Thanksgiving" =>
             * [4th Thursday of November] 3) HolidayByMonthDay: e.g., "xmas" => [December 25] Each holiday of the first type is resolved by a C++ function; the 2nd and 3rd type of holidays are
             * mapped to AbsoluteDateTime and FetchedRelativeDateTime, respectively, in grammar and are not needed to be represented in proto.
             */
            nonFixed?: string;
        }
        interface NlpSemanticParsingDatetimeMoonEventInfo {
            phase?: string;
            type?: string;
        }
        interface NlpSemanticParsingDatetimeNonGregorianDate {
            chineseMonth?: string;
            /** The day is the offset within the month, same as in Gregorian calendars. */
            day?: number;
            hebrewMonth?: string;
            islamicMonth?: string;
            /** The year is relative to the calendar (e.g. 5777 for Hebrew calendar). */
            year?: number;
        }
        interface NlpSemanticParsingDatetimeQuantity {
            /** For internal use - DateTime subgrammar users should look at Duration.modifier. = MORE in [3 more days]. */
            modifier?: string;
            /** = 3 in "3 milliseconds". */
            number?: number;
            /**
             * This field keeps the span info of the number element in a quantity expression, which is useful for downstream components to obtain the number annotations inside a quantity when
             * necessary.
             */
            numberSpan?: NlpSemanticParsingAnnotationEvalData;
            /**
             * Quantities are typically converted into milliseconds, regardless of the units the user used. Sometimes this loses crucial information, e.g., "5 days" vs "5 nights". When quantities
             * are converted to milliseconds, 'symbolic_quantity' will contain the sequence of units that the user actually supplied. This can be more than one element in cases like "one minute
             * and 30 seconds". In cases where 'symbolic_quantity' has more than one element, THERE IS NO GUARANTEED ORDER between elements.
             */
            symbolicQuantity?: NlpSemanticParsingDatetimeQuantity[];
            /** = MILLISECOND in "3 milliseconds". */
            unit?: string;
        }
        interface NlpSemanticParsingDatetimeRange {
            /** Deprecated fields. Do NOT use. */
            begin?: NlpSemanticParsingDatetimeAbsoluteDateTime;
            beginRelative?: NlpSemanticParsingDatetimeRelativeDateTime;
            /**
             * if |duration| is set, one field from start or finish must be populated, but not both. |exclusive| value is still relevant to decide if the endpoints of the range are included in the
             * range (value defined in the start/finish fields as well as the datetime value resulting of offseting the duration over the given range endpoint).
             */
            duration?: NlpSemanticParsingDatetimeQuantity;
            end?: NlpSemanticParsingDatetimeAbsoluteDateTime;
            endRelative?: NlpSemanticParsingDatetimeRelativeDateTime;
            exclusive?: boolean;
            finish?: NlpSemanticParsingDatetimeDateTime;
            fuzzyRange?: string;
            metadata?: string;
            properties?: NlpSemanticParsingDatetimeResolutionProperties;
            /** Modifier that return the appropriate subrange. For more information, see the description of RangeOfDateTimeModifier. Example: * *late* morning */
            rangeModifier?: string;
            /**
             * |start| and |finish| are inclusive unless exclusive field is true. the values in start and finish can be an absolute point, a relative or another range. Recurrences and repeated
             * values are not expected/allowed.
             */
            start?: NlpSemanticParsingDatetimeDateTime;
            /**
             * The field is set if the range is the result of resolving/grounding a relative datetime expression referring to a part of the day. E.g. "morning", "afternoon", "evening", "night",
             * "tonight", etc.
             */
            symbolicValue?: string;
        }
        interface NlpSemanticParsingDatetimeRecurrent {
            /** How many times it repeats. */
            countRestriction?: number;
            /**
             * An arbitrary exception to the recurrence. This can be an absolute point, a relative, a range or a recurrent expression. Examples: * "every Tuesday except for July 13th 2021" *
             * "every Tuesday except for July 13th and November 2nd" * "every second Monday except during the summer" * "everyday except Thursdays" * "every Friday, except from October 1st to
             * October 22nd"
             */
            exception?: NlpSemanticParsingDatetimeDateTime[];
            /**
             * |frequency| is used to represent the frequency of the recurrence over a given recurrent period. E.g. "twice a week", "once a month". An unknown frequency is represented with 0, as
             * in just "repeating".
             */
            frequency?: number;
            metadata?: string;
            /** |period| and |unit| specify how often |start_point| or |start_range| repeats. |period| should not be 0. */
            period?: number;
            rangeRestriction?: NlpSemanticParsingDatetimeRange;
            relativeRangeRestriction?: NlpSemanticParsingDatetimeRelativeDateTime;
            /**
             * A recurrent expression can be restricted by either a datetime |restriction| or |count_restriction| below. The restriction datetime can be expressed as an explicit range a relative
             * datetime expression, a datetime point or a recurrent datetime. E.g. "every monday [next month]", "every second tuesday [this year]", etc. If |period| is > 0 and |restriction| is not
             * set, repeat indefinitely. Note that this can support recurrent expressions as |restriction| as well. For example in the expression "every monday on [every other month]" where [every
             * other month] is a restriction expressed as a recurrent datetime.
             */
            restriction?: NlpSemanticParsingDatetimeDateTime;
            /**
             * |start| is used to represent the starting points, ranges or relative datetims in a recurrent expression, for example: "every morning", (range) "everyday at 5 pm", (point) "every
             * second monday" (relative) |start| should never contain a recurrent element.
             */
            start?: NlpSemanticParsingDatetimeDateTime[];
            /** DO NOT USE: deprecated fields soon to be removed. */
            startPoint?: NlpSemanticParsingDatetimeAbsoluteDateTime[];
            startRange?: NlpSemanticParsingDatetimeRange[];
            startRelative?: NlpSemanticParsingDatetimeRelativeDateTime[];
            /** The target to be fetched. This could be a named day-of-week or month (e.g., "Monday", "April"), or a date/time unit (e.g., "day", "week", "month"). */
            target?: NlpSemanticParsingDatetimeTargetToFetch;
            /**
             * |time_interval| is a time amount or duration, used to described the time interval between the instances of the recurrence. (e.g. "every 3 hours", "every 35 minutes", "every 2 months
             * and 15 days", etc)
             */
            timeInterval?: NlpSemanticParsingDatetimeQuantity;
            unit?: string;
        }
        interface NlpSemanticParsingDatetimeRelativeDateTime {
            fetched?: NlpSemanticParsingDatetimeFetchedRelativeDateTime;
            metadata?: string;
            /**
             * When a relative datetime which resolves into a range is being used as the endpoint of a range (begin_relative/end_relative), its begin/end will be taken accordingly unless this
             * modifier indicates the opposite: begin_relative with relative range and modifier == AFTER means that its end will be taken as the beginning of the resulting range. Similarly,
             * end_relative with a relative range and modifier == BEFORE means that its begin will be taken as the end of the resulting range. E.g. "after next month" will be a range with a
             * begin_relative that will take the end of "next month" as its starting point (exclusive). values other than AFTER and BEFORE in the specific conditions explained here will be ignored
             * and have no effect in the resolution of RelativeDateTimes.
             */
            modifier?: string;
            shifted?: NlpSemanticParsingDatetimeShiftedRelativeDateTime;
        }
        interface NlpSemanticParsingDatetimeResolutionProperties {
            /** Simple enum container for exporting meridiem mentions. Note: this is marked as deprecated as we are moving to properly parse expressions with explicit meridiem information. */
            meridiem?: string;
            /** Encodes whether the datetime was phrased in a specific way, see enum above. */
            metadata?: string;
            /** Expresses the relative DateTime query that gave rise to these grounded semantics. */
            relative?: NlpSemanticParsingDatetimeRelativeDateTime;
        }
        interface NlpSemanticParsingDatetimeShiftedRelativeDateTime {
            /**
             * The base could be an absolute datetime point for example: "March 1", a relative datetime point, for example: "2 days before March 1" or a symbolic base type, for example:
             * CURRENT_DATETIME. This could also be used to combine EXPLICIT_PRONOUN with the actual value of that reference being setup as a datetime point in base or relative_base
             */
            base?: NlpSemanticParsingDatetimeAbsoluteDateTime;
            baseType?: string;
            /** Can be used to tag relative datetime expressions with metadata information in the grammar. */
            metadata?: string;
            relativeBase?: NlpSemanticParsingDatetimeResolutionProperties;
            shiftAmount?: NlpSemanticParsingDatetimeQuantity;
            /** If true, shifting to the past; if false, shifting to the future. */
            shiftPast?: boolean;
        }
        interface NlpSemanticParsingDatetimeSpan {
            numBytes?: number;
            /** 0-based start byte offset of the span. */
            startByte?: number;
            /** The text of the span: a substring of ParserInput's canonical_input. */
            text?: string;
        }
        interface NlpSemanticParsingDatetimeTargetToFetch {
            event?: NlpSemanticParsingDatetimeEvent;
            fuzzyRange?: string;
            month?: string;
            quarter?: string;
            reference?: string;
            season?: string;
            /** Unnamed target: "week", "month" etc. E.g., "1st week of April". */
            unit?: string;
            /** Named target: only one of the following is expected. */
            weekday?: string[];
        }
        interface NlpSemanticParsingDatetimeTimeZone {
            timezone?: string;
        }
        interface NlpSemanticParsingEntitySourceData {
            /** Indicates backends from which parts of an entity were retrieved. */
            entitySources?: string[];
        }
        interface NlpSemanticParsingExpressionStatus {
            status?: string;
        }
        interface NlpSemanticParsingLocalAmenities {
            /** Applied amenity constraints. Nothing should be inferred about the ordering of the values in this field. */
            type?: string[];
        }
        interface NlpSemanticParsingLocalBasicLocation {
            element?: NlpSemanticParsingLocalLocationElement[];
        }
        interface NlpSemanticParsingLocalBusinessType {
            airline?: boolean;
            airport?: boolean;
            bank?: boolean;
            bikeSharingStation?: boolean;
            busStop?: boolean;
            clothingStore?: boolean;
            /**
             * If the element implies a cuisine type then we include the gcid string when available. Currently this happens for BUSINESS_CATEGORY type. The field is repeated to model categories
             * like "mandarin buffet restaurant" with multiple cuisine gcid's: mandarin_restaurant and buffet_restaurant.
             */
            cuisineGcid?: string[];
            departmentStore?: boolean;
            drugDropOff?: boolean;
            electricVehicleChargingStation?: boolean;
            electronicStore?: boolean;
            /**
             * This field is used to determine the emergency type of the element, which is specified by the grammar parse in
             * (http://cs/file:googledata/localsearch/quality/grammar/local_patterns.asciipb). e.g. "coronavirus_treatment_locations" TODO(b/151330576) Deprecate the emergency field and replace
             * with normal triggering.
             */
            emergency?: string;
            foodPantry?: boolean;
            gasStation?: boolean;
            groceryStore?: boolean;
            hairdresser?: boolean;
            hardwareStore?: boolean;
            hospital?: boolean;
            /** Also youth hostels, guest houses, etc. */
            hotel?: boolean;
            parking?: boolean;
            petStore?: boolean;
            pharmacy?: boolean;
            /**
             * This is used for transit stations annotated by QRef. The transit_station business_type above is only used for business categories, and therefore is used downstream to find nearby
             * stations rather than a particular station, and so cannot be present in a Location that is a specific station from QRef. For these cases, this business_type is used instead. e.g.
             * "grand central" "millbrae station" "union station" will have business_type qref_transit_station
             */
            qrefTransitStation?: boolean;
            /** Also bars and cafes */
            restaurant?: boolean;
            retail?: boolean;
            /** Pre-k to high school */
            school?: boolean;
            shoppingCenter?: boolean;
            soupKitchen?: boolean;
            sportStore?: boolean;
            subwayStation?: boolean;
            telecom?: boolean;
            toyStore?: boolean;
            trainStation?: boolean;
            /** A particular line in a transit system, e.g., "3 train", "Red Line", "Cirle Line", etc. */
            transitLine?: boolean;
            /** Operator of a transit line, e.g., "MTA", "BART", "CTA", etc. */
            transitOperator?: boolean;
            /**
             * The different types of transit station business types will be used to figure out which vehicle types to use when querying Tripfinder's SearchStations service. The stations in that
             * backend seem to be divided into HEAVY_RAIL, SUBWAY, and TRAM. There isn't a very reliable division between intercity rail and commuter rail -- Amtrak, LIRR, PATH, and NJ Transit are
             * all classified as HEAVY_RAIL. That's why in these types we make a distinction between train and subway, and not train and muni_rail, (unlike TransitMode in the TravelAction proto).
             */
            transitStation?: boolean;
            /** Also colleges */
            university?: boolean;
            /**
             * All of the vehicle types serviced by this business or business category. e.g. VEHICLE_TYPE_RAIL and VEHICLE_TYPE__BUS for "transit stop". This allows downstream to serve different
             * result types for transit station categories in different languages. e.g. In en-US "train station" seeks both railway station and subway station results. But the equivalent word in
             * French/Italian/German seeks only railway stations.
             */
            vehicleType?: string[];
            /** Stadiums, theaters, cinemas, etc. */
            venue?: boolean;
        }
        interface NlpSemanticParsingLocalChainMemberConstraint {
            /** Specifies which parent chain mids to filter by. */
            chainIds?: string[];
        }
        interface NlpSemanticParsingLocalCompoundLocation {
            joiner?: NlpSemanticParsingLocalJoiner;
            location1?: NlpSemanticParsingLocalLocation;
            /**
             * If location_2 is absent, it should likely be interpreted as an implicit "here". For example, "nearest Starbucks" will be represented as a compound location with "Starbucks" as
             * location_1, "nearest" as the joiner, and empty location_2.
             */
            location2?: NlpSemanticParsingLocalLocation;
        }
        interface NlpSemanticParsingLocalContactLocation {
            /** Contact as a location. */
            contact?: NlpSemanticParsingModelsCommunicationRecipient;
            /** The type of contact address (home, work, etc). */
            contactType?: NlpSemanticParsingModelsCommunicationPhoneType;
        }
        interface NlpSemanticParsingLocalCuisineConstraint {
            cuisineGcid?: string;
        }
        interface NlpSemanticParsingLocalEvChargingStationSpeedConstraint {
            chargingSpeed?: string;
        }
        interface NlpSemanticParsingLocalExtent {
            /** True for values like "a few". */
            nonSpecificValue?: boolean;
            units?: string;
            /** String representation, e.g., for debug. */
            unitsString?: string;
            /**
             * For approximate values such as "a few" or "several", we populate |value| with a specific numeric value which is a generous (i.e., high) interpretation of the text, and we set
             * |non_specific_value| to true.
             */
            value?: number;
            /** Can hold numbers as well as "a few". */
            valueString?: string;
        }
        interface NlpSemanticParsingLocalGcidConstraint {
            /** GCID - with the 'gcid:' prefix. */
            gcid?: string;
        }
        interface NlpSemanticParsingLocalHealthInsuranceConstraint {
            network?: string;
        }
        interface NlpSemanticParsingLocalHotelType {
            /** Basic accommodation types variations. */
            allInclusiveResort?: boolean;
            beachResort?: boolean;
            bedAndBreakfast?: boolean;
            boutiqueHotel?: boolean;
            businessHotel?: boolean;
            /** Other accommodation types. */
            cabin?: boolean;
            campsite?: boolean;
            capsuleHotel?: boolean;
            casinoAccommodation?: boolean;
            castleHotel?: boolean;
            chalet?: boolean;
            commonLodgingHouse?: boolean;
            condoHotel?: boolean;
            conventionHotel?: boolean;
            cottage?: boolean;
            ecoHotel?: boolean;
            extendedStayHotel?: boolean;
            farmstay?: boolean;
            gite?: boolean;
            golfResort?: boolean;
            guesthouse?: boolean;
            guestRanch?: boolean;
            hostel?: boolean;
            /** Basic accommodation types. */
            hotel?: boolean;
            houseboat?: boolean;
            inn?: boolean;
            /** Japanese accommodation types. */
            japaneseInn?: boolean;
            japaneseInnWithHotSpring?: boolean;
            lodge?: boolean;
            lodging?: boolean;
            loveHotel?: boolean;
            motel?: boolean;
            mountainHut?: boolean;
            /** Any other lodging related type. */
            other?: boolean;
            pension?: boolean;
            resort?: boolean;
            safariLodge?: boolean;
            seasideResort?: boolean;
            servicedApartment?: boolean;
            skiResort?: boolean;
            suite?: boolean;
            vacationApartment?: boolean;
            vacationHouse?: boolean;
            /** Vacation rental accommodation types. */
            vacationRental?: boolean;
            villa?: boolean;
            wellnessAndSpaAccommodation?: boolean;
            youthHostel?: boolean;
        }
        interface NlpSemanticParsingLocalHyperReliableData {
            /**
             * Whether a location is a commodity (distance is an important metric), neutral or non-commodity (distance is not important). Commodity locations are "atm", "gas station", etc.
             * Non-commodity locations are "restaurant", "hotel", etc, and all others are neutral. The value is 1 for commodity queries, 0 for non-commodity queries, no-value for neutral queries
             * (when the field doesn't exist in the grammar). The reason it is a float is to prepare for future changes when we expand the signal value from discrete classes to a score, and the
             * score will be in the range of [0,1].
             */
            commodityStrength?: number;
            gcidsynsOverride?: NlpSemanticParsingLocalHyperReliableDataGCIDSynsOverride[];
            hyperReliable?: boolean;
            /** Categories used for retrieval and used in Artemis diversity tiers as restricts. See https://ariane.googleplex.com/launch/190585 for details. */
            retrievalGcids?: string[];
        }
        interface NlpSemanticParsingLocalHyperReliableDataGCIDSynsOverride {
            gcidScore?: number;
            hyperReliableGcid?: string;
        }
        interface NlpSemanticParsingLocalImplicitLocalCategory {
            airport?: boolean;
            bank?: boolean;
            chargingStation?: boolean;
            gasStation?: boolean;
            gym?: boolean;
            hairSalon?: boolean;
            hospital?: boolean;
            hotel?: boolean;
            laundromat?: boolean;
            movieTheater?: boolean;
            postOffice?: boolean;
            spa?: boolean;
        }
        interface NlpSemanticParsingLocalJoiner {
            numBytes?: number;
            numBytesForConversion?: number;
            /** The raw input span corresponding to this joiner. */
            startByte?: number;
            /** Byte data added for conversion between this proto and IntentQuery in LooseParser. Must not be used for downstream triggering. */
            startByteForConversion?: number;
            /** The original joiner string from the tokenized query. Particularly important if the type is OTHER. */
            text?: string;
            type?: string;
        }
        interface NlpSemanticParsingLocalLocalResultId {
            featureId?: GeostoreFeatureIdProto;
            /** The full address of the result. This should be a verbose address string that geocodes reliably. */
            geocodingAddress?: string;
            /** The knowledge graph reference of the result. */
            kgMid?: string;
            /** The position of the result. */
            position?: GeostorePointProto;
            /** The position of the result, if it can't be expressed as a pointproto. */
            rect?: GeostoreRectProto;
        }
        interface NlpSemanticParsingLocalLocation {
            /** Exactly one of the location types should be populated. */
            basicLocation?: NlpSemanticParsingLocalBasicLocation;
            compoundLocation?: NlpSemanticParsingLocalCompoundLocation;
            /** DEPRECATED. Instead, use LocationElement.contact_location. */
            contactLocation?: NlpSemanticParsingLocalContactLocation;
            /** True if the location is merged, for example by CombineLocationsFn. */
            isMerged?: boolean;
            /**
             * The constraint includes various constraints on the location such as amenities, price range, ratings, or attributes such as new, cheap, etc. These constraints are a part of the
             * location but are not modeled as location elements and are not included in the location text. The (debatable) motivation is that they do not stand on their own and are not an
             * intrinsic part of the location. Note on texts and spans. For a location such as "kid friendly hotels with an indoor pool" we expect to get a basic location with a single location
             * element and two constraints: - For the location element: - Both text and span match "hotels" - For the first constraint: - Both text and span match "kid friendly" - For the second
             * constraint: - Both text and span match "indoor pool" - For the full location: - text: "hotels" - span covers "kid friendly hotels with an indoor pool"
             */
            locationConstraint?: NlpSemanticParsingLocalLocationConstraint[];
            numBytes?: number;
            /**
             * A LocalResult corresponding to the location the user specified, populated by local dialog (generally following a search). This field will only be set if the location is unambiguous,
             * possibly following a series of disambiguation turns of dialog.
             */
            resolvedLocalResult?: QualityDialogManagerLocalResult;
            /**
             * The span, in the raw input, which corresponds to this location, expressed as a byte offset and byte size. This allows the extraction of the location string as it appears in the raw
             * text.
             */
            startByte?: number;
            /**
             * A string representation of the location. Depending on the annotators and the location itself the string may represent the raw query, the pre-processed query, or something else. As a
             * non-trivial example, for [target address mountain view] we will generate the text "target mountain view" without "address". We make a best-effort to come up with a good string, but
             * make no formal guarantees. You should never present this text directly to outside users.
             */
            text?: string;
            /** A location info including featureId and lat/lng that uniquely identifies the location the user specified. */
            userSpecifiedLocation?: KnowledgeVerticalsWeatherProtoUserSpecifiedLocation;
            vicinityLocation?: NlpSemanticParsingLocalVicinityLocation;
        }
        interface NlpSemanticParsingLocalLocationConstraint {
            /** LINT.IfChange */
            amenities?: NlpSemanticParsingLocalAmenities;
            chainMember?: NlpSemanticParsingLocalChainMemberConstraint;
            cuisine?: NlpSemanticParsingLocalCuisineConstraint;
            evcsSpeedConstraint?: NlpSemanticParsingLocalEvChargingStationSpeedConstraint;
            /** Used for GCID filter. Unlike other grammar, for now this is populated in Superroot (currently based on QBLD classification, and an allowlist of GCID). */
            gcidConstraint?: NlpSemanticParsingLocalGcidConstraint;
            /** Used for health insurance filter populator. */
            healthInsurance?: NlpSemanticParsingLocalHealthInsuranceConstraint;
            /** Some constraints are also hyper-reliable, such as [brunch] and [coffee]. */
            hyperReliableData?: NlpSemanticParsingLocalHyperReliableData;
            menuItem?: NlpSemanticParsingLocalMenuItem;
            new?: boolean;
            numBytes?: number;
            open24Hours?: boolean;
            price?: NlpSemanticParsingLocalPriceConstraint;
            quality?: NlpSemanticParsingLocalQualityConstraint;
            rooms?: NlpSemanticParsingLocalRoomConstraint;
            scalableAttribute?: NlpSemanticParsingLocalScalableAttribute;
            service?: NlpSemanticParsingLocalServiceConstraint;
            /** The span, in the raw input, which corresponds to this constraint, expressed as a byte offset and byte size. */
            startByte?: number;
            text?: string;
            /** Experimental, may change. */
            ungroundedConstraint?: boolean;
            /** Used to remove all constraints, e.g. [forget all the filters] */
            unspecified?: boolean;
            /** Used for vaccine refinement: go/covid-vaccine-refinement. */
            vaccineType?: string;
            visitHistory?: NlpSemanticParsingLocalVisitHistoryConstraint;
        }
        interface NlpSemanticParsingLocalLocationElement {
            /** For elements with a NICKNAME alias location, this field will hold all matching alias icons, which are used in search to resolve the location. */
            aliasIcon?: PersonalizationMapsAliasIcon[];
            /** The following fields (alias_location, qref_location, and saft_location) should have at most one non-empty value between them. */
            aliasLocation?: string;
            /** Set only when type is BUSINESS_NAME or BUSINESS_CATEGORY. */
            businessType?: NlpSemanticParsingLocalBusinessType;
            contactLocation?: NlpSemanticParsingLocalContactLocation;
            /**
             * This will hold semantics from the dialog_referents subgrammar with offsets and indices relating to a list of results shown to the user. This field is repeated while in the future we
             * could support multiple item list selection. i.e. [the starbucks] where multiple entries in the results will be indicated here
             */
            dialogReferents?: NlpSemanticParsingModelsDialogReferentsDialogReferents[];
            /** Set only when type is DIRECTIONAL_MODIFIER. */
            directionalModifier?: string;
            /**
             * DEPRECATED. See basic_location.element.type == LOCATION_REFERENT to determine this instead. Populated by a type VISITED local action, this field is used to indicate a location
             * element is a general-case $PT_visited_location string.
             */
            genericLocation?: boolean;
            /** Set only when business_type is hotel. */
            hotelType?: NlpSemanticParsingLocalHotelType;
            hyperReliableData?: NlpSemanticParsingLocalHyperReliableData;
            implicitLocalCategory?: NlpSemanticParsingLocalImplicitLocalCategory;
            /**
             * A field used to store the ID of a specific location entity, especially one not extracted via QRef. For example, - a location selected by the users via a dialog follow-up query like
             * [the second one]. Will only be populated in the LocalSemanticsServlet, not in the grammar. - a location resolved based on a full search, e.g., following the geocoding step for a
             * directions query. This field is also used by NoramlizeLocationForFingerprinting as the canonical place to store FeatureIds.
             */
            localResultId?: NlpSemanticParsingLocalLocalResultId;
            /**
             * Represents zip codes, street numbers, etc. that were detected directly by the grammar (and not, e.g., by QRef). DEPRECATED. We ran into problems with zip codes having leading
             * zeroes. Now we store numbers only in the text field.
             */
            number?: number;
            numBytes?: number;
            /** A collection of QRefAnnotations repesenting Reference and Resolution data for Personal References. See go/copley-local and go/copley-annotator. */
            personalReferenceLocation?: NlpSemanticParsingPersonalReferenceAnnotation;
            qrefLocation?: NlpSemanticParsingQRefAnnotation;
            saftLocation?: NlpSemanticParsingSaftMentionAnnotation;
            source?: string;
            /** The byte span, in the raw query, which corresponds to this location element. */
            startByte?: number;
            /**
             * A string representation of the location element. Typical, this field will be populated by the MakeLocationElementFn semantic function with the substring of the raw_query defined by
             * start_byte and num_bytes. However, the field can also be populated explicitly in the grammar, in which case MakeLocationElementFn leaves it alone.
             */
            text?: string;
            /**
             * Train number associated with /collection/geo/transit_line. Populated when user requests specific instance of a transit line. For example, long distance trains in India have two
             * numbers for each train, one for up direction and other for down. And user use these numbers in queries along with name to specify the specific trip of the train. More details in
             * go/number-transit-line-queries.
             */
            transitLineNumber?: string;
            type?: string;
        }
        interface NlpSemanticParsingLocalMenuItem {
            /** This ID corresponds to the name of the menu item in the query. For example [restaurants that serve thai curry] has menu_item_id = "thai curry". */
            menuItemId?: string;
        }
        interface NlpSemanticParsingLocalPriceConstraint {
            cheap?: boolean;
            /** The currency codes are expected to be string from the list in i18n/identifiers/currencycode.* */
            currencyCode?: string;
            expensive?: boolean;
            maxPrice?: number;
            minPrice?: number;
            moderatelyPriced?: boolean;
            /**
             * The user mentioned something about price, but didn't mention a specific constraint. This is used to indicate an intent to remove all price constraints, in queries like [forget the
             * price].
             */
            unspecified?: boolean;
        }
        interface NlpSemanticParsingLocalQualityConstraint {
            best?: boolean;
            highlyRated?: boolean;
            stars?: NlpSemanticParsingLocalStarRatings;
            starType?: string;
            /**
             * The user mentioned something about quality, but didn't mention a specific constraint. This is used to indicate an intent to remove all quality constraints, in queries like [forget
             * the rating].
             */
            unspecified?: boolean;
        }
        interface NlpSemanticParsingLocalRoomConstraint {
            /** It is possible to have fractional bathrooms. */
            minNumBathrooms?: number;
            minNumBedrooms?: number;
        }
        interface NlpSemanticParsingLocalScalableAttribute {
            attributeId?: string;
        }
        interface NlpSemanticParsingLocalServiceConstraint {
            serviceType?: string;
        }
        interface NlpSemanticParsingLocalStarRatings {
            five?: boolean;
            four?: boolean;
            fourAndAHalf?: boolean;
            one?: boolean;
            oneAndAHalf?: boolean;
            orFewer?: boolean;
            /** If this field is set, exactly one of the star classes above should be set, and the interpretation should be that at least that many stars should be present. */
            orMore?: boolean;
            three?: boolean;
            threeAndAHalf?: boolean;
            two?: boolean;
            twoAndAHalf?: boolean;
            unspecified?: boolean;
        }
        interface NlpSemanticParsingLocalVicinityLocation {
            /** If the base is missing then clients should assume that it implicitly means "here". E.g., "within five miles" really means "within five miles from here" */
            base?: NlpSemanticParsingLocalLocation;
            /** The text between the extent and the base, e.g., for "50 miles from here" the connector is "from". */
            connector?: string;
            extent?: NlpSemanticParsingLocalExtent;
        }
        interface NlpSemanticParsingLocalVisitHistoryConstraint {
            visitedType?: string;
        }
        interface NlpSemanticParsingModelsCommunicationPhoneType {
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** Whether the annotation is from $Text. */
            isAnnotatedFromText?: boolean;
            /** Normalized (canonicalized) text, e.g. "mobile". */
            normalizedText?: string;
            /** Original text in query, e.g. "cell". */
            originalText?: string;
            /** DEPRECATED. Used original_text instead. */
            rawText?: string;
        }
        interface NlpSemanticParsingModelsCommunicationRecipient {
            calendarEvent?: AssistantApiCoreTypesCalendarEvent;
            calendarEventWrapper?: any;
            /** Contact details (e.g. gaia_id, phone, etc). Replaces 'focus_name' above. */
            contact?: NlpSemanticParsingModelsPersonPerson;
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            isAnnotatedFromText?: boolean;
            /** Deprecated in favor of recipient.contact.name_annotation_source. */
            nameAnnotationSource?: string;
            numberAnnotationSource?: string;
            /**
             * NOTE: for CONTACT recipient, this is *NOT* the real raw text of the recipient span of historical reasons. Major differences includes: - stripping possessive suffix, e.g. "John's" ->
             * "John" - stripping prefix/suffix/title, e.g. "Mr. John" -> "John" - uninflect name for languages like Russian, e.g. "Андрею" -> "Андрей" Currently this is the same as .contact.name,
             * and is used as the string shown to the user on clientside UI. If you're looking for real raw text, use .contact.raw_text
             */
            rawText?: string;
            recipientType?: string;
            /** A reference to a person by relationship name. eg. my father. */
            relationship?: NlpSemanticParsingModelsCommunicationRelationshipArgument;
            sensitiveNumBytes?: number;
            /** The beginning and end of the recipient name that should be removed before logging. */
            sensitiveStartByte?: number;
        }
        interface NlpSemanticParsingModelsCommunicationRelationshipArgument {
            /** The alias of the relationship in the query, e.g. "mom". */
            alias?: string;
            /** The canonical format of the relationship, e.g. "Mother". */
            canonical?: string;
            /**
             * Mid for an entity that has lexical data (a LexiconEntry). See https://g3doc.corp.google.com/nlp/generation/g3doc/lexical_data.md for for more information about lexical data. This is
             * the canonical mid for this entity (eg. it would be /m/0lbxz for "mother" in EN even if user referred to "mom").
             */
            canonicalLexicalMid?: string;
        }
        interface NlpSemanticParsingModelsDevice {
            /** The name of the device (Nexus 5, Nexus 10, etc). */
            deviceName?: NlpSemanticParsingModelsDeviceName;
            /** The type of the device (phone, tablet, watch, etc). */
            deviceType?: string;
        }
        interface NlpSemanticParsingModelsDeviceName {
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            rawText?: string;
        }
        interface NlpSemanticParsingModelsDialogReferentsDialogReferents {
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** The field mentioned in the user's utterance, if any. */
            field?: NlpSemanticParsingModelsDialogReferentsListSelection;
            /** Used for a grammar mention of an index. */
            index?: number;
            /** Represents a tied referent in a different field of the same label */
            next?: NlpSemanticParsingModelsDialogReferentsDialogReferents;
            /** The requested value(s) for selection from a list of alternatives. */
            selection?: NlpSemanticParsingModelsDialogReferentsListSelection[];
            /**
             * Set when the user's utterance refers to the (an) overall task/goal of the dialog (e.g. "the meeting starts at 10 am" mentions the goal, "meeting"). The field is repeated in case the
             * user ambiguously identifies a task (two tasks named 'meeting').
             */
            taskMention?: NlpSemanticParsingModelsDialogReferentsListSelection[];
        }
        interface NlpSemanticParsingModelsDialogReferentsListSelection {
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** A unique identifier that is the canonical value for the chosen list item. If we are selecting among fields, this is the field_id specified in the corresponding DialogField. */
            id?: string;
            /** If true, semantic function should look at watch actions in the following display entity if the first one is not playable. This is useful for "Play it" on entity page. */
            looseOffsetRestriction?: boolean;
            /**
             * The offset within the list, if know. If the list of values wasn't known (e.g. from the discourse context) then the offset is a zero-based mapping of the ordinal value of the
             * selection ("first one" maps to zero; "last one" to minus one).
             */
            offset?: number;
            /**
             * When the user selects a list value by name then this is the matched text from the utterance. Note that, if the list of values is known, then the aqua annotator should have mapped it
             * to an offset.
             */
            rawText?: string;
        }
        interface NlpSemanticParsingModelsMediaAlbumTitle {
            /** Annotations from custom media annotator. */
            annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** If true, indicates the user wants their favorite album. Like [play my favorite album my Eminem] */
            favorite?: boolean;
            /** If true, indicates the user wants the first album. Like [play adele's first album] */
            first?: boolean;
            /** Is annotated by Nimble for the media Fast Path. */
            isFromFastPath?: boolean;
            /** If true, indicates the user wants the latest album. Like, [play adele's latest album] */
            latest?: boolean;
            /** More from this album. */
            playMore?: boolean;
            qref?: NlpSemanticParsingQRefAnnotation;
            /** Required, corresponds to the raw text, like "The White Album." */
            rawText?: string;
        }
        interface NlpSemanticParsingModelsMediaAudio {
            album?: NlpSemanticParsingModelsMediaAlbumTitle;
            artist?: NlpSemanticParsingModelsMediaMusicArtist;
            /** Like an audio book. "Listen to (moby dick) audiobook" */
            book?: NlpSemanticParsingModelsMediaBook;
            /** A date time constraint for audio entity, for example, "jazz station 1980". */
            dateTime?: NlpSemanticParsingDatetimeDateTime;
            /** Constraining the query to some detail about the episode. Example: "listen to episode (13) of this american life with (mike birbiglia)" would have the 2 constraints in parens. */
            episodeConstraint?: NlpSemanticParsingModelsMediaEpisodeConstraint[];
            /**
             * Soundtrack or theme song (see score_type param that indicates whether the user refers to a soundtrack or a theme song) of the game. "Play soundtrack from (Deus Ex Human
             * Revolution)".
             */
            game?: NlpSemanticParsingModelsMediaGame;
            genericMusic?: NlpSemanticParsingModelsMediaGenericMusic;
            genre?: NlpSemanticParsingModelsMediaMusicGenre;
            /** Soundtrack or theme song (see score_type param that indicates whether the user refers to a soundtrack or a theme song) of the movie. E.g. "Play (Let It Go) from (Disney's Frozen)" */
            movie?: NlpSemanticParsingModelsMediaMovie;
            /** News topic. "Listen to news about (Ukraine)" */
            newsTopic?: NlpSemanticParsingModelsMediaNewsTopic;
            /** True when the query does not contains an explict audio name. E.g. When user says "play" or "listen to". */
            noExplicitAudio?: boolean;
            playlist?: NlpSemanticParsingModelsMediaMusicPlaylist;
            /** Podcast feeds. "Listen to (This American Life)" */
            podcast?: NlpSemanticParsingModelsMediaPodcast;
            radio?: NlpSemanticParsingModelsMediaRadio;
            /** E.g. "play NPR radio", "Play BBC radio". */
            radioNetwork?: NlpSemanticParsingModelsMediaRadioNetwork;
            /**
             * The query for backends to use in search. e.g. for an user query of "play kids song video on tv" from assistant, this field would be "kids song". Note: there is no guarantee this
             * field is populated; when it is not, backends should fall back to "raw_text" fields in song, artist, album etc.
             */
            rawText?: string;
            /**
             * If any of movie, game or tv show fields is populated this field indicates specific score type requested in the query. E.g. for [play soundtrack from frozen] this field is
             * SOUNDTRACK, for [play frozen song] this field is THEME_SONG.
             */
            scoreType?: string;
            /** Constraining the query to some detail about the season. Example: "listen to season 2 of serial" */
            seasonConstraint?: NlpSemanticParsingModelsMediaSeasonConstraint;
            song?: NlpSemanticParsingModelsMediaSong;
            /**
             * Optional tags associated with how the media entity should be played. For example, this can be set to SEED_RADIO to signify that the user wants to play a radio station seeded by the
             * entity.
             */
            tag?: string[];
            /** Soundtrack or theme song (see score_type param that indicates whether the user refers to a soundtrack or a theme song) of the tv show. E.g. "Play soundtrack from (Friends)". */
            tvShow?: NlpSemanticParsingModelsMediaTVShow;
        }
        interface NlpSemanticParsingModelsMediaAudiobookInfo {
            /** The MID of the audiobook entity (/book/book_edition). */
            audiobookMid?: string;
            authors?: string[];
            /** The MID of the book entity (/book/book) which this audiobook is associated with. */
            bookMid?: string;
            narrators?: string[];
        }
        interface NlpSemanticParsingModelsMediaBook {
            /** Annotations from custom media annotator. */
            annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** Annotation comes from a text annotator. Needed to boost recall. Typically need to be verified in superroot, and have separate scoring. */
            isAnnotatedFromText?: boolean;
            /** If true, indicates the user wants the latest book. Like, [play Dan Brown's latest book] */
            latest?: boolean;
            qref?: NlpSemanticParsingQRefAnnotation;
            /** Required, corresponds to the raw text, like "East of Eden" */
            rawText?: string;
        }
        interface NlpSemanticParsingModelsMediaCastDeviceAnnotation {
            castDeviceSource?: string;
            /** This field is populated when the user says [play X on $cast_device] and we know the type of $cast_device but cannot identify the exact device. */
            castDeviceType?: string;
            /** The timestamp that the device is linked with the user in milliseconds. This is inherited from the corresponding assistant DeviceSettings as is. */
            creationTimestampMs?: string;
            /** DEPRECATED: Please use device_identifier instead. */
            deviceId?: string;
            /**
             * The identification of the device. This field is populated when the user says [play X on $device_name] and $device_name matches one of the devices linked to user's account. } oneof
             * Media Device
             */
            deviceIdentifier?: AssistantApiCoreTypesDeviceId;
            name?: string;
            /** This field is populated when the user metioned quantification in the query. E.g., "2" or "all". */
            quantification?: NlpSemanticParsingModelsMediaQuantification;
        }
        interface NlpSemanticParsingModelsMediaCost {
            /** Contains the standard code for the given type of currency. The value must represent a valid i18n_identifiers::CurrencyCode. */
            currencyCode?: string;
            /** Contains the price in a particular currency. */
            price?: number;
        }
        interface NlpSemanticParsingModelsMediaDeeplinkInfo {
            /**
             * The type of the deeplink. Sometimes the deeplink is not only used for playing media, but also used for other actions. For example, the deeplink could be for playing a movie trailer
             * from YouTube or recording a movie from YouTube TV.
             */
            actionType?: string;
            /**
             * The upper-case, III country code, e.g., "US", in which the deeplink cannot play. For possible values, see: google3/i18n/identifiers/regioncode.h
             * google3/java/com/google/i18n/identifiers/RegionCode.java For details on converting to and from ISO country codes, see http://iii-howto#GettingCanonRegionCodes.
             */
            blacklistedCountry?: string[];
            /**
             * The upper-case, III country code, e.g., "US", in which the deeplink can play. If unset or has "earth" (b/72566951), means the deeplink can be used world-wide except in
             * |blacklisted_country| list. For possible values, see: google3/i18n/identifiers/regioncode.h google3/java/com/google/i18n/identifiers/RegionCode.java For details on converting to and
             * from ISO country codes, see http://iii-howto#GettingCanonRegionCodes.
             */
            country?: string[];
            /** Deeplink to the media. This deeplink is meant to be send to the provider app on available platforms without any modifications. Required. */
            deeplink?: string;
            /**
             * Some providers give us an opaque, unstable deeplink to use at execution-time. E.g. see http://go/collab-ranking-nl-uri#heading=h.ndmdfw388tk3 Such a deeplink is not useful for
             * logging, caching, comparing to other candidate deeplinks, etc. So most fulfillment code will want the traditional, stable deeplink that can be interpreted, parsed, cached, etc
             * (found in the "deeplink" field, above). But this opaque, unstable deeplink (if non-empty) must be included in the music initiation clientop.
             */
            deeplinkForExecution?: string;
            /**
             * Indicate whether the deeplink is compatible with credentials. If true, CCS will not send the credentials to cast app. Currently this field is only used for voice-follow on cases on
             * smart displays.
             */
            incompatibleWithCredentials?: boolean;
            /**
             * List of offers that allow user to access the deeplink, that is if the list contains PREMIUM_SUBSCRIPTION and BASIC_SUBSCRIPTION users that have either premium or basic subscription
             * can use the deeplink. If the list is empty it means that there are no subscription restrictions.
             */
            offer?: string[];
            /**
             * This field is only used when "offer" includes a PAY_PER_USE. When "offer" includes a PAY_PER_USE, paid_offer_detail will contain offers for BUY and RENT offer_types with associated
             * cost info.
             */
            paidOfferDetail?: NlpSemanticParsingModelsMediaPaidOfferDetail[];
            /** List of platforms that support the deeplink. If the list is empty it means that there are no platform restrictions. */
            platform?: string[];
            /**
             * Document scores which are used for ranking action links. Document scores might come from CDOC in Raffia or other indexing systems. For example, for web pages, the score shows how
             * likely the web page (composite doc) which generated this link refers to the given entity or how close a particular entity is with the given composite doc. For the larger design,
             * please see go/ma_dedup. For PACIFIC_COLLAB_RANKING deeplink, the score is the normalized confidence score returned by partner for fulfillment candidate. For pivot candidates, the
             * score is calculated with the index of the alternative results.
             */
            score?: number;
            /**
             * Name of subscription packages which are granted access to this deeplink. This is to match exactly the end users authentication system. This is to be used if the offer is
             * BASIC_SUBSCRIPTION or PREMIUM_SUBSCRIPTION. There can be multiple packages -- the user needs only to authenticate with a single package. For more information please see:
             * go/subscription-package
             */
            subscriptionPackageName?: string[];
            /**
             * Tags associated with the content played by this deeplink. In the common case, the deeplink is supposed to specify a music entity within the provider's inventory, and the provider
             * app should decide the actual content based on the user's account profile (e.g., for a deeplink to an artist, playing tracks from the artist or similar artists, and for a song,
             * playing the official album recording of the song). But in some cases, the deeplink belong to special content. For example, for an artist a seed radio based on the artist, and a live
             * or karaoke version of a song. We use this field to mark such special content types.
             */
            tag?: string[];
            /** A time window in which the deeplink is valid. If not set, the deeplink is considered valid. */
            validTimeWindow?: NlpSemanticParsingModelsMediaDeeplinkInfoTimeWindow;
            /** DEPRECATED: This field is ignored by understanding and fulfillment. */
            vuiId?: string;
            /** Additional info specific to YouTube Deeplink (if applicable). */
            youtubeDeeplinkInfo?: NlpSemanticParsingModelsMediaYouTubeDeeplinkInfo;
        }
        interface NlpSemanticParsingModelsMediaDeeplinkInfoTimeWindow {
            /** Time in seconds since epoch. */
            endTimestamp?: string;
            /** Time in seconds since epoch. */
            startTimestamp?: string;
        }
        interface NlpSemanticParsingModelsMediaDescription {
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            rawText?: string;
        }
        interface NlpSemanticParsingModelsMediaEpisodeConstraint {
            /**
             * The absolute index of the episode. 1 is the first element and -1 is the last element in the sequence, -2 is the second-to-last element, and so on. Examples: "first episode" => 1
             * "3rd episode" => 3 "last episode" => -1
             */
            absoluteIndex?: number;
            /**
             * Date/time of the message. This could be an absolute date/time (e.g. find my message from monday) or a date/time range (e.g. find my message in the past four hours). This constrains
             * *when* the episode came out.
             */
            dateTime?: NlpSemanticParsingDatetimeDateTime;
            /** A description of the episode. Example: For the query: [listen to this american life about cars] the description would be "cars" */
            description?: NlpSemanticParsingModelsMediaDescription;
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            rawText?: string;
            /** The relative index of the episode. Examples: "previous episode" => -1 "current episode" => 0 "next episode" => 1 */
            relativeIndex?: number;
        }
        interface NlpSemanticParsingModelsMediaFrequency {
            /** The broadcast band used by the radio station. */
            band?: string;
            /** Frequency in MHz (for FM) and KHz (for AM). */
            value?: number;
        }
        interface NlpSemanticParsingModelsMediaGame {
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** Annotation comes from a text annotator. Needed to boost recall. Typically need to be verified in superroot, and have separate scoring. */
            isAnnotatedFromText?: boolean;
            qref?: NlpSemanticParsingQRefAnnotation;
            /** Required, corresponds to the raw text, like "Deus Ex Human Revolution" */
            rawText?: string;
        }
        interface NlpSemanticParsingModelsMediaGenericMusic {
            /** Annotations from custom media annotator. Deprecated - generic music deeplinks should be added to the Provider config, not to the grammar. */
            annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** New music. */
            newMusic?: boolean;
            /** Required, corresponds to the raw text, like "my tracks" */
            rawText?: string;
            type?: string;
        }
        interface NlpSemanticParsingModelsMediaLatLng {
            /** The latitude in degrees. It must be in the range [-90.0, +90.0]. */
            latitude?: number;
            /** The longitude in degrees. It must be in the range [-180.0, +180.0]. */
            longitude?: number;
        }
        interface NlpSemanticParsingModelsMediaMediaAnnotation {
            /** Name of the artist (if applicable). Used for songs and albums. */
            artistName?: string;
            /** Additional info specific to an audiobook (if applicable). */
            audiobookInfo?: NlpSemanticParsingModelsMediaAudiobookInfo;
            /**
             * Type of the media content. This field is not always populated, but only when this annotation is used to represent an individual media item, e.g., when it is the value of an intent
             * argument storing a media object to play.
             */
            contentType?: string;
            /** Images of the media. */
            image?: AssistantApiCoreTypesImage[];
            /** Name of the media. Required. */
            name?: string;
            /** Additional info specific to a news audio/video stream (if applicable). */
            newsInfo?: NlpSemanticParsingModelsMediaNewsInfo;
            /** The personal ingestion engine. */
            personalDataIngestionEngine?: string;
            /** Visibility setting of the retrieved playlist. */
            playlistVisibility?: string;
            /** Additional info specific to podcast stream (if applicable). */
            podcastInfo?: NlpSemanticParsingModelsMediaPodcastInfo;
            primaryEntityMid?: string;
            /** List of providers and their deeplinks. */
            providerInfo?: NlpSemanticParsingModelsMediaMediaProviderInfo[];
            /** Purchase info for purchased or preordered movies, episodes, seasons, tv shows. */
            purchaseInfo?: NlpSemanticParsingModelsMediaPurchaseInfo;
            /** Only one of these fields should be set depending on the type of the content. oneof content_specific_info { Additional info specific to a radio station (if applicable). */
            radioInfo?: NlpSemanticParsingModelsMediaRadioInfo;
            /** Rental info for rented movies. */
            rentalInfo?: NlpSemanticParsingModelsMediaRentalInfo;
            source?: string;
            /** Additional info specific to YouTube playlist (if applicable). */
            youtubePlaylistInfo?: NlpSemanticParsingModelsMediaYouTubePlaylistInfo;
        }
        interface NlpSemanticParsingModelsMediaMediaAnnotationList {
            annotation?: NlpSemanticParsingModelsMediaMediaAnnotation[];
        }
        interface NlpSemanticParsingModelsMediaMediaProviderInfo {
            /** Deeplinks provided by the provider. If empty it indicates that the media is unavailable with the provider, e.g. due to country restrictions or limited catalog. */
            deeplinkInfo?: NlpSemanticParsingModelsMediaDeeplinkInfo[];
            /**
             * The unique and reverse unique provider enumerator in KG (e.g., "ORANGE_SPAIN" for /g/11h6nkfyrm). It is more stable than the KG mid. See go/kema-api#keys. Some mids cannot have the
             * enumerator property due to historical reason (e.g., multiple media providers were created for iTunes and only ""/g/11fhyxjwt5" has provider enumerator as "ITUNES_NEW" in KG). These
             * entities need to have hard-coded key (e.g., "/m/019g58" has key "ITUNES") kept outside of KG.
             */
            kgProviderKey?: string;
            /** Media ID of a MediaItem in a MediaBrowseTree (MBT). This field is used to play a specific media item from MBT using playFromMediaId API. */
            mediaId?: string;
            /** The machine ID (MID) of the media provider. */
            providerMid?: string;
            /** The name of the media provider. */
            providerName?: string;
        }
        interface NlpSemanticParsingModelsMediaMovie {
            /** Annotations from custom media annotator. */
            annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** Annotation comes from a text annotator. Needed to boost recall. Typically need to be verified in superroot, and have separate scoring. */
            isAnnotatedFromText?: boolean;
            /** Is annotated by Nimble for the media Fast Path. */
            isFromFastPath?: boolean;
            providerMetadata?: NlpSemanticParsingModelsMediaProviderMetadata[];
            qref?: NlpSemanticParsingQRefAnnotation;
            /** Required, corresponds to the raw text, like "Casablanca" */
            rawText?: string;
        }
        interface NlpSemanticParsingModelsMediaMusicArtist {
            /** Annotations from custom media annotator. */
            annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** If true, indicates the user wants their favorite album. Like [play my favorite album my Eminem] */
            favorite?: boolean;
            /** Is annotated by Nimble for the media Fast Path. */
            isFromFastPath?: boolean;
            /** More from this artist. */
            playMore?: boolean;
            qref?: NlpSemanticParsingQRefAnnotation;
            /** Required, corresponds to the raw text, like "The Beatles" */
            rawText?: string;
        }
        interface NlpSemanticParsingModelsMediaMusicGenre {
            /** Annotations from custom media annotator. */
            annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** More from this genre. */
            playMore?: boolean;
            qref?: NlpSemanticParsingQRefAnnotation;
            /** Required, corresponds to the raw text, like "British Invasion" */
            rawText?: string;
        }
        interface NlpSemanticParsingModelsMediaMusicPlaylist {
            /** Annotations from custom media annotator. */
            annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** Annotation comes from a text annotator. Needed to boost recall. Typically need to be verified in superroot, and have separate scoring. */
            isAnnotatedFromText?: boolean;
            /**
             * If the model is confident that this is a bizarre long-tail mood-based playlist, it can send a signal to downstream systems (that might do things like generate random music) Example:
             * * [play music for brushing my teeth with the lights off on tuesday] This is pretty much an 'easter egg' -- it is not critical.
             */
            longtailMood?: boolean;
            /** Optional, some canonical name for the playlist. */
            normalizedText?: string;
            /** Needed for proto conformance in Semantic Parsing. */
            qref?: NlpSemanticParsingQRefAnnotation;
            /** Required, corresponds to the raw text, like "80s remix" (tokenized) */
            rawText?: string;
            special?: string;
        }
        interface NlpSemanticParsingModelsMediaNewsInfo {
            /** The docid of the news result from News360 backend. */
            docid?: string;
            /** Indicates how the type of the news result. */
            newsContentType?: string;
            /** Publication time of the news, in seconds (unix epoch). */
            publicationTime?: AssistantApiTimestamp;
            /** The publisher of the news. */
            publisher?: string;
        }
        interface NlpSemanticParsingModelsMediaNewsTopic {
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            rawText?: string;
        }
        interface NlpSemanticParsingModelsMediaPaidOfferDetail {
            /** Represents the price of this offer according to the locale and region. */
            cost?: NlpSemanticParsingModelsMediaCost[];
            /** Specifies the type of offer. */
            paidOfferType?: string;
        }
        interface NlpSemanticParsingModelsMediaPodcast {
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** Annotation comes from a text annotator. Needed to boost recall. Typically need to be verified in superroot, and have separate scoring. */
            isAnnotatedFromText?: boolean;
            /** Optional, some canonical name for the playlist. */
            normalizedText?: string;
            qref?: NlpSemanticParsingQRefAnnotation;
            /** Required, corresponds to the raw text, like "this american life" */
            rawText?: string;
        }
        interface NlpSemanticParsingModelsMediaPodcastInfo {
            /** An internal identifier for the wernicke database that identifies a cluster of multiple sources for a particular podcast. */
            clusterId?: string;
            /** GUID of the given podcast episode. */
            episodeGuid?: string;
            /** The url for the rss feed providing this podcast. */
            feedUrl?: string;
            /**
             * Podcast recommendations features. These features are used to train models for reranking podcast recommendations. Full list of features: http://shortn/_bg6NvzYs6F This won't be sent
             * to clients. It will only be annotated for crust results
             */
            podcastRecsFeatures?: SuperrootPodcastsRecommendationsPodcastRecsFeatures;
            title?: string;
        }
        interface NlpSemanticParsingModelsMediaProviderMetadata {
            /** URL like https://www.netflix.com/title/70305883 -- this is used as a deeplink to play the video. */
            deeplinkUrl?: string;
            /** Provider MID. */
            providerMid?: string;
        }
        interface NlpSemanticParsingModelsMediaPurchaseInfo {
            orderType?: string;
            /** The time at which the item is purchased. */
            purchaseTimestampSec?: string;
        }
        interface NlpSemanticParsingModelsMediaQuantification {
            lexical?: string;
            /** Numerical quantification. E.g., "three speakers". */
            number?: number;
        }
        interface NlpSemanticParsingModelsMediaRadio {
            /** Annotations from custom media annotator. */
            annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** If true, indicates the user wants their favorite radio station to be played. Ex: [play my favorites on radio] */
            favorite?: boolean;
            /**
             * This proto may only be partially filled depending on the query. ## Some examples (all of them have open_intent): ## | Query
             * |radio.raw_text|radio.frequency.band|radio.frequency.value| |[play kqed fm]| [kqed fm] | [fm] | N/A | |[play 88.5 fm]| [88.5 fm] | [fm] | 88.5 | | [play 88.5 | [88.5] | N/A | 88.5 |
             * ## | [play fm] | [fm] | [fm] | N/A |
             */
            frequency?: NlpSemanticParsingModelsMediaFrequency;
            /** Annotation comes from a text annotator. Needed to boost recall. Typically need to be verified in superroot, and have separate scoring. */
            isAnnotatedFromText?: boolean;
            /** Is annotated by Nimble for the media Fast Path. */
            isFromFastPath?: boolean;
            qref?: NlpSemanticParsingQRefAnnotation;
            /** Required, corresponds to the raw text, like "107.7" */
            rawText?: string;
        }
        interface NlpSemanticParsingModelsMediaRadioInfo {
            /** Frequency of the terrestrial radio station. */
            frequency?: NlpSemanticParsingModelsMediaFrequency;
            /** Location of the radio station. */
            location?: NlpSemanticParsingModelsMediaLatLng;
            /** Popularity of the radio station. This will be used in ranking of the radio stations. This value should be between 0 (least popular) and 5 (most popular). */
            popularity?: number;
        }
        interface NlpSemanticParsingModelsMediaRadioNetwork {
            /** Annotations from custom media annotator. */
            annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            qref?: NlpSemanticParsingQRefAnnotation;
            /** Required, corresponds to the raw text, like "npr" */
            rawText?: string;
        }
        interface NlpSemanticParsingModelsMediaRentalInfo {
            /** Time period for users to continue watching. */
            activatePeriodSec?: string;
            /** Time period for users to begin watching. */
            grantPeriodSec?: string;
            /** The time at which the item is purchased. */
            purchaseTimestampSec?: string;
            /** Time until which ownership is granted */
            validUntilTimestampSec?: string;
        }
        interface NlpSemanticParsingModelsMediaSeasonConstraint {
            /**
             * The absolute index of the season. 1 is the first element and -1 is the last element in the sequence, -2 is the second-to-last element, and so on. Examples: "first season" => 1 "3rd
             * season" => 3 "last season" => -1
             */
            absoluteIndex?: number;
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            rawText?: string;
            /** The relative index of the season. Examples: "previous season" => -1 "current season" => 0 "next season" => 1 */
            relativeIndex?: number;
        }
        interface NlpSemanticParsingModelsMediaSong {
            /** Annotations from custom media annotator. */
            annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** If true, indicates the user wants their favorite album. Like [play my favorite song] */
            favorite?: boolean;
            /** If true, indicates the user wants the first song. Like [play adele's first song] */
            first?: boolean;
            /** Annotation comes from a text annotator. Needed to boost recall. Typically need to be verified in superroot, and have separate scoring. */
            isAnnotatedFromText?: boolean;
            /** Is annotated by Nimble for the media Fast Path. */
            isFromFastPath?: boolean;
            /** If true, indicates the user wants the latest song. Like, [play adele's latest song] */
            latest?: boolean;
            /** Optional, indicates this reference came from QRef. */
            qref?: NlpSemanticParsingQRefAnnotation;
            /** Required, corresponds to the raw text, like "Hey Jude." */
            rawText?: string;
        }
        interface NlpSemanticParsingModelsMediaTVShow {
            /** Annotations from custom media annotator. */
            annotationList?: NlpSemanticParsingModelsMediaMediaAnnotationList;
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** Is annotated by Nimble for the media Fast Path. */
            isFromFastPath?: boolean;
            providerMetadata?: NlpSemanticParsingModelsMediaProviderMetadata[];
            qref?: NlpSemanticParsingQRefAnnotation;
            /** Required, corresponds to the raw text, like "Breaking Bad" */
            rawText?: string;
        }
        interface NlpSemanticParsingModelsMediaYouTubeDeeplinkInfo {
            /** See go/yt-clicktracking. Serialized youtube.api.innertube.InnerTubeClickTrackingProto. */
            clickTrackingId?: string;
            /**
             * For YouTube Channels, by default the deeplink is set to be the playlist of all uploads from the channel. This field is used for YouTube in-app browse when we need the YouTube
             * channel's main page url. We will use the uploader_channel_id to construct the needed channel deeplink.
             */
            uploaderChannelId?: string;
        }
        interface NlpSemanticParsingModelsMediaYouTubePlaylistInfo {
            /**
             * Count of videos in the YouTube playlist that are playable in WoodStock. For performance reasons the maximum value this field can reach is capped, see:
             * kMaxVideosPerPlaylistForSearchMetadata.
             */
            numVidsPlayableInWoodstock?: string;
            /** Total number of videos present in the retrieved playlist. */
            videoCount?: number;
        }
        interface NlpSemanticParsingModelsMoneyCurrency {
            /** KG Currency mid */
            freebaseMid?: string;
        }
        interface NlpSemanticParsingModelsMoneyMoney {
            amount?: NlpSemanticParsingNumberNumber;
            currency?: NlpSemanticParsingModelsMoneyCurrency;
        }
        interface NlpSemanticParsingModelsNarrativeNewsNewsProvider {
            /** Annotation data for the provider. */
            data?: QualityActionsNewsProviderAnnotationData;
            /** Required, but should only be used inside Aqua and must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            rawText?: string;
        }
        interface NlpSemanticParsingModelsOnDevice {
            /** The device(s) to perform an action. */
            device?: NlpSemanticParsingModelsDevice[];
        }
        interface NlpSemanticParsingModelsPersonPerson {
            /** Alternative names like "John" for "Joan", with info such as RecognitionAlternateSource indicating where is it from. */
            alternativeNameInfo?: QualityQrewriteAlternativeNameInfo[];
            /** Alternative names, e.g., names with similar pronunciation, Kathy and Cathy. */
            alternativeNames?: string[];
            annotationSource?: string[];
            /** Contact metadata. Only available for personal contact. */
            contactData?: QualityQrewritePersonalContactData[];
            /** Required, but should only be used inside Aqua. Must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** Whether the person is from personal contacts (e.g. Focus contacts or device contacts) or the person is constructed from a Gaia profile visible to the user (e.g. via Family Service). */
            isPersonalContact?: boolean;
            /**
             * Indicates whether $Person is used for person-group reference. If true, then the PersonalContactData in repeated contact_data field probably correspond to a group of different
             * persons, where $Person is used to represent family, kids, parents, etc.
             */
            isPersonGroupReference?: boolean;
            /**
             * The name of the person without normalizations, preserves casing of the raw text, but removes possible prefix/suffix. For example: raw_text: "Mr. John" normalized_text: "john" name:
             * "John" raw_text: "Tüll" normalized_text: "tuell" name: "Tüll"
             */
            name?: string;
            /** Normalized text produced by annotator. Some annotators generate a normalized version to help better match with contact list. */
            normalizedText?: string;
            /**
             * Contains information about a Copley Person reference (go/copley-people). Note that this contains no information about the resolved people (e.g. names, phone numbers) but only about
             * the user's reference. Resolution metadata is stored in contact_data.pkg_person.
             */
            pkgSemantics?: NlpSemanticParsingQRefAnnotation;
            rawText?: string;
        }
        interface NlpSemanticParsingModelsRecurrence {
            /** Optional. Specifies when in the day the task should occur. Applies to all frequencies DAILY and greater. If absent, the repeating tasks are considered "all day" type. */
            dailyPattern?: NlpSemanticParsingModelsRecurrenceDailyPattern;
            /**
             * This field of the Recurrence message should not in general be used by outside clients of the grammar. It is intended to be used internally in Aqua for evaluation purposes. The
             * rationale is that token counts depend on the particular tokenization used in Aqua which may be different from the one used by the client and may change from time to time. Outside
             * clients should not create a dependency on the current tokenization used in Aqua.
             */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /**
             * Multiplier on the frequency of the recurrence. Use this to specify patterns that recur every X days, months, years, etc. Example: [remind me to call mom every 2nd week]. Default is
             * 1 (every day, every month, every year). Floating point numbers are understood and rounded to the nearest integer. E.g. "every 2.8 months" => (every 3)
             */
            every?: number;
            /** Required. The high-level frequency of the recurrence. */
            frequency?: string;
            /** Specify a monthly recurrence. Valid and required for MONTHLY frequencies only. */
            monthlyPattern?: NlpSemanticParsingModelsRecurrenceMonthlyPattern;
            /**
             * How many times the task should be repeated within the frequency interval. Floating point numbers are understood and rounded to the nearest integer. E.g. "3.8 times per week" =>
             * (num_instances_in_frequency 4)
             */
            numInstancesInFrequency?: number;
            /** Required. The end condition for the recurrence. */
            recurrenceEnd?: NlpSemanticParsingModelsRecurrenceRecurrenceEnd;
            /** Required. The start of the recurrence. */
            recurrenceStart?: NlpSemanticParsingModelsRecurrenceRecurrenceStart;
            /** Optional time included with some types of recurrence phrases, such as "every morning". */
            time?: NlpSemanticParsingDatetimeDateTime;
            /** Specify a weekly recurrence. Valid and required for WEEKLY frequencies only. */
            weeklyPattern?: NlpSemanticParsingModelsRecurrenceWeeklyPattern;
            /** Specify a yearly recurrence. Valid only for YEARLY frequencies. */
            yearlyPattern?: NlpSemanticParsingModelsRecurrenceYearlyPattern;
        }
        interface NlpSemanticParsingModelsRecurrenceDailyPattern {
            dayPeriod?: NlpSemanticParsingDateTimeAnnotation;
            timeOfDay?: NlpSemanticParsingDateTimeAnnotation;
        }
        interface NlpSemanticParsingModelsRecurrenceMonthlyPattern {
            /** Special flag to indicate the last day of the month, equivalent to setting month_day to -1. Deprecated, use month_day=-1 instead. */
            lastDay?: boolean;
            /** Special flag to indicate a week_day in the last week of the month, as this cannot be captured by week_day_number. Deprecated, use week_day_number=-1 instead. */
            lastWeek?: boolean;
            /**
             * Absolute day of the month (if positive) or relative day from the end of the month (if negative). Example: 2nd and 20th of the month [2, 20]. Example: Last day of the month [-1].
             * Positive values should correspond to actual calendar day number (indexing starts at 1).
             */
            monthDay?: number[];
            /** For capturing the nth weekday of the month. Use together with week_day_number or last_week to specify n. */
            weekDay?: string;
            /**
             * The nth occurrence of week_day to match. I.e. For 3rd Wednesday of the month, week_day = WEDNESDAY and week_day_number = 3. Values beyond the end of the month are skipped. If
             * negative, this is interpreted as the nth-to-last occurrence of the week day in the month. I.e. for last Thursday of the month, week_day = THURSDAY and week_day_number = -1.
             */
            weekDayNumber?: number;
        }
        interface NlpSemanticParsingModelsRecurrenceRecurrenceEnd {
            /**
             * Should be used in cases where the size of the recurrence is infinite (no end date specified), in which case we rely on an offline process to extend. Set by server only, setting it
             * on a new recurrence will throw an exception.
             */
            autoRenew?: boolean;
            /**
             * Used in cases where the recurrence is too large to create in a single transaction. In this case we create a manageable number of instances initially and rely on an offline process
             * to continually extend the recurrence until this date. Set by server only, setting it on a new recurrence will throw an exception.
             */
            autoRenewUntil?: NlpSemanticParsingDateTimeAnnotation;
            endDateTime?: NlpSemanticParsingDateTimeAnnotation;
            /** Deprecated - prefer end_date_time.absolute_time_ms. */
            endMillis?: string;
            /** Note that auto-renewing is not supported in conjunction with num_occurrences. Therefore we impose a hard limit of 1000 when using this field. */
            numOccurrences?: number;
        }
        interface NlpSemanticParsingModelsRecurrenceRecurrenceStart {
            /** Only the year/month/day portion are used to find the start date of the recurrence. To specify a time or period of each instance, use DailyPattern. */
            startDateTime?: NlpSemanticParsingDateTimeAnnotation;
            /** Deprecated - prefer start_date_time.absolute_time_ms. */
            startMillis?: string;
        }
        interface NlpSemanticParsingModelsRecurrenceWeeklyPattern {
            /** Set of weekdays the recurrence applies to. */
            weekDay?: string[];
            weeklyPatternEnd?: string;
            weeklyPatternStart?: string;
        }
        interface NlpSemanticParsingModelsRecurrenceYearlyPattern {
            /** The monthly pattern to recur. */
            monthlyPattern?: NlpSemanticParsingModelsRecurrenceMonthlyPattern;
            /** The months of the year to apply the pattern. */
            yearMonth?: string[];
        }
        interface NlpSemanticParsingModelsShoppingAssistantBrandPhrase {
            mid?: string;
            rawText?: string;
        }
        interface NlpSemanticParsingModelsShoppingAssistantMerchant {
            /** This field should not be used by clients of the grammar. It is intended to be used internally in Aqua for metric and regression tests. */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** Merchant Center identifier for LIA merchants. */
            localMerchantId?: string;
            mcid?: NlpSemanticParsingModelsShoppingAssistantMerchantMerchantCenterId[];
            /** Merchant Center identifier for GSX merchants. Deprecated: use MerchantCenterId. */
            merchantId?: string[];
            /** Optional. Knowledge Graph identifier for the merchant. */
            mid?: string;
            /** A name for the merchant. Example: Walmart */
            name?: string;
        }
        interface NlpSemanticParsingModelsShoppingAssistantMerchantMerchantCenterId {
            id?: string;
            isGsx?: boolean;
            isLocal?: boolean;
            isPla?: boolean;
        }
        interface NlpSemanticParsingModelsShoppingAssistantOffer {
            /** The offer document id as used in Shopping's metadata. */
            docid?: string;
            /** The merchant selling the product. */
            merchant?: NlpSemanticParsingModelsShoppingAssistantMerchant;
            /** The price of the product sold by the merchant. */
            price?: NlpSemanticParsingModelsMoneyMoney;
            /** The product for sale. */
            product?: NlpSemanticParsingModelsShoppingAssistantProduct;
            /** Optional. The physical store where the product can be purchased. */
            store?: NlpSemanticParsingModelsShoppingAssistantStore;
        }
        interface NlpSemanticParsingModelsShoppingAssistantPhrase {
            brand?: NlpSemanticParsingModelsShoppingAssistantBrandPhrase;
            offer?: NlpSemanticParsingModelsShoppingAssistantOffer;
            product?: NlpSemanticParsingModelsShoppingAssistantProductPhrase;
            unrecognized?: NlpSemanticParsingModelsShoppingAssistantUnrecognizedPhrase;
        }
        interface NlpSemanticParsingModelsShoppingAssistantProduct {
            /** The shopping catalog identifier. */
            catalogId?: string;
            /** The highes price this product is available for. */
            maxPrice?: NlpSemanticParsingModelsMoneyMoney;
            /** TODO(ppoudyal) Add logging for media_product. */
            mediaProduct?: NlpSemanticParsingModelsShoppingAssistantProductMediaProduct;
            /** Optional. Knowledge Graph identifier for the product. */
            mid?: string;
            /** The lowest price this product is available for. */
            minPrice?: NlpSemanticParsingModelsMoneyMoney;
            /** Title of the product. Example: Moto X Blue 64GB Note: This refers to only the catalog title not user specified phrase */
            title?: string;
        }
        interface NlpSemanticParsingModelsShoppingAssistantProductClassification {
            /**
             * TODO(ppoudyal) Expand confidence to cases where the product phrase might be a book/movie/video_game but isn't just a title The score (between 0 - 1) measuring the confidence that
             * product
             */
            bookConfidence?: number;
            /** TODO(ppoudyal) Deprecate is_video_game once the score covers all cases covered by $VideoGameProductPhrase The product phrase contains a video game title. */
            isVideoGame?: boolean;
            /** phrase mentions a book title The score (between 0 - 1) measuring the confidence that product */
            movieConfidence?: number;
            /** phrase mentions a movie title The score (between 0 - 1) measuring the confidence that product */
            videoGameConfidence?: number;
        }
        interface NlpSemanticParsingModelsShoppingAssistantProductExpression {
            /** This field should not be used by clients of the grammar. It is intended to be used internally in Aqua for metric and regression tests. */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            grammaticalGender?: string;
            grammaticalNumber?: string;
            /** Ordered list of phrases that the user used to describe a product. */
            phrases?: NlpSemanticParsingModelsShoppingAssistantPhrase[];
            productClassification?: NlpSemanticParsingModelsShoppingAssistantProductClassification;
            /** Associated shopping list item info. Only set when the product is come from a shopping list item. */
            shoppingListItemInfo?: NlpSemanticParsingModelsShoppingAssistantShoppingListItemInfo;
        }
        interface NlpSemanticParsingModelsShoppingAssistantProductMediaProduct {
            /** The author of the media */
            author?: NlpSemanticParsingModelsShoppingAssistantProductMediaProductMediaAttributeValue;
            /** The genre of the media */
            genre?: NlpSemanticParsingModelsShoppingAssistantProductMediaProductMediaAttributeValue;
            /** The title of the media Example: The assasin's creed */
            mediaTitle?: NlpSemanticParsingModelsShoppingAssistantProductMediaProductMediaAttributeValue;
            /** Order in media series (series title is given by the product title) */
            orderInSeries?: NlpSemanticParsingModelsShoppingAssistantProductMediaProductMediaAttributeValue;
            /** The topic of the media */
            topic?: NlpSemanticParsingModelsShoppingAssistantProductMediaProductMediaAttributeValue;
        }
        interface NlpSemanticParsingModelsShoppingAssistantProductMediaProductMediaAttributeValue {
            /** The knowledge graph identifier for the attribute */
            mid?: string;
            /** Raw text of the media attribute (eg. author) */
            rawText?: string;
        }
        interface NlpSemanticParsingModelsShoppingAssistantProductPhrase {
            metadata?: NlpSemanticParsingModelsShoppingAssistantProduct;
            rawText?: string;
        }
        interface NlpSemanticParsingModelsShoppingAssistantShoppingListItemInfo {
            itemId?: string;
            listId?: string;
        }
        interface NlpSemanticParsingModelsShoppingAssistantStore {
            /** Local store identifier. */
            id?: string;
            /** The location of the store. */
            location?: NlpSemanticParsingLocalLocation;
            /** A name for the store. Example: Walmart - Cranberry */
            name?: string;
        }
        interface NlpSemanticParsingModelsShoppingAssistantUnrecognizedPhrase {
            rawText?: string;
        }
        interface NlpSemanticParsingNumberFractionNumber {
            denominator?: NlpSemanticParsingNumberSimpleNumber;
            /** Fields for fraction numbers */
            numerator?: NlpSemanticParsingNumberSimpleNumber;
            /**
             * This field is used to indicate the number of digits after the decimal point in the normalized_value field in number.proto, which contains the floating point representation of the
             * fraction
             */
            precision?: number;
            /** This field is set only for mixed fraction */
            wholeNumber?: NlpSemanticParsingNumberSimpleNumber;
        }
        interface NlpSemanticParsingNumberNumber {
            /**
             * Span info of the annotation - mostly used for evaluation purpose. Note: this data must never be used outside Aqua because it relies on the internal tokenization used in Aqua that
             * could change over time.
             */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            fractionNumber?: NlpSemanticParsingNumberFractionNumber;
            /** An optional field that holds whether the number_type number is a normalized spelled-out number or not. This field will not be set in cases when this information is not available. */
            isSpelledOut?: boolean;
            /**
             * NumberModifier is used to capture when the expression is not an absolute number, but a number expression to represent an increase/decrease/comparison. E.g. [10 more percent], [5
             * less].
             */
            modifier?: string;
            /**
             * Contains a normalized string representation of the numeric value that has: * No digit grouping delimiter (e.g. "," in english). * Decimal mark (if present) as "." (dot). For
             * fraction_number, this contains the floating point representation of the fraction. The number of digits after the decimal point is defined in the precision field of
             * fraction_number.proto.
             */
            normalizedValue?: string;
            /** The raw text of the annotation. */
            rawText?: string;
            simpleNumber?: NlpSemanticParsingNumberSimpleNumber;
            /** We expect this field to be set only when is_spelled_out is true. */
            spelledOutType?: string;
        }
        interface NlpSemanticParsingNumberSimpleNumber {
            /** The type of decimal mark that was present before normalization. Note: different locales may use different decimal marks. */
            decimalMark?: string;
            /** The type of digit grouping delimiter that was present before normalization. Note: different locales may use different digit grouping delimiters. */
            groupingDelimiter?: string;
            /** We expect this field to be set only when grouping_delimiter is set. */
            groupingSystem?: string;
            /**
             * Contains a normalized string representation of the numeric value that has: * No digit grouping delimiter (e.g. "," in english). * Decimal mark (if present) as "." (dot). This field
             * is kept for backward compatibility. The field is also available in number.proto
             */
            normalizedValue?: string;
            /** Stores prefix output by the GRM number grammar (http://b/28623478). */
            prefix?: string;
            /** Stores suffix output */
            suffix?: string;
            type?: string;
        }
        interface NlpSemanticParsingPersonalIntelligenceEntity {
            /** Used if the entity is an airline with an airline annotation. */
            airlineConfig?: TravelFlightsAirlineConfig;
            /** Required, but should only be used inside Aqua. Must not be used by outside clients!! */
            evalData?: NlpSemanticParsingAnnotationEvalData;
            /** raw string representation */
            name?: string;
            qrefAnnotation?: NlpSemanticParsingQRefAnnotation;
        }
        interface NlpSemanticParsingPersonalReferenceAnnotation {
            /** A Copley Personal Reference represents a user's reference to a something that could be personal entity, e.g. "my hotel", "mom", "brunch". */
            reference?: NlpSemanticParsingQRefAnnotation;
            /**
             * A Copley Personal Resolution represents the resolution of a Reference, e.g. if the user has a reservation at The Kendall Hotel, the reference "my hotel" could be resolved to The
             * Kendall Hotel, and there would be a QRefAnnotation containing the mid and other data. It is possible for there to be zero resolutions for a given reference.
             */
            resolutions?: NlpSemanticParsingQRefAnnotation[];
        }
        interface NlpSemanticParsingProtoActionsOnGoogleAogSlot {
            /** ID of the entity of this slot. */
            entityId?: string;
            /** Number of bytes of this slot in resolved query. */
            numBytes?: number;
            /** Part of input text, matched by that slot. In the case of composite slots, each slot should have its own original. */
            original?: string;
            /** Name of parameter of this slot. */
            parameterName?: string;
            /**
             * Represents a "list parameter". Each parameter may be declared as a list and have multiple slot values, referenced by a single alias. Each slot value in a list may contain multiple
             * possible values. For example: aqua return 3 dates if the year is not specified in a query - one for the current year, one for the past year, and one for the following year. If user
             * defines a list parameter with type @sys.date, and the query contains multiple dates - we should return a list of possible values for each date from the query, i.e. it will be a list
             * of list of dates.
             */
            slotList?: NlpSemanticParsingProtoActionsOnGoogleSlotList;
            /** Represents a structured value. Used in composite entities. Composite entities can have arbitrary structure. */
            slotMap?: NlpSemanticParsingProtoActionsOnGoogleSlotMap;
            /** Start byte position of this slot in resolved query. */
            startByte?: number;
            /** One or more possible values. This field does not represent a list parameter. */
            value?: NlpSemanticParsingProtoActionsOnGoogleSlotValue;
        }
        interface NlpSemanticParsingProtoActionsOnGoogleDateTime {
            /**
             * Date value. Note, that month and day are 1 based. If this DateTime is a PARTIAL datetime, then fields have value -1, which means these fields are inferred rather than derived
             * directly from query.
             */
            date?: GoogleTypeDate;
            /** Property of this DateTime value that can be used to match user specification of parameters, e.g. date.recent. */
            property?: NlpSemanticParsingProtoActionsOnGoogleDateTimeProperty;
            /** Time value. Only hours and minutes are used. Hours are in 24h format. */
            time?: GoogleTypeTimeOfDay;
            /** Timezone field specified only if this DateTime has type TIME or DATETIME. */
            timeZone?: GoogleTypeTimeZone;
        }
        interface NlpSemanticParsingProtoActionsOnGoogleDateTimeProperty {
            /** Since datetime is a superset of date, time and date&time, this field is used to indicate which type the associated DateTime object belongs to. */
            datetimeType?: string;
            /** The relative relationship between this DateTime value and DateTime&Timezone info provided in ClassifyRequest. */
            relativeDatetimeType?: string;
        }
        interface NlpSemanticParsingProtoActionsOnGoogleSlotList {
            slots?: NlpSemanticParsingProtoActionsOnGoogleAogSlot[];
        }
        interface NlpSemanticParsingProtoActionsOnGoogleSlotMap {
            slots?: { [P in string]: NlpSemanticParsingProtoActionsOnGoogleAogSlot };
        }
        interface NlpSemanticParsingProtoActionsOnGoogleSlotValue {
            values?: NlpSemanticParsingProtoActionsOnGoogleSlotValueSingleValue[];
        }
        interface NlpSemanticParsingProtoActionsOnGoogleSlotValueSingleValue {
            /** Represents date or time. */
            dateTimeValue?: NlpSemanticParsingProtoActionsOnGoogleDateTime;
            /** Represents a string value. */
            stringValue?: string;
            /** This field is only populated by on-device Heron. This field should not be populated by any other service. */
            typeValue?: NlpSemanticParsingProtoActionsOnGoogleTypedValue;
        }
        interface NlpSemanticParsingProtoActionsOnGoogleTypedValue {
            /** Represents a boolean value. */
            boolValue?: boolean;
            /** Represents date or time. */
            dateTimeValue?: NlpSemanticParsingProtoActionsOnGoogleDateTime;
            /**
             * Represents number value. In accordance to ParamValue
             * fields(https://source.corp.google.com/piper///depot/google3/third_party/java_src/appactions/proto/app_actions_data.proto;rcl=431529042;l=12)
             */
            numberValue?: number;
            /** Represents a string value. */
            stringValue?: string;
        }
        interface NlpSemanticParsingQRefAnnotation {
            /**
             * Whether this qref annotation was created by CloseAnswers on Postref. Annotations of this type don't correspond to a particular mention of the entity on the query but rather to an
             * interpretation of the full query.
             */
            addedByCloseAnswers?: boolean;
            /** A copy of the span of canonical (raw) parser input text corresponding to this annotation. */
            annotatedSpan?: string;
            /** Attribute ID of a personal_summary_node_child. */
            attributeId?: string;
            /** The ID of the cluster (set entity) this entity belongs to. */
            clusterId?: string;
            /** Cluster set qref confidence score. */
            clusterSetScore?: number;
            /** The set of mids that are members of the same cluster. */
            clusterSiblingMid?: string[];
            collectionMembership?: NlpSemanticParsingQRefAnnotationCollectionMembership[];
            /** The confidence (in [0, 1]) of the entity being correctly annotated. */
            confidenceScore?: number;
            /** DEPRECATED: Equivalent ids (e.g. de-duped mids) for this entity. */
            deprecatedEquivalentMids?: string[];
            /** DEPRECATED: Higher level id's that support the given id. This field has been deprecated in favor of related_entity. b/27363861 */
            deprecatedMdvcSupportingMid?: string[];
            /**
             * Copy the display info. This can be used by annotators to give grammars a canonical name for an entity. For instance, the media grammar could use it to output the same canonical name
             * for "rock music" and "rock".
             */
            displayName?: string;
            /** The index of the entity from which this annotation is obtained, within the WebrefEntities message in the interpretation defined by interpretation_number, above. */
            entityNumber?: number;
            /** The relationship information from QRef. Only included if the QRefAnnotator is initialised with include_annotated_relationships. */
            entityRelationship?: NlpSemanticParsingQRefAnnotationEntityRelationship[];
            /** Holds information about the backends which contributed to this entity. */
            entitySourceData?: NlpSemanticParsingEntitySourceData;
            /** The mid of the entity in freebase associated with this span. */
            freebaseMid?: string;
            /** The Gaia ID for this entity. This is populated generally for people and businesses. */
            gaiaId?: string;
            /** The shopping global product cluster id(s) of the annotated entity (in KG, the key(s) of type /business/variant_cluster). */
            globalProductClusterId?: string[];
            /**
             * The index of the QueryJoin interpretation from which this annotation was obtained. This field is not used for entities coming from low-confidence annotations, since such entities
             * are not included in any interpretation.
             */
            interpretationNumber?: number;
            /** True if this entity is an mdvc dimension of some other annotated entity. Only included if the QRefAnnotator is initialised with include_annotated_relationships. */
            isMdvcDimension?: boolean;
            /** Whether this annotation originates from nimble. (go/nimble-annotator) */
            isNimbleAnnotation?: boolean;
            /** The center point of this location. This is either directly provided by the FeatureProto.center field or the centroid using the points of the polygon in the FeatureProto. */
            location?: GeostorePointProto;
            /**
             * The location type of the entity, as an int32 representing a TypeCategory enum value. For example, this could be TYPE_LOCALITY (37) or TYPE_COUNTRY (33). We store this type as an int
             * because including FeatureProto would cause java/com/google/ads/adh/pipeline/bigquery:ProtoCatalog to become too large, resulting in OOM errors.
             */
            locationType?: number;
            /** Whether this entity is low confidence. Not used. Currently whitelisted entities below min_confidence threshold are marked as low confidence and maybe not trusted by downstreams. */
            lowConfidence?: boolean;
            matchedLightweightToken?: RepositoryWebrefLightweightTokensMatchedLightweightToken[];
            /**
             * Nested annotations that represent subparts of the given mdvc full annotation. An MDVC full annotation is outputted as the summary node as the root node, and all the children of it
             * as leaves (mdvc_child). QRef outputs a graph of relationships between the mdvc enties, and for mdvc full the aquatator nests the relevant children inside the summary node's proto.
             */
            mdvcChild?: NlpSemanticParsingQRefAnnotation[];
            /** The set of verticals this summary node belongs to. */
            mdvcVerticals?: string[];
            /** A list of any implied entities merged into this annotation during parsing. Order is derivation-dependent. */
            mergedImpliedEntity?: NlpSemanticParsingQRefAnnotation[];
            merlotCategory?: NlpSemanticParsingQRefAnnotationMerlotCategoryData[];
            /** Metadata to be passed through from the AnnotationContext API. */
            otherMetadata?: any;
            /** The geo oyster_id of the entity, relevant only for locations. Only included if the QRefAnnotator is initialised with include_oyster_id. */
            oysterId?: GeostoreFeatureIdProto;
            /**
             * Personal summary nodes are compound entities made up of entities and their attributes, where the entities can be compound too. E.g., "my father's mother" can have a summary node
             * annotation of "Mother(Father(Myself))".
             */
            personalSummaryNodeChild?: NlpSemanticParsingQRefAnnotation[];
            /** The shopping product line id(s) of the annotated /business/shopping_product_line entity. */
            productLineId?: string[];
            /**
             * The confidence (in [0, 1]) that the annotation is reference that implies another entity. (eg "my hotel" in "navigate to my hotel" is reference to explicit hotel from user hotel
             * reservation).
             */
            referenceScore?: number;
            /** Mids related to the given entity */
            relatedEntity?: NlpSemanticParsingRelatedEntity[];
            /** The confidence (in [0, 1]) that the annotation was created on an implicit mention (eg my hotel) as opposed to an explicit mention (eg: the westin copley square) */
            resolutionScore?: number;
            /** If the annotation was created by using personal data, we record the provenance for that data here. */
            sourceTypeList?: CopleySourceTypeList;
            subCluster?: NlpSemanticParsingQRefAnnotationSubCluster[];
        }
        interface NlpSemanticParsingQRefAnnotationCollectionMembership {
            /** Identifier of the collection. Usually something like "/collection/us_states". */
            collectionId?: string;
            /**
             * A value in [0, 1] indicating the relevance of the collection given this entity. NOTE: This field is deprecated and will stop being populated soon. In the meantime, it will always be
             * populated with 1.0.
             */
            collectionScore?: number;
        }
        interface NlpSemanticParsingQRefAnnotationEntityRelationship {
            /** The index of the other entity in the relationship. */
            entityIndex?: number;
            /** True if this entity is implied by the other (includes geo contains). */
            impliedBy?: boolean;
            /** True if this entity implies the other (includes geo contained by). */
            implies?: boolean;
            /** Names of the relationship links. */
            linkPropertyName?: string[];
        }
        interface NlpSemanticParsingQRefAnnotationMerlotCategoryData {
            categoryId?: number;
            confidence?: number;
        }
        interface NlpSemanticParsingQRefAnnotationSubCluster {
            clusterId?: string;
            clusterSetScore?: number;
            clusterSiblingMid?: string[];
        }
        interface NlpSemanticParsingRelatedEntity {
            /** Denotes whether or not the related entity is derived from cluster support transfer. */
            clusterSupportTransferRelation?: string;
            /** Denotes whether or not the related entity composes a compound entity together with other related entities. */
            composedFromRelation?: string;
            /** Whether or not the given mid is related to the other mid. Equivalent mids are usually mutually exclusive with other kinds of relations. */
            equivalentRelation?: string;
            /** The mdvc relation with the related mid. */
            mdvcRelation?: string;
            /** Mid that is related. */
            mid?: string;
            /** Denotes whether or not there was support transfer between the two entities. */
            supportTransferRelation?: string;
            /** Set if the related entity is the source of an STBR rule and the target is not this one. */
            targetIsStbrSource?: boolean;
        }
        interface NlpSemanticParsingSaftCoreference {
            /** Categories can be either a $PronounMention or $NominalMention. */
            category?: string;
            /** The substring of the raw query spanned by this annotation. */
            rawText?: string;
            /** The name of the entity this mentions refers to. */
            referentText?: string;
        }
        interface NlpSemanticParsingSaftMeasure {
            /** Defines the category of measure, like $Mass. */
            category?: string;
            /** The substring of the raw query spanned by this annotation. */
            rawText?: string;
            /** The numerical value of the measure. */
            value?: number;
        }
        interface NlpSemanticParsingSaftMentionAnnotation {
            /** Annotations for spans that are resolved coreference mentions. */
            coreference?: NlpSemanticParsingSaftCoreference;
            /** Annotations for spans like "san francisco giants". */
            entity?: NlpSemanticParsingSaftSpan;
            /** Annotations for spans "53 pounds". */
            measure?: NlpSemanticParsingSaftMeasure;
            /** Annotations for spans like "the president of the United States". */
            title?: NlpSemanticParsingSaftSpan;
        }
        interface NlpSemanticParsingSaftSpan {
            /** Categories can be either syntactic (NNS for fine-grained-POS) or semantics ($Mass for measures). */
            category?: string;
            /** The substring of the raw query spanned by this annotation. */
            rawText?: string;
        }
        interface NlxDataSchemaByte {
            /** The document that contains this character. */
            document?: MultiscalePointerIndex;
        }
        interface NlxDataSchemaCharacter {
            /** The document that contains this character. */
            document?: MultiscalePointerIndex;
            /** The paragraph that contains this character. */
            paragraph?: MultiscalePointerIndex;
            /** The sentence that contains this character. */
            sentence?: MultiscalePointerIndex;
            /** The character itself. Must contain valid UTF-8. Must be exactly one Unicode character. */
            text?: string;
            /** The token that contains this character. */
            token?: MultiscalePointerIndex;
        }
        interface NlxDataSchemaDocument {
            /** The author(s) of this document. */
            author?: MultiscalePointerIndex[];
            /** The bytes in this document. */
            bytes?: MultiscalePointerSpan;
            /** The characters in this document. */
            characters?: MultiscalePointerSpan;
            /** The identifier of this document. */
            id?: string;
            /** A set of BCP-47 codes indicating the language(s) of this document. */
            languageCode?: string[];
            /** The language spans in this document. */
            languageSpans?: MultiscalePointerSpan;
            /** The mentions in this document. */
            mentions?: MultiscalePointerSpan;
            /** The paragraphs in this document. */
            paragraphs?: MultiscalePointerSpan;
            /** The sentences in this document. */
            sentences?: MultiscalePointerSpan;
            /** The text of this document. Must contain valid UTF-8. */
            text?: string;
            /** The tokens in this document. */
            tokens?: MultiscalePointerSpan;
            /** The url of this document. */
            url?: string;
        }
        interface NlxDataSchemaEntity {
            /** Entity gender. Default label set is 'masculine', 'feminine', or 'neuter'. (Perhaps in the future we can split 'neuter' into 'inanimate', 'unknown', and 'non-binary'.) */
            gender?: string;
            /** Machine identifier, such as those from the Freebase database (or similar entity database). */
            mid?: string;
            /** Free-form entity name. */
            name?: string;
            /**
             * Entity type, typically something like person/location/organization. The schema for types is not specified. If this entity has a MID, use the mid field instead or in conjunction with
             * the type.
             */
            type?: string[];
        }
        interface NlxDataSchemaLanguageSpan {
            /** The bytes in this span. */
            bytes?: MultiscalePointerSpan;
            /** The characters in this span. */
            characters?: MultiscalePointerSpan;
            /** The document that contains this span. */
            document?: MultiscalePointerIndex;
            /** A set of BCP-47 codes indicating the language(s) of this span of text. */
            languageCode?: string[];
        }
        interface NlxDataSchemaMention {
            /** The bytes in this mention. */
            bytes?: MultiscalePointerSpan;
            /** The document that contains this mention. */
            document?: MultiscalePointerIndex;
            /** The entity that this mention refers to. */
            entity?: MultiscalePointerIndex;
            /** Mention kind, typically 'referential', 'attributive', or 'modifier'. */
            kind?: string;
            /** The mention text itself. Must contain valid UTF-8. */
            text?: string;
            /** The token(s) in this mention. This may not be present, or have zero length if representing an implicit mention, as in the prodrop case. */
            tokens?: MultiscalePointerSpan;
            /**
             * Mention type, typically 'named' (for name mentions) or 'nominal'. More types include 'pronominal', 'conjoined' for conjoined mention construction, and 'non-referential' for
             * non-referential pronoun mentions.
             */
            type?: string;
        }
        interface NlxDataSchemaParagraph {
            /** The bytes in this paragraph. */
            bytes?: MultiscalePointerSpan;
            /** The characters in this paragraph. */
            characters?: MultiscalePointerSpan;
            /** The document that contains this paragraph. */
            document?: MultiscalePointerIndex;
            /** The sentences in this paragraph. */
            sentences?: MultiscalePointerSpan;
            /** The text of this paragraph. Must contain valid UTF-8. */
            text?: string;
            /** The tokens in this paragraph. */
            tokens?: MultiscalePointerSpan;
        }
        interface NlxDataSchemaScaleSet {
            byte?: NlxDataSchemaByte[];
            /** Metadata for which layer (scale) fields are present. WARNING: CURRENT USAGE IS AD HOC, DO NOT RELY ON THESE BEING POPULATED CORRECTLY. This should improve in v2. */
            byteDocumentPresence?: MultiscaleFieldPresence;
            /** Metadata for which layers (scales) are present. WARNING: CURRENT USAGE IS AD HOC, DO NOT RELY ON THESE BEING POPULATED CORRECTLY. This should improve in v2. */
            bytePresence?: MultiscaleLayerPresence;
            character?: NlxDataSchemaCharacter[];
            characterDocumentPresence?: MultiscaleFieldPresence;
            characterParagraphPresence?: MultiscaleFieldPresence;
            characterPresence?: MultiscaleLayerPresence;
            characterSentencePresence?: MultiscaleFieldPresence;
            characterTextPresence?: MultiscaleFieldPresence;
            characterTokenPresence?: MultiscaleFieldPresence;
            document?: NlxDataSchemaDocument[];
            documentAuthorPresence?: MultiscaleFieldPresence;
            documentBytesPresence?: MultiscaleFieldPresence;
            documentCharactersPresence?: MultiscaleFieldPresence;
            documentIdPresence?: MultiscaleFieldPresence;
            documentLanguageCodePresence?: MultiscaleFieldPresence;
            documentLanguageSpansPresence?: MultiscaleFieldPresence;
            documentMentionsPresence?: MultiscaleFieldPresence;
            documentParagraphsPresence?: MultiscaleFieldPresence;
            documentPresence?: MultiscaleLayerPresence;
            documentSentencesPresence?: MultiscaleFieldPresence;
            documentTextPresence?: MultiscaleFieldPresence;
            documentTokensPresence?: MultiscaleFieldPresence;
            documentUrlPresence?: MultiscaleFieldPresence;
            entity?: NlxDataSchemaEntity[];
            entityGenderPresence?: MultiscaleFieldPresence;
            entityMidPresence?: MultiscaleFieldPresence;
            entityNamePresence?: MultiscaleFieldPresence;
            entityPresence?: MultiscaleLayerPresence;
            entityTypePresence?: MultiscaleFieldPresence;
            languageSpan?: NlxDataSchemaLanguageSpan[];
            languageSpanBytesPresence?: MultiscaleFieldPresence;
            languageSpanCharactersPresence?: MultiscaleFieldPresence;
            languageSpanDocumentPresence?: MultiscaleFieldPresence;
            languageSpanLanguageCodePresence?: MultiscaleFieldPresence;
            languageSpanPresence?: MultiscaleLayerPresence;
            mention?: NlxDataSchemaMention[];
            mentionBytesPresence?: MultiscaleFieldPresence;
            mentionDocumentPresence?: MultiscaleFieldPresence;
            mentionEntityPresence?: MultiscaleFieldPresence;
            mentionKindPresence?: MultiscaleFieldPresence;
            mentionPresence?: MultiscaleLayerPresence;
            mentionTextPresence?: MultiscaleFieldPresence;
            mentionTokensPresence?: MultiscaleFieldPresence;
            mentionTypePresence?: MultiscaleFieldPresence;
            paragraph?: NlxDataSchemaParagraph[];
            paragraphBytesPresence?: MultiscaleFieldPresence;
            paragraphCharactersPresence?: MultiscaleFieldPresence;
            paragraphDocumentPresence?: MultiscaleFieldPresence;
            paragraphPresence?: MultiscaleLayerPresence;
            paragraphSentencesPresence?: MultiscaleFieldPresence;
            paragraphTextPresence?: MultiscaleFieldPresence;
            paragraphTokensPresence?: MultiscaleFieldPresence;
            sentence?: NlxDataSchemaSentence[];
            sentenceBytesPresence?: MultiscaleFieldPresence;
            sentenceCharactersPresence?: MultiscaleFieldPresence;
            sentenceDocumentPresence?: MultiscaleFieldPresence;
            sentenceParagraphPresence?: MultiscaleFieldPresence;
            sentencePresence?: MultiscaleLayerPresence;
            sentenceTextPresence?: MultiscaleFieldPresence;
            sentenceTokensPresence?: MultiscaleFieldPresence;
            token?: NlxDataSchemaToken[];
            tokenBytesPresence?: MultiscaleFieldPresence;
            tokenCharactersPresence?: MultiscaleFieldPresence;
            tokenDependencyHeadPresence?: MultiscaleFieldPresence;
            tokenDependencyLabelPresence?: MultiscaleFieldPresence;
            tokenDependencyPresence?: MultiscaleFieldPresence;
            tokenDocumentPresence?: MultiscaleFieldPresence;
            tokenParagraphPresence?: MultiscaleFieldPresence;
            tokenPosPresence?: MultiscaleFieldPresence;
            tokenPresence?: MultiscaleLayerPresence;
            tokenSentencePresence?: MultiscaleFieldPresence;
            tokenTextPresence?: MultiscaleFieldPresence;
        }
        interface NlxDataSchemaSentence {
            /** The bytes in this sentence. */
            bytes?: MultiscalePointerSpan;
            /** The characters in this sentence. */
            characters?: MultiscalePointerSpan;
            /** The document that contains this sentence. */
            document?: MultiscalePointerIndex;
            /** The paragraph that contains this sentence. */
            paragraph?: MultiscalePointerIndex;
            /** The text of this sentence. Must contain valid UTF-8. */
            text?: string;
            /** The tokens in this sentence. */
            tokens?: MultiscalePointerSpan;
        }
        interface NlxDataSchemaToken {
            /** The bytes in this token. */
            bytes?: MultiscalePointerSpan;
            /** The characters in this token. */
            characters?: MultiscalePointerSpan;
            /** DEPRECATED: PLEASE USE dependency_head AND dependency_label FIELDS. One edge of the dependency parse. */
            dependency?: NlxDataSchemaTokenDependencyEdge;
            /** The head of this token. By default, the root of the sentence is its own head; it should also have deprel as 'root'. */
            dependencyHead?: MultiscalePointerIndex;
            /** Relation label for this dependency. Generally this should be using the Universal Dependencies label format, using fine-grained labels like nsubj:pass. */
            dependencyLabel?: string;
            /** The document that contains this token. */
            document?: MultiscalePointerIndex;
            /** The paragraph that contains this token. */
            paragraph?: MultiscalePointerIndex;
            /** Coarse part-of-speech tag. */
            pos?: string;
            /** The sentence that contains this token. */
            sentence?: MultiscalePointerIndex;
            /** The text of this token. Must contain valid UTF-8. */
            text?: string;
        }
        interface NlxDataSchemaTokenDependencyEdge {
            /** Relation label for this dependency. Generally this should be using the Universal Dependencies label format, using fine- grained labels like nsubj:pass. */
            deprel?: string;
            /** The head of this token. By default, the root of the sentence is its own head; it should also have deprel as 'root'. */
            head?: MultiscalePointerIndex;
        }
        interface NSRVersionedItem {
            /** The NSR value corresponding to this version. */
            value?: number;
            /** The version id. */
            versionId?: number;
        }
        interface OceanDataDocinfoWoodwingItemMetadata {
            author?: string;
            category?: string;
            description?: string;
            title?: string;
        }
        interface OceanDocInfo {
            /** data returned with search docresults (snippets) */
            docTag?: OceanDocTag;
        }
        interface OceanDocTag {
            /** TODO(leonid) Deprecate these Authors string for front end. */
            authors?: string;
            /** A bitmap containing all available download formats (values defined in AvaialableDownloadFormats enum) NOTE: Only populated for Volume level docs */
            availableDownloads?: number;
            blockSnippet?: boolean;
            bookspecific?: OceanDocTagBookSpecific;
            catalogspecific?: OceanDocTagCatalogSpecific;
            /** The content type of the document. See BoundVolumeSource::ContentType in ocean/data/volume_types.protodevel for possible values. */
            contentType?: number;
            contributor?: OceanDocTagContributor[];
            /** cover page (PrintedAsSeen string), to generate results snippet thumbnail image urls */
            coverPage?: string;
            /** The size (in pixels) of the full-resolution clean images used for the cover page. The width and height will be zero if no image for that page. */
            coverPageSize?: OceanImageSize;
            /** this is in ONIX format. */
            DEPRECATEDApplicationDate?: string;
            /** this is in ONIX format. */
            DEPRECATEDIssueDate?: string;
            DEPRECATEDPatentAssignee?: string;
            /** patent-specific fields. ALL DEPRECATED, moved into PatentSpecific group, above. */
            DEPRECATEDPatentNumber?: string;
            /**
             * Percent rights granted by publisher. This should only be set, and definitely should only be considered, if source_type == BoundVolumeSource::PUBLISHER. '0' may mean we have no info
             * on publisher rights so we have to just assume 0%. Deprecated as this is taken into account by viewability
             */
            DEPRECATEDPublisherPercentVisible?: number;
            /** Editors string for front end. */
            editors?: string;
            encryptedExpressionId?: string;
            encryptedVolumeId?: string;
            /**
             * DEPRECATED! Being replaced in favor of viewability, below. geo restrict info (from OceanRights::geo_restrict) In CAv2: geo restrict info (from
             * ocean::VolumeImprintRights::geo_restrict)
             */
            geoRestrict?: string[];
            /** Text quality as defined in CA_VolumeScoreResult::OACapabilities::TextQualityAssessment Note - This is only populated if good_text() and is_ge_quality() are true */
            goodTextDetail?: number;
            /**
             * List of locales for which this book can be bought from a publisher, and read as a Google eBook. Each locale is a lowercase, two-letter country-code (eg "ca"), and is copied from
             * PublisherGrantability.Locale.locale, defined in ocean/data/docinfo/volume_viewability.proto.
             */
            grantableLocale?: string[];
            /** Set to true if volume has ge quality */
            isGeQuality?: boolean;
            /** whether this a landing page chosen at indexing time. */
            isLandingPage?: boolean;
            magazinespecific?: OceanDocTagMagazineSpecific;
            /** metadata_cover_exists will be set if there's a metadata-provided cover thumbnail. the thumbnail will be used for scanless books or when a scanned book is in metadata-only view. */
            metadataCoverExists?: boolean;
            /** The size (in pixels) of the metadata cover image. */
            metadataCoverSize?: OceanImageSize;
            newspaperspecific?: OceanDocTagNewspaperSpecific;
            /** Number of pages in this volume (usually as specified in metadata) */
            numPages?: number;
            /** A bitmap indicating whether content may be objectionable NOTE: Only populated for volume level docs */
            objectionableContentBitmap?: number;
            /** pageid of the page (OceanTypes::PageIdType) */
            pageid?: number;
            /** page_number of the page (OceanTypes::PageNumberType) In CAv2: page_number of the page ocean::PageNumber::T */
            pageNumber?: number;
            /** the page rank value of the book page */
            pagerank?: number;
            patentspecific?: OceanDocTagPatentSpecific;
            /** Price information for a volume (per locale). Note existence of a price for a locale implies that the book is sellable for that locale. */
            price?: OceanGEPrice;
            /** printed page number (OceanPrintedPageNumber; from OceanPageInfoMap::Page::printed_page_number) */
            printedPageNumber?: string;
            /** the URL of the reference page (About this book) */
            refPageUrl?: string;
            /** the URL for the "search in book" */
            searchInBookUrl?: string;
            segmentTime?: number;
            /** The source type of the document. See BoundVolumeSource::SourceType in ocean/data/volume_types.protodevel for possible values. */
            sourceType?: number;
            /** In CAv2 only: structured page number (printed number as we understand it) (result of ocean::StructuredPageNumberProto::AppendToString) */
            structuredPageNumber?: string;
            /** Bitmap indicating top-level subjects associated with this document. See ocean/metadata/subjects/util.h for more detail. */
            subjectBitmap?: string;
            /** Sub title string for front end */
            subTitle?: string;
            /** the URL of the cover page. */
            thumbnailUrl?: string;
            /** Title string for front end. */
            title?: string;
            /**
             * Bibkey to be used as part of the URL (to make them persistent in some sense). This is obtained by doing a GetURLKey() on the bibdata which returns the main bibkey associated with
             * the volume based on priority. This is parseable into an OceanVolumeBibKey (ocean/metadata/bibkeys.h) Note: This should ideally be a required field longer term but for now keeping it
             * optional for compatibility. In case of this being absent, we don't include the key in the URL (just use volumeId as before). Note: For content type books, this key is supplemented
             * by other bibkeys for this volumes(the field is aux_bibkeys)
             */
            urlKey?: string;
            /**
             * using_actual_cover will be set if we are using the actual cover of the book (instead of the table of content, etc.). This is particularly useful to identify books where we inserted
             * a generated cover via Coverups.
             */
            usingActualCover?: boolean;
            /** Volume viewability, which defines how/if the volume should be displayed in various locales. */
            viewability?: OceanVolumeViewability;
            volumeType?: number;
            /** The version of the volume (serialized form). ONLY populated for Volume level docs */
            volumeVersion?: string;
            workcluster?: OceanDocTagWorkCluster;
        }
        interface OceanDocTagBookSpecific {
            /**
             * These are other bibkeys for this book beside the url_key, which is the primary key. For example, a book may have ISBN, OCLC num etc. In that case ISBN is the url_key and the OCLC
             * number is the auxillary bibkey. The aux_bibkeys should have the same form as the url_key
             */
            auxBibkeys?: string[];
            imprint?: string;
            numberingrange?: OceanDocTagBookSpecificNumberingRange[];
            numRatingHalfStars?: number;
            /** publisher id, if available */
            partnerId?: string;
            /**
             * Set if the book is one of several editions or versions. Used by OFE to show numbered editions. The value is copied from clustering information. See also
             * ocean/metadata/proto/bibdata_components.proto The value there is from metadata records by ocean/metadata/parsing/parse_utils.cc, and is a 1-based value.
             */
            productEditionNumber?: number;
            /** In the format yyyy.mm.dd, or possibly just yyyy. */
            publicationDate?: string;
            publisherName?: string;
            /** Subject (from Bisac) */
            subject?: string;
        }
        interface OceanDocTagBookSpecificNumberingRange {
            endNumbering?: string[];
            numberingSchema?: number[];
            numberType?: number[];
            startNumbering?: string[];
        }
        interface OceanDocTagCatalogSpecific {
            /** Is this the latest issue of this catalog series? This is required to filter results if the latest restrict is on. */
            latest?: boolean;
            /**
             * time_t date corresponding to the catalog publication date. Approximate when the catalog does not have an exact "date" of publication, e.g. For "Spring 2002", year, month and day are
             * 2002, 03 and 21, respectivley. This value is used to compare catalog issues to determine the latest. The value is stored in seconds-since-epoch, 1/1/1970. This is not a problem for
             * catalogs because we are not dealing with any catalogs from before the 70's.
             */
            publicationDate?: number;
            /** String to be displayed as catalog publication time, e.g. "Spring 2002". */
            publicationTimeToDisplay?: string;
        }
        interface OceanDocTagContributor {
            name?: string;
            /** ContributionType enum from ocean/metadata/metadata_enums.proto Note that we pick only the "highest-ranking" contribution (i.e. writer and editor would collapse to "writer". */
            type?: number;
        }
        interface OceanDocTagMagazineSpecific {
            /** A human-readable date for display in the UI. Unlike "publication_date_" above, this should not be parsed into structured data, but should only be displayed as is. */
            displayDate?: string;
            /** Description specific to a magazine issue, such as featured articles and article summaries. */
            issueDescription?: string;
            issueEnd?: number;
            issueStart?: number;
            /** Items within a magazine issue. */
            item?: OceanDataDocinfoWoodwingItemMetadata[];
            otherNumberingEnd?: number;
            /** NOTE: These should to be values from MetadataNumberingSchema; when this becomes a proto2, we can use MetadataEnums values. */
            otherNumberingSchema?: number;
            /** For season or quarter dates. */
            otherNumberingStart?: number;
            /** For each page of a magazine, maps to the item index of "item". */
            pageToItem?: number[];
            publicationDateEnd?: string;
            publicationDateStart?: string;
            /** This is used to render the metadata line of the snippet and should be present in all magazine documents. */
            serialTitle?: string;
            serialVolumeid?: string;
            volume?: number;
        }
        interface OceanDocTagNewspaperSpecific {
            /** Newspaper Article Roll Coordinates used to figure out the location of the article wrt the page. It is of the form x,y. */
            articleRollCoords?: string;
            /** Atlantis specific. Deprecated. */
            newspaperDate?: number;
            newspaperName?: string;
            /** Atlantis specific. Deprecated. */
            newspaperUrl?: string;
            /** These fields are only populated for Santorini (newspapers on goovols) formatted newspapers, not for Atlantis: YYYY.MM.DD format. */
            publicationDate?: string;
            /** Atlantis specific. Deprecated. */
            publisher?: string;
        }
        interface OceanDocTagPatentSpecific {
            /** this is in ONIX format. */
            applicationDate?: string;
            /** 2-letter language of the document such as "en" or "fr" This field was created for plumbing in the OFE API intl patent flow, and is probably not otherwise filled in. */
            contentLanguage?: string;
            docType?: number;
            /** Just the number, no bibkey prefix. Called 'doc number' b/c it could be patent number for patents, application number for applications. */
            documentNumber?: string;
            /** US and Int'l patent classification codes for "related patents". */
            domesticClassification?: string[];
            internationalClassification?: string[];
            /** this is in ONIX format. */
            issueDate?: string;
            patentAssignee?: string;
            /** For applications, the 'publication number' Something like US20071234567A1: 'US' prefix, 4 digit year, 7 digit serial number, 2 character code, all stuck together. */
            publicationNumber?: string;
            /**
             * Path identifying the image used for the thumbnail of this patent. e.g. "EP1234567B1/imgf0001.png" The client is expected to fill in the rest of the url such as:
             * https://patentimages.storage.googleapis.com/thumbnails/EP1234567B1/imgf0001.png
             */
            relativeThumbnailPath?: string;
            tenCharUsClassification?: string[];
        }
        interface OceanDocTagWorkCluster {
            clusterSize?: number;
            workId?: string;
        }
        interface OceanGEMoney {
            /** amount in micros. 1 is represented 1000000 */
            amountInMicros?: string;
            /** The currency codes come from google3/i18n/identifiers/currencycode.h. */
            currencyCode?: string;
        }
        interface OceanGEPrice {
            locale?: OceanGEPriceLocale[];
        }
        interface OceanGEPriceLocale {
            /** The two character ISO country code */
            locale?: string;
            /** Price used for sale by the OFE */
            offerPrice?: OceanGEMoney;
            /** The time (in secs from epoch) the content goes on sale (only set when the book is not already sellable at the time of indexing). */
            onSaleTimeSecs?: string;
        }
        interface OceanImageSize {
            /** pixels */
            height?: number;
            /** pixels */
            width?: number;
        }
        interface OceanLocaleViewability {
            /** These capture "commercial" contract related access rights provided by partners for a volume. */
            accessRights?: OceanVolumeAccessRights;
            /**
             * Are we allowed to add all the front matter to the preview in addition to the preview amount that is from percent_book_shown? This means the front matter becomes freely previewable
             * and does not count towards the previewable amount based on the percentage.
             */
            allowAddingFrontmatterToPreview?: boolean;
            /** By default, we allow continuous browse. PFE provides a means for partners to opt out entirely or just specific books. */
            allowContinuousBrowse?: boolean;
            /** whether OFE should display this volume in syndicated search results */
            allowRetailSyndication?: boolean;
            /** The bibkey upon which this viewability information is based. */
            bibkey?: string;
            /** Whether we can show ads with this book in this locale. */
            canDisplayAds?: boolean;
            /** In future, we will generate epub iff can_download_epub = true irrespective of viewability or download pdf state. */
            canDownloadEpub?: boolean;
            /** In future, we will generate PDF iff can_download_pdf = true irrespective of viewability. */
            canDownloadPdf?: boolean;
            /** Whether to show library links for the books in this imprint. */
            canShowLibraryLinks?: boolean;
            /** Whether we can show photos for this book in this locale. */
            canShowPhotos?: boolean;
            /** It should be OK to use metadata covers normally, but we allow publishers to explicitly disallow them. */
            canUseMetadataCover?: boolean;
            /**
             * The client who provided the rights for this bibkey, and who should receive revenue derived from this book in this locale. This will only be present when we receive explicit rights
             * from a publisher.
             */
            clientId?: string;
            /**
             * Volume related access rights that are computed by Goovols Syncher from partner and book metadata. This complements VolumeAccessRights. This message is used to capture "commerical"
             * contracts that are computed from other sources. Any future computed rights that are not related to volume access should go into a new message.
             */
            computedAccessRights?: OceanVolumeComputedAccessRights;
            dates?: OceanLocaleViewabilityDates;
            /** Volume display specific attributes are kept in display_details */
            displayDetails?: OceanVolumeDisplayDetails;
            /**
             * This only applies when view_type == VIEW_METADATA and controls whether we're allowed to include scanned info (keywords, toc, etc). in the metadata-view. For books in metadata view
             * because they have been opted out, this would be false.
             */
            metadataViewMayIncludeInfoFromScans?: boolean;
            /** This only applies when view_type == VIEW_METADATA and controls whether we're allowed to include a text sample even for a metadata view book. */
            metadataViewSampleAllowed?: boolean;
            /**
             * How much of the book can be viewed in this locale. Will be 100 for VIEW_FULL; 0 for VIEW_SNIPPET_, VIEW_NONE and VIEW_METADATA; and some value between 0 and 100 (exclusive) for
             * VIEW_PARTIAL.
             */
            percentBookShown?: number;
            /**
             * If present, this is the rights policy's determination of the public domain status. (Of course, this determination is generally conservative (i.e. false negatives are likely), though
             * exactly how conservative may depend on parameters to the rights policy.) If absent, public domain status can be inferred from view_type and view_reason, but that isn't quite
             * perfectly reliable: view_type should always be VIEW_FULL for public domain, but view_reason might be REASON_PUBLIC_DOMAIN (definitely public domain, obviously), some other value, or
             * absent. In the future, new viewabilities should always have this field whenever possible.
             */
            publicDomain?: boolean;
            sourcedetails?: OceanLocaleViewabilitySourceDetails;
            /** The reason for the view_type. */
            viewReason?: string;
            /** The viewability specified for this locale. */
            viewType?: string;
        }
        interface OceanLocaleViewabilityDates {
            /**
             * If specified, the LocaleViewability will become effective on this date. This field is used to allow pre-indexing of future books which will become viewable and searchable according
             * to the LocaleViewability on the specified date. Before the effective date, the volume will have scanless-like VIEW_METADATA viewability. For details, see the design document at
             * http://go/oceanviewabilityeffectivedate. The date is expressed as the number of seconds since the Unix epoch.
             */
            effectiveDate?: string;
        }
        interface OceanLocaleViewabilitySourceDetails {
            imprint?: OceanVolumeImprint;
        }
        interface OceanPerDocData {
            /** rights, mask-availability, porn, etc. */
            flags?: string;
            numPages?: number;
            pageid?: number;
            /** 1-based */
            pageNumber?: number;
            volumeid?: string;
        }
        interface OceanVolumeAccessRights {
            /** If false, then we can only provide text layer generated from publisher provided epub. */
            allowAutoGeneratedText?: boolean;
            /** Whether we can show info cards inside this book. */
            canShowInfoCards?: boolean;
            /** Whether we can show photos inside this book. */
            canShowPhotos?: boolean;
            /** Maximum number of Adobe Digital Editions device per sale item allowed. 0 means no download allowed. -1 means unlimited download. */
            numAdeDeviceAllowed?: number;
            /** Maximum number of Adobe id per sale item allowed. 0 means no download allowed. -1 means unlimited download. */
            numAdobeIdAllowed?: number;
            /**
             * Max. number of Google eBooks downloads allowed. This is related to iPhone/iPad/Androrid/WebReader reading, not to epub/pdf downloads. 0 means no download allowed. This is related to
             * bug #3094719.
             */
            numDownloadsAllowed?: number;
            /** Number of readers can read the Google eBooks simultaneously */
            numSimultaneousAccess?: number;
            /** Download type for offline reading */
            offlineDownload?: string;
            /** How much of a volume we allow user to extract as text (for copy+paste) */
            percentCopyable?: number;
            /** How much of a volume we allow user to print */
            percentPrintable?: number;
            /** True iff restrict view only to epub text. Don't show page images if this is true. Some pubs don't have copyright for page layout and fonts. */
            restrictOnlyToText?: boolean;
            /** Whether we sell fixed layout as image only. */
            sellFixedLayoutAsImageOnly?: boolean;
            /** Whether text to speech is allowed */
            textToSpeech?: boolean;
            /** Whether we treat this book as public domain. */
            treatAsPublicDomain?: boolean;
        }
        interface OceanVolumeComputedAccessRights {
            /** Whether this book can be shared with family members. */
            canFamilyShare?: boolean;
            /** Whether the panelization feature is enabled for internal users only. */
            panelizationFeatureInternalOnly?: boolean;
            /** Whether the book is viewable for internal users only. */
            viewableInternalOnly?: boolean;
        }
        interface OceanVolumeDisplayDetails {
            /** The creative commons license specified, Please refer ocean.CreativeCommonsLicenseType.Type for enum values Not exposed in Partner Frontend anymore. */
            ccLicense?: number;
        }
        interface OceanVolumeImprint {
            /** These capture "commercial" contract related access rights provided by partners for a volume. */
            accessRights?: OceanVolumeAccessRights;
            /** Id used in the google ads system */
            adsId?: string;
            /** Are we allowed to add all the front matter to the preview in addition to the preview amount that is from percent_book_shown? */
            allowAddingFrontmatterToPreview?: boolean;
            /**
             * By default, we allow continuous browse. PFE provides a means for partners to opt out entirely or just specific books. This will be deprecated once UpdateVolumesReqHandler returns
             * VolumeViewability.
             */
            allowContinuousBrowse?: boolean;
            /** By default, we allow retailer syndication. PFE provides a means for partner to opt out. This will be deprecated once UpdateVolumesReqHandler returns VolumeViewability. */
            allowRetailSyndication?: boolean;
            /**
             * Beware: the author strings are not in fixed format..these can be comma separated or 'and' separated or have extra terms like 'et al' and sometimes have weird ones like 'no author'
             * as these are fed in via a somewhat flexible free text tool.
             */
            author?: string;
            /**
             * Commercial info comes with book identifiers like ISBN(or some bibkey), Title, Author. Passing these along as well with the commercials for better book identification/link up with
             * rights.
             */
            bibkey?: string;
            /** Text to display in the buy-the-book blurb */
            buyTheBookText?: string;
            /** ISBN/ISSN-parameterized URL to the imprint's site for buying a book. For ISBN-parameterized links, the ISBN value will be substituted in the cannonical 13-digit form. */
            buyTheBookUrl?: string;
            /** iff true volume is available as Google Edition. This will be deprecated once UpdateVolumesReqHandler returns VolumeViewability. */
            canDownloadEpub?: boolean;
            /** iff true and VIEW_TYPE=FULL_VIEW, then we will allow PDF download This will be deprecated once UpdateVolumesReqHandler returns VolumeViewability. */
            canDownloadPdf?: boolean;
            /** Whether to show library links for the books in this imprint. This will be deprecated once UpdateVolumesReqHandler returns VolumeViewability. */
            canShowLibraryLinks?: boolean;
            /** It should be OK to use metadata covers normally, but we allow publishers to explicitly disallow them. This will be deprecated once UpdateVolumesReqHandler returns VolumeViewability. */
            canUseMetadataCover?: boolean;
            /** Whether to disable other btb links for the books in this imprint. Show only btb link from this partner and remove everything else. */
            disableOtherBuyTheBookLinks?: boolean;
            /** Volume display specific attributes are kept in display_details This will be deprecated once UpdateVolumesReqHandler returns VolumeViewability. */
            displayDetails?: OceanVolumeDisplayDetails;
            /** The ISBN supplied by publisher (or Google) for the Google Edition e-book. One day it should be an attribute of the tome cluster. */
            geBibkey?: string;
            /** The imprint id from the ocean devel db for this imprint. */
            imprintId?: string;
            imprintName?: string;
            /** URL to the imprint's website, to go to upon a click on the logo */
            imprintUrl?: string;
            logoHeight?: number;
            /** URL/location for the imprint's logo to display */
            logoLocation?: string;
            /** The logo image's geometry */
            logoWidth?: number;
            /** Percentage of book we are allowed to display This will be deprecated once UpdateVolumesReqHandler returns VolumeViewability. */
            percentBookShown?: number;
            promotionalText?: string;
            /** We may allow imprints to run promotional campaigns. The following fields capture the blurb to display and the URL (ISBN-parameterized) link to provide. */
            promotionalUrl?: string;
            /** Sometimes the Publisher/Imprint Name the book is published under is different from the current name and we may have this information. */
            publishedImprintName?: string;
            /** Need a unique identifier for PFE records, using PVI ID */
            pviRowid?: string;
            title?: string;
            /** Some records are deactivated, suppressed or excluded; we still want to hear about them, but we aren't going to be using their bibdata */
            useBibdata?: boolean;
            verticalType?: string;
        }
        interface OceanVolumeViewability {
            /** The viewability for any locale that is not explicitly listed. */
            defaultViewability?: OceanLocaleViewability;
            DEPRECATEDDefaultViewType?: number;
            /**
             * DEPRECATED: Viewability-Limbo was a state that prevented indexing from running if the viewability of a volume had dropped significantly. It was removed during viewability
             * refactoring: http://go/viewability
             */
            inViewabilityLimbo?: boolean;
            locale?: OceanVolumeViewabilityLocale[];
            /**
             * Whether the volume viewability was updated by the indexer as opposed to a direct update in goovols. The absense of this bit will indicate to the indexer that it should not
             * short-circuit indexing side effects that should occur when viewability changes.
             */
            updatedByIndexer?: boolean;
        }
        interface OceanVolumeViewabilityLocale {
            DEPRECATEDViewType?: number;
            /** The two-character ISO country code for the locale. */
            locale?: string;
            /** The viewability specified for this locale. */
            viewability?: OceanLocaleViewability;
        }
        interface OcrPhotoBoundingBox {
            /** Angle of rotation of (in degrees, clockwise is positive) of the box about the top-left corner. */
            angle?: number;
            /** Sequence of rotated boxes that tightly enclose the text. */
            curvedBox?: OcrPhotoCurvedBoundingBox;
            /** Box height (bottom pixels at top + height - 1). */
            height?: number;
            /** x coordinate of top-left corner */
            left?: number;
            /** y coordinate of top-left corner */
            top?: number;
            /** Box width (rightmost pixels at left + width - 1). */
            width?: number;
        }
        interface OcrPhotoCurve {
            /** The sequence of points that approximate the curve. */
            points?: OcrPhotoCurvePoint[];
        }
        interface OcrPhotoCurvedBoundingBox {
            /** The curve of points along the middle of the text line. */
            midLineCurve?: OcrPhotoCurve;
            /** If top_to_bottom is true, this is the width of the curved box. Otherwise, it is the height of the curved box. */
            thickness?: number;
            /** If true, the curve is interpreted as top to bottom of the line image. Otherwise, it is from left to right. */
            topToBottom?: boolean;
        }
        interface OcrPhotoCurvePoint {
            x?: number;
            /**
             * NOTE: if we wish to support perspective (varying thickness), later on we could extend this message with a thickness field. In that case, CurvedBoundingBox.thickness() would be used
             * as a default if !Point.has_thickness().
             */
            y?: number;
        }
        interface OcrPhotoTextBox {
            /** ID of the text block that this line belongs to. */
            blockId?: number;
            /** Text bounding box. */
            box?: OcrPhotoBoundingBox;
            /** Content type for this box. */
            contentType?: string;
            /** Optional width of characters in the text. */
            symbolWidths?: number[];
            /** Text string. */
            text?: string;
        }
        interface OfficialPagesOfficialKey {
            country?: string;
            language?: number;
            query?: string;
        }
        interface OfficialPagesQuerySet {
            queries?: OfficialPagesOfficialKey[];
            /**
             * This is the fingerprint of the OfficialKey queries in the queries field. The index of a fingerprint in this field corresponds to the index of the fingerprinted query in the queries
             * field. The fingerprint is produced with the QueryCountryLanguageFingerprint function in external-utils.h
             */
            queryCountryLanguageFingerprints?: string[];
        }
        interface OrionDocEntitiesProto {
            docid?: string;
            /** This is encoded using EntityCandidate::Encode */
            encodedEntity?: number[];
        }
        interface PairwiseQScoringData {
            confidenceValue?: number;
            value?: number;
        }
        interface PairwiseQVersionedItem {
            /** The PairwiseQ confidence value corresponding to this version. */
            confidenceValue?: number;
            /** The PairwiseQ value corresponding to this version. */
            value?: number;
            /** The version id. */
            versionId?: number;
        }
        interface PeoplestackFlexorgsProtoInternalExternal {
            /** All evaluations are done within the context of a given application, e.g., "Gmail" and should not be reused in other apps. */
            application?: string;
            /**
             * * There can be multiple states based on the context: 1. AUTOCOMPLETE + Gmail - context 1 2. AUTOCOMPLETE + Chat/Dynamite - context 2 3. "SOME OTHER ACTION" + Gmail - context 3 A
             * client should identify whether a patrticular context is present in the list and only if one is found - use the state that goes alogn with the context, otherwise the client should
             * default to whatever is the safe assumption about "internality/externality" the application should be making (likely, consider everything not explicitly "internal" as "external").
             */
            stateStatus?: PeoplestackFlexorgsProtoInternalExternalStateStatus[];
        }
        interface PeoplestackFlexorgsProtoInternalExternalStateStatus {
            contextType?: string;
            state?: string;
        }
        interface PerDocData {
            /** AppsLink contains Android application IDs in outlinks. It is used to improve results ranking within applications universal. See http://go/apps-universal for the project details. */
            appsLink?: QualityCalypsoAppsLink;
            /** For indexing Asteroid Belt intent scores. See go/asteroid-belt for details. */
            asteroidBeltIntents?: QualityOrbitAsteroidBeltDocumentIntentScores;
            authorObfuscatedGaiaStr?: string[];
            biasingdata?: BiasingPerDocData;
            /** A replacement for BiasingPerDocData that is more space efficient. Once this is live everywhere, biasingdata will be deprecated. */
            biasingdata2?: BiasingPerDocData2;
            BlogData?: BlogPerDocData;
            /**
             * The body words over tokens ratios for the beginning part and whole doc. NB: To save space, field body_words_to_tokens_ratio_total is not set if it has the same value as
             * body_words_to_tokens_ratio_begin (e.g., short docs).
             */
            bodyWordsToTokensRatioBegin?: number;
            bodyWordsToTokensRatioTotal?: number;
            /** the book citation data for each web page, the average size is about 10 bytes */
            BookCitationData?: BookCitationPerDocData;
            /** Brainloc contains location information for the document. See ariane/273189 for details. */
            brainloc?: QualityGeoBrainlocBrainlocAttachment;
            /** A measure of commerciality of the document Score > 0 indicates document is commercial (i.e. sells something) Computed by repository/pageclassifiers/parsehandler-commercial.cc */
            commercialScore?: number;
            compressedQualitySignals?: CompressedQualitySignals;
            /** Compressed URL string used for SETI. */
            compressedUrl?: string;
            contentAttributions?: ContentAttributions;
            /** This field stores the country information for the document in the form of CountryAttachment. */
            countryInfo?: CountryCountryAttachment;
            /** For crawler-ID variations, the crawling context applied to the document. See go/url, and the description in google3/indexing/crawler_id */
            crawlerIdProto?: LogsProtoIndexingCrawlerIdCrawlerIdProto;
            /**
             * This field is used internally by the docjoiner to forward the crawl pageranks from original canonicals to canonicals we actually chose; outside sources should not set it, and it
             * should not be present in actual docjoins or the index.
             */
            crawlPagerank?: number;
            crowdingdata?: CrowdingPerDocData;
            /**
             * Stores dates-related info (e.g. page is old based on its date annotations). Used in FreshnessTwiddler. Use encode/decode functions from
             * quality/timebased/utils/dates-info-helper-inl.h
             */
            datesInfo?: string;
            /** The obfuscated google profile gaia id(s) of the author(s) of the document. This field is deprecated, use the string version. */
            DEPRECATEDAuthorObfuscatedGaia?: string[];
            DEPRECATEDQuarantineWhitelist?: boolean;
            /** Contains desktop interstitials signal for VOLT ranking change. */
            desktopInterstitials?: IndexingMobileInterstitialsProtoDesktopInterstitials;
            /** The document spam score is represented as a 7-bits, going from 0 to 127. */
            DocLevelSpamScore?: number;
            /** 16-bit */
            domainAge?: number;
            /** Free form debug info. NB2: consider carefully what to save here. It's easy to eat lots of gfs space with debug info that nobody needs... */
            Event?: PerDocDebugEvent[];
            /** Date for Events. A web page might list multiple events with different dates. We only take one date (start date) per event. */
            eventsDate?: string[];
            /**
             * This field is available only in the docjoins: it is cleared before building per-doc data in both Mustang and Teragoogle. (MessageSet is inefficient in space for serving data) Use
             * this for all new fields that aren't needed during serving. Currently this field contains: * UrlSignals for the document level spam classifier (when the doclevelspamscore is set). *
             * PerDocLangidData and realtimespam::ClassifierResult for the document level fresh spam classifier (when the doc-level fresh spam score is generated). * MicroblogDocQualitySignals for
             * document-level microblog spam classifier. This only exists in Firebird for now. * spam_buckets::BucketsData for a document-structure hash
             */
            extraData?: any;
            /** Contains Site signal information for Firefly ranking change. See http://ariane/313938 for more details. */
            fireflySiteSignal?: QualityCopiaFireflySiteSignal;
            /**
             * Stores scores of freshness-related classifiers: freshbox article score, live blog score and host-level article score. The encoding/decoding API is in
             * quality/freshness/freshbox/goldmine/freshbox_annotation_encoder.h. To use this field, you MUST join g/pq-classifiers-announce and add your use case at http://shortn/_RYXS2lX2IV.
             */
            freshboxArticleScores?: number;
            /**
             * Stores freshness and aging related data, such as time-related quality metrics predicted from url-pattern level signals. Use the encoding decoding API in
             * quality/freshness/docclassifier/aging/encoded-pattern-signals.h This field is deprecated.
             */
            freshnessEncodedSignals?: string;
            /**
             * Contains encoded FringeQueryPrior information. Unlikely to be meaningful for anyone other than fringe-ranking team. Contact fringe-ranking team if any questions, but do NOT use
             * directly without consulting them.
             */
            fringeQueryPrior?: QualityFringeFringeQueryPriorPerDocData;
            /** geo data; approx 24 bytes for 23M U.S. pages */
            geodata?: string;
            /** The gibberish score is represented in 7 bits, going from 0 to 127. */
            GibberishScore?: number;
            /** 16 bytes of groups2 data: used only in groups2 index */
            GroupsData?: GroupsPerDocData;
            homePageInfo?: number;
            /** The page-rank of the homepage of the site. Copied from the cdoc.doc().pagerank_ns() of the homepage. */
            homepagePagerankNs?: number;
            /**
             * The earliest firstseen date of all pages in this host/domain. These data are used in twiddler to sandbox fresh spam in serving time. It is 16 bit and the time is day number after
             * 2005-12-31, and all the previous time are set to 0. If this url's host_age == domain_age, then omit domain_age Please use //spam/content/siteage-util.h to convert the day between
             * epoch second. Regarding usage of Sentinel values: We would like to check if a value exists in scoring bundle while using in Ranklab AST. For this having a sentinel value will help
             * us know if the field exists or has a sentinel value (in the case it does not exist). 16-bit
             */
            hostAge?: number;
            /** Site rank computed for host-level sitechunks. This value encodes nsr, site_pr and new_nsr. See quality_nsr::util::ConvertNsrDataToHostNsr and go/nsr. */
            hostNsr?: number;
            imagedata?: ImagePerDocData;
            /** This field indicates whether the document is in the newsstand corpus. */
            inNewsstand?: boolean;
            /** Is this document considered spam by the anchor bayes classifier? */
            IsAnchorBayesSpam?: boolean;
            /** Set by the FreshDocs instant doc joiner. See //indexing/instant/hotdocs/README and http://go/freshdocs-hotdocs. */
            isHotdoc?: boolean;
            kaltixdata?: KaltixPerDocData;
            /** The keyword stuffing score is represented in 7 bits, going from 0 to 127. */
            KeywordStuffingScore?: number;
            /** For indexing k'nex annotations for FreshDocs. */
            knexAnnotation?: SocialPersonalizationKnexAnnotation;
            /** Plausible languages in order of decreasing plausibility. Language values are small, IE < 127 so this should compress to one byte each. */
            languages?: number[];
            /**
             * Last significant update of the document. This is sourced from the quality_timebased.LastSignificantUpdate proto as computed by the LSUSelector from various signals. The value is a
             * UNIX timestamp in seconds.
             */
            lastSignificantUpdate?: string;
            /**
             * Metadata about last significant update. Currently this only encodes the quality_timebased.LastSignificantUpdate.source field which contains the info on the source of the signal.
             * NOTE: Please do not read the value directly. Use helpers from quality/timebased/lastsignificantupdate/lsu-helper.h instead.
             */
            lastSignificantUpdateInfo?: string;
            /** Info on how to launch a mobile app to consume this document's content, if applicable (see go/calypso). */
            launchAppInfo?: QualityRichsnippetsAppsProtosLaunchAppInfoPerDocData;
            liveResultsData?: WeboftrustLiveResultsDocAttachments;
            /** Information on localized clusters, which is the relationship of translated and/or localized pages. */
            localizedCluster?: IndexingDupsLocalizedLocalizedCluster;
            /** Additional metadata for lowend mobile documents in the Google index. */
            MobileData?: MobilePerDocData;
            /** If not 0, we should not show the image in overlay mode in image snippets */
            noimageframeoverlayreason?: number;
            /** Stripped site-level signals, not present in the explicit nsr_* fields, nor compressed_quality_signals. */
            nsrDataProto?: QualityNsrNsrData;
            /** This field is propagated to shards. In addition, it is populated at serving time by go/web-signal-joins. */
            nsrIsCovidLocalAuthority?: boolean;
            /** This field is propagated to shards. It will also be populated at serving time by go/web-signal-joins (see b/168114815). */
            nsrIsElectionAuthority?: boolean;
            /**
             * This field is propagated to shards. It will also be populated at serving time by go/web-signal-joins (see b/170607253). Bit indicating whether this site is video-focused, but not
             * hosted on any major known video hosting domains.
             */
            nsrIsVideoFocusedSite?: boolean;
            /**
             * SiteChunk computed for nsr. It some cases it can use more information than just url (e.g. youtube channels). See NsrAnnotator for details. If sitechunk is longer than
             * --populate_nsr_sitechunk_max_length (default=100), it will not get populated. This field might be compressed and needs to be decoded with quality_nsr::util::DecodeNsrSitechunk. See
             * go/nsr-chunks for more details. This field contains only nontrivial primary chunks.
             */
            nsrSitechunk?: string;
            /** Total number of urls encoded in the url section = # of alternate urls + 1 */
            numUrls?: number;
            /** 28 bytes per page, only in the Ocean index */
            oceandata?: OceanPerDocData;
            /**
             * Onsite prominence measures the importance of the document within its site. It is computed by propagating simulated traffic from the homepage and high craps click pages. It is a
             * 13-bit int.
             */
            onsiteProminence?: number;
            origin?: number;
            /**
             * The original content score is represented as a 7-bits, going from 0 to 127. Only pages with little content have this field. The actual original content score ranges from 0 to 512.
             * It is encoded with quality_q2::OriginalContentUtil::EncodeOriginalContentScore(). To decode the value, use quality_q2::OriginalContentUtil::DecodeOriginalContentScore().
             */
            OriginalContentScore?: number;
            /** The number of hard tokens in the title. */
            originalTitleHardTokenCount?: number;
            /** Experimental pageranks (DEPRECATED; only pagerank in MustangBasicInfo is used). */
            pagerank?: number;
            pagerank0?: number;
            pagerank1?: number;
            pagerank2?: number;
            /** String that encodes the position ranges for different regions of the document. See "indexer/pageregion.h" for an explanation, and how to decode the string */
            pageregions?: string;
            pageTags?: number[];
            phildata?: PhilPerDocData;
            /** Additional metadata for Premium document in the Google index. */
            PremiumData?: PremiumPerDocData;
            /** This field stores information about product sites. */
            productSitesInfo?: QualityProductProductSiteData;
            /** bitmask of QuarantineBits (or'd together) used to store quarantine related information. For example: QUARANTINE_WHITELIST | QUARANTINE_URLINURL. */
            QuarantineInfo?: number;
            /**
             * The set of (query, country, language) triples for which this document is considered to be the official page. For example, www.britneyspears.com would be official for ("britney
             * spears", "us", 0) and others (0 is English).
             */
            queriesForWhichOfficial?: OfficialPagesQuerySet;
            /** Top two document language BCP-47 codes as generated by the RosettaLanguageAnnotator in the decreasing order of probability. */
            rosettaLanguages?: string[];
            /** Application information associated to the document. */
            rsApplication?: RepositoryAnnotationsRdfaRdfaRichSnippetsApplication;
            /**
             * Top document language as generated by SAFT LangID. For now we store bare minimum: just the top 1 language value, converted to the language enum, and only when different from the
             * first value in 'languages'.
             */
            saftLanguageInt?: number[];
            /** DEPRECATED ---------------------------------------------------------------- Please do not use these fields in any new code. experimental */
            ScaledExptIndyRank?: number;
            /** experimental */
            ScaledExptIndyRank2?: number;
            /** experimental */
            ScaledExptIndyRank3?: number;
            ScaledExptSpamScoreEric?: number;
            ScaledExptSpamScoreYoram?: number;
            /** The independence rank is represented as a 16-bit integer, which is multiplied by (max_indy_rank / 65536) to produce actual independence rank values. max_indy_rank is typically 0.84. */
            ScaledIndyRank?: number;
            /** End DEPRECATED ------------------------------------------------------------ Link age score is represented as a 7-bit integer, going from 0 to 127. */
            ScaledLinkAgeSpamScore?: number;
            /**
             * Selection tier rank is a language normalized score ranging from 0-32767 over the serving tier (Base, Zeppelins, Landfills) for this document. This is converted back to fractional
             * position within the index tier by scaled_selection_tier_rank/32767.
             */
            scaledSelectionTierRank?: number;
            ScaledSpamScoreEric?: number;
            /** Spamscores are represented as a 7-bit integer, going from 0 to 127. */
            ScaledSpamScoreYoram?: number;
            /** Scholar/Science Document type: <0 == not a Science Document -- default 0 == Science doc fully visible >0 == Science doc but limited visibility, the number is the visible terms */
            scienceDoctype?: number;
            /** Deprecated 2016/01/14. */
            scienceHoldingsIds?: string[];
            /**
             * SemanticDate, estimated date of the content of a document based on the contents of the document (via parsing), anchors and related documents. Date is encoded as a 32-bits UNIX date
             * (1970 Jan 1 epoch). Confidence is encoded using a SemanticDate specific format. For details of encoding, please refer to
             * quality/freshness/docclassifier/semanticdate/public/semantic_date.proto
             */
            semanticDate?: number;
            /** DEPRECATED: semantic_date_confidence replaced by semantic_date_info. */
            semanticDateConfidence?: number;
            /** Info is encoded using a SemanticDate specific format. Contains confidence scores for day/month/year components as well as various meta data required by the freshness twiddlers. */
            semanticDateInfo?: number;
            /** A set of cluster ids which are generated in Alexandria and used to de-dup results at serving time. */
            servingTimeClusterIds?: IndexingDocjoinerServingTimeClusterIds;
            shingleInfo?: ShingleInfoPerDocData;
            /** Additional metadata for smartphone documents in the Google index. */
            smartphoneData?: SmartphonePerDocData;
            smearingMaxTotalOffdomainAnchors?: number;
            /**
             * For Social Search we store the fingerprint of the SG node name. This is used in one of the superroot's PRE_DOC twiddlers as a lookup key for the full Social Search data. PRE_DOC =
             * twiddlers firing before the DocInfo request is sent to the mustang backend.
             */
            socialgraphNodeNameFp?: string;
            /** Site level scores coming from spambrain. */
            spambrainData?: SpamBrainData;
            /** The document total spam score identified by spambrain, going from 0 to 1. */
            spambrainTotalDocSpamScore?: number;
            /** Actions based on Cookbook recipes that match the page. */
            spamCookbookAction?: SpamCookbookAction;
            /**
             * Contains hacked site signals which will be used in query time joins. As of Oct'19, the field is stored in a separate corpus. It'll only be populated for in-flight requests between
             * retrieve and full-score in perdocdata. So no extra storage is needed on muppet side.
             */
            spamMuppetSignals?: SpamMuppetjoinsMuppetSignals;
            /** The spamrank measures the likelihood that this document links to known spammers. Its value is between 0 and 65535. */
            spamrank?: number;
            /** For SpamTokens content scores. Used in SiteBoostTwiddler to determine whether a page is UGC Spam. See go/spamtokens-dd for details. */
            spamtokensContentScore?: number;
            /** The spamword score is represented in 7-bits, going from 0 to 127. */
            SpamWordScore?: number;
            /** Tag-site-ness of a page, repesented in 7-bits range from 0 to 100. Smaller value means worse tag page. */
            TagPageScore?: number;
            /** Encoded Document Time Sensitivity signal. */
            timeSensitivity?: number;
            /** Number of hard tokens originally in title without counting the stopwords. */
            titleHardTokenCountWithoutStopwords?: number;
            ToolBarData?: ToolBarPerDocData;
            /**
             * A copy of the value stored in /namespace/indexing/wwwglobal//fakepr/* for this document. A value of quality_bakery::FakeprUtils::kUnknownToolbarPagerank indicates that we don't have
             * toolbar pagerank for this document. A value between 0 and 10 (inclusive) means that this is the toolbar pagerank of the page. Finally, if this value is not set it means that the
             * toolbar pagerank is equivalent to: quality_bakery::FakeprUtils::EstimatePreDemotionFromPagerankNearestSeeds( basic_info.pagerank_ns()) called on the MustangBasicInfo attachment for
             * the same document.
             */
            toolbarPagerank?: number;
            /** Top petacat of the site. Used in SiteboostTwiddler to determine result/query matching. */
            topPetacatTaxId?: number;
            topPetacatWeight?: number;
            /** This field stores information about good travel sites. */
            travelGoodSitesInfo?: QualityTravelGoodSitesData;
            /** For now, the count of matching trendspam queries. */
            trendspamScore?: number;
            /** This field is propagated to shards. Stores clustering information on a site level for the Tundra project. */
            tundraClusterId?: number;
            /** The uac spam score is represented in 7 bits, going from 0 to 127. Threshold is 64. Score >= 64 is considered as uac spam. */
            uacSpamScore?: number;
            /**
             * These two fingerprints are used for de-duping results in a twiddler. They should only be populated by freshdocs, and will only be present for documents that are chosen to be
             * canonicals in a cluster whose previous canonical is also in the index. Additionally, url_after_redirects_fp is only present if it is different from a fingerprint of the URL.
             */
            urlAfterRedirectsFp?: string;
            /** Contains url poisoning data for suppressing spam documents. */
            urlPoisoningData?: UrlPoisoningData;
            /** For indexing v2 k'nex, see/go/knex-v2-doc-annotation for details. */
            v2KnexAnnotation?: QualitySherlockKnexAnnotation;
            videoCorpusDocid?: string;
            videodata?: VideoPerDocData;
            /** Audio-based language classified by Automatic Language Identification (only for watch pages). */
            videoLanguage?: QualityVidyaVideoLanguageVideoLanguage;
            /** Contains page UX signals for VOLT ranking change. See http://ariane/4025970 for more details. */
            voltData?: IndexingMobileVoltVoltPerDocData;
            /** Language classified by the WatchPageLanguage Model (go/watchpage-language). Only present for watch pages. */
            watchpageLanguageResult?: WatchpageLanguageWatchPageLanguageResult;
            webmirrorEcnFp?: string;
            /** WebRef entities associated to the document. See go/webref for details. */
            webrefEntities?: RepositoryWebrefWebrefMustangAttachment;
            WhirlpoolDiscount?: number;
            /**
             * Stores scores of ymyl health classifier as defined at go/ymyl-classifier-dd. To use this field, you MUST join g/pq-classifiers-announce and add your use case at
             * http://shortn/_nfg9oAldou.
             */
            ymylHealthScore?: number;
            /**
             * Stores scores of ymyl news classifier as defined at go/ymyl-classifier-dd. To use this field, you MUST join g/pq-classifiers-announce and add your use case at
             * http://shortn/_nfg9oAldou.
             */
            ymylNewsScore?: number;
        }
        interface PerDocDebugEvent {
            /** depends on the source */
            Message?: string;
            /** source tag, helps interpret value/message */
            Source?: string;
            /** seconds since the epoch */
            Timestamp?: number;
            /** depends on the source */
            Value?: string;
        }
        interface PersonalizationMapsAliasAliasId {
            /**
             * A unique identifier for this alias, this identifier is unique to the type of this Alias. This means that aliases of different types can have the same sub_id, hence always use the
             * full AliasId message to refer to an alias, not this field only. Because HOME and WORK aliases are unique, aliases of type HOME or WORK always have sub_id 0.
             */
            subId?: string;
            type?: string;
        }
        interface PersonalizationMapsAliasIcon {
            /**
             * The id of the alias associated with this point. This is used to query for details for the info window and to display different icons depending on the AliasType contained in this
             * message.
             */
            aliasId?: PersonalizationMapsAliasAliasId;
            /**
             * If this is a dropped pin alias, the leaf (level 30) S2 cell ID corresponding to the aliased lat/lng. Calculated once and stored here so that it can safely be used as an identifier
             * across clients without risk of rounding differences leading to different values.
             */
            droppedPinS2cellId?: string;
            /** The featureid that was associated with the alias when it was saved. If this is not set the lat/lng in 'point' is the aliased entity, i.e. this is a dropped pin alias. */
            featureId?: GeostoreFeatureIdProto;
            /** For non-address feature aliases (e.g. businesses), the name of the feature (formatted from the FeatureProto) when it was saved. */
            featureName?: string;
            /** The type of the feature associated with the alias. */
            featureType?: string;
            /** One-line geocoded address that this lat/lng represents at the time this alias was created by the user. */
            formattedAddress?: string;
            /** Free-text alias if alias type is NICKNAME. Otherwise unset. Limited to 40 characters. */
            nickname?: string;
            /** lat/lng the icon is to be shown at. */
            point?: GeostorePointProto;
            /** The id of the sticker asset chosen by the user to replace the default asset for the alias. */
            stickerId?: number;
            /** If the feature associated with the alias has synthetic_geometry. */
            syntheticFeature?: boolean;
            /** [INTERNAL ONLY] Last update of bigtable by kansas, in microseconds. Volatile only and not saved in kansas column. inmemory only because >= 16. */
            timestamp?: string;
        }
        interface PersonalizationSettingsApiProtoLocalDiscoveryLocalDiscoverySettingsMetadata {
            /** Contexts regarding the preferences from OPA_RECIPES. */
            opaRecipesContext?: PersonalizationSettingsApiProtoLocalDiscoveryOpaRecipesContext;
            /** The UI entry point from which the entity preference was set. */
            uiEntryPoint?: string;
        }
        interface PersonalizationSettingsApiProtoLocalDiscoveryOpaRecipesContext {
            /** The recipe doc id where the setting comes from. */
            docId?: string;
            /** The recipe url where the setting comes from. */
            url?: string;
        }
        interface PhilPerDocData {
            /** phil data , approx 70 bytes for top 500M */
            PhilString?: string;
            PhilVersion?: number;
        }
        interface PhotosAnimationMetadata {
            /** The duration of the animation or movie (not including any looping), in milliseconds. If there is only a single frame (and thus not animated), the duration will be 0. */
            durationMs?: string;
            /**
             * The number of times the animation plays. If 0, the animation will loop indefinitely. If positive, this number includes the initial playthrough. For example, a value of 3 means that
             * each frame is shown 3 times.
             */
            loopCount?: number;
            numFrames?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface PhotosDynamicDepthMetadata {
        }
        interface PhotosFourCMetadata {
            caption?: string;
            copyright?: string;
            creator?: string[];
            credit?: string;
        }
        interface PhotosGDepthMetadata {
            /** Depth map far plane distance. */
            far?: number;
            /** Depth map format. */
            format?: string;
            /** Depth map source image height. */
            imageHeight?: number;
            /** Depth map source image width. */
            imageWidth?: number;
            /** Depth map mime type. */
            mime?: string;
            /** Depth map near plane distance. */
            near?: number;
            /** Depth map units of distance. */
            units?: string;
        }
        interface PhotosImageMetadata {
            actionadvised?: string;
            addlmodelinfo?: string;
            advisory?: string[];
            altitude?: number;
            animationMetadata?: PhotosAnimationMetadata;
            aperturefnumber?: number;
            aperturevalue?: number;
            artworkorobject?: string[];
            audioduration?: string;
            audiooutcue?: string;
            audiosamplingrate?: string;
            audiosamplingresolution?: string;
            audiotype?: string;
            author?: string;
            authorposition?: string;
            /** Indicates whether auto-enhance has been applied to the image. */
            autoenhance?: boolean;
            baseurl?: string;
            /** The number of bits per pixel used to express a color. Most images have 8-bit depth and Photos/thumbnailer currently do not support more than 8 bits (except RAW). */
            bitDepth?: number;
            /** Start of reflected fields. These do not duplicate the above fields. */
            bitspersample?: number;
            brightnessvalue?: number;
            burstuuid?: string;
            cameraid?: string;
            /** Exif camera make */
            cameramake?: string;
            /** Exif camera model */
            cameramodel?: string;
            /** Caption embedded in IPTC */
            caption?: string;
            captionwriter?: string;
            capturesoftware?: string;
            category?: string;
            ccdwidth?: number;
            celllength?: number;
            cellwidth?: number;
            certificate?: string;
            /** A typed representation that translates the values from ycbcrsubsampling. */
            chromasubsampling?: string;
            ciadrcity?: string;
            ciadrctry?: string;
            ciadrextadr?: string[];
            ciadrpcode?: string;
            ciadrregion?: string;
            ciemailwork?: string;
            citelwork?: string;
            city?: string;
            ciurlwork?: string;
            colormap?: number;
            /** Indicates whether or not the source image had an embedded color profile. */
            colorprofile?: boolean;
            colorspace?: number;
            compressedbitsperpixel?: number;
            compressionlevel?: number;
            contact?: string;
            contentlocationcode?: string[];
            contentlocationname?: string[];
            contrast?: number;
            contributor?: string[];
            copyrightnotice?: string;
            country?: string;
            countrycode?: string;
            coverage?: string;
            createdate?: string;
            credits?: string;
            croppedareaimageheightpixels?: number;
            croppedareaimagewidthpixels?: number;
            croppedarealeftpixels?: number;
            croppedareatoppixels?: number;
            customrendered?: number;
            cvterm?: string[];
            date?: string;
            datecreated?: string;
            datesent?: string;
            datetime?: string;
            datetimedigitized?: string;
            /**
             * 0 = no daylight savings, 1 = daylight savings enabled. Note that this field only represents whether the setting in the camera was turned on or off. It must not be used to modify the
             * timestamp of the photo. That is, the capture time is already completely determined by exif_time, timezoneoffset and timezoneminutes.
             */
            daylightsavings?: number[];
            DEPRECATEDBlendingtype?: string;
            /**
             * This field was originally marked incorrectly as optional (rather than repeated). In order to fix it, the first field has been marked as deprecated and replaced with a field with a
             * new name and tag number.
             */
            DEPRECATEDGpstimestamp?: number;
            DEPRECATEDIscolor?: number;
            DEPRECATEDLargestvalidinteriorrectheight?: number;
            DEPRECATEDLargestvalidinteriorrectleft?: number;
            DEPRECATEDLargestvalidinteriorrecttop?: number;
            DEPRECATEDLargestvalidinteriorrectwidth?: number;
            DEPRECATEDProcess?: number;
            destination?: string[];
            /** +/- 90 inclusive */
            destinationLatitude?: number;
            /** +/- 180 inclusive */
            destinationLongitude?: number;
            digimageguid?: string;
            digitalsourcefiletype?: string;
            digitalsourcetype?: string;
            digitalzoomratio?: number;
            distance?: number;
            /**
             * DynamicDepth (go/dynamic-depth) metadata is described in the metadata of sub-images in the container. The presence of this field can be used to determine that an image is in the
             * dynamic depth format.
             */
            dynamicDepthMetadata?: any;
            editorialupdate?: string;
            editstatus?: string;
            envelopenumber?: string;
            envelopepriority?: string;
            event?: string;
            /**
             * 4C metadata (caption, copyright, creator, credit) specific to each of the three metadata segments (EXIF, XMP, IPTC). These are used to keep separate the 4C data from each segment so
             * that we can properly preserve the per-segment 4C data on write (when PreserveLevel is set appropriately).
             */
            exif4c?: PhotosFourCMetadata;
            /**
             * Timestamp embedded in the image. The value comes from the first valid date-time field extracted from the metadata in the order: 1) datecreated (ie. DateTimeOriginal) 2)
             * datetimedigitized (ie. DateTimeDigitized) 3) datetime (ie. DateTime or last modified date) The type of this field is equivalent to a time_t (ie. number of seconds since the epoch -
             * 00:00 hours, Jan 1, 1970) except that it is an int64 rather than an int.
             */
            exifTime?: string;
            /**
             * The exif_time_utc field is a UTC-based alternative to the exif_time field, which is in local time, rather than UTC. If they were not separate, clients would be unable to distinguish
             * if the source were UTC- or local-based.
             */
            exifTimeUtc?: string;
            /** The exif_time_utc_source indicates the source from which the exif_time_utc field is calculated. */
            exifTimeUtcSource?: string;
            expirationdate?: string;
            expirationtime?: string;
            exposurebias?: number;
            exposureindex?: number;
            exposurelockused?: boolean;
            exposuremode?: number;
            exposureprogram?: number;
            exposuretime?: number;
            extrasamples?: number;
            fillorder?: number;
            firmware?: string;
            firstphotodate?: string;
            fixtureidentifier?: string;
            flashcompensation?: number;
            flashenergy?: number;
            flashreturn?: number;
            flashused?: number;
            focallength?: number;
            focallengthin35mmfilm?: number;
            focalplaneunits?: number;
            focalplanexres?: number;
            format?: string;
            freebytecounts?: string;
            freeoffsets?: number;
            fullpanoheightpixels?: number;
            fullpanowidthpixels?: number;
            function?: boolean;
            gaincontrol?: number;
            gaudiomime?: string;
            /**
             * A unique String. The property should be present and identical for all images that make up a burst. It should be unique across devices (UUID recommended). Unlike
             * GCreations:CameraBurstId, we should use images with this property to create auto collages and animations.
             */
            gcameraburstid?: string;
            /**
             * A value of 1 indicates that this was the primary (“best shot”) at capture time. Within Photos we should only treat this image as the best shot if the user hasn’t made an explicit
             * choice. Defining the initial primary allows consistency between OEMs, Photos clients, and the Photos backend. This value is optional, cameras are not required to set it on any photo
             * in a burst. Clients will default to the 0th frame, but may run an algorithm to pick a better default.
             */
            gcameraburstprimary?: number;
            /**
             * The possible values are: “Animation”, “Collage”, “Pano”, “Movies”. Photos will avoid creating the listed types using the containing image or video. The property is optional. The
             * property can be included multiple times to disable creation of multiple different types.
             */
            gcameradisableautocreation?: string[];
            /**
             * The following XMP metadata are used specifically for MicroVideo. More information about MicroVideo format can be found at go/photos-microvideo-format A value of 1 indicates that
             * this file was a MicroVideo at capture time. Otherwise, this is not a MicroVideo (not set or 0).
             */
            gcameramicrovideo?: number;
            /**
             * The offset in bytes from the end of the file to the point where the appended mp4 begins (equivalent to the length of the compressed mp4). This field might be provided in the
             * original MicroVideo from client, but it might become invalid when the image component is edited, so it is expected that the thumbnailer will validate it and find the correct value
             * (by scanning through the JPEG) if it is invalid. In other words, only a valid offset should be returned by thumbnailer.
             */
            gcameramicrovideooffset?: number;
            /** The presentation timestamp in microseconds of the video frame corresponding to the image still. Value may be -1 to denote unset/unspecified. */
            gcameramicrovideopresentationtimestampus?: number;
            /** Indicates the file format version of the MicroVideo (initially 1). */
            gcameramicrovideoversion?: number;
            /**
             * An indication that this item should be treated as a Motion Photo. 0 -> Not Motion Photo, 1 -> Motion Photo, everything else is undefined per the spec. If it's a motion photo, the
             * previous gcamera fields should be ignored.
             */
            gcameramotionphoto?: number;
            /** The presentation timestamp in microseconds of the video frame corresponding to the image still. Value may be -1 to denote unset/unspecified. */
            gcameramotionphotopresentationtimestampus?: number;
            /** Indicates the Motion Photo version of the spec (initially 1). */
            gcameramotionphotoversion?: number;
            /**
             * Camera creations metadata. The opaque id string created by the OEM. For bursts, this field should not be present. Instead, the two properties below will allow Photos to identify and
             * provide special treatment for bursts.
             */
            gcameraspecialtypeid?: string;
            gcreationscameraburstid?: string;
            /** String representation of creation type. Should be one of {"GCameraCollage", "GCameraAnimation", "GCameraGroupSmiles", "GPhotosCollage", "GPhotosAnimation"}. */
            gcreationstype?: string;
            gdepthMetadata?: PhotosGDepthMetadata;
            gimagemime?: string;
            /** This is in UTC time. Format is YYYY:mm:dd. */
            gpsdatestamp?: string;
            gpsdestbearing?: number;
            gpsdestbearingref?: string;
            gpsdestdistance?: number;
            gpsdestdistanceref?: string;
            gpsdestlatitude?: number;
            gpsdestlatituderef?: string;
            gpsdestlongitude?: number;
            gpsdestlongituderef?: string;
            gpsdifferential?: number;
            gpsdop?: number;
            gpsimgdirection?: number;
            gpsimgdirectionref?: string;
            gpsmapdatum?: string;
            gpsmeasuremode?: string;
            gpssatellites?: string;
            gpsspeed?: number;
            gpsspeedref?: string;
            gpsstatus?: string;
            /** This is in UTC Time. Contains three floats: hour, minute and second. Supports subsecond resolution. */
            gpstime?: number[];
            gpstrack?: number;
            gpstrackref?: string;
            grayresponsecurve?: number;
            grayresponseunit?: number;
            /**
             * The image has an alpha channel (potential transparency). If the image is decoded, this will be updated to indicate whether there is any active transparency. Formats supporting
             * alpha: png, webp, gif, heif.
             */
            hasAlpha?: boolean;
            headline?: string;
            height?: number;
            hostcomputer?: string;
            identifier?: string[];
            imagenumber?: string;
            imageorientation?: string;
            imagetype?: string;
            initialhorizontalfovdegrees?: number;
            initialverticalfovdegrees?: number;
            initialviewheadingdegrees?: number;
            initialviewpitchdegrees?: number;
            initialviewrolldegrees?: number;
            instructions?: string;
            intellectualgenre?: string;
            interoperabilityindex?: string;
            iptc4c?: PhotosFourCMetadata;
            iptclastedited?: string;
            /** The image is a Multi-Picture Object. */
            ismpformat?: boolean;
            isoequivalent?: number;
            keyword?: string[];
            label?: string;
            language?: string[];
            languageidentifier?: string;
            lastphotodate?: string;
            /** GPS Info: +/- 90 inclusive */
            latitude?: number;
            lens?: string;
            lensid?: string;
            lensinfo?: string;
            lightsource?: number;
            location?: string;
            locationshown?: string[];
            /** +/- 180 inclusive */
            longitude?: number;
            marked?: boolean;
            maxaperturevalue?: number;
            maxavailheight?: number;
            maxavailwidth?: number;
            maxsamplevalue?: number;
            metadatadate?: string;
            meteringmode?: number;
            /**
             * This is similar to gcameramicrovideooffset, except it stores the unverified value that was provided in the motion photo file. This field is not part of the XMP or spec. It is used
             * to ensure we preserve data from the original file when offset is modified.
             */
            microvideooriginaloffset?: number;
            /** Mime type of image */
            mimeType?: number;
            minormodelagedisclosure?: string;
            minsamplevalue?: number;
            mode?: number;
            modelage?: number[];
            modelreleaseid?: string[];
            modelreleasestatus?: string;
            modifydate?: string;
            /**
             * The Motion Photo Video Data (MPVD) box header of a HEIF motion photo. It is used for reconstructing the original moton photo bytes. See go/photos-be-heic-motion-photos for more
             * details.
             */
            motionphotovideodataboxheader?: string;
            nickname?: string;
            objectattributereference?: string[];
            objectcycle?: string;
            objecttypereference?: string;
            offsettime?: string;
            offsettimedigitized?: string;
            offsettimeoriginal?: string;
            organisationinimagecode?: string[];
            organisationinimagename?: string[];
            /** Exif camera orientation. "1" means "no rotation". */
            orientation?: number;
            originatingprogram?: string;
            owner?: string[];
            ownername?: string;
            panoramaMetadata?: PhotosPanoramaMetadata;
            personinimage?: string[];
            photometricinterpretation?: number;
            planarconfiguration?: number;
            poseheadingdegrees?: number;
            posepitchdegrees?: number;
            poserolldegrees?: number;
            primarychromaticities?: number;
            productid?: string[];
            programversion?: string;
            projectiontype?: string;
            propertyreleaseid?: string[];
            propertyreleasestatus?: string;
            publisher?: string[];
            rating?: number;
            redeyemode?: boolean;
            referenceblackwhite?: number;
            referencedate?: string[];
            referencenumber?: string[];
            referenceservice?: string[];
            relatedimagefileformat?: string;
            relatedimageheight?: string;
            relatedimagewidth?: string;
            relatedsoundfile?: string;
            relation?: string[];
            releasedate?: string;
            releasetime?: string;
            resolutionunit?: number;
            /**
             * being returned to caller Use values defined in "MIME_TYPE" This field is deprecated. Rotation is now accomplished via ImageInfo.exif_orientation and ImageInfo.edit_list. Number of
             * degrees (0, 90, 180,
             */
            rotate?: number;
            rowsperstrip?: string;
            samplesperpixel?: number;
            saturation?: number;
            scene?: string[];
            scenecapturetype?: number;
            sensingmethod?: number;
            sensorheight?: number;
            sensorwidth?: number;
            serialnumber?: string;
            serviceidentifier?: string;
            sharpness?: number;
            shutterspeedvalue?: number;
            software?: string;
            source?: string;
            sourcephotoscount?: number;
            spectralsensitivity?: string;
            state?: string;
            stitchingsoftware?: string;
            stripbytecounts?: string;
            stripoffsets?: string;
            subjectarea?: number;
            subjectcode?: string[];
            subjectdistancerange?: number;
            subjectlocation?: number;
            subjectreference?: string[];
            sublocation?: string;
            subsectime?: string;
            subsectimedigitized?: string;
            subsectimeoriginal?: string;
            supplementalcategory?: string[];
            thresholding?: number;
            /** The build CL for the version of thumbnailer that built this image. */
            thumbnailerBuildCl?: number;
            timesent?: string;
            /** Remaining minutes of offset. */
            timezoneminutes?: number[];
            /**
             * The elements in the timezone and daylight savings field arrays correspond to the following date/time fields: 0) datecreated (ie. DateTimeOriginal) 1) datetime (ie. DateTime or last
             * modified date) 2) datetimedigitized (ie. DateTimeDigitized) If the field does not exist, then there is no valid time zone information for that date/time field. Offset in hours.
             */
            timezoneoffset?: number[];
            title?: string;
            transmissionreference?: string;
            type?: string[];
            /** For unique hash: */
            uniqueid?: string;
            uno?: string;
            urgency?: string;
            url?: string;
            usageterms?: string;
            /** GPano-related fields. A handful of these have been deprecated due to a change in the spec since its initial design. */
            usepanoramaviewer?: boolean;
            version?: string;
            webstatement?: string;
            whitebalance?: number;
            whitepoint?: number;
            /** width and height are before any rotation (including EXIF orientation). */
            width?: number;
            xmp4c?: PhotosFourCMetadata;
            xresolution?: number;
            ycbcrcoefficients?: number;
            ycbcrpositioning?: number;
            ycbcrsubsampling?: number;
            yresolution?: number;
        }
        interface PhotosPanoramaMetadata {
            sphericalPanorama?: boolean;
            /** True if the image is a VR180 image. See go/3d180 for details. */
            vr180Panorama?: boolean;
        }
        interface PhotosVisionGroundtruthdbNormalizedBoundingBox {
            xmax?: number;
            xmin?: number;
            ymax?: number;
            ymin?: number;
        }
        interface PhotosVisionObjectrecFeatureVector {
            /** For single precision floating point data */
            floatData?: number[];
        }
        interface PhotosVisionObjectrecGeoLocation {
            /** Altitude of the point above the earth's surface, in meters. */
            altitudeMeters?: number;
            /** Country code string. */
            countryCode?: string;
            /** Indicates if the lat/lon above is assumed to come from a GPS device. */
            fromGps?: boolean;
            /** Latitude in degrees north. Values south of the equator are negative. */
            lat?: number;
            /**
             * When applied to a single point, represents the estimated error bounds of manual geotagging. The estimate is based on size of the bounding box of the map used for manual geotagging.
             * When applied to a group of points, the error bounds represent the dispersion around the group center (lat/lon above). The dispersion in this case is computed as half the
             * interquartile range. Reference: http://en.wikipedia.org/wiki/Interquartile_range (lat +/- lat_error_bound, lng +/- lng_error_bound).
             */
            latErrorBound?: number;
            /** Longitude in degrees east. Values west of 0 deg are negative. */
            lon?: number;
            lonErrorBound?: number;
        }
        interface PhotosVisionObjectrecGlobalFeature {
            /** Optional info provided by the feature extractor. */
            additionalInfo?: string;
            featureVector?: PhotosVisionObjectrecFeatureVector;
            quantizedFeatureVector?: PhotosVisionObjectrecQuantizedFeatureVector;
            /** Tag for this global feature. E.g., "DELG", "SBv4" or "DELG_region1". */
            tag?: string;
            version?: string;
        }
        interface PhotosVisionObjectrecImageTemplate {
            /** Name of the author or image source. User-defined. Must be NULL-terminated. */
            authorName?: string;
            /**
             * Identifier for which corpus the image belongs to. Currently Cyclone uses this field in: - photos_vision_objectrec.SpatialMatcherRequest.residual_template to select which spatial
             * matcher should be applied to the candidate matches - photos_vision_objectrec.CustomCorpusQuantizer to map a custom corpus to one or more posting lists
             */
            corpus?: string;
            /** The geolocation of the image. Assumed to represent the location where the photo was taken from. */
            geoLocation?: PhotosVisionObjectrecGeoLocation;
            globalFeature?: PhotosVisionObjectrecGlobalFeature[];
            imageHeight?: number;
            /** Unique identifier for the image used to compute this template. */
            imageId?: string;
            /** URL or filename of the image used to compute this template. User-defined. Must contain only ASCII characters and be NULL-terminated. */
            imageUrl?: string;
            /** Dimension of the image used to compute this template. */
            imageWidth?: number;
            info?: string;
            /** Tags pertaining to this image. User-defined. Must be NULL-terminated. */
            objectInfo?: string[];
            /** Name of the object/scene depicted. User-defined. Must contain only ASCII characters and be NULL-terminated. */
            objectName?: string;
            /**
             * Opaque template data. May be used to pass through additional data from template sources to processing modules, that is not already covered by other members of this PB. It is the
             * responsibility of processing modules to verify that the data is in a compatible format.
             */
            opaqueData?: string;
            /** Region-of-interest: The bounding box of the object or scene depicted in the image. */
            roi?: PhotosVisionObjectrecROI;
            subset?: PhotosVisionObjectrecImageTemplateSubSet[];
            /** Feature version. */
            version?: string;
        }
        interface PhotosVisionObjectrecImageTemplateSubSet {
            descriptor?: PhotosVisionObjectrecLocalDescriptor[];
            descriptorType?: number;
            /** Used to indicate if the descriptor is binary or not. When decompressing feature this is useful to decide calling different decompression functions. */
            isBinaryDescriptor?: boolean;
            /** Used to store the number of descriptors for statistical purposes, if the descriptors themselves are not stored. */
            numDescriptors?: number;
        }
        interface PhotosVisionObjectrecLocalDescriptor {
            /**
             * Optional affine matrix. Supersedes scale and orientation if present. r' = affine_matrix.r + (x,y) defines an affine transform from the normalized image patch (in which the interest
             * point is centered at the origin with scale 1) to the image. If the affine matrix is set, the following approximations are recommended: scale = sqrt(0.5 * (xx*xx + xy*xy + yx*yx +
             * yy*yy)); orientation = atan2(yx - xy, xx + yy); If not present, the affine matrix can be computed from scale and orientation as: xx = scale * cos(orientation); xy = scale *
             * -sin(orientation); yx = scale * sin(orientation); yy = scale * cos(orientation);
             */
            affineMatrix?: PhotosVisionObjectrecMatrix2D;
            data?: string;
            /**
             * data_factor and data represent the local descriptor vector in a compressed format, using only 8 bit per value. Each byte of the data string yields one component of the local
             * descriptor by bit-casting it to an int8 and multiplying it by data_factor. Protocol buffers do not support int8 directly.
             */
            dataFactor?: number;
            /** Unquantized feature vector (float). */
            featureVector?: PhotosVisionObjectrecFeatureVector;
            /**
             * Opaque descriptor data. May be used to pass through descriptor data from descriptor sources to processing modules, that is not already covered by data/data_factor and/or cannot be
             * expressed as a vector of numbers. It is the responsibility of processing modules to verify that the data is in a compatible format.
             */
            opaqueData?: string;
            /** Orientation is optional, as some interest point detectors don't compute it. The range of orientation is [-pi,pi). */
            orientation?: number;
            /** Each interest point must have a characteristic scale > 0. */
            scale?: number;
            /** The strength or weight, indicating the relative significance of this point. */
            strength?: number;
            /**
             * The position in the image with sub-pixel accuracy. The center of the upper left pixel has coordinates (0.0, 0.0). Thus the range for x and y is (-0.5, width - 0.5) x (-0.5, height -
             * 0.5).
             */
            x?: number;
            y?: number;
        }
        interface PhotosVisionObjectrecMatrix2D {
            xx?: number;
            xy?: number;
            yx?: number;
            yy?: number;
        }
        interface PhotosVisionObjectrecQuantizedFeatureVector {
            data?: string;
            dataFactor?: number;
        }
        interface PhotosVisionObjectrecROI {
            xMax?: number;
            xMin?: number;
            yMax?: number;
            yMin?: number;
        }
        interface PornFlagData {
            /**
             * Aggregated brain_porn_scores for navboost co-clicked images. Historical: this signal is deprecated and no longer populated as of 2020-12-01. Refer to b/172897542 for more
             * information.
             */
            coclickBrainScores?: ImageSafesearchContentBrainPornAnnotation;
            /** Score predicting how likely an image is offensive or suggestive about CSAI (child sexual abuse imagery). */
            csaiScore?: number;
            /** DebugInfo stores debug information from the overall classifier. This allows for instance to update counters related to blacklisting without running the full classifier again. */
            debugInfo?: ImagePornDebugInfo[];
            /** Final offensive score based on image salient terms and image OCR vulgar and offensive scores. */
            finalOffensiveScore?: number;
            /** Final violence score based on some image signals (brain pixel score, co-clicked images violence score, navboost queries score, etc.). */
            finalViolenceScore?: number;
            /** A string that indicates the version of SafeSearch classifier used to compute final_violence_score. */
            finalViolenceScoreVersion?: string;
            /**
             * A proto that stores SafeSearch internal signals that are not exported to clients. SafeSearch team does not provide any guarantees about the presence or the semantics of these
             * signals in the future.
             */
            internalSignals?: SafesearchInternalImageSignals;
            /** number of faces */
            numberFaces?: number;
            /** Information about image OCR text. For details see image/safesearch/content/public/ocr_annotation.proto. */
            ocrAnnotation?: ImageSafesearchContentOCRAnnotation;
            /** Vulgar score of the text found by OCR in the image. */
            ocrVulgarScore?: number;
            /** QuimbyCongas-based detection of offensive symbols in the image (currently swastika and Nazi yellow badge). */
            offensiveSymbolDetection?: ImageSafesearchContentOffensiveSymbolDetection;
            /**
             * Binary version of the PhotoDNA hash (144 bytes long). If not set (has_photodna_hash() == false) it means that it was not computed, if empty (has_photodna_hash() == true &&
             * photodna_hash() == "") it means that the computation failed (cannot be computed for images smaller than 50 x 50).
             */
            photodnaHash?: string;
            /**
             * This field is set to true when we are pretty confident that the image is porn (with higher precision than the img_porn_moderate restrict). In particular, it means that the image
             * might be demoted for non-porn queries when SafeSearch is Off.
             */
            pornWithHighConfidence?: boolean;
            /** QBST-based image offensive score, Navboost based */
            qbstOffensiveScore?: number;
            /** QBST-based image spoof score, Navboost based, unrelated to the pixel-based score in PornAnnotation. */
            qbstSpoofScore?: number;
            /** Query statistics from Navboost logs. For more details see classifier/porn/proto/image_porn_classifier_signals.proto. */
            queryStats?: ClassifierPornQueryStats;
            /** Aggregated navboost query violence score. */
            queryTextViolenceScore?: number;
            /** url of the referer page */
            referer?: string;
            /** Information about referrers and their porn classification. For details see classifier/porn/proto/image_porn_classifier_signals.proto. */
            referrerCounts?: ClassifierPornReferrerCounts;
            /** Starburst-based score predicting sexualization level of the image. */
            semanticSexualizationScore?: number;
            /** url of the image */
            url?: string;
            /** Information about the URL porn scores for image URLs associated with this image. */
            urlPornScores?: ClassifierPornAggregatedUrlPornScores;
        }
        interface PostalAddress {
            /**
             * These correspond to the "AddressLine" elements in xAL, which are used to hold unstructured text. This is an addendum to the structured values; when the address is formatted, the
             * provided lines are prepended to the formatted version of the street component fields for Western countries, and appended for CJK countries. These lines are in display order.
             * Formerly users of PostalAddress were discouraged from mixing address_line with structured address elements. Mixing is now encouraged if address_line has to be used at all.
             */
            addressLine?: string[];
            /** Top-level administrative subdivision of this country. Examples: US state, IT region, UK constituent nation, JP prefecture. */
            administrativeAreaName?: string;
            /** Name corresponding to country code. Optional. This can usually be inferred from country_name_code. */
            countryName?: string;
            /** xAL does not specify a scheme for country codes. We strongly recommend ISO 3166-1-alpha-2 (two letter codes, as used in DNS) if you use this field. (Use "GB", not "UK".) */
            countryNameCode?: string;
            /**
             * Dependent locality or sublocality. Used for UK dependent localities, or neighborhoods or boroughs in other locations. If trying to represent a UK double-dependent locality, include
             * both the double-dependent locality and the dependent locality in this field, e.g. "Whaley, Langwith".
             */
            dependentLocalityName?: string;
            /**
             * Dependent thoroughfares are used to define UK-style dependent thoroughfares, and secondary streets in addresses in other locales, including intersections. Formatting is
             * locale-dependent.
             */
            dependentThoroughfareName?: string;
            /** NEW: The firm or organization. This goes at a finer granularity than address_lines in the address. Omit if not needed. */
            firmName?: string;
            /**
             * Required to support the suppression of country names from formatted results for addresses within geo-politically disputed areas. Note that we cannot achieve this by not setting the
             * country, as this would prevent us from selecting a suitable formatting template. Addresses converted from Oyster, by the standard conversion libraries, will have this field set if
             * the address lies within a geo-politically disputed area (ie, contained within features of type TYPE_DISPUTED_AREA) even if the disputed area itself is not a visible part of the
             * formatted address. An example of a disputed area is "No Man's Land" near Jerusalem which has the flag FLAG_NEVER_DISPLAY set for all its names. See: go/disputed-areas-2014 for more
             * information.
             */
            isDisputed?: boolean;
            /**
             * Language of the address. May affect address formatting for multi- lingual countries. Also allows storing multilingual location names as repeated PostalAddress. Not in xAL. Use
             * language codes which are accepted by i18n_identifiers::LanguageCodeCoverter::FromOther(). Examples include "en" and "de-CH".
             */
            languageCode?: string;
            /**
             * Locality. This is something of a fuzzy term, but it generally refers to the city/town portion of an address. In regions of the world where localities are not well defined or do not
             * fit into this structure well (for example, Japan), leave locality_name empty and use address_line. Examples: US city, IT comune, UK post town.
             */
            localityName?: string;
            /** Despite the name, postal_code_number values are frequently alphanumeric. Examples: "94043", "SW1W", "SW1W 9TQ". */
            postalCodeNumber?: string;
            /** Used for postal-code suffixes, such as the 4-digit extension of a US ZIP+4 code. */
            postalCodeNumberExtension?: string;
            /**
             * This corresponds to PostBoxNumber in xAL format. In xAL format, it's nested inside PostBox, which also contains a "Type" field to distinguish between PO Box, Private Bag etc.
             * Current support in this proto is for PO Box only. Note that although this is modelled as a string, it should have the number only, with any necessary punctuation (such as "-"). For
             * example, for "P.O. Box 123", this field would hold "123" - the template displaying this would prepend P.O. Box when formatting if necessary.
             */
            postBoxNumber?: string;
            /** The "premise" is something like a house or building. */
            premiseName?: string;
            /** NEW: The recipient. This goes at a finer granularity than address_lines in the address. Not present in xAL. Omit if not needed. */
            recipientName?: string;
            /**
             * This corresponds to the SortingCode sub-element of the xAL PostalServiceElements element. Use is very country-specific. Where it is used, the value is either a string like "CEDEX",
             * optionally followed by a number (e.g. "CEDEX 7"), or just a number alone, representing the "sector code" (Jamaica), "delivery area indicator" (Malawi) or "post office indicator"
             * (e.g. Côte d'Ivoire).
             */
            sortingCode?: string;
            /** Second-level administrative subdivision of this country. Examples: US county, IT province, UK county. */
            subAdministrativeAreaName?: string;
            /** The "subpremise" is something like an apartment or suite. xAL offers more structured premise and subpremise values, but we don't. */
            subPremiseName?: string;
            /** Name of thoroughfare. Intersections should be represented with this field or address_line. Examples: "Amphitheatre Parkway", "N Shoreline Blvd & Charleston Rd" */
            thoroughfareName?: string;
            /**
             * Thoroughfare numbers (street numbers) can be very complex indeed. xAL defines fancy structures like "ThoroughfareNumberRange" to represent the details, but we haven't included that
             * yet. It is worth noting that this needs to be a string, not a number. Example: "1600"
             */
            thoroughfareNumber?: string;
        }
        interface PrecomputedRestricts {
            restricts?: string[];
        }
        interface PremiumPerDocData {
            /** type froogle/currency/currency.h */
            Currency?: number;
            /** publishing date (seconds since 1970, */
            Date?: string;
            /** entitlement data */
            Entitlement?: number[];
            /** True if a free document is archival in nature. */
            IsArchival?: boolean;
            /** User is entitled to see the premium content for free. */
            IsEntitled?: boolean;
            /** price * 100 if available */
            Price?: number;
            /** negative values for prior dates) FP of the Premium publication name */
            Publication?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface Proto2BridgeMessageSet {
        }
        interface PseudoVideoData {
            /** ASR model MPM version. */
            AsrModel?: string;
            /** This should be the MustangDocId, we need to figure out how to generate a uint64 given the int64 we have in data_set */
            DocKey?: string;
            /** Language of the recognizer used to generate transcript. */
            Lang?: string;
            /** This is the videodocid associate to the http://video.google.com/videoplay?docid= NUMBER */
            MustangDocId?: string;
            s3Mode?: string;
            /** S3 ASR model info. */
            s3ModelInfoLabel?: string;
            transcript?: PseudoVideoDataTranscript;
            /** URL for document. */
            Url?: string;
        }
        interface PseudoVideoDataTranscript {
            /** The complete transcription text. */
            Text?: string;
            timestamp?: PseudoVideoDataTranscriptTimestamp[];
        }
        interface PseudoVideoDataTranscriptTimestamp {
            CharOffset?: number;
            /** quantized to values in range 0-127 */
            Confidence?: number;
            TimeOffset?: number;
        }
        interface PtokenPToken {
            compoundPtokenData?: string;
            ptokenData?: string;
        }
        interface QualityActionsAppInfo {
            /** The list of android intents that the app is capable of executing. */
            androidIntent?: string[];
            /** This is the string matched from the query. */
            appName?: string;
            /** Category of this package. */
            category?: QualityActionsAppUnderstandingCategory;
            confidence?: number;
            /** This is the display name of the app as shown below the app icon. */
            displayName?: string;
            /** URL for the website associated with this app. */
            fallbackUrl?: string;
            /**
             * Note that the package_name could be empty for two reasons: - The AppInfo is annotated by device content. - The ngram exists in app name fastmap, but there are a lot of packages
             * associated with it. e.g., there could be a lot of apps for app name "recipes app".
             */
            packageName?: string;
            /** For the future source, use the field in source_data.source(). */
            source?: string;
            sourceData?: QualityActionsAppInfoSourceData[];
        }
        interface QualityActionsAppInfoSourceData {
            allowListSourceData?: QualityActionsAppInfoSourceDataAllowListSourceData;
            /** Confidence from navboost. */
            confidence?: number;
            /** Number of installs from marmot. */
            install?: string;
            isCategorical?: boolean;
            mediaProviderSourceData?: QualityActionsAppInfoSourceDataMediaProviderSourceData;
            source?: string;
            /** Signals present when the source is TELEPORT. */
            teleportSourceData?: AssistantTeleportTeleportNicknameSignals;
        }
        interface QualityActionsAppInfoSourceDataAllowListSourceData {
            /** Whether the app is in the pre-release stage and only available for testing. */
            preReleaseMode?: boolean;
            /**
             * Whether app compatibility is unknown. This field is needed for apps like apple tv that have different package names on different devices. Play Gateway Service (PGS) lookup is needed
             * to validate that the app is available on the user's device. go/app-fulfillment-quality
             */
            unknownAppDeviceCompatibility?: boolean;
        }
        interface QualityActionsAppInfoSourceDataMediaProviderSourceData {
            /** The unique provider key/enumeration string as used in KG. See also /base/mediaasset/provider/provider_enumerator. */
            providerKey?: string;
            /** The type of content served by the App. See also chrome.dongle.pints.ProviderType. */
            providerType?: string;
        }
        interface QualityActionsAppUnderstandingCategory {
            category?: string;
            confidence?: number;
        }
        interface QualityActionsCustomizedNotification {
            /** Buttons on the notification */
            buttons?: QualityActionsCustomizedNotificationButton[];
            /** Surface type for the notification */
            surfaceType?: string;
            /** Tap action on the notification body. This overwrites the default tap action on reminder trigger notification (which on mobile, is the reminders hub page). */
            tapAction?: QualityActionsCustomizedNotificationPayload;
            /** Notification text */
            text?: string;
        }
        interface QualityActionsCustomizedNotificationButton {
            /** REQUIRED. text for the button label */
            label?: string;
            /** REQUIRED. tap action for the button */
            tapAction?: QualityActionsCustomizedNotificationPayload;
        }
        interface QualityActionsCustomizedNotificationPayload {
            /** Currently for payload we only support raw string url. More structured options may be added in the future */
            url?: string;
        }
        interface QualityActionsNewsProviderAnnotationData {
            providers?: QualityActionsNewsProviderAnnotationDataProvider[];
        }
        interface QualityActionsNewsProviderAnnotationDataProvider {
            /**
             * List of supported locales for this provider. Must follow the format from go/iii, e.g.: 'en', 'en-US', 'en-GB', etc. Short forms without regions codes, such as, 'en' match all
             * possible regions: en-US, en-GB, en-IN, etc.
             */
            locales?: string[];
            /** The official name of the provider. Used in TTS and should be localized. */
            officialName?: string;
            /**
             * TTS hint for the pronunciation of the name. Should be left blank unless TTS performs poorly on official_name. Example: Without hinting, TTS mispronounces "The Daily 202" as "the
             * daily two hundred and two". Feeding tts the string "the daily two oh two" produces correct TTS.
             */
            officialNamePronunciation?: string;
            /** The provider id used for news source URL lookup in Kansas. See b/27250779 for details. */
            providerId?: number;
            /**
             * A score of how confident the annotated span is a news provider. For example, a high score is assigned for span "bbc news", but a low score for span "bbc", which only triggers
             * narrative news aqua parse for a query with explicit news intent, e.g [play news from bbc].
             */
            score?: number;
        }
        interface QualityActionsReminder {
            /** OPTIONAL. True if the reminder is archived. Not present implies false. */
            archived?: boolean;
            /** OPTIONAL. The time when this reminder is archived. Deprecated. Use `archived_timestamp` instead. */
            archivedTime?: AssistantApiDateTime;
            /** OPTIONAL. When the reminder was completed (only present when archived == true). Maps to apps_intelligence.dialog.Task's complete_time field. */
            archivedTimestamp?: string;
            /** REQUIRED. async_interaction_type of the reminder trigger notification */
            asyncInteractionType?: string;
            /**
             * OPTIONAL. Attachments associated with this Reminder. If the attachment has different behavior on different surfaces (e.g., deeplinks), specify multiple attachments here, and specify
             * the surface types and links in the inner fields. There should be at most one attachment for each surface.
             */
            attachment?: AssistantRemindersAttachment[];
            /**
             * OPTIONAL. Populated only for assignable reminders (E.g. "buy milk"). It will be used in the post-execution card-rendering. If not poulated, i.e. in non-assignable mode, caller
             * should fallback to use $title.
             */
            bareTitle?: string;
            /** OPTIONAL. The reminders "client" id. This ID uniquely identifies a reminder instance and may be generated by any client that writes to our Reminder backend. */
            clientId?: string;
            /** REQUIRED. The type of this attachment. This is used for frontends (e.g., Hubpage) to customize UX. And also for customized VE logging. */
            clientType?: QualityDialogManagerReminderClientType;
            /** OPTIONAL. The create time of this reminder. This field is propagated only for the reminders fetched from backend. */
            createTime?: AssistantApiDateTime;
            /** OPTIONAL. The create time of this reminder. This field is propagated only only for the reminders fetched from backend. */
            createTimestamp?: string;
            /** OPTIONAL. Creator of a reminder (owned by the current user). Used in shared reminder RUD operations. */
            creator?: QualityActionsReminderPerson;
            /** OPTIONAL. Contains fields needed to build the customized notification card */
            customizedNotificationCard?: QualityActionsCustomizedNotification[];
            /**
             * A representation of the Gregorian calendar date and timezone-relative time a reminder is scheduled for. This contains the date and time of either a single reminder or the upcoming
             * instance of a recurring reminder.
             */
            datetime?: AssistantApiDateTime;
            /** OPTIONAL. Full-length description of the reminder. */
            description?: string;
            documentAssignmentSource?: any;
            dynamiteGroupAssignmentSource?: any;
            /** DEPRECATED. Use `client_id` or `server_id` instead. */
            id?: string;
            location?: QualityActionsReminderLocation;
            /** OPTIONAL. Associated logs to be plumbed through along with a reminder. */
            log?: AssistantLogsReminderLog;
            /**
             * OPTIONAL. Memory record payload which is associated with this reminder. This will be set for all Assistant reminders created after the first launch of the Reminder Memory
             * integration, see go/reminders-memory for more details. Also, this might apply to all other types of reminders.
             */
            memoryPayload?: AssistantRemindersMemoryPayload;
            /** OPTIONAL. True if the reminder is notifying on the device that is making the request to the server. */
            notifying?: boolean;
            /**
             * OPTIONAL. Populated if the reminder is based off of a personal reference, e.g. [my hotel] when the user has a hotel reservation. Contains the information needed for suggestion chip
             * attribution, e.g. a link back to the email reservation.
             */
            personalReferenceMetadata?: CopleySourceTypeList;
            /** OPTIONAL. Recipient of a reminder (created by the current user). Used for shared reminder CRUD operations. */
            recipient?: QualityActionsReminderPerson;
            recurrence?: QualityActionsReminderRecurrenceInfo;
            /** OPTIONAL. The reminders backend "server" id. Only filled in some scenarios, e.g. to generate the reminders hubpage detailed-reminder view. */
            serverId?: string;
            symbolicTime?: string;
            /** REQUIRED. The main textual representation of the reminder with the final title. For assignable reminders, this would be e.g. "From John: buy milk". */
            title?: string;
            /** OPTIONAL. The last updated time of this reminder. This field is propagated only for the reminders fetched from ARIS (go/aris-dd). */
            updateTimestamp?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface QualityActionsReminderDocument {
        }
        // tslint:disable-next-line:no-empty-interface
        interface QualityActionsReminderDynamiteGroup {
        }
        interface QualityActionsReminderLocation {
            categoryInfo?: QualityActionsReminderLocationCategoryInfo;
            chainInfo?: QualityActionsReminderLocationChainInfo;
            /** Optional additional information about the types of the custom location. This field is not stored in backend, and is only used to plumb NLP information to fulfillment UI. */
            customLocationType?: string;
            /**
             * An address string that is suitable for displaying to the user in an application interface. It can be detailed, or brief. e.g. "80 Absolute Ave, Unit 1708, Mississauga, ON" e.g. "151
             * Charles Street West"
             */
            displayAddress?: string;
            /** Filled if location_type is CUSTOM and this is a resolved instance of a business (not for specific address locations). */
            geoFeatureId?: GeostoreFeatureIdProto;
            lat?: number;
            lng?: number;
            locationType?: string;
            /** Descriptive name, e.g. "43rd st new york", a user-edited place name (e.g. "Gym"), or a reverse geocoded business name. This can be any string. */
            name?: string;
            /** Deprecated in favor of Reminder.personal_reference_metadata. */
            personalLocationMetadata?: CopleySourceTypeList;
            /** A localized, shortened version of the address, suitable for TTS. This originates in the LocationFrame. */
            ttsAddress?: string;
        }
        interface QualityActionsReminderLocationCategoryInfo {
            /**
             * A (localized) display string describing the category. This is s generic string describing the category, and may be different than the term the user actually said, e.g. name:
             * "supermarket", display_name: "Grocery Stores"
             */
            displayName?: string;
            locationCategory?: string;
        }
        interface QualityActionsReminderLocationChainInfo {
            /** The freebase mid of the chain entity. */
            chainMid?: string;
            /**
             * The geostore.NameProto.text (corresponding to the user's language) at the time of reminder creation. In most cases, this is the same as name, but there may be corner cases where
             * they differ, e.g. name: "bestbuy", chain_name: "Best Buy".
             */
            chainName?: string;
            /** The (corporate entity) chain's MapFacts feature id. */
            featureId?: GeostoreFeatureIdProto;
        }
        interface QualityActionsReminderPerson {
            /** REQUIRED. Their full name, which will be shown/spoken when referring to this person informally, e.g. "You have 2 reminders from Dave Smith." */
            displayName?: string;
            /** OPTIONAL. Their email address. */
            emailAddress?: string;
            /** REQUIRED. Their gaia id (used by the backend for CRUD operations). */
            gaiaId?: string;
            /** REQUIRED. Their given name, which will be shown/spoken when referring to this person informally, e.g. "You have 2 reminders from Dave." */
            givenName?: string;
            /**
             * OPTIONAL. The URL of the photo. This field is read from photo field from go/people-api. Also see go/khdgk for URL formats. This field might be missing if user does not have photo
             * URL available.
             */
            photoUrl?: string;
        }
        interface QualityActionsReminderRecurrenceInfo {
            /** OPTIONAL. Client-assigned-id for the recurring reminder */
            clientId?: string;
            /** The recurrence pattern. */
            recurrence?: AssistantApiRecurrence;
            /** An id which uniquely identifies a recurrence series. */
            recurrenceId?: string;
            /** REQUIRED. Server-assigned-id for the recurring reminder */
            serverId?: string;
        }
        interface QualityActionsRingtone {
            /** The delay between each two sounds. */
            pauseDuration?: AssistantApiDuration;
            /** The sound urls will be used to play. */
            soundUrl?: string[];
        }
        interface QualityActionsRoom {
            homegraphId?: string;
            name?: string;
        }
        interface QualityActionsTimer {
            /** The time when this timer was created */
            creationTime?: AssistantApiTimestamp;
            /** Identifies the device this timer belongs to. */
            device?: AssistantApiSettingsDeviceSettings;
            /**
             * When not paused: the time the timer is (or was) scheduled to expire, in milliseconds since the Unix epoch. This should be deprecated and replaced by the expire_timer_time with
             * DateTime type once DateTime proto includes unix timestamp (b/63636831).
             */
            expireTime?: string;
            /**
             * This is currently being only used only for the response generation when the user describe the expired datatime as a search constraint. We will used it for everything else once that
             * for filtering once DateTime proto includes unix timestamp (b/63636831) and expire_time is deprecated.
             */
            expireTimerTime?: NlpSemanticParsingDatetimeDateTime;
            /** A string key used as an identifier to this timer, unique for a given Provider. */
            id?: string;
            /** The label, provided by a user, associated with this timer. */
            label?: string;
            /** The time when this timer was last updated (creation, paused, resumed, etc.) */
            lastUpdated?: AssistantApiTimestamp;
            /** The duration of the timer when it was started, in milliseconds. */
            originalDuration?: string;
            /** The duration set for the timer. The DateTimeModifier field is ignored. This field is currently only experimental until we switch the Dialog code and gramnar to the new format. */
            originalTimerDuration?: NlpSemanticParsingDatetimeDuration;
            /** The provider that owns this alarm. For Android, this includes the app that owns this alarm, where an intent should be sent to modify it. */
            provider?: AssistantApiCoreTypesProvider;
            /** When PAUSED: the remaining duration in milliseconds. */
            remainingDuration?: string;
            /**
             * The duration remained for the timer. This is needed because there is no expiration date for paused timer. The DateTimeModifier field is ignored. This field is currently only
             * experimental until we switch the Dialog code and gramnar to the new format.
             */
            remainingTimerDuration?: NlpSemanticParsingDatetimeDuration;
            /** The ringtone will be played when the timer fires, it will replace the beep sound if it is not empty. */
            ringtone?: QualityActionsRingtone;
            /** Ringtone Task Metadata information used to generate sound for firing the timer. */
            ringtoneTaskMetadata?: AssistantApiCoreTypesGovernedRingtoneTaskMetadata;
            /** Contains info about the room the timer is in */
            room?: QualityActionsRoom;
            /** The current status of the timer. */
            status?: string;
            /** Whether or not the device will vibrate when the timer fires. */
            vibrate?: boolean;
        }
        interface QualityAuthorityTopicEmbeddingsVersionedItem {
            pageEmbedding?: string;
            /** Compressed site/page embeddings. */
            siteEmbedding?: string;
            /** Number denoting how much a site is focused on one topic. */
            siteFocusScore?: number;
            /** The measure of how far page_embeddings deviate from the site_embedding. */
            siteRadius?: number;
            versionId?: number;
        }
        interface QualityCalypsoAppsLink {
            applicationId?: string[];
        }
        interface QualityCalypsoAppsUniversalAuLiveOpDetail {
            /** Key is country, and value is the schedule information in that country. */
            countryLevelScheduleInformation?: { [P in string]: QualityCalypsoAppsUniversalAuLiveOpEvent };
            /** Fallback option for the LiveOp format. We will try en-US -> en -> any locale and get the first one that is available. */
            defaultFormatInformation?: QualityCalypsoAppsUniversalAuLiveOpFormat;
            /** Fallback option for the LiveOp event scheduling information. Will use earliest start time and last end time from PDC LiveOps data dump. */
            defaultScheduleInformation?: QualityCalypsoAppsUniversalAuLiveOpEvent;
            /** android */
            eventId?: string;
            /** [REQUIRED] type of live op event. */
            eventType?: string;
            /** ios */
            eventUrl?: string;
            /** Key is locale, and value is the format information for that locale. */
            localeLevelFormatInformation?: { [P in string]: QualityCalypsoAppsUniversalAuLiveOpFormat };
            priority?: string;
        }
        interface QualityCalypsoAppsUniversalAuLiveOpEvent {
            /** [REQUIRED] End time in UTC for the live-op event. */
            endTimestampMillis?: string;
            /** If specified, a live-op event must be shown only after this preview-time (in UTC). Otherwise, the event can be shown at any time as long as its before the end time. */
            previewTimestampMillis?: string;
            /** [REQUIRED] Start time in UTC for the live-op event. */
            startTimestampMillis?: string;
        }
        interface QualityCalypsoAppsUniversalAuLiveOpFormat {
            deeplink?: string;
            description?: string;
            /** iOS only, kind of event type */
            eyebrow?: string;
            imageUrl?: string;
            squareImageUrl?: string;
            /** iOS only, sort of start schedule */
            status?: string;
            title?: string;
            videoId?: string;
            videoUrl?: string;
        }
        interface QualityCalypsoAppsUniversalAuLiveOpsDetailInfo {
            liveOpEvents?: QualityCalypsoAppsUniversalAuLiveOpDetail[];
            packageName?: string;
        }
        interface QualityCalypsoAppsUniversalImage {
            fifeUrl?: string;
            height?: number;
            width?: number;
        }
        interface QualityCalypsoAppsUniversalImageData {
            /** aka. promotional image / cover image. */
            featureGraphic?: QualityCalypsoAppsUniversalImage;
            screenshot?: QualityCalypsoAppsUniversalImage[];
        }
        interface QualityCopiaFireflySiteSignal {
            dailyClicks?: string;
            dailyGoodClicks?: string;
            dataTimeSec?: string;
            firstBoostedTimeSec?: string;
            impressionsInBoostedPeriod?: string;
            latestBylineDateSec?: string;
            latestFirstseenSec?: string;
            numOfArticles8?: string;
            /** number of articles (lattice article score is 0.8 or more) sliced by 30 days (num_of_articles_by_periods[0] is the newest). */
            numOfArticlesByPeriods?: string[];
            numOfGamblingPages?: string;
            numOfUrls?: string;
            /** number of urls sliced by 30 days (num_of_urls_by_periods[0] is the newest). */
            numOfUrlsByPeriods?: string[];
            recentImpForQuotaSystem?: string;
            /** Hash value of the site. This will be used by our experiment and analysis. */
            siteFp?: string;
            totalImpressions?: string;
        }
        interface QualityDialogManagerExternalIds {
            /** This field tells us whether this LocalResult supports any of the services that Blue Ginger offers. */
            blueGingerSupportedServices?: BlueGingerClientVisibleProtoBlueGingerSupportedServices;
            knowledgeGraphMid?: string;
            /** Google-internal actions supported by go/madden for this LocalResult. */
            maddenSupportedActions?: GeoOndemandAssistantSupportedActions;
            openTableRestaurantId?: string;
        }
        interface QualityDialogManagerLocalIntentOptions {
            /**
             * LINT.ThenChange( //depot/google3/googledata/nlp/generation/messages/assistant/\ dialog_LOCAL_LocalAssistantSchema/\ dialog.LOCAL.LocalAssistantSchema_zxx.genx.textpb,
             * //depot/google3/quality/dialog_manager/verticals/local/assistant/\ suggestion_chip_util.cc)
             */
            intent?: string[];
        }
        interface QualityDialogManagerLocalResult {
            /** This field can represent different areas depending on the country. For example in the US it is state but in Canada it would be a province. */
            adminArea1?: string;
            /** The set of available intents changes with result. An intersection of available_intents and allowed_intents (See: local_config.proto), is shown to the user. */
            availableIntents?: QualityDialogManagerLocalIntentOptions;
            /** Bitset of business types this result falls into. Many fields in this message may be unset - expect good coverage for restaurants and hotels for now, but not for other verticals. */
            businessType?: NlpSemanticParsingLocalBusinessType;
            country?: string;
            /**
             * The two-letter ISO 3166-1 country code of this result. Generated by FindFeatureCountryCode http://google3/geostore/base/public/country.h?l=39&rcl=154898119 so it should always be
             * populated, but technically there is no guarantee.
             */
            countryCode?: string;
            /**
             * For a directions result, this field will be the distance from the origin to this result using the best measure we have available - the distance along a route, if we have one, or
             * just the crow's flight distance. For a local result, this field will be the crow's flight distance from the user to the result.
             */
            distanceMeters?: string;
            /**
             * The standard units of the location where the user is based (not their current location). For example, miles for a user from the US, kilometers for the UK. A US user currently in the
             * UK should have units read in miles.
             */
            distanceUnits?: string;
            /** Various external IDs that we may have for this result. */
            externalIds?: QualityDialogManagerExternalIds;
            featureType?: string;
            /** Internal Food ordering action (i.e food ordering via Google) metadata. */
            internalFoodOrderingMetadata?: LocalsearchProtoInternalFoodOrderingActionMetadata;
            /** If true, this LocalResult is located in the same state as the user's location. */
            inUserAdminArea1?: boolean;
            /** If true, this LocalResult is located in the same country as the user's location. */
            inUserCountry?: boolean;
            /** Whether this result is in the same city or town that the user is in. */
            inUserLocality?: boolean;
            /** If the original query had a chain intent, and this result is for a business chain. */
            isBusinessChain?: boolean;
            /** City/Town. */
            locality?: string;
            /** The name of the result, extracted from its FeatureProto's name field. */
            name?: string;
            /** Neighborhood within a city. This field is not likely to be set for towns or smaller cities. */
            neighborhood?: string;
            /** All info we will need to lookup this result in search. */
            resultId?: NlpSemanticParsingLocalLocalResultId;
            streetName?: string;
            streetNumber?: string;
            /** A list of text synonyms the user could use to refer to the result. */
            synonym?: string[];
            /** The address of this result formatted for TTS output. This formatting removes acronyms like 2-letter state codes as they cannot be spoken well. */
            ttsAddress?: string;
        }
        interface QualityDialogManagerReminderClientType {
            type?: string;
        }
        interface QualityDniDocPreviewRestrictions {
            /**
             * Publish date set by webmaster. See detailed description here: http://shortn/_1eC0zzjR7k. Note that this will currently only be set for canonical documents where byline date could be
             * extracted.
             */
            bylineDateSecs?: string;
            /** The time that the info in this attachment was computed during crawl, in microseconds. */
            crawlTsUsec?: string;
            /** Whether this document comes from a domain that is affected by Extended News Previews (ENP) and its status (approved/rejected). */
            extendedNewsPreviewsDomain?: QualityDniExtendedNewsPreviews;
            /** Whether the favicon for a given domain should be displayed. FAVICON_DISPLAY_UNSPECIFIED - Display the favicon DISABLE_FAVICON - the favicon should not be rendered by the feature */
            faviconDisplay?: string;
            /**
             * Firstseen date populated by indexing. It works as fallback to byline_date if it doesn't exist. Note that this will currently only be set for canonical documents where firstseen date
             * could be populated.
             */
            firstseenDateSecs?: number;
            /** Only be true when the page itself is an AMP page. For paired AMP, the canonical page will have this bit as false. */
            isAmp?: boolean;
            isEucdDomain?: boolean;
            /**
             * The max number of snippet characters allowed. Based on document markup. No limit if value is less than 0, Google could use any length of snippets. Default value 0 is the strictest
             * restriction, to avoid violating mistakenly If not set, there is no snippet length policy to enforce. Features must first check has_max_snippet_length to avoid applying an overly
             * strict policy.
             */
            maxSnippetLength?: number;
            /** Same as the max_snippet_length, max_thumbnail_size, max_video_preview_secs listed above. But values are based on publisher's preferences from Search Console's robots meta tag tool. */
            maxSnippetLengthFromPublisher?: number;
            maxSnippetLengthPublisherDefault?: number;
            /**
             * The max thumbnail size allowed. Based on document markup Default value NONE is the strictest restriction, to avoid violating mistakenly. If not set, there is no thumbnail policy to
             * enforce.
             */
            maxThumbnailSize?: string;
            maxThumbnailSizeFromPublisher?: string;
            maxThumbnailSizePublisherDefault?: number;
            /**
             * The max seconds of video preview allowed. Based on document markup. No limit if value is less than 0, Google could show any seconds of video. Default value 0 is the strictest
             * restriction, to avoid violating mistakenly If not set, there is no preview length policy to enforce. Features must first check has_max_video_preview_secs to avoid applying an overly
             * strict policy.
             */
            maxVideoPreviewSecs?: number;
            maxVideoPreviewSecsFromPublisher?: number;
            maxVideoPreviewSecsPublisherDefault?: number;
        }
        interface QualityDniExtendedNewsPreviews {
            /** Publisher's country code (ISO-3166) Used in V0. */
            countryCode?: string;
            /** List of countries that desnippet the publisher. ISO 3166-1-alpha-2 country code (such as FR). See go/iiuse#region-identifiers. Used in V1. */
            desnippetedCountryCode?: string[];
            /**
             * Search Console Signals that modifies how policy are calculated. Didn't add `wmconsole.EnpDesnippetingOverrideRules` direcly to avoid cicular dependency issue:
             * go/enp-v2#bookmark=id.dvb1qcltabv9 ENPv2 proto (EnpDesnippetingOverrideRules): google3/crawler/wmconsole/proto/config_enp_desnippeting_override_rules.proto
             */
            policyCriteriaBase64?: string;
            /** ENP status. */
            status?: string;
            /** The default version is V0 (for backward compatibility). */
            version?: string;
        }
        interface QualityFringeFringeQueryPriorPerDocData {
            encodedCalibratedFringeSitePriorScore?: number;
            /** An encoding of the Chard XLQ-hoax prediction in [0,1]. */
            encodedChardXlqHoaxPrediction?: number;
            /** An encoding of the Chard XLQ-YMYL prediction in [0,1]. */
            encodedChardXlqYmylPrediction?: number;
            /**
             * An estimate of the vulnerability of this doc to show fringe content, based on the context around the document. Can be interpreted as a 'safe' QScore threshold to use (see
             * go/doc-fringe-vulnerability for more info). Encoded for compactness and to restrict visibility. Please contact fringe-ranking@ to get access to
             * quality_fringe::DocumentFringeVulnerabilityEncoding to decode this field.
             */
            encodedDocumentFringeVulnerability?: number;
            /**
             * Highest entity prior seen for document's Headline and SingleTopic entities (see go/topicality-score for definitions of entity topicalities). Represents probability that a query is
             * fringe, given that the entity is in the result set with topicality >= Headline. Scores scaled to integers between 0 and 1000 for compactness. Scores must be interpreted through
             * FringeQueryPriorEncoding::Decode API.
             */
            encodedEntityPriorScore?: number;
            /**
             * Probability that a query is fringe, given this document is in the result set. Scores scaled to integers between 0 and 1000 for compactness. Scores must be interpreted through
             * FringeQueryPriorEncoding::Decode API.
             */
            encodedFringePriorScore?: number;
            /**
             * Probability that a query is fringe, given this document's site is in the result set. Scores scaled to integers between 0 and 1000 for compactness. Scores must be interpreted through
             * FringeQueryPriorEncoding::Decode API.
             */
            encodedFringeSitePriorScore?: number;
            /**
             * Probability that a query is fringe, given this document's site is in the result set. Does not use signals with a dependency on the QueryFringeScore of a document. Scores scaled to
             * integers between 0 and 1000 for compactness. Scores must be interpreted through FringeQueryPriorEncoding::Decode API. Will NOT be present if the
             * fringe_site_prior_score_for_qfs_training is not significantly different from the site_prior_score.
             */
            encodedFringeSitePriorScoreForQfsTraining?: number;
            /** A combined encoding of the pXLQ score in [0,1] and the confidence with which that score should be interpreted in [0,1]. */
            encodedPredictedXlqScoreAndConfidence?: number;
            /**
             * A score in [0, 1] representing the similarity of this doc to known fringe-vulnerable 'seeds'. See go/fringe-proximity for more information. Encoded for compactness and to restrict
             * visibility.
             */
            encodedProximityScore?: number;
        }
        interface QualityGenieComplexQueriesComplexQueriesOutputRewrite {
            entities?: QualityGenieComplexQueriesComplexQueriesOutputRewriteEntity[];
            rewriteType?: string;
            textualRewrite?: string;
        }
        interface QualityGenieComplexQueriesComplexQueriesOutputRewriteEntity {
            mid?: string;
            name?: string;
        }
        interface QualityGeoBrainlocBrainlocAttachment {
            brainlocVersion?: number;
            topCitiesRawScores?: number[];
            /** Compressed top locations and their scores. *Locations are stored using their model vocab IDs. *Location scores are stored using 14 bits of precision (2 bytes). */
            topCitiesVocabIds?: number[];
            topCountiesRawScores?: number[];
            topCountiesVocabIds?: number[];
            topCountriesRawScores?: number[];
            topCountriesVocabIds?: number[];
            topStatesRawScores?: number[];
            topStatesVocabIds?: number[];
        }
        interface QualityLabelsGoogleLabelData {
            label?: QualityLabelsGoogleLabelDataLabel[];
        }
        interface QualityLabelsGoogleLabelDataLabel {
            /** If global_label_value is present, confidence is ignored. confidence is DEPRECATED. */
            confidence?: number;
            /** A byte-size value representing 64 * (1 + global_label_value). Use this instead of global_label_value to save on label storage. See quality_prose::LabelValueToBucket() for more info. */
            globalLabelBucket?: number;
            globalLabelValue?: number;
            /** At least one of label_id and label_name must be filled in */
            labelId?: number;
            labelName?: string;
            provider?: QualityLabelsGoogleLabelDataLabelProvider[];
            providerId?: string[];
        }
        interface QualityLabelsGoogleLabelDataLabelProvider {
            /**
             * This field is intended to be deprecated. If id == 0 and feed is true it means this label is from a feed. If id == 0 and feed is false, this label is from "Google" If id != 0, feed
             * is meaningless.
             */
            feed?: boolean;
            /**
             * We are currently using this field to indicate an id of the set of classifiers that produced this label. This deviates from the original intention. Also see ClassifierDescription and
             * refer to http://go/genre-labels-provider-id for further info.
             */
            id?: string;
            /** A byte-size value representing 64 * (1 + global_label_value). Use it instead of global_label_value to save on label storage. */
            labelBucket?: number;
            labelValue?: number;
            /** This name will only sometimes be filled in! Frontends can in general expect this to be filled in, but it will not usually be stored in backends. */
            name?: string;
        }
        interface QualityNavboostCrapsAgingData {
            /** Documents with byline date younger than month at the event time. */
            lastMonthBucket?: QualityNavboostCrapsAgingDataAgingAgeBucket;
            /** Documents with byline date younger than week at the event time. */
            lastWeekBucket?: QualityNavboostCrapsAgingDataAgingAgeBucket;
            /** Documents with byline date younger than year at the event time. */
            lastYearBucket?: QualityNavboostCrapsAgingDataAgingAgeBucket;
            /** Documents with byline date older than year at the event time. */
            yearPlusBucket?: QualityNavboostCrapsAgingDataAgingAgeBucket;
        }
        interface QualityNavboostCrapsAgingDataAgingAgeBucket {
            goodClicks?: number;
            impressions?: number;
        }
        interface QualityNavboostCrapsCrapsClickSignals {
            /**
             * Thus far this field is only used for host level unsquashed impressions. When compressed (e.g., in perdocdata.proto, CompressedQualitySignals), this value is represented individually
             * and thus is generally incompatible with the other values which are compressed as click-ratios.
             */
            absoluteImpressions?: number;
            badClicks?: number;
            clicks?: number;
            goodClicks?: number;
            impressions?: number;
            lastLongestClicks?: number;
            /** The subset of clicks that are associated with an event from a Unicorn user. */
            unicornClicks?: number;
            /**
             * This is not being populated for the current format - instead two instances of CrapsClickSignals (squashed/unsquashed) are used. We are migrating to the new format where this field
             * will be populated.
             */
            unsquashedClicks?: number;
            /**
             * This is not being populated for the current format - instead two instances of CrapsClickSignals (squashed/unsquashed) are used. We are migrating to the new format where this field
             * will be populated.
             */
            unsquashedImpressions?: number;
            unsquashedLastLongestClicks?: number;
        }
        interface QualityNavboostCrapsCrapsData {
            /** Contains counter for Aging signal (go/freshness-aging). It's used internally by Craps/Aging pipeline. */
            agingCounts?: QualityNavboostCrapsAgingData;
            badClicks?: number;
            clicks?: number;
            /** The two-letter uppercase country slice of the CrapsData. Examples: "US", "FR", "BR" */
            country?: string;
            /** The device interface and os slice of the CrapsData. */
            device?: QualityNavboostCrapsCrapsDevice;
            /** Contains CrapsClickSignals for specific features. (i.e. for mobile, US, metro id - 123") */
            features?: QualityNavboostCrapsFeatureCrapsData[];
            goodClicks?: number;
            /** These fields may become legacy fields; we may retire them and use the squashed field (below) instead, to allow for some nesting. */
            impressions?: number;
            /** The language slice of the CrapsData. Examples: "en", "fr", "pt-BR", */
            language?: string;
            /** The number of clicks that were last and longest in related user queries. */
            lastLongestClicks?: number;
            /** DO NOT USE: Use the above mobile_signals fields instead. DO NOT REMOVE: Field is present in legacy protos in golden tests. */
            mobileData?: QualityNavboostCrapsCrapsData;
            /** The portion of this CrapsData aggregated on data from tier 1/2 mobile interfaces in QSessions. */
            mobileSignals?: QualityNavboostCrapsCrapsClickSignals;
            /** Contains a packed string in network byte order, as expected by CrapsIpPrior. Only populated if we looked up the ip_prior_bad_fraction at retrieval time. */
            packedIpAddress?: string;
            /**
             * Level of pattern. More general patterns get higher values. For URL patterns this field = 0. For example, if we have "http://abc.def.ghi/xyz.html" level 0 pattern will be
             * "http://abc.def.ghi/xyz.html" level 1 pattern will be "p://abc.def.ghi" level 2 pattern will be "p://def.ghi"
             */
            patternLevel?: number;
            /** For pattern data, this will contain stats of the SCC's of the individual urls contributing to the pattern. */
            patternSccStats?: QualityNavboostCrapsStatsWithWeightsProto;
            query?: string;
            /**
             * This field can be used by the craps pipeline to slice up signals by various attributes such as device type, country, locale etc. The slice_tag can be an arbitrary string, and the
             * CrapsData values for each slice_tag are aggregated separately, together with the default empty slice_tag.
             */
            sliceTag?: string;
            /** Not used yet - we will probably move the impressions / clicks / good_clicks bad clicks / last longest clicks into here from top level, and rename those fields to legacy. */
            squashed?: QualityNavboostCrapsCrapsClickSignals;
            /**
             * Used to assign a prior based on IP address. See quality/navboost/craps/craps-ip-prior.h. This value is prior to the linear transformation (scaling / offset / min / max) that's
             * applied in craps-penalty.cc.
             */
            unscaledIpPriorBadFraction?: number;
            /** We will start using this one for the retuning rollout. */
            unsquashed?: QualityNavboostCrapsCrapsClickSignals;
            unsquashedMobileSignals?: QualityNavboostCrapsCrapsClickSignals;
            url?: string;
        }
        interface QualityNavboostCrapsCrapsDevice {
            os?: string;
            /**
             * An enum taken from GWSLogEntryProto that indicates what type of device a request came from. This includes an entry for DESKTOP(1), MOBILE(2), and TABLET(3) devices. Reference: -
             * gwslog(608): GWSLogEntryProto.ux_interface
             */
            uxInterface?: number;
            /**
             * Indicates the device browser tier for the given request. 1 means modern browsers, 3 means very old browsers, and 2 is everything in the middle. See Reference: - gwslog(609):
             * GWSLogEntryProto.ux_tier
             */
            uxTier?: number;
        }
        interface QualityNavboostCrapsFeatureCrapsData {
            /** Country, like "us". If not present, it's an aggregation for all countries. This is the same format as one used in Glue. */
            country?: string;
            /** Device, like "m". If not present, it's an aggregation for all devices. "m" - mobile devices. "d" - destop devices. */
            device?: string;
            /** Language, like "en". If not present, it's an aggregation for all languages. This is the same format as one used in Glue. */
            language?: string;
            /** Location id for metro and city. If not present, it's an aggregation for all locations within current country. */
            locationId?: number;
            /** CRAPS Signals for the locale. */
            signals?: QualityNavboostCrapsCrapsClickSignals;
        }
        interface QualityNavboostCrapsStatsWithWeightsProto {
            hi?: number;
            kind?: number;
            lo?: number;
            mean?: number;
            median?: number;
            n?: number;
            pc10?: number;
            pc25?: number;
            pc75?: number;
            pc90?: number;
            stddev?: number;
            stdError?: number;
            variance?: number;
            varOfMean?: number;
            weightedN?: number;
        }
        interface QualityNsrExperimentalNsrTeamData {
            versionedSignals?: QualityNsrExperimentalNsrTeamScoringSignal[];
        }
        interface QualityNsrExperimentalNsrTeamScoringSignal {
            valueBool?: boolean;
            valueDouble?: number;
            valueFloat?: number;
            valueInt32?: number;
            valueUint32?: number;
            versionId?: number;
        }
        interface QualityNsrExperimentalNsrTeamWSJData {
            experimentalNsrTeamData?: QualityNsrExperimentalNsrTeamData;
            /**
             * The key used to lookup this data in the WSJ corpus. The WSJ data is sitechunk-level, however the documents in the MDU shards are simply urls. WSJ does a mapping from url ->
             * {primary_chunk, secondary, fallbacks, etc.} and retrieves all the keys from the corpus. This lookup key field will keep track of which key was used for this particular lookup.
             */
            lookupKey?: string;
        }
        interface QualityNsrNsrData {
            /** Score from article classification of the site. */
            articleScore?: number;
            articleScoreV2?: number;
            /** Site-level chard score: site quality predictor based on content. */
            chardEncoded?: number;
            chardVariance?: number;
            /** An id for defining clusters of sites. Used in ecosystem experiments (project Tundra). */
            clusterId?: number;
            clusterUplift?: QualityNsrNsrDataClusterUplift;
            /** Delta site-level signal in Q* penalizing sites with a large number of distracting/annoying resources loaded by the site (see go/clutter-v0). */
            clutterScore?: number;
            clutterScores?: QualityNsrVersionedFloatSignal[];
            directFrac?: number;
            /** Categorical signals. */
            healthScore?: number;
            host?: string;
            /** Currently corresponds to i18n_g42_bucket. */
            i18nBucket?: number;
            /** Site-level impressions. */
            impressions?: number;
            /** Bit to determine whether the site has the local authority covid signal, as computed by go/covid-local-authority */
            isCovidLocalAuthority?: boolean;
            /** Bit to determine whether the site has the election authority signal, as computed by go/election-authority */
            isElectionAuthority?: boolean;
            /**
             * Bit to determine whether the site has mostly video content, but is not hosted on any known video-hosting domains. Site is considered to be video-focused, if it has > 50% of the URLs
             * with watch pages (with smoothing prior). ariane/4045246
             */
            isVideoFocusedSite?: boolean;
            language?: number;
            largeOrgId?: number;
            /** Locality score of the site, i.e. the locality component of the LocalAuthority signal (see go/pq-localauthority). */
            localityScore?: number;
            metadata?: QualityNsrNsrDataMetadata;
            /** This field used as a temporary field for clean transitions when we need to roll out Q* and NSR changes simultaneously. */
            newNsr?: number;
            nsr?: number;
            /** If true indicates that we do not have NSR data computed for the chunk, and instead the data is coming from an average of other host chunks. */
            nsrdataFromFallbackPatternKey?: boolean;
            /** The epoch from which this NSR value is coming from. */
            nsrEpoch?: string;
            /**
             * This signal is used to unconditionally override NSR as a bid in Q*. Should only be used in case of emergency (see go/nsr-override-bid). To have any effect, the value should be
             * present and greater than 0.001.
             */
            nsrOverrideBid?: number;
            /** NSR variance logodds [0, infinity). */
            nsrVariance?: number;
            /** Fractional signals. */
            pnav?: number;
            /** NSR - prior. Estimate of whether the site is above/below average NSR in its slice. */
            priorAdjustedNsr?: QualityNsrVersionedFloatSignal[];
            /** Secondary NSR sitechunk. When present, it provides more granular chunking than primary sitechunks (see quality/nsr/util/sitechunker.h for details). */
            secondarySiteChunk?: string;
            shoppingScore?: number;
            /** Aggregated value of url autopilot scores for this sitechunk. */
            siteAutopilotScore?: number;
            /**
             * Primary NSR sitechunk. In most of the cases it's same as HOST_LEVEL_V3 sitechunked canonical url of the document. In rare, but important cases it's based on page markup (see
             * quality/nsr/util/sitechunker.h for details).
             */
            siteChunk?: string;
            /** These are only annotated in the Goldmine NSR annotator. */
            siteChunkSource?: string;
            /** Average value of the site_link_in for pages in the sitechunk. */
            siteLinkIn?: number;
            /** Aggregated value of url link out scores for this sitechunk. */
            siteLinkOut?: number;
            sitePr?: number;
            /**
             * Estimate of site's PQ rating stddev--spread of the page-level PQ ratings of a site. Note this is different from nsr_variance which predicts error of NSR itself from the aggregated
             * site-level rating.
             */
            siteQualityStddev?: number;
            /** The SpamBrain LAVC score, as of July 2022. See more information at go/cloverfield-lavc-deck. */
            spambrainLavcScore?: number;
            spambrainLavcScores?: QualityNsrVersionedFloatSignal[];
            /** Site-level tofu score: site quality predictor based on content. */
            tofu?: number;
            ugcScore?: number;
            url?: string;
            /** Versioned map of NSR values for experimenting with the next release. */
            versionedData?: QualityNsrNSRVersionedData[];
            videoScore?: number;
            /** Score of the Video LQ model. */
            vlq?: number;
            /** NSR from a headroom model targeting low-quality video sites. */
            vlqNsr?: number;
            ymylNewsV2Score?: number;
        }
        interface QualityNsrNsrDataClusterUplift {
            /** Score for the local sites arm. */
            local?: number;
            /** Score for the small sites arm. */
            small?: number;
        }
        interface QualityNsrNsrDataMetadata {
            /**
             * Same as raffia_lookup_key_per_field. Note that the goldmine_lookups have priority; if a field appears in both goldmine and raffia entries, it means it was taken from goldmine. If
             * it's missing here but present in raffia_lookup_key_per_field, it was taken from raffia.
             */
            goldmineLookupKeyPerField?: { [P in string]: number };
            /** The lookup keys attempted by goldmine. Note that goldmine only runs for urls which can be chunked differently than raffia; in those cases, goldmine related fields are empty. */
            goldmineLookupKeys?: string[];
            raffiaLookupKey?: string;
            /**
             * Returns the raffia lookup key per each field in the NsrData proto (with exclusion of the Metadata sub-message (i.e. this)). It contains information like 3 : 1, meaning that the
             * field inside NsrData with id '3' (in this case 'host') has been taken by raffia from the raffia lookup key at index 1.
             */
            raffiaLookupKeyPerField?: { [P in string]: number };
            /**
             * This is an internal field set by Raffia, to indicate which lookup keys have been attempted to populate the NsrData for this document. This will allow us to determine which key has
             * been used to populate each field in the proto. The keys are ordered by lookup priority; raffia will give priority to earlier keys, and only take fields from later keys if they are
             * missing.
             */
            raffiaLookupKeys?: string[];
        }
        interface QualityNsrNSRVersionedData {
            /** The corresponding NSR value. */
            value?: number;
            /** The unique id of the version, preferably just scaled: 19.1 x 10 = 191. */
            versionId?: number;
        }
        interface QualityNsrPQData {
            /** URL-level chard prediction (encoded as an int). */
            chard?: number;
            deltaAutopilotScore?: number;
            deltaLinkIncoming?: number;
            deltaLinkOutgoing?: number;
            /** The delta score of the URL-level quality predictor. */
            deltaPageQuality?: number;
            /** Total deltaNSR adjustment based on subchunks. This is a page-level adjustment (subchunks are retrieved based on the page classification). */
            deltaSubchunkAdjustment?: number;
            linkIncoming?: number;
            linkOutgoing?: number;
            /** The total number of offdomain anchors seen by the NSR pipeline for this page. */
            numOffdomainAnchors?: number;
            page2vecLq?: number;
            subchunkData?: QualityNsrPQDataSubchunkData[];
            /** URL-level tofu prediction. */
            tofu?: number;
            urlAutopilotScore?: number;
            /** URL-level score of the VLQ model. */
            vlq?: number;
        }
        interface QualityNsrPQDataSubchunkData {
            /** Confidence associated with the chunk. */
            confidence?: number;
            /** Subchunk delta in nsr. */
            deltaNsr?: number;
            /** Weight with which this document belong to this subchunk (greater than 0). */
            pageWeight?: number;
            /** Type of this chunk. Eg, ymyl_health, d2v, etc. */
            type?: string;
        }
        interface QualityNsrVersionedFloatSignal {
            /** The corresponding float value. */
            value?: number;
            /** Unique version id. */
            versionId?: number;
        }
        interface QualityOrbitAsteroidBeltDocumentIntentScores {
            /** Map of imageid key to ImageIntentScores, for images on cdoc.doc_images */
            imageIntentScores?: { [P in string]: QualityOrbitAsteroidBeltImageIntentScores };
            /**
             * The 'intents' and 'scores' fields are stored as parallel lists for compactness. The 'scores' field should not be accessed directly, but instead through the functions in
             * document_intent_scores_utils.
             */
            intents?: string[];
            /** The intent scores, scaled to integers between 0 and 100 for compactness. */
            scores?: number[];
            /**
             * Version 0: Presence of an intent label in the 'intents' field represents our best-effort classification. The 'scores' field is not meaningful. Version 1: Values in the 'scores'
             * field represent the estimated precision of the classifier for a threshold at that score.
             */
            version?: number;
        }
        interface QualityOrbitAsteroidBeltImageIntentScores {
            /** The unique identifier for an Asteroid Belt document intent is being reused here */
            intents?: string[];
            /** The intent scores, scaled to integers between 0 and 100 for compactness. */
            scores?: number[];
        }
        interface QualityPreviewChosenSnippetInfo {
            /** Whether this snippet is a vulgar candidate. */
            isVulgar?: boolean;
            leadingTextType?: string;
            /** The rendered snippet html. */
            snippetHtml?: string;
            snippetType?: string;
            /** Source of the chosen snippet, decided in PORC. String value of quality.porc.TextSnippetCandidate.TextSnippetSource defined at google3/quality/porc/proto/text_snippet.proto */
            source?: string;
            tidbits?: QualityPreviewChosenSnippetInfoTidbitInfo[];
            /** Whether this snippet has trailing ellipsis. */
            trailingEllipsis?: boolean;
        }
        interface QualityPreviewChosenSnippetInfoTidbitInfo {
            /** Section name of current snippet. */
            sectionName?: string;
            /** Separator to put before this tidbit. */
            separator?: string;
            /** Tidbit text for validation. */
            tidbitText?: string;
            /** Tidbit token range in the section. */
            tokenBegin?: string;
            tokenEnd?: string;
        }
        interface QualityPreviewRanklabSnippet {
            /** Features from SnippetFlow in Superroot. */
            brainFeatures?: QualityPreviewSnippetBrainFeatures;
            documentFeatures?: QualityPreviewSnippetDocumentFeatures;
            /** For experimental usage, not populated yet. */
            experimentalFeatures?: QualityPreviewSnippetExperimentalFeatures;
            /** The final score of this candidate. */
            finalScore?: number;
            /** Is this the candidate chosen by Muppet scorer. */
            isMuppetSelectedSnippet?: boolean;
            /** Query term (original terms only) coverage features. */
            originalQueryTermCoverageFeatures?: QualityPreviewSnippetQueryTermCoverageFeatures;
            qualityFeatures?: QualityPreviewSnippetQualityFeatures;
            /** Core set of snippet features. */
            queryFeatures?: QualityPreviewSnippetQueryFeatures;
            /** Query term (including synonyms) coverage features. */
            queryTermCoverageFeatures?: QualityPreviewSnippetQueryTermCoverageFeatures;
            /** Radish related information. */
            radishFeatures?: QualityPreviewSnippetRadishFeatures;
            /** Information to identify current chosen snippet. */
            snippetInfo?: QualityPreviewChosenSnippetInfo;
        }
        interface QualityPreviewRanklabTitle {
            /** `goldmine_final_score` value in base. */
            baseGoldmineFinalScore?: number;
            /** The ranking index of this candidate (starting from 0) in base. */
            baseRank?: number;
            /** Title source type. */
            dataSourceType?: string;
            /** Document language for this title. It is used for model inference and hence flattened into RanklabTitle instead of RanklabDoc. */
            docLang?: string;
            /**
             * Represents how relavant this title candidate is to the document. Ranged in [0, 1], and this signal is basically calculated as Cosine-similarity between salient term vector and pQ2T
             * model of title candidate sentence.
             */
            docRelevance?: number;
            /** Numbers of duplicated tokens. For example, duplicated tokens for a title "dog cat cat cat" is 2 (for 2 extra "cat"). */
            dupTokens?: number;
            /** A score assigned for candidates forced by experiments. */
            forcedExperimentScore?: number;
            /** The score for `text` computed in Goldmine (AlternativeTitlesAnnotator) with additional scoring adjustments applied. Currently includes Blockbert scoring. */
            goldmineAdjustedScore?: number;
            /** =============================================================== Internal boost feature signals used to compute `goldmine_page_score`. They are exposed only for debugging purpose. */
            goldmineAnchorFactor?: number;
            goldmineAnchorSupportOnly?: number;
            goldmineBlockbertFactor?: number;
            goldmineBodyFactor?: number;
            /** Deprecated: use `goldmine_page_score` instead. */
            goldmineFinalScore?: number;
            goldmineForeign?: number;
            goldmineGeometryFactor?: number;
            goldmineHasBoilerplateInTitle?: number;
            goldmineHasTitleNgram?: number;
            goldmineHeaderIsH1?: number;
            goldmineHeadingFactor?: number;
            goldmineIsBadTitle?: number;
            goldmineIsHeadingTag?: number;
            goldmineIsTitleTag?: number;
            goldmineIsTruncated?: number;
            goldmineLocalTitleFactor?: number;
            goldmineLocationFactor?: number;
            goldmineNavboostFactor?: number;
            goldmineOgTitleFactor?: number;
            goldmineOnPageDemotionFactor?: number;
            /** The number of BoostFeatures present in AlternativeTitlesGeneator but not populated above. */
            goldmineOtherBoostFeatureCount?: number;
            /** The score for the `text` computed in Goldmine (AlternativeTitlesAnnotator). */
            goldminePageScore?: number;
            goldmineReadabilityScore?: number;
            goldmineSalientTermFactor?: number;
            goldmineSitenameFactor?: number;
            goldmineSubHeading?: number;
            goldmineTitleTagFactor?: number;
            goldmineTrustFactor?: number;
            goldmineUrlMatchFactor?: number;
            /** Whether a title contains site information. */
            hasSiteInfo?: boolean;
            /** Whether this title candidate is truncated or not. */
            isTruncated?: boolean;
            /** Whether a title is valid (i.e., not empty). */
            isValid?: boolean;
            /** Numbers of body title tokens covered by this title, in range of [0, 1]. Not set if body title is considered "bad". */
            percentBodyTitleTokensCovered?: number;
            /** Numbers of tokens covered by body title, in range of [0, 1]. Not set if body title is considered "bad". */
            percentTokensCoveredByBodyTitle?: number;
            /** How good or bad this title is as a `data_source_type` title type. */
            perTypeQuality?: string;
            /** Rank of this title among titles of the same `data_source_type`. */
            perTypeRank?: number;
            /** The number of (different) terms with a query match. It may include the match with any SQuery node (e.g., synonyms). */
            queryMatch?: number;
            /**
             * A number of matched query terms divided by the number of all terms in query. Synonyms or other terms that appear in squery but not in the raw query are excluded. Takes values in [0,
             * 1].
             */
            queryMatchFraction?: number;
            /**
             * Represents how relavant this title candidate is to the query. Ranged in [0, 1], and this signal is basically calculated as Cosine-similarity between QBST term vector and pQ2T model
             * of title candidate sentence.
             */
            queryRelevance?: number;
            sourceGeometry?: boolean;
            sourceHeadingTag?: boolean;
            sourceLocalTitle?: boolean;
            sourceOffdomainAnchor?: boolean;
            sourceOndomainAnchor?: boolean;
            sourceOnsiteAnchor?: boolean;
            /**
             * =============================================================== Title candidate's original source information. They are populated only for non-production environment for debugging
             * purposes.
             */
            sourceTitleTag?: boolean;
            sourceTransliteratedTitle?: boolean;
            /** `goldmine_final_score` value in test. */
            testGoldmineFinalScore?: number;
            /** The ranking index of this candidate (starting from 0) in test. */
            testRank?: number;
            /**
             * Title text to display. Populated for debugging purpose only, and won't be used for model inferences. This represetns the exact display text in SERP, with modifications like
             * truncations or site-title appending involved.
             */
            text?: string;
            /** A rendered width of this title divided by the max allowed width for title. Takes values in [0, 1]. */
            widthFraction?: number;
        }
        interface QualityPreviewSnippetBrainFeatures {
            /** Is the bolding triggered. */
            isSnippetBrainBoldingTriggered?: boolean;
            /** The score by SnippetBrain model. */
            modelScore?: number;
        }
        interface QualityPreviewSnippetDocumentFeatures {
            experimentalTitleSalientTermsScore?: number;
            leadingtextDistanceScore?: number;
            metaBoostScore?: number;
            salientPositionBoostScore?: number;
            salientTermsScore?: number;
            schemaOrgDescriptionBoostScore?: number;
            unstableTokensScore?: number;
        }
        interface QualityPreviewSnippetExperimentalFeatures {
            isLikelyHomepage?: boolean;
            numQueryItems?: number;
            numTidbits?: number;
            numVisibleTokens?: number;
            radish?: QualityPreviewSnippetRadishFeatures;
        }
        interface QualityPreviewSnippetQualityFeatures {
            foreignMetaScore?: number;
            hiddenRatioScore?: number;
            numTidbitsScore?: number;
            numVisibleTokensScore?: number;
            outlinkScore?: number;
            redundancyScore?: number;
            sentenceStartScore?: number;
        }
        interface QualityPreviewSnippetQueryFeatures {
            experimentalQueryTitleScore?: number;
            passageembedScore?: number;
            queryHasPassageembedEmbeddings?: boolean;
            queryScore?: number;
            radishScore?: number;
        }
        interface QualityPreviewSnippetQueryTermCoverageFeatures {
            snippetQueryTermCoverage?: number;
            titleQueryTermCoverage?: number;
            titleSnippetQueryTermCoverage?: number;
        }
        interface QualityPreviewSnippetRadishFeatures {
            /** Answer score of the passage for this `navboost_query`. */
            answerScore?: number;
            /** Navboost query for this radish signal. */
            navboostQuery?: string;
            /** The ratio of overlapping tokens between the radish passage and snippet candidate. */
            passageCoverage?: number;
            /** Integer value of indexing::annotations::wa_passages::Passage::Type. */
            passageType?: number;
            /** The index of this passage under `navboost_query`. */
            queryPassageIdx?: number;
            /** How the similarity score is computed. Integer value of mustang_repos_www_snippets::RadishSignalScoringInfo::SimilarityMethod. */
            similarityMethod?: number;
            /** Similarity score between this `navboost_query` and the incoming query. */
            similarityScore?: number;
            snippetCoverage?: number;
        }
        interface QualityProductProductSiteData {
            /** Data for each locale. */
            locale?: QualityProductProductSiteDataLocaleData[];
        }
        interface QualityProductProductSiteDataLocaleData {
            /** Site boosting multiplier. */
            boostFactor?: number;
            /**
             * Whether this is a gobi site, ie, a site from a gobi domain that should be boosted for a category query with this gobi domain. For example, amazon.com is a gobi store domain for
             * category query [hdtv] but some sites (like askville.amazon.com) from amazon.com should not be boosted.
             */
            gobiSite?: boolean;
            /** Locale for this data. */
            locale?: string;
        }
        interface QualityProseCSEUrlInfo {
            /** There were defined back in 2007, but were never used. optional string label = 2; optional uint64 user = 3; optional float score = 4; */
            cseId?: string;
        }
        interface QualityQrewriteAccountProvenance {
            dataSources?: string[];
            googleAccount?: QualityQrewriteAccountProvenanceGoogleAccount;
            /** Note google_account and third_party_account could both exist. For example, a user could share her Spotify account with other users registered on the same device. */
            thirdPartyAccount?: QualityQrewriteAccountProvenanceThirdPartyAccount;
        }
        interface QualityQrewriteAccountProvenanceGoogleAccount {
            email?: string;
            gaiaId?: string;
            isDasherAccount?: boolean;
            isSecondaryAccount?: boolean;
        }
        interface QualityQrewriteAccountProvenanceThirdPartyAccount {
            /** Email address of the linked account (eg foo@outlook.com). */
            email?: string;
            /** Unique identifier for the third party provider. Defined by Google via AoG. */
            thirdPartyProviderId?: string;
        }
        interface QualityQrewriteAlternativeNameInfo {
            matchSignal?: AssistantVerticalsCommonContactMatchSignal;
            name?: string;
            source?: string;
        }
        interface QualityQrewriteCalendarReference {
            calendarAlias?: any;
            contactCalendarName?: QualityQrewriteContactCalendarName;
            familyCalendarAlias?: QualityQrewriteFamilyCalendarAlias;
            primaryCalendarAlias?: any;
        }
        interface QualityQrewriteCandidateId {
            field?: QualityQrewriteCandidateIdField[];
        }
        interface QualityQrewriteCandidateIdField {
            index?: number;
            type?: string;
        }
        interface QualityQrewriteContactCalendarName {
            contact?: NlpSemanticParsingModelsPersonPerson;
        }
        interface QualityQrewriteFamilyCalendarAlias {
            familyCalendarId?: string;
        }
        interface QualityQrewritePersonalContactData {
            /** Tracks the account owner of this contact. See go/cross-account-understanding. */
            accountProvenance?: QualityQrewriteAccountProvenance;
            /**
             * Other metadata relating with the contact. This field is added so that the value can be copied to the corresponding field |additional_contact_metadata| in person.proto, that later
             * will be logged to Assistant Interaction Event footprint from client side.
             */
            additionalContactMetadata?: Array<{ [P in string]: any }>;
            /** Populated only if matched_name_type is GIVEN_NAME_ALIAS or FULL_NAME_ALIAS. */
            commonNameAliasConfidence?: number;
            /** Concept id for relationships in query language, e.g. "Mother" in English, "Mère" in French. It's only populated for source = RELATIONSHIP. */
            conceptId?: string;
            /**
             * Concept id for relationships in English, e.g. "Mother" for all non-English locales. It's only populated for source = RELATIONSHIP. It is used as the key to store relationship in
             * memory (see http://go/assistant-relationship). For English, this field is not filled, and we will use concept_id field as the relationship key in memory.
             */
            conceptIdEn?: string;
            /**
             * TODO(shuaiwang) these are kept here temporarily because aqua regression tests are still referring to them, migrating aqua regression tests to use the new person_data field depends
             * on binary change (i.e. this proto change) so there's a period we need to keep both.
             */
            displayName?: string;
            familyName?: string;
            /** The ffrac score of the suggested contact from Starlight. */
            ffracScore?: number;
            gaiaId?: string;
            givenName?: string;
            /**
             * Whether we have address info for this contact. IMPORTANT, READ BEFORE USING THIS FIELD: - This is a temporary solution to export this info for device contacts. - This could only be
             * set for device contacts, contacts from other sources won't have this bit set even if there's address available inside person_data. - This will go away once Starlight supports device
             * contacts, addresses will be available inside person_data the same way as Focus contacts. TODO(shuaiwang) remove after b/20412551
             */
            hasAddressForDeviceContacts?: boolean;
            hasGplusProfile?: boolean;
            /** If the contact data is from on device lookup. */
            isFromOnDeviceLookup?: boolean;
            /** Indicate the contact matches the transliterated query. */
            isTransliteratedMatch?: boolean;
            /**
             * If the lookup was done using relationship which is visible to guests. This value will only be set if lookup was done using relationship. E.g. user has a guest relationship (doctor)
             * -> (John) And user says "call doctor", then this value will be true.
             */
            isVisibleToGuestsRelationship?: boolean;
            lookupNameSource?: string;
            /**
             * LINT.ThenChange(//depot/google3/assistant/verticals/communication/\ fulfillment/proto/contact_logging_enums.proto, //depot/google3/assistant/api/dialog_state/values/person.proto,
             * //depot/google3/assistant/context/proto/person.proto)
             */
            matchedNameType?: string;
            /** Alternate name from recognition that has contact matched. Need this to make name correction history log consistent. */
            matchedRecognitionAlternateName?: string;
            /** Populate only if AlternateSource is not NONE. */
            matchSignal?: AssistantVerticalsCommonContactMatchSignal;
            /**
             * Log version of PersonalContactData. Holds e.g. FUZZY match results. It is populated in NamedContactFrame when fuzzy match is performed:
             * http://google3/quality/dialog_manager/frames/contact/named_contact_frame.cc?l=255&rcl=331994299 Currently only fuzzy ngram match results are logged here.
             */
            personalContactDataLog?: AssistantLogsCommunicationPersonalContactDataLog;
            /** Metadata such as name, email, phone, etc. */
            personData?: AppsPeopleOzExternalMergedpeopleapiPerson;
            /**
             * Contains information about a Copley Person resolution (go/copley-people). This field is used to propagate metadata related to the resolved person, used for attribution and logging.
             * Meaningful data (addresses, phone numbers) are copied into person_data.
             */
            pkgPerson?: NlpSemanticParsingQRefAnnotation;
            pkgReferenceType?: string;
            /** Populate only if AlternateSource is not NONE. */
            recognitionAlternateScore?: number;
            /** If not none, then it indicates the personal contact data is alternate and how the alternate is fulfilled. */
            recognitionAlternateSource?: string;
            /** Lexical information for relationships in query language, e.g. "Mother" in English, "Mère" in French. It's only populated for source = RELATIONSHIP. */
            relationshipLexicalInfo?: CopleyLexicalMetadata;
            /**
             * Resolved relationship names and contact pointers from Assistant Memory. This field is populated into both relationship annotation (source = RELATIONSHIP) and Focus/device contacts
             * retrieved by that contact name. The data from Assistant Memory comes from two different columns: ASSISTANT_SETTINGS and PWS_CONTACT_ANNOTATION. We support multiple people with same
             * relationship (e.g. multiple brothers) by using a repeated relationship_memory field. Examples are at go/person-subgrammar-relationship.
             */
            relationshipMemory?: QualityQrewriteRelationshipMemoryData[];
            /**
             * Gaia ID of the user this contact belongs to. Only populates if contact is shared from another user. See go/shared-contacts-assistant. E.g. user A triggers the request and uses user
             * B's contact data (which is marked as visible to user A). This field will be populated with user B's gaia id.
             */
            sharedContactOwnerGaiaId?: string;
            /**
             * LINT.ThenChange(//depot/google3/assistant/verticals/communication/\ fulfillment/proto/contact_logging_enums.proto, //depot/google3/assistant/api/dialog_state/values/person.proto)
             * Data source of the contact data.
             */
            source?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface QualityQrewritePrimaryCalendarAlias {
        }
        // tslint:disable-next-line:no-empty-interface
        interface QualityQrewriteQRewriteAccountAwareCalendarAliasWrapper {
        }
        interface QualityQrewriteRelationshipMemoryData {
            /** The contact pointer. See http://go/assistant-contact-id. */
            contactPointer?: FocusBackendContactPointer;
            /** The contact name copied from UserAttribute.value. */
            value?: string;
        }
        interface QualityRankembedMustangMustangRankEmbedInfo {
            /** Each uint64 encodes 8 8-bit values for the quantized document embedding */
            compressedDocumentEmbedding?: QualityRankembedMustangMustangRankEmbedInfoCompressedEmbedding;
            /**
             * This field replaces the above 3 "per-encoding-type-fields", where the encoding type (and the embedding type) are part of the encoding, and is stored in the first byte. The remaining
             * bytes are the same as the previous 3 fields, but shifted by 1 byte. - byte[0]: encoding type & embedding type - byte[1....]: similar to the above depending on the encoding type.
             */
            fixedPointEncoding?: string;
            /** - byte[0]: version - bytes[1...4]: scalar - bytes[5,...]: the values, one byte per 2 values */
            scaledFixedPoint4Encoding?: string;
            /** - byte[0]: version - bytes[1...4]: scalar - bytes[5,...]: the values, one byte per value */
            scaledFixedPoint8Encoding?: string;
            /** - byte[0]: version - bytes[1...4]: scalar - bytes[5...8]: shift - bytes[9,...]: the values, one byte per 2 values */
            scaledShiftedFixedPoint4Encoding?: string;
            /**
             * First 7 bits encode the version, then each chunck of 5 bits encode the index of a potential improv query (lsb to msb) -------|-----|-----|-----|-----|----- version| id1 | id2 | id3
             * | id4 | id5 where id1 is the index of the first improv query in the improv debug table. As of cl/270008220, this field only contains the version info. For backward compatibility,
             * version still only uses the first 7 bits, and is still prepended by 5 1 bits.
             */
            versionAndImprovInfo?: number;
        }
        interface QualityRankembedMustangMustangRankEmbedInfoCompressedEmbedding {
            /** using fixed64 instead of uint64 saves ~14% is storage */
            packedValue?: string[];
            value?: string[];
        }
        interface QualityRichsnippetsAppsProtosLaunchableAppPerDocData {
            indexStatus?: string;
            /** Android package id of the application associated with this document (example: 'com.imdb.mobile'), encoded with the Fingerprint2011() function. */
            packageIdFingerprint?: string;
            /** A subset of the data in the PerAppInfo message, encoded to save on space. See quality/calypso/utils/app_info_utils.h for encoding/decoding. */
            perAppInfoEncoded?: string;
        }
        interface QualityRichsnippetsAppsProtosLaunchAppInfoPerDocData {
            app?: QualityRichsnippetsAppsProtosLaunchableAppPerDocData[];
        }
        interface QualitySalientCountriesSalientCountry {
            /** 2-letter country format. */
            country?: string;
            /** How salient this country is for the document. [0,1] range. */
            salience?: number;
        }
        interface QualitySalientCountriesSalientCountrySet {
            /** Packed Country and salience optimized for index storage */
            packedCountry?: number[];
            packedSalience?: number[];
            salientCountry?: QualitySalientCountriesSalientCountry[];
        }
        interface QualitySalientTermsDocData {
            /** confidence is a measurement of how much data we had to compute the SalientTermSet. Range: [0.0, 1.0] */
            confidence?: number;
            /** head_volume_ratio is the ratio of the sum of term frequency of the top K terms over the volume of all terms. Range: [0.0, 1.0]. K is defined by Accumulator2Params::head_size. */
            headVolumeRatio?: number;
            /** language is the main language of this SalientTermSet. */
            language?: string;
            /** signal_data contains signal-specific (e.g., body, anchors, clicks) data for this SalientTermSet. */
            signalData?: QualitySalientTermsSignalData[];
            /** virtual_volume is a measurement of how much data we had to compute the SalientTermSet. Range: [0.0, +infinity)]. */
            virtualVolume?: number;
        }
        interface QualitySalientTermsSalientTerm {
            /** idf of the original_term. Used by Accumulator2. This field is only available in debug mode. */
            idf?: number;
            /**
             * label can be two things depending on where this message is. When right under a SalientTermSet, it is the normalized term returned by quality_salient_terms::utils::NormalizeTerm()
             * from salient_terms_utils.h. When under another SalientTerm message, it is the original term as found in a signal (see original_term field).
             */
            label?: string;
            /**
             * original_term are the different ways we found this normalized term in the signals. They are in increasing idf order (the most common version first). An empty string means that this
             * original term is the same as the label field in the parent SalientTerm message. NOTE: Please do not access this field directly. Use
             * quality_salient_terms::utils::OriginalTermsIterator from salient_terms_utils.h instead.
             */
            originalTerm?: QualitySalientTermsSalientTerm[];
            /**
             * salience is the importance of the term as a descriptor in [0, 1] (the higher the more important). This field takes precedence over weight field below. NOTE: Please do not access
             * this field directly. Use quality_salient_terms::utils::GetSalience() from salient_terms_utils.h instead.
             */
            salience?: number;
            /** signal_term contains extra signal-specific (e.g., body, anchors, clicks) data for this term. */
            signalTerm?: QualitySalientTermsSignalTermData[];
            /** virtual_tf is the accumulated corrected term frequency from all the signals. This field is only available in debug mode. */
            virtualTf?: number;
            /**
             * weight is the importance of the term as a descriptor in [0, 100] (the higher the more important). NOTE: Please do not access this field directly. Use
             * quality_salient_terms::utils::GetSalience() from salient_terms_utils.h instead. DEPRECATED: prefer salience field above.
             */
            weight?: number;
        }
        interface QualitySalientTermsSalientTermSet {
            /** doc_data contain additional salient-term-set-level data. */
            docData?: QualitySalientTermsDocData;
            /** salient_term is the list of terms that are good descriptors, sorted in decreasing order of weight. */
            salientTerm?: QualitySalientTermsSalientTerm[];
            /** version is the Salient Terms version used to create the SalientTermSet. This is specific to web documents salient terms. */
            version?: string;
        }
        interface QualitySalientTermsSignalData {
            /**
             * A fixed bias for this signal, the higher the stronger. This can be used to balance the weight of signals independently of the confidence we give it. This field is only available in
             * debug mode.
             */
            bias?: number;
            /** The measurement of how much we trust this signal. Range: [0.0, 1.0] This field is available is both debug and non-debug mode. */
            confidence?: number;
            /** Raw saliences equal to half_salience will be equal to 0.5 normalized. Range: [0, volume]. This field is only available in debug mode. */
            halfSalience?: number;
            /**
             * The minimum TF for a term not to be considered noise. While the possible range of values for this field is [0, observed_volume], it is expected to be a somewhat small percentage of
             * observed_volume (e.g. 5%). This field is only available in debug mode.
             */
            noiseCorrection?: number;
            /** The measurement of how much we trust this signal, calculated using the observed volume. Range: [0.0, 1.0] This field is only available in debug mode. */
            observedConfidence?: number;
            /** The amount of signal we observed for a document. Range: [0.0, +infinity) This field is only available in debug mode. */
            observedVolume?: number;
            /** The amount of raw signal we observed for a document. Range: [0.0, +infinity) This field is only available in debug mode. */
            rawVolume?: number;
            /** source is the type of the signal of this SignalData. */
            source?: string;
            /** The amount of signal left after applying all corrections. Range: [0.0, +infinity) This field is only available in debug mode. */
            volume?: number;
        }
        interface QualitySalientTermsSignalTermData {
            /** The deduction of bigram counts from its unigram children. This field is only available in debug mode. */
            bigramDiscountTf?: number;
            /** How much we trust this bigram. For bigrams only. Range: [0.0, 1.0] This field is only available in debug mode. */
            bigramness?: number;
            /**
             * Measures how topical this term is to a particular signal. A term like "lincoln" in the Abraham Lincoln's Wikipedia page should have a centrality close to 1.0 while non-central terms
             * like "florida" should have a centrality close to 0.0. Range: [0.0, 1.0] This field is only available in debug mode.
             */
            centrality?: number;
            /** The final term frequency for a particular term. This field is only available in debug mode. */
            correctedTf?: number;
            /** The term frequency we were expecting for a term given its IDF. Range: [0, observed_volume] This field is only available in debug mode. */
            expectedTf?: number;
            /** Global NPMI. For bigrams only. This is a measure of the quality of bigrams calculated using IDF. Range: [-1.0, 1.0] This field is only available in debug mode. */
            globalNpmi?: number;
            /** The IDF of the label of a particular term. For a canonical term, this is the mean IDF of its originals, weighted by their observed TF. This field is only available in debug mode. */
            idf?: number;
            /** Whether or not this term is a bigram. This field is only available in debug mode. */
            isBigram?: boolean;
            /** Raw string that identifies a particular term. This field is only available in debug mode. */
            label?: string;
            /**
             * Local NPMI (normalized pointwise mutual information). For bigrams only. This is a measure of the quality of bigrams calculated using observed TF. Range: [-1.0, 1.0] This field is
             * only available in debug mode.
             */
            localNpmi?: number;
            /** The observed term frequency in a particular signal. This field is only available in debug mode. */
            observedTf?: number;
            /** The list of the original terms for a canonical. This is used in the pipeline and it is not present in the final output. This field is only available in debug mode. */
            originalTerm?: QualitySalientTermsSignalTermData[];
            /** The raw term frequency in a particular signal. This field is only available in debug mode. */
            rawTf?: number;
            /** The measure of how important this term is in this signal. Range: [0.0, 1.0] This field is only available in debug mode. */
            salience?: number;
            /** source is the type of the signal of this SignalTermData. */
            source?: string;
        }
        interface QualitySherlockKnexAnnotation {
            item?: QualitySherlockKnexAnnotationItem[];
        }
        interface QualitySherlockKnexAnnotationItem {
            /** in [0, 1]. */
            calibratedScore?: number;
            debugName?: string;
            /** in /m/ or /g/. */
            equivalentMid?: string;
            /** in [0, 1]. */
            score?: number;
            version?: number;
        }
        interface QualityShoppingShoppingAttachment {
            /** Score from the blockbert article classifier model. go/article-understanding-project */
            datasetModelArticleScore?: number;
            datasetModelBuyingGuideScore?: number;
            /** From forum and qna confidence score * 100, http://go/sdu-ugc-page-intro */
            datasetModelForumListScore?: number;
            datasetModelForumSingleScore?: number;
            datasetModelIndirectAvailabilityScore?: number;
            datasetModelInStoreOnlyScore?: number;
            /** From indexing.ml.PageType.confidence * 100 (DatasetModelAnnotation in cdoc) go/sdu-shopping-page-intro */
            datasetModelMultiProductScore?: number;
            datasetModelProductComparisonScore?: number;
            datasetModelProductReviewScore?: number;
            datasetModelProductTopnScore?: number;
            datasetModelQnaListScore?: number;
            datasetModelQnaSingleScore?: number;
            datasetModelSingleProductScore?: number;
            datasetModelSoldOutScore?: number;
            /** From indexing.badpages.CollapserInfo.expired_shopping_page_score * 100 */
            expiredShoppingPageScore?: number;
            /** From MagicPageTypeAnnotation.multiplicity.confidence_score * 100 Deprecated as of July 2020 when dataset_model_multi_product_score and dataset_model_single_product_score were added. */
            multiProductScore?: number;
            product?: QualityShoppingShoppingAttachmentProduct[];
            /** From ShoppingSiteClassifier.score * 100 */
            shoppingSiteScore?: number;
            /** From ShoppingSiteClassifierShopfab.score * 100 */
            shoppingSiteScoreShopfab?: number;
            singleProductScore?: number;
        }
        interface QualityShoppingShoppingAttachmentLocale {
            /** Use integers for fast scoring. Note: 26 is UNKNOWN_LANGUAGE_ID, 0 is UNKNOWN region, see i18n::languages::Language and StableInternalRegionconverter Use -1 as default for both. */
            languageId?: number;
            regionId?: number;
        }
        interface QualityShoppingShoppingAttachmentMokaFacetValue {
            facetId?: string;
            measureValue?: number;
            tagId?: string;
        }
        interface QualityShoppingShoppingAttachmentOffer {
            condition?: string;
            controlType?: string;
            /** fingerprint of original offer item_urland mobile_offer_url (if present) to be able to understand if offer data came from different url. */
            fingerprintOfOfferUrls?: string[];
            /** image_id is sorted and distinct for efficient search during serving. */
            imageId?: string[];
            /** inferred_images are sorted by inferred_image_id for efficient search during serving. */
            inferredImages?: ShoppingWebentityShoppingAnnotationInferredImage[];
            /** information about methods used to match offer with indexed url. See shopping_annotation.proto */
            matchingType?: string;
            /** account_id of the merchant in shopping systems. */
            merchantAccountId?: string;
            /** merchant_item_id is meaningless without the merchant_account_id. */
            merchantItemId?: string;
            /** direct to consumer brand merchant relationship */
            nonDisplayableBrandMerchantRelationship?: string;
            nonDisplayableCurrency?: string;
            /** Normalized riskiness score for Organic destinations. It's in range [0,1000] with 0 being the worst score and 1000 being the best. */
            nonDisplayableOrganicScoreMillis?: number;
            offerDocid?: string;
            refType?: string;
            soriVersionId?: ShoppingWebentityShoppingAnnotationSoriVersionId;
        }
        interface QualityShoppingShoppingAttachmentPBlock {
            /** Field full_title may contain duplicate info from title and list_title. */
            fullTitle?: string;
            /** Ordering for `image_docid`, and `image_info` are the same. */
            imageDocid?: string[];
            imageInfo?: QualityShoppingShoppingAttachmentPBlockImageInfo[];
            isFreeDelivery?: boolean;
            isFreeReturn?: boolean;
            listTitle?: string;
            maxPriceValue?: number;
            minPriceValue?: number;
            price?: string;
            priceCurrency?: string;
            priceValue?: number;
            /**
             * Product info extracted by Product Blocks go/sdu-shopping-page-intro and go/product-block-extraction. Here is an example of a page with a ## list_title (Shoes) and 3 blocks with
             * their own titles: | Shoes | | ---------------------| | * For Running | | ---------------------| | * Men's Hiking | | ---------------------| ## | * Dress Shoes | The field full_title
             * is what we constructed to best describe the product in the block. For example, for the above 3 blocks, their full_titles will contain info from list_title: "Shoes For Running",
             * "Shoes Men's Hiking", "Dress Shoes". Note that the list_title is not repeated for the 3rd block Real sample pages: http://screen/6UaoBtwWsLfbSKg http://screen/BDHRgDonKG3KcXu,
             * http://screen/53tLwNaX8mmYzDz
             */
            title?: string;
        }
        interface QualityShoppingShoppingAttachmentPBlockImageInfo {
            height?: number;
            width?: number;
        }
        interface QualityShoppingShoppingAttachmentProduct {
            aggregateRating?: ShoppingWebentityShoppingAnnotationProductRating;
            brandEntityId?: string;
            catalogId?: string;
            globalProductClusterId?: string;
            locale?: QualityShoppingShoppingAttachmentLocale;
            mokaFacet?: QualityShoppingShoppingAttachmentMokaFacetValue[];
            nonDisplayableDescription?: string;
            nonDisplayableTitle?: string;
            offer?: QualityShoppingShoppingAttachmentOffer;
            /** Whether an outlink points to the same domain or off-domain. Only added if the relationship is known, and the Offer has ref_type of OUTLINK. */
            outlinkDomainRelationship?: string;
            /** Client needs to make decision on which field to use when both non_displayable_title and pblock.final_title are present. */
            pblock?: QualityShoppingShoppingAttachmentPBlock;
            productClusterMid?: string;
            /** Organic product popularity. */
            productPopularity?: number;
            /** Relevance embedding from ShoppingAnnotation.Product */
            relevanceEmbedding?: QualityRankembedMustangMustangRankEmbedInfo[];
            /** Matched/Inferred weak product identity - set only if the global_product_cluster_id is missing */
            weakGlobalProductClusterId?: string;
        }
        interface QualitySitemapBreadcrumbTarget {
            docs?: QualitySitemapBreadcrumbTargetDoc[];
        }
        interface QualitySitemapBreadcrumbTargetDoc {
            /** The number of web pages that contains the url in their breadcrumbs. */
            count?: number;
            title?: string;
            url?: string;
        }
        interface QualitySitemapCoClickTarget {
            docs?: QualitySitemapCoClickTargetDoc[];
            language?: string;
        }
        interface QualitySitemapCoClickTargetDoc {
            coClickByLocale?: QualitySitemapCoClickTargetDocCoClickByLocale[];
            title?: string;
            url?: string;
        }
        interface QualitySitemapCoClickTargetDocCoClickByLocale {
            coClicks?: number;
            coClicksCapped?: number;
            coClicksParent?: number;
            locale?: string;
        }
        interface QualitySitemapScoringSignals {
            annotations?: string[];
            chromeTransCount?: string;
            chromeTransProb?: number;
            chromeWeight?: number;
            country?: string[];
            countryConfidence?: number[];
            impressions?: string;
            langConfidence?: number[];
            language?: string[];
            localCountryIdentifier?: string[];
            longClicks?: string;
            longCtr?: number;
            navboostScore?: number;
            navmenuScore?: number;
            pagerank?: number;
            recentLongCtr?: number;
            targetCdocLanguages?: number[];
            titleScore?: number;
        }
        interface QualitySitemapSubresult {
            docid?: string;
            itemMetadata?: QualitySitemapThirdPartyCarouselsListItemMuppetMetadata;
        }
        interface QualitySitemapSubresultList {
            subresult?: QualitySitemapSubresult[];
        }
        interface QualitySitemapTarget {
            DEPRECATEDSnippet?: string[];
            isGoodForMobile?: boolean;
            isMobileN1dup?: boolean;
            /** The languages of the document, taken from its cdoc.properties().languages() */
            languages?: number[];
            /**
             * The image data will be copied from the DocInfo response, and will be retrieved online, so this field should not be populated during indexing. This is a temporary field for
             * experimentation.
             */
            salientImage?: WWWResultInfoSubImageDocInfo;
            score?: number;
            scoringSignals?: QualitySitemapScoringSignals;
            /** Section texts used for Page Anchors Preview (go/page-anchor-preview-dd). */
            sectionTexts?: string[];
            /** The snippet response for the target document for an empty query. */
            snippetResponse?: GenericSnippetResponse;
            sourceAnchor?: boolean;
            title?: string;
            twoLevelScore?: number;
            url?: string;
        }
        interface QualitySitemapTargetGroup {
            /** If all the targets in this group are named anchors on the source page. */
            allTargetsNamedAnchors?: boolean;
            /** If all the targets in this group are named topictags_scrollto on the source page. */
            allTargetsNamedTopictagsScrollto?: boolean;
            breadcrumbTarget?: QualitySitemapBreadcrumbTarget;
            coClickTarget?: QualitySitemapCoClickTarget[];
            countryCode?: string;
            DEPRECATEDCountry?: number;
            label?: string;
            language?: number;
            modifiedByHostcardHandler?: boolean;
            scoringSignals?: QualitySitemapScoringSignals;
            Target?: QualitySitemapTarget[];
            /** A list of top urls with highest two_level_score, i.e., chrome_trans_clicks. */
            topUrl?: QualitySitemapTopURL[];
            twoLevelTarget?: QualitySitemapTwoLevelTarget[];
        }
        interface QualitySitemapThirdPartyCarouselsListItemMuppetMetadata {
            /** DEPRECATED. No longer populated, and not used anywhere. */
            urlFoundOnPage?: boolean;
        }
        interface QualitySitemapTopURL {
            score?: number;
            url?: string;
        }
        interface QualitySitemapTwoLevelTarget {
            firstLevelTarget?: QualitySitemapTarget;
            secondLevelTarget?: QualitySitemapTarget[];
        }
        interface QualitySnippetsTruncationSnippetBoldedRange {
            /** Bolded range [begin, end) */
            begin?: QualitySnippetsTruncationSnippetBoldedRangePosition;
            end?: QualitySnippetsTruncationSnippetBoldedRangePosition;
            /** Only populated for debugging. */
            text?: string;
            type?: string;
        }
        interface QualitySnippetsTruncationSnippetBoldedRangePosition {
            byteOffset?: number;
            index?: number;
        }
        interface QualityTimebasedLastSignificantUpdate {
            /** This is stored only for debugging purposes. Please consult dates@ team before making a dependency on this field. */
            adjustmentInfo?: QualityTimebasedLastSignificantUpdateAdjustments;
            /**
             * LastSignificantUpdate as UNIX timestamp in seconds. This is the new signal (go/lsu-dd) from LSU Selector V2 (once that is enabled, see b/171879888 for status), falling back to the
             * legacy V1 signal if the V2 signal does not exist. Please use the 'source' field to determine where the value comes from.
             */
            date?: string;
            /** The source the signal comes from. */
            source?: string;
        }
        interface QualityTimebasedLastSignificantUpdateAdjustments {
            adjustmentSource?: string;
            /** The timestamp is precise when it's derived from existing (>March 2022) passage timestamp. */
            isUpperboundTimestampPrecise?: boolean;
            /**
             * The timestamp that was picked up by the component indicated in the LastSignificantUpdateSource but was dropped due to exceeding the upper bound. The two following fields are present
             * only when the adjustment took place.
             */
            unadjustedTimestampInSeconds?: string;
            /** The upperbound value derived from passage timestamps. If present, the LSU date should never exceed this value. Design doc: go/lsu-max-passage-timestamp */
            upperboundTimestampInSeconds?: string;
        }
        interface QualityTimebasedOldnessInfo {
            /** Set to true if this page is considered old. */
            isOldPage?: boolean;
        }
        interface QualityTimebasedPageType {
            /** Set to true if this page is classified as a forum page. */
            isForumPage?: boolean;
            /** Set to true if this page has a fresh repeated date sequence. */
            isPageWithFreshRepeatedDates?: boolean;
            /** Set to true if this page is classified as a question answers page. */
            isQnaPage?: boolean;
        }
        interface QualityTimebasedSyntacticDate {
            /**
             * The following field is set only when the byline date is different from the "date" field above. Currently this happens when the byline date is within the 24 hours of the crawl time,
             * or close but not exactly the same as blog post date due to time zone. The syntactic date is never later than the crawl time. NOTE: If this field is set, use_as_byline_date will be
             * meaningless, and better to be cleared.
             */
            bylineDate?: string;
            /**
             * The number of seconds since epoch (Jan 1, 1970). This can be negative to indicate a publication date that is before 1970. For example, the ones from NY Times archive:
             * "http://select.nytimes.com/gst/abstract.html?res=F10B13FB3D5A10728FDDAF089" "4DD405B8588F1D3&scp=91&sq=world+war+II&st=p"
             */
            date?: string;
            daterange?: QualityTimebasedSyntacticDateDateRange;
            debugInfo?: string;
            /** If set to true, the source of the date has explicit time zone specification. Note: This is only used internally and should not be populated in docjoins. */
            fromExplicitTimeZone?: boolean;
            /**
             * Used to store extra information about the syntactic date. For now only two bits are set. Please refer to the encoding/decoding functions provided in:
             * quality/timebased/syntacticdate/util.h Bit 1 = High confidence byline. This bit is set if the syntactic date has a byline date and this date is considered to be high confidence. Bit
             * 2 = High confidence byline without content age. This bit is set if the syntactic date has a byline date and this date is considered to be high confidence without support from
             * content age.
             */
            info?: number;
            position?: QualityTimebasedSyntacticDatePosition;
            /** The precision mark should be of type PRECISION_MARK. */
            precisionMark?: number;
            /** If this is true, do not use syntactic date in date restricts. */
            syntacticDateNotForRestrict?: boolean;
            /**
             * Indicates the time zone offset in seconds applied to derive `date' in UTC. Example: Annotation: "1pm PST" (UTC-8) => -8 * 3600 = -28800 Note: This is only used internally and should
             * not be populated in docjoins.
             */
            timeZoneOffsetSeconds?: string;
            /** This bit is set if we believe that the syntactic date is really high confidence, but does not qualify as a byline date. */
            trustSyntacticDateInRanking?: boolean;
            /** Whether this date is good for display as the snippet byline date. */
            useAsBylineDate?: boolean;
            /**
             * This bit is set if the syntactic date is good to be used in site-level timezone guessing statistics calculation. (The date should be absolute date having a timestamp with hour and
             * minute level information. It can come with or without time zone information, which is indicated in from_explicit_time_zone field defined below.)
             */
            useInTimeZoneGuessingMode?: boolean;
            /** If true, the DateRange is used as date restrict, if false, the date is used as date restrict. Has no effect if syntactic_date_not_for_restrict is true. */
            useRangeInsteadOfDateForRestrict?: boolean;
        }
        interface QualityTimebasedSyntacticDateDateRange {
            end?: string;
            start?: string;
        }
        interface QualityTimebasedSyntacticDatePosition {
            begin?: number;
            end?: number;
        }
        interface QualityTravelGoodSitesData {
            i18n?: QualityTravelGoodSitesDataI18n[];
            isAggr?: boolean;
            isAttractionOfficial?: boolean;
            isEntity?: boolean;
            isHotelOfficial?: boolean;
            /** Factor that determines how local anchor credit is scaled before being added to global anchors. */
            normalizationFactor?: number;
            signal?: QualityTravelGoodSitesDataSignal[];
            site?: string;
            /** Site quality score, which determines the site type. */
            totalScore?: number;
            type?: string;
        }
        interface QualityTravelGoodSitesDataI18n {
            locale?: string;
            type?: string;
        }
        interface QualityTravelGoodSitesDataSignal {
            name?: string;
            value?: number;
        }
        interface QualityVidyaVideoLanguageVideoLanguage {
            /** Audio language of video classified by Automatic Language Identification. It corresponds to the first language (the highest confidence) in ALIResults.lang_results. */
            language?: string;
            /** Type of detected speech. */
            speechClass?: string;
        }
        interface QualityViewsExtractionClusterInfo {
            /** The cluster_id represents the id of the set entity that WebRef provides. */
            clusterId?: string;
            /** Cluster set qref confidence score. */
            clusterSetScore?: number;
            /**
             * The mids of cluster members that are part of the same cluster. Note that cluster members may end up having their own interpretation (EntityInfo which includes a ClusterInfo) or not
             * (eg because they do not explain the full query, and so aqua does not output an interpretation for them). The latter case (a cluster member is output only as part of this field), is
             * equivalent to its score being 0.
             */
            clusterSiblingMid?: string[];
            /** The score represents the score of the entity within the cluster. */
            score?: number;
            subCluster?: QualityViewsExtractionClusterInfo[];
        }
        interface QualityWebanswersTranscriptAnnotations {
            videoTranscriptAnnotations?: QualityWebanswersVideoTranscriptAnnotations[];
        }
        interface QualityWebanswersVideoTranscriptAnnotations {
            /** Should precisely match the amarna_docid in ContentBasedVideoMetadata. */
            amarnaDocid?: string;
            /** The language of the transcript as recorded in Amarna. */
            lang?: string;
            punctuatedTranscript?: string;
            saftDocument?: NlpSaftDocument;
            saftSentenceBoundary?: SentenceBoundaryAnnotations;
            /** Timing information that maps sentence boundaries in the punctuated transcript with timing offsets for the start and end of those sentences. */
            timingInfo?: QualityWebanswersVideoYouTubeCaptionTimingInfoAnnotations;
            webrefEntities?: RepositoryWebrefWebrefEntities;
        }
        interface QualityWebanswersVideoYouTubeCaptionTimingInfoAnnotations {
            durationMs?: number;
            instances?: QualityWebanswersVideoYouTubeCaptionTimingInfoAnnotationsInstance[];
            uploaderName?: string;
        }
        interface QualityWebanswersVideoYouTubeCaptionTimingInfoAnnotationsInstance {
            /** Byte offsets in HTML. begin is inclusive and end is exclusive. */
            begin?: number;
            end?: number;
            videoBeginMs?: number;
            videoEndMs?: number;
        }
        interface RegistrationInfo {
            /** This is the number of days since January 1st 1995 that this domain was last created. This should always fit in 15 bits. */
            createdDate?: number;
            /**
             * This is the number of days since January 1st 1995 that this domain last expired. This should always fit in 15 bits. Jan 1st 1995 was chosen by the history project as a special epoch
             * date. Both the registrationinfo dates and the linkage dates are measured in days since this epoch.
             */
            expiredDate?: number;
        }
        interface RepositoryAnnotationsGeoTopic {
            /** Stores parent/container information containing city, province & country. */
            address?: GeostoreAddressProto;
            /** The raw scores used to calculate the normalized_score. Note that not all these scores may be exposed to the users. */
            componentScores?: RepositoryAnnotationsGeoTopicalityScore[];
            /** A score [0, 1] indicating the confidence. */
            confidence?: number;
            /** Is this a dense city (e.g., population > 100k)? */
            denseCity?: boolean;
            /** Sub type for POI types like ESTABLISHMENT_POI, ESTABLISHMENT_GROUNDS & ESTABLISHMENT_BUILDING */
            establishmentType?: number;
            /** Latitude and Longitude of the location. */
            latE7?: number;
            lngE7?: number;
            /** Name of the Geographic location. This is the normalized name. */
            locationName?: string;
            /** A score [0, 1] indicating the likelihood of the location being the GeoTopicality. */
            normalizedScore?: number;
            /** Oyster Feature ID of the location. */
            oysterId?: GeostoreFeatureIdProto;
            /** Oyster Feature Type */
            oysterType?: number;
            /** The sum of the normalized scores of POIs contained within a particular locality. */
            sumContainedPoiNormalizedScores?: number;
        }
        interface RepositoryAnnotationsGeoTopicality {
            /** The geotopics are ordered by normalized_score in descending order. */
            geotopics?: RepositoryAnnotationsGeoTopic[];
        }
        interface RepositoryAnnotationsGeoTopicalityScore {
            rawScore?: number;
            type?: string;
        }
        interface RepositoryAnnotationsMustangSentimentSnippetAnnotations {
            /** Deprecated: use snippet_score instead */
            deprecatedMagnitude?: number;
            /** Deprecated: use snippet_score instead */
            deprecatedPolarity?: number;
            end?: number;
            isTruncated?: boolean;
            phraseType?: string;
            snippetScore?: number;
            /**
             * This protobuffer is serving double duty as both a Mustang attachment and the response proto that gets returned by Mustang in the WWWSnippetResponse's info MessageSet. When stored as
             * an attachment, this field will always be empty. However, when returned with the WWWSnippetResponse, Mustang will print and store the actual sentiment snippet's text here.
             */
            snippetText?: string;
            /** begin and end are token offsets. */
            start?: number;
        }
        interface RepositoryAnnotationsRdfaBreadcrumbs {
            /** Each crumb represents one link of the breadcrumb chain. */
            crumb?: RepositoryAnnotationsRdfaCrumb[];
            /** The URL of the document from which this breadcrumb trail was extracted. */
            url?: string;
        }
        interface RepositoryAnnotationsRdfaCrumb {
            /** The text that represented this crumb in the document. */
            title?: string;
            /** The URL linked from this crumb. */
            url?: string;
        }
        interface RepositoryAnnotationsRdfaRdfaRichSnippetsApplication {
            /** Fields for internal use */
            applicationUrl?: string;
            appTypeData?: RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationAppTypeData;
            breadcrumbs?: RepositoryAnnotationsRdfaBreadcrumbs;
            /** Application information. */
            category?: string[];
            /** These are currently used only for Google Play. */
            countriesSupported?: string[];
            countryPrices?: RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationCountryPrice[];
            currency?: string;
            description?: string;
            /** Developer console ID of the app if it exists. The ID is available for an app registered to Google Developers Console, not Play Developer Console. */
            devConsoleId?: string;
            /** Top 1 of extracted icon colors. We keep this field for backward compatibility. */
            extractedIconColor?: number;
            /** Top 10 of extracted icon colors. r = (rgb >> 16) & 0xff; g = (rgb >> 8) & 0xff; b = rgb & 0xff; */
            extractedIconColors?: number[];
            /** Tags to be indexed for filtering, e.g. "ft_popular_score_gt_1m". */
            filteringTag?: string[];
            genre?: string[];
            /** Whether the app has editors choice tag */
            hasEditorsChoiceBadge?: boolean;
            /** Icon and Screenshots */
            iconUrlHref?: string;
            iconUrlThumbnail?: string;
            /** Copied from google3/contentads/shared/boulder/mobile-app-data-image-data.proto. */
            imageData?: QualityCalypsoAppsUniversalImageData;
            /** Whether the app offers in-app purchase. */
            inAppPurchase?: boolean;
            /**
             * Indicates if the localized data comes from default locale. This is needed because the default localized data does not specify its locale. If this is true, lang_locale may not be the
             * correct locale and should be ignored.
             */
            isDefaultLangLocale?: boolean;
            /** locale for the localized data, such as name, description and screenshots */
            langLocale?: string;
            lastUpdated?: string;
            /** Unified proto for android LiveOps and iOS LiveEvents. */
            liveOpDetails?: QualityCalypsoAppsUniversalAuLiveOpsDetailInfo;
            localizedTrustedGenome?: RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationLocalizedTrustedGenome;
            /** Market Android or itunes */
            marketplace?: string;
            name?: string;
            numDownloads?: string;
            /** See google3/quality/richsnippets/schema/data/operating_systems_rules.txt for possible values. */
            operatingSystems?: string[];
            /** Whether this App is optional result for Grid UI. */
            optionalResult?: boolean;
            originalRating?: string;
            physicalDeviceTags?: string[];
            platformTags?: string[];
            popularScore?: number;
            /** Price */
            price?: string;
            rankData?: RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRankData;
            /** Ratings and reviews Either for this version only or for all versions to be displayed. */
            rating?: string;
            ratingCount?: string;
            releaseDate?: string;
            reviewAuthor?: string;
            reviewCount?: string;
            /** TODO(b/260128276) deprecate this field in favor of image_data. */
            screenUrlHref?: string[];
            screenUrlThumbnail?: string[];
            /** bytes or numeric with MB or GB */
            size?: string;
            subcategory?: string[];
            /** Whether this App supports Android TV. Note that some App supports more than one platforms. So we would use boolean for a platform. */
            supportsAndroidTv?: boolean;
            /** Whether this App supports Google Cast. */
            supportsChromecast?: boolean;
            totalRating?: number;
            /** Rating_count including all versions of this application. */
            totalRatingCount?: number;
            /** Trusted Genome data with categorical app information key: locale (e.g. en, en_US) */
            trustedGenomeData?: { [P in string]: VendingConsumerProtoTrustedGenomeAnnotation };
            /** Vendor */
            vendor?: string;
            vendorCanonicalUrl?: string;
            vendorUrl?: string;
            version?: string;
        }
        interface RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationAppTypeData {
            /** Top level app category type (GAME or APPLICATION). Copied from playwright. */
            playStoreAppType?: string;
        }
        interface RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationCountryPrice {
            countryCode?: string;
            /** ISO 4217 currency code. */
            currencyCode?: string;
            /** Price string converted from double value in a standard currency unit, like '199.35' or '1400'. */
            price?: string;
        }
        interface RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationLocalizedTrustedGenome {
            /** The chosen language */
            language?: string;
            /** The TG tags matching the locale of the doc, if available */
            localizedTg?: VendingConsumerProtoTrustedGenomeAnnotation;
        }
        interface RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRank {
            appStoreLink?: string;
            categoryId?: string;
            categoryName?: string;
            chartType?: string;
            rank?: string;
        }
        interface RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRankData {
            /** Copied from the category_id field from Playwright docs. It helps decide which category to show in app ranking info. */
            playwrightCategoryId?: string[];
            rank?: RepositoryAnnotationsRdfaRdfaRichSnippetsApplicationRank[];
        }
        interface RepositoryWebrefAggregatedEntityNameScores {
            entityScore?: RepositoryWebrefEntityNameScore[];
        }
        interface RepositoryWebrefAnchorIndices {
            /** The set of indices in the Anchors::anchor() array that belong to the collapsed anchors. */
            index?: number[];
        }
        interface RepositoryWebrefAnnotatedCategoryInfo {
            /** A debug string for the category. */
            debugString?: string;
            /** Listiness score of the category. */
            listiness?: number;
            /** The mid of the entity representing the category. */
            mid?: string;
        }
        interface RepositoryWebrefAnnotationDebugInfo {
            description?: string;
            infoString?: string[];
            /** Raw classification output from relevance classifier for classifier training and debugging. See http://go/entityclassifier for details on the classifier. */
            rawClassification?: EntitySignalsEntityClassification;
            url?: string;
        }
        interface RepositoryWebrefAnnotationRatings {
            docLevelRelevanceRatings?: RepositoryWebrefDocLevelRelevanceRatings;
        }
        interface RepositoryWebrefAnnotationStatsPerType {
            /** The average score for the open world for: - all ranges of this segment_type; - all capitalized ranges of this segment_type; - all uncapitalized ranges of this segment_type. */
            avgOpenWorld?: number;
            avgOpenWorldCap?: number;
            avgOpenWorldUncap?: number;
            /**
             * The number of ranges with candidates that made it past primary pruning for: - all ranges of this segment_type; - all capitalized ranges of this segment_type; - all uncapitalized
             * ranges of this segment_type.
             */
            numRangesWithCandidates?: string;
            numRangesWithCandidatesCap?: string;
            numRangesWithCandidatesUncap?: string;
            /** The segment type. */
            tokenType?: string;
        }
        interface RepositoryWebrefAnnotatorCheckpointFprint {
            fingerprint?: string;
            label?: string;
        }
        interface RepositoryWebrefAnnotatorProfile {
            numCandidateMentions?: number;
            numEntities?: number;
            numMentions?: number;
            numTokens?: number;
            /** Root/total of the timings from all the processors that worked on the given document or query. */
            processorTimingsRoot?: RepositoryWebrefProcessorTiming;
        }
        interface RepositoryWebrefBookEditionMetadata {
            /** Use varint encoding to save space. */
            bookEditionIsbn?: string;
            bookEditionMid?: string;
        }
        interface RepositoryWebrefBootstrappingScore {
            scoreRatio?: number;
        }
        interface RepositoryWebrefCategoryAnnotation {
            /** Experimental scores to be used by Discover. */
            browsyTopic?: RepositoryWebrefCategoryAnnotationBrowsyTopic;
            /** Title of the category. Eg "Politics", "Technology". */
            debugString?: string;
            /** Sources asserting the category. In the future we may have one calibrated confidence score. */
            hitcat?: RepositoryWebrefCategoryAnnotationHitCatSource;
            /** Mid representation of the category. Eg "/m/05qt0". WARNING: In UDR this field is not populated, use document_entity.entity.mid instead of document_entity.category.mid. */
            mid?: string;
            /** Qprime asserting this category. */
            shopping?: RepositoryWebrefCategoryAnnotationShoppingSignals;
        }
        interface RepositoryWebrefCategoryAnnotationBrowsyTopic {
            confidence?: number;
        }
        interface RepositoryWebrefCategoryAnnotationHitCatSource {
            /**
             * Confidence of the category in the range [0.0, 1.0). If a page has the category "NBA" with high confidence we also expect it to have the "Basketball" with high confidence. Categories
             * with a confidence lower than 0.05 are omitted. This can be interpreted as a confidence of 0, i.e. a strong signal that the category is not relevant for the page. For some categories
             * this score is calibrated per-category to estimate the true precision. E.g., 70% of documents retrieved within the confidence range [0.7 - eps, 0.7 + eps] will be relevant when eps
             * is close to 0.
             */
            confidence?: number;
            /**
             * Calibrated cumulative confidence guaranteeing maxmial recall for a precision target. E.g., At least 90% of documents retrieved with cumulative_confidence >= 0.9 will be relevant.
             * This score is always calibrated per-category to estimate the true cumulative precision and is not set for uncalibrated categories.
             */
            cumulativeConfidence?: number;
            /** Note: For testing the next version. May change at any time. Experimental confidence of the category in the range (0.0, 1.0). */
            experimentalConfidence?: number;
        }
        interface RepositoryWebrefCategoryAnnotationShoppingSignals {
            /** Whether QPrime asserts that particular category. */
            isShoppingAnnotation?: boolean;
        }
        interface RepositoryWebrefCategoryInfo {
            /**
             * Contains all types relevant for this entity, along with their provenances and confidences. This field basically replicates information above in a unified way, so that Refcon scroing
             * can make better use of it. If present, Refcon scoring will use all_types, and ignore other fields like freebase_type. Note: there is some basic conflict resolution applied when
             * all_types are computed (implemented in type-extractor.cc, IsLikelyConflictingFreebase).
             */
            allTypes?: RepositoryWebrefFreebaseType[];
            freebaseType?: RepositoryWebrefFreebaseType[];
            kgCollection?: RepositoryWebrefKGCollection[];
            oysterType?: RepositoryWebrefOysterType;
            /**
             * verticals4 categories that cooccur with this entity, aggregated over D2E. See where we read from CompactDocClassification in
             * http://google3/repository/webref/preprocessing/fatcat-categories.cc.
             */
            salientCategory?: RepositoryWebrefFatcatCategory[];
            wikipediaCategory?: RepositoryWebrefWikipediaCategory[];
            /** WPCat CategotyResult classification. */
            wpCategory?: RepositoryWebrefFreebaseType[];
        }
        interface RepositoryWebrefClusterMetadata {
            /**
             * If true, this entity is a synthetic entity created to represent a "set" in a cluster, i.e. to represent a set of entities (its children in the cluster graph) when we cannot
             * disambiguate among them. This is similar to a KG Collection, but this is not in KG.
             */
            isSet?: boolean;
            /** Explanation of where this cluster, and this entity, come from. All entities in a cluster have this, not just entities that have been created because of the cluster. */
            ruleInstance?: RepositoryWebrefClusterProtoRuleInstance;
        }
        interface RepositoryWebrefClusterProtoMidListRule {
            /** Id of this rule; this is used to generate ids for the synthetic entities created for a cluster. Required. */
            id?: string;
            /** The mids of the entities that will be made into a cluster. */
            mid?: string[];
        }
        interface RepositoryWebrefClusterProtoMidListRuleInstance {
            role?: string;
            /** The rule that this is an instance of. Required. */
            rule?: RepositoryWebrefClusterProtoMidListRule;
        }
        interface RepositoryWebrefClusterProtoRelationRule {
            /**
             * The topic_property_name for the link that defines the relation, e.g. "/tv/tv_series_episode/series". Can start with a "!" to indicate that this link is reversed during extraction
             * and we want the reversed case. Required.
             */
            relation?: string;
        }
        interface RepositoryWebrefClusterProtoRelationRuleInstance {
            role?: string;
            /** The rule that this is an instance of. Required. */
            rule?: RepositoryWebrefClusterProtoRelationRule;
            /** The one entity that the links of type R point to. Required. */
            target?: RepositoryWebrefWebrefEntityId;
        }
        interface RepositoryWebrefClusterProtoRuleInstance {
            /**
             * Exactly one of these *RuleInstance fields needs to be present for clusters which have not been merged; it selects the specific kind of rule instance. For merged clusters both fields
             * may be present.
             */
            midList?: RepositoryWebrefClusterProtoMidListRuleInstance;
            relation?: RepositoryWebrefClusterProtoRelationRuleInstance[];
        }
        interface RepositoryWebrefCompactFlatPropertyValue {
            predicateEncodedMid?: string[];
            /** The property corresponding to predicte_encoded_mid above. This is populated in some non-serving tables. */
            propertyName?: string;
            value?: RepositoryWebrefCompactKgValue[];
        }
        interface RepositoryWebrefCompactKgPropertyValue {
            encodedMid?: string;
            hrid?: string;
            value?: RepositoryWebrefCompactKgValue[];
            valueStatus?: string;
        }
        interface RepositoryWebrefCompactKgTopic {
            /** Mid of the topic; only filled in if no values. */
            mid?: string;
            propertyValue?: RepositoryWebrefCompactKgPropertyValue[];
        }
        interface RepositoryWebrefCompactKgValue {
            /** Present when value is bool. */
            boolValue?: boolean;
            /**
             * Compound values are those that contain either a number of simple valued facets (such as a latitude/longitude pair), or "mediator" topics representing multi-dimensional relationships
             * between topics. See metaweb/data/topictable/topic.proto for more details.
             */
            compoundValue?: RepositoryWebrefCompactKgTopic;
            /** Present when value is datetime. */
            datetimeValue?: string;
            /** Present when value is enum. */
            enumValue?: string;
            /** Present when value is float. */
            floatValue?: number;
            /** Present when value is an id. */
            idValue?: string;
            /** Present when value is int. */
            intValue?: string;
            /** Present when value is a serialized protocol buffer. */
            serializedProtoValue?: string;
            /** Present when value is text. */
            textValue?: string;
            /** Present when value is URI. */
            uriValue?: string;
            /** 32-bit fprint of uri. Can be used instead of `uri_value` to save space. See `GetNormalizedUriFprint32()`. */
            uriValueFprint32?: number;
        }
        interface RepositoryWebrefComponentReference {
            /**
             * Optionally the freebase_mid of the WebrefEntity which the Component identifies via entity_index. This is purely to help humans diagnose the WebrefEntities structure, may not always
             * be present and should not be used by production code. Use QueryJoinToMeaningStructConverter to compose a proper value in place of the component reference.
             */
            debugEntity?: string;
            /**
             * The WebrefEntity referenced by `index` is equivalent to this function call in this context, but not universally such that we don't want to recursively expand its MRF. Use this for
             * example if an entity corresponds to a category in an Intersect: CellPhones() & RelatedTo(/m/foo), where /m/cell_phones is equivalent to CellPhones() (and may or may not have an
             * annotated span), but we don't want to generally assert that /m/cell_phones == CellPhones(). This cannot be an actual FunctionCall to avoid a circular dependency.
             */
            funcallName?: string;
            /** The index of the Component of the CompoundMention which has the mrf_index of this MRF expression in WebrefEntity. Required. */
            index?: number;
        }
        interface RepositoryWebrefConceptNameMetadata {
            /** Bitfield of ConceptNameMetadata::NameType bits. */
            nameTypeMask?: string;
        }
        interface RepositoryWebrefDetailedEntityScores {
            /** Additional info regarding how the score of an annotation was obtained. These will no longer be set once the feature `topic2_detailed_scores` is enabled (Q4 2017). */
            anchorScore?: number;
            bodyScore?: number;
            /**
             * Represents how much the entity is connected/related to the other entities in the document. This signal partially influences the topicality score, but it is not totally aligned with
             * it: an entity can be very related to the rest of the document, but not central for understanding it. Likewise, an entity can be central to understand a document, but not very
             * related to the rest of the document. The value is in [0, 1].
             */
            connectedness?: number;
            /** How well the document scores for the entity. The score is unnormalized, and serves as a relative ranking signal between different documents for an entity. */
            docScore?: number;
            /** If the annotation corresponds to a geo topic, this is populated with GeoTopic::normalized_score. */
            geoTopicNormalizedScore?: number;
            /**
             * True if the entity is the author of the document. This was mainly developed and tuned for news articles (e.g. /m/02x27qn on "www.vogue.com/article/flint-town-netflix") but is also
             * popluated for other content (e.g. scientific articles). Important: the semantics of this field may change in the future or it might be removed and replaced with a different API. If
             * you want to use this field, please reach out to ke-authors@ first.
             */
            isAuthor?: boolean;
            /** True if the entity is the publisher of the page (e.g. CNN on "http://www.cnn.com/foo/bar"). */
            isPublisher?: boolean;
            /** Set to true iff the entity matches the full URL of the document, meaning that it is a reference page or related page of the entity. */
            isReferencePage?: boolean;
            /** If the annotation corresponds to a local entity, this is populated with LocalEntityAnnotations::Instance::location_confidence. */
            localEntityLocationConfidence?: number;
            nbScore?: number;
            /** DEPRECATED: this field is no longer set. As of early June 2018 it is referenced in hundreds of test files and is difficult to remove from the code base. */
            newsTopicalityScore?: number;
            /**
             * Representation of the topicality score that is normalized in [0, 1] and which sum over all entities in the document is 1. It represents the "proportion" of the document that talks
             * about the entity. This score is less human interpretable as the bucketized topicality score (EntityAnnotations.topicality_score), but is more suited for some usages like
             * aggregations.
             */
            normalizedTopicality?: number;
            /**
             * Signals used for mining new reference pages, set by the reference-page-scorer processor (that is turned off by default). This field is not populated, except for special reference
             * page extraction runs.
             */
            referencePageScores?: RepositoryWebrefReferencePageScores;
            /**
             * Relevance score generated by a Machine Learning entity classifier. This signal is similar to topicality, but machine learning based and supported by EntitySignals, not Webref. See
             * http://go/entityclassifier for details on the classifier.
             */
            relevanceScore?: number;
        }
        interface RepositoryWebrefDetailedMentionScores {
            patternInfo?: RepositoryWebrefPatternInfo[];
            /** How much confidence that a entity is annotated on a given name. NOTE: it's slightly different with normal annotation confidence. */
            posteriorForLearning?: number;
            /** How much support this mention received from the results for PostRef. This is populated only if explicitly requested and different from 0. */
            resultEntityScore?: number;
        }
        interface RepositoryWebrefDisplayInfo {
            /** Per language display name from reliable sources. */
            displayName?: RepositoryWebrefDisplayName[];
        }
        interface RepositoryWebrefDisplayName {
            /** An encylopedia style topic name (e.g. "Dog", not "Dogs"). Corresponds to Freebase /type/object/name and similar sources. */
            canonicalName?: string;
            /** The language of this name. See http://goto/iii for all the details on the language identifiers. */
            language?: string;
            /**
             * A name as it would be used for a news topic, an interest, the subject of a story. E.g. in list of things ("Related topics: Smartphones, computers, accidents". "Interests: Dogs").
             * *Fall back:* If the field is not populated, fall back to the "canonical_name" field. This field is usually not populated since (a) in most cases the subject form name is the same as
             * the canonical name, and (b) data coverage of subject-form names is currently much lower than data coverage of canonical names. Note: In some languages (e.g. French) the difference
             * between canonical names and subject names is larger than in English (not just plural vs. singular), but still strictly grammatical (including an article, capitalization, plural vs.
             * singular). Corresponds to Freebase /freebase/linguistic_hint/subject_form.
             */
            subjectName?: string;
        }
        interface RepositoryWebrefDocLevelRelevanceRatings {
            perDocRelevanceRatings?: RepositoryWebrefPerDocRelevanceRatings[];
        }
        interface RepositoryWebrefDocumentMetadata {
            /**
             * A copy of selected extensions from cdoc.doc_attachments and cdoc.per_doc_data, controlled by: --webref_doc_metadata_copy_instant_navboost_document (copies
             * doc_attachments[quality_freshness_abacus::InstantNavBoostDocument] (TypeId 105421467), defined in quality/freshness/abacus/public/abacus.proto). Used in Querybase to have navboost
             * associated with relevant cdocs. --webref_doc_metadata_copy_per_doc_navboost (copies per_doc_data[navboostdata]) (TypeId 4256936), defined in
             * mustang/repository/navboost/proto/navboostmustang.proto. Used in Querybase to have navboost associated with relevant docs. Note that it is not present in the original
             * doc_attachments, but in per_doc_data, and we copy it over here so as not to depend on the proto directly, as they are not compatible due to different app_engine compatibility.
             * --webref_doc_metadata_copy_images (copies doc_attachments[indexing::images::RelatedImageSignal]) (TypeId 21265426), defined in indexing/images/proto/image-linker.proto.
             */
            cdocAttachments?: any;
            /** The timestamp of when the document was crawled (if known). Copied from CompositeDoc.Content.CrawlTime. */
            crawlTime?: string;
            /**
             * Fingerprint of the document. We compute and set this fingerprint when creating the pagesets that we use for evals. Otherwise, this field is not normally set. We use the field to
             * make sure that the human ratings that we have are generated for the same version of the document, otherwise they might be invalid. We do not compute the fingerprint on the fly (e.g.
             * as a fingerprint of the proto buffer serialization of the cdoc) because protocol buffer serialization is not stable.
             */
            docFp?: string;
            /** DocId of the annotated document as read from cdoc.doc().docid(). */
            docId?: string;
            /** Urls that forward to this url. Needed for url -> topical entity entries. */
            forwardingUrls?: RepositoryWebrefForwardingUrls;
            /** Set to true if the document is a known disambiguation page, e.g. https://en.wikipedia.org/wiki/Orange. */
            isDisambiguationPage?: boolean;
            /** The document language, as read from doc().content().language(). This is go/language-enum value. */
            language?: string;
            /** The (weighted) number of incoming anchors (links from other documents). */
            numIncomingAnchors?: number;
            /**
             * Copies of selected repeated extensions from cdoc, controlled by: --webref_doc_metadata_copy_images (copies the repeated doc_images field (TypeId 8798074), defined in
             * image/search/imagedoc.proto).
             */
            repeatedCdocAttachments?: any[];
            /** The salient terms for this document. Only set if --webref_doc_metadata_copy_salient_terms is true. Same motivation as the title field above. */
            salientTerms?: QualitySalientTermsSalientTermSet;
            /**
             * The title of the document. Only set if --webref_doc_metadata_set_title is true. The idea is that we can use this to more easily learn things like: title contains "restaurants" ->
             * more likely to be a list page.
             */
            title?: string;
            /** The total clicks on this document, taken from navboost data. */
            totalClicks?: number;
            /** The url of the document. */
            url?: string;
        }
        interface RepositoryWebrefDomainSpecificRepresentation {
            /** The actual domain specific data. For example it can be freebase.Topic, repository_wikipedia.WikiJoin, ocean.WorkMetadata, geostore.Feature. */
            entityData?: any;
        }
        interface RepositoryWebrefEnricherDebugData {
            /**
             * Contains selected properties (from KG) whose values are not other entities (in which case they would be represented in link_info) but scalar values, possibly reachable through
             * (multiple) CVTs.
             */
            nonMidProperties?: RepositoryWebrefCompactFlatPropertyValue[];
            /**
             * This field contains reference pages for this entity. A reference page is a page that is highly topical for this entity, which can be used to mine additional information about this
             * entity. Example reference pages for Apple Inc. would be the composite docs for "http://en.wikipedia.org/wiki/Apple_Inc." and http://www.apple.com. For actors or movies, you can also
             * have the imdb page. Also see: http://go/refx-pages.
             */
            referencePage?: RepositoryWebrefSimplifiedCompositeDoc[];
            /**
             * This field contains mined related pages for the entity. A related page is a page that is moderately topical for this entity (More details: http://shortn/_KCE0GfQlpJ). This is mainly
             * used to mine additional information for entities which do not have reference pages Unlike reference pages, a single doc can be a related page for multiple mids.
             */
            relatedPage?: RepositoryWebrefSimplifiedCompositeDoc[];
        }
        interface RepositoryWebrefEntityAnnotations {
            /**
             * The overall confidence that the entity is annotated somewhere in the document or query. For WebRef it is computed as a function of the mention confidences weighted by the importance
             * of each mention, where for documents a mention is of greater importance if it occurs in the title, h1 or anchors. For QRef it is just the maximum of the confidence over all
             * mentions. NOTE: You probably want to use the mention-level segment_mentions.mention.confidence_score field instead of this one.
             */
            confidenceScore?: number;
            debugInfo?: RepositoryWebrefAnnotationDebugInfo;
            /** Additional information about how the entity relates to the page, for example whether it is a business entity which published the page. */
            detailedEntityScores?: RepositoryWebrefDetailedEntityScores;
            /** All ranges explained by the entity or any other entity it implies. Used in the context of partial query interpretation (go/partial-understanding). */
            explainedRangeInfo?: RepositoryWebrefExplainedRangeInfo;
            /**
             * An entity is marked as implicit if there is no explicit mention of the entity in the content of the page. For instance, all mentions of the entity are in query, url and/or anchors;
             * or the entity has only implicit content mentions.
             */
            isImplicit?: boolean;
            /**
             * True if the entity is an MDVC summary entity, i.e. it might not be mentioned directly on the query, but it is the product of resolving a set of explicit annotations. E.g. "2014 FIFA
             * World Cup" can be the summary for the query: [soccer world cup in brazil] even though none of the names of the entity is mentioned on the query. Summary nodes can also be synthetic,
             * i.e. have a /t/ mid, as they represent the intersection between a set of regular annotations. For more information, see http://go/mdvc-output.
             */
            isResolution?: boolean;
            /**
             * All mentions of a given concept grouped by segments. For Webref, there are many different kinds of segment, such as content, title and anchors; while for QRef, there is only one
             * segment called CONTENT. For QRef this field contains the primary output of the annotator, and for WebRef it together with topicality_score does.
             */
            segmentMentions?: RepositoryWebrefSegmentMentions[];
            /** Rank of the entity when sorted by topicality score. */
            topicalityRank?: number;
            /**
             * The WebRef topicality score of the entity for this document. This score indicates how related is the entity to the overall topic of the document. See
             * https://goto.google.com/topicality-score for details. This field is not present in QRef output. Note that the topicality and the confidence score are orthogonal measures. It is
             * possible that the annotator is absolutely sure that an entity is mentioned in a given range in the document, but this entity may be unrelated to the overall topic of the page (e.g.
             * the entity "RSS" is mentioned in the footer of appleinsider.com). In this case the mention has a very high confidence score, but very low topicality score.
             */
            topicalityScore?: number;
        }
        interface RepositoryWebrefEntityDebugInfo {
            /** A human-readable description of the entity. This can range from brief, machine-generated notes to lengthy human-written paragraphs from Wikipedia. */
            description?: string;
            /** The language (III LanguageCode) of the `title` and `description` fields. */
            language?: string;
            /** Internal score to merge debug info. should not set in final entityjoins. */
            score?: number;
            /** A short human-readable name/title of the entity, similar to what is displayed at the top of a Hume page. Suitable to be displayed in a list. */
            title?: string;
            /** Link to a page with more information about the entity (internal Hume page, external Wikipedia page, etc.). */
            url?: string;
        }
        interface RepositoryWebrefEntityJoin {
            /** The id of this entity, prefer accessing through webref-entities-util.h functions. */
            annotatedEntityId?: RepositoryWebrefWebrefEntityId;
            /**
             * This field contains reference pages for this entity. A reference page is a page that is highly topical for this entity, which can be used to mine additional information about this
             * entity. Example reference pages for Apple Inc. would be the composite docs for "http://en.wikipedia.org/wiki/Apple_Inc." and http://www.apple.com. For actors or movies, you can also
             * have the imdb page. Also see: http://go/refx-pages.
             */
            cdoc?: RepositoryWebrefSimplifiedCompositeDoc[];
            /**
             * The context names (with scores) of this entity. The difference to regular names (aka name_info) is that context names are not used for finding mentions in a document as they consist
             * of names somehow related to the entity (e.g. name "fisherman s wharf" for the entity "Gary Danko"). Used for reconciling freebase and oyster.
             */
            contextNameInfo?: RepositoryWebrefGlobalNameInfo[];
            /** Debug information about the entity. */
            debugInfo?: RepositoryWebrefEntityDebugInfo[];
            /** Optional profiling data from the enricher that enriched this entity (and produced this EntityJoin as debug output). */
            enricherAnnotatorProfile?: RepositoryWebrefAnnotatorProfile;
            /** Contains debug data produced by enricher and only used for debug purpose (e.g. demo). */
            enricherDebugData?: RepositoryWebrefEnricherDebugData;
            /**
             * Additional metadata about the entity, that can be derived from the "raw data" (composite doc, domain specific data...), or come from other sources. Despite its name, this field
             * often contains quite important information.
             */
            extraData?: RepositoryWebrefExtraMetadata;
            /** Human ratings (e.g. ratings from EWOK). This is typically only populated in the evaluation pipelines (e.g. P@5). */
            humanRatings?: RepositoryWebrefHumanRatings;
            /** Contains all links (with scores) that Webref knows for this entity. Links are relationships between entities. The data in this field is very important for the quality of the model. */
            linkInfo?: RepositoryWebrefGlobalLinkInfo[];
            /** Contains all names (with scores) that Webref knows for this entity. The data in this field is very important for the quality of the model. */
            nameInfo?: RepositoryWebrefGlobalNameInfo[];
            /** Contains names and names metadata used by Refcon. */
            refconNameInfo?: RepositoryWebrefRefconRefconNameInfo[];
            /**
             * An entity can have metadata from various data sources. Generally speaking all sources will be / should be reconciled into a single KG Topic entry. However, in some cases we pull in
             * additional chunks of metadata from these sources; these are stored in this field. For example a local business could have a KG entry (topic proto), wikipedia entry (WikiJoin) and a
             * MapFacts entry (Feature proto).
             */
            representation?: RepositoryWebrefDomainSpecificRepresentation[];
        }
        interface RepositoryWebrefEntityLinkMetadata {
            /** The aggregate kind flags for the link. */
            aggregateFlags?: RepositoryWebrefLinkKindFlags;
            /** Information about all the link kinds associated with the link. */
            kindInfo?: RepositoryWebrefLinkKindInfo[];
        }
        interface RepositoryWebrefEntityLinkSource {
            /** KG-property if the SourceType is associated with a KG-property (TOPIC_PROPERTY, NEW_TOPIC_PROPERTY). */
            kgProperty?: string;
            /**
             * Score in [0, \infty) that represents how relatively likely it is to see that entity cooccurring with the main entity (in the entity join). A value of 1.0 means that the two entities
             * are basically independent. The higher the more likely (relatively to the individual entity probabilities) they are to cooccur.
             */
            score?: number;
            type?: string;
        }
        interface RepositoryWebrefEntityNameRatings {
            language?: string;
            name?: string;
            /** Every entity name receives one or a few ratings from human raters. */
            ratings?: RepositoryWebrefEntityNameRatingsEntityNameRating[];
            /**
             * Multiple tags can be assigned to a rated entity name. The tags can be used when computing metrics in the Name Eval, so that different metrics are computed separately for different
             * sets of examples that have the same tag.
             */
            tags?: string[];
        }
        interface RepositoryWebrefEntityNameRatingsEntityNameRating {
            label?: string;
            source?: string;
        }
        interface RepositoryWebrefEntityNameScore {
            /**
             * If the EntityNameScore is part of a bootstrapped model, then this field contains the score_ratio from the previous model ("Model 0"). If Model 0 does not have a corresponding entry,
             * because it did not know about this name for this entity, then bootstrapping_previous_iteration is left empty.
             */
            bootstrappingPreviousIteration?: RepositoryWebrefBootstrappingScore;
            /**
             * Confidence that this name is a trusted name of the entity. A reasonable threshold for name trust is 0.6. A name can be trusted and still have very low score_ratio, esp. if it is
             * ambiguous (e.g. 'mercury') and/or not the dominant interpretation (e.g. "siberian husky" -> /m/06krnsr (a book)).
             */
            confidence?: number;
            /** Debug information about the entity. */
            debugInfo?: RepositoryWebrefEntityDebugInfo[];
            /** Source and score data, this is internal to refx (e.g. for demo/debug). */
            debugVariantSignals?: RepositoryWebrefPreprocessingNameVariantSignals[];
            /** Sparse metadata about the entity, usage should be moved back to individual fields, this avoids having cyclic dependencies. */
            entity?: RepositoryWebrefEntityJoin;
            /** Stores region specific score ratios for the entity when it is significantly different from the language version above. */
            extendedScoreRatio?: RepositoryWebrefExtendedEntityNameScore[];
            /** Include this name in the name lookup table. */
            includeInModel?: boolean;
            /** Transient field, only used in bootstrap pipeline. */
            internalBootstrapIsOpenWorld?: boolean;
            internalIsClusterParent?: boolean;
            /** Set to true iff the concept is cluster parent and the name can be a name for any child of the cluster. (e.g. 'starbucks' is cluster_global for the [Starbucks] chain cluster). */
            isClusterGlobal?: boolean;
            /** Documened at: repository/webref/universal/webref_data/enricher/entity-data.h */
            isDropped?: boolean;
            /**
             * Only for context names: Whether this EntityNameScore represents an entity that was dominant in the search results but was not annotated by QRef during learning. Matchless result
             * contexts are useful for bootstrapping, where different model iterations may have different names and thus context scores from Model 0 that are inconsistent with the names from Model
             * 1.
             */
            isMatchlessResultContext?: boolean;
            /** Documened at: repository/webref/universal/webref_data/enricher/entity-data.h */
            isPruned?: boolean;
            /** The id of the entity. */
            mid?: string;
            /** Metadata about this name aggregated from name signals. */
            nameMetadata?: RepositoryWebrefPreprocessingNameEntityMetadata;
            /** Metadata of segment range, which is annotated by this entity. */
            rangeMetadata?: RepositoryWebrefRangeMetadata[];
            /** The absolute score of that entity. score = artificial_score + volume_based_score */
            score?: number;
            /** Ratio between this entity score and the total score over all entities. This is including the "open world" information if it was estimated. */
            scoreRatio?: number;
            /** When this field is true, we consider this context name as candidate in Enricher's names pipeline. */
            useAsNameCandidate?: boolean;
            /** Absolute score that comes from quantitative sources such as navboost clicks, anchors, etc. artificial_score = score - volume_based_score */
            volumeBasedScore?: number;
        }
        interface RepositoryWebrefEntityNameSource {
            /** All the entity-name scores from that source. Keyed by the EntityNameScore.entity_id field. */
            entityScore?: RepositoryWebrefEntityNameScore[];
            /** Describes where the data comes from. */
            type?: string;
        }
        interface RepositoryWebrefEntityScores {
            /** Probability that any given name of this entity is fully capitalized. */
            allCapsProb?: number;
            /**
             * This field is only for debugging and link weight experiments. It stores the entity's idf from the alpha model. Alpha idfs are used for link weight computations and available during
             * model omega building via enricher_current_entity_idf_for_link_direction.
             */
            alphaEntityIdf?: number;
            /** Probability that the entity is a common ngram (e.g. from dictionary). */
            commonNgramProb?: number;
            /**
             * The final (model omega) idf of an entity. Equals log2(1 / probability of the entity to appear in a document). This probability is currently estimated from its names (i.e. it is a
             * sum of the name frequency weighted by P(entity | name)).
             */
            entityIdf?: number;
            /** Probability that any given name of this entity is capitalized. */
            nameCapitalizationProb?: number;
            /** The following fields are deprecated and should eventually be removed. They use data and rules that have not been refreshed for ~10y and KG has changed a lot in the meantime. */
            personProb?: number;
        }
        interface RepositoryWebrefExplainedRangeInfo {
            /** All ranges explained by the entity. */
            explainedRange?: RepositoryWebrefExplainedRangeInfoExplainedRange[];
            geoQueryCoverage?: string;
        }
        interface RepositoryWebrefExplainedRangeInfoExplainedRange {
            /** SegmentMention describing the occurrence of the token in the document. */
            mention?: RepositoryWebrefSegmentMention;
        }
        interface RepositoryWebrefExtendedEntityNameScore {
            /** The domain name of the website, e.g. "play.google.com". */
            domain?: string;
            /** The region in the III standard (http://go/iii). Eg. "US", "GB" */
            region?: string;
            /** Score ratio for the entity, same as the EntityNameScore score ratio. */
            scoreRatio?: number;
        }
        interface RepositoryWebrefExtraMetadata {
            /** For a book entity, store its book editions metadata. Used by Juggernaut to do /book/book_edition recon, see ariane/265006. This field is used by Juggernaut only. */
            bookEditionMetadata?: RepositoryWebrefBookEditionMetadata[];
            /** Information about category types of the entity. */
            categoryInfo?: RepositoryWebrefCategoryInfo;
            /** Metadata about clusters. */
            clusterMetadata?: RepositoryWebrefClusterMetadata;
            /** Information for displaying the entity in applications. */
            displayInfo?: RepositoryWebrefDisplayInfo;
            /** Additional scores for the entity. */
            entityScores?: RepositoryWebrefEntityScores;
            /**
             * An entity in KG that represents the same (or equivalent) entity in the real world. In particular, this is used for mid-forwarding: when de-duping entities in KG, the old ids
             * represent the exact same entity as the one they were merged with. So when we see one id in the query and the other in a document, they are treated as the same entity.
             */
            equivalentEntityId?: RepositoryWebrefWebrefEntityId[];
            /** Geo-specific entity metadata. */
            geoMetadata?: RepositoryWebrefGeoMetadataProto;
            /** Metadata related to KC attributes and Question & Answer triggering. */
            kcAttributeMetadata?: RepositoryWebrefKCAttributeMetadata;
            /**
             * A list of entities that are latent given this entity. For example, "Lionel Messi" can have the latent entity "FC Barcelona". The latent entity links are materialized in an offline
             * pipeline using r/w/scripts/latent_entities/latent-entities.pq. For more information, see go/latent-entities.
             */
            latentEntities?: RepositoryWebrefLatentEntities;
            /** Metadata about MDVC. */
            mdvcMetadata?: RepositoryWebrefMdvcMetadata;
            /** Other metadata. */
            otherMetadata?: any;
            /**
             * The primary recording mid of a recording cluster entity. Used by Juggernaut to do /music/recording recon, see b/139901317. The primary recording is unique to a recording cluster.
             * This field is used by Juggernaut only.
             */
            primaryRecording?: string;
            /** Products-specific entity metadata. */
            productMetadata?: RepositoryWebrefProductMetadata;
            /** # LINT.ThenChange( //depot/google3/repository/webref/evaluation/query/metrics/util.cc) */
            specialEntityType?: string;
            specialWord?: MapsQualitySpecialWordsProto[];
            /** Metadata about support transfer rules defined for this entity. */
            supportTransferRules?: RepositoryWebrefSupportTransferRule[];
        }
        interface RepositoryWebrefFatcatCategory {
            /** The category ID from verticals4. See go/verticals4 and where we read them in http://google3/repository/webref/preprocessing/fatcat-categories.cc */
            id?: number;
            /** The relative weight of the category within a distribution. */
            score?: number;
        }
        interface RepositoryWebrefForwardingUrls {
            /** Urls that forward to this url. Used for url -> topical entity entries. */
            forwardingUrl?: string[];
        }
        interface RepositoryWebrefFprintModifierProto {
            capitalization?: string;
            enclosing?: string;
            /** i18.languages.Language enum defined in i18n/languages/proto/languages.proto UNKNOWN_LANGUAGE */
            language?: number;
            namespaceType?: string;
            punctuation?: string;
            sentence?: string;
            sourceType?: string;
            stemming?: string;
            style?: string;
            tokenType?: string;
        }
        interface RepositoryWebrefFreebaseType {
            /** Optional - for inferred types the principal source of information. */
            provenance?: string[];
            /** Optional score. Not present in KG directly but e.g. in WPCat. */
            score?: number;
            /** Mid of this type. Equivalent to type_name, but is more compact. When present, overrides type_name (which can be omitted in this case to save space). */
            typeMid?: string;
            /** e.g.: "/business/industry", "/book/book_subject", "/people/person"... */
            typeName?: string;
        }
        interface RepositoryWebrefGenericIndices {
            /** The segment index. */
            index?: number;
        }
        interface RepositoryWebrefGeoMetadataProto {
            /** Stores parent/container information containing city, province & country. */
            address?: GeostoreAddressProto;
            addressSynonyms?: RepositoryWebrefGeoMetadataProtoAddressSynonym[];
            /** Area in km^2 of the feature if the feature has polygon. */
            areaKm2?: number;
            /** The tight bounds of this feature. Note that these are different from the FeatureProto.bound field. */
            bound?: GeostoreRectProto;
            /** Country code of the country of the entity. Only available in qref-metadata. */
            countryCode?: string;
            /** The geographic location (center) and geometry of this entity. See geostore.FeatureProto for more details. */
            location?: GeostorePointProto;
            /** The best name from Oyster for this entity. Is only included for some types of entities, and is a trimmed version of the proto (some fields are cleared). */
            name?: GeostoreNameProto;
            /** The oyster id of the entity */
            oysterId?: GeostoreFeatureIdProto;
            /**
             * Numerical country code, converted with i18n/identifiers/stableinternalregionconverter.h. It is the same as country_code, but it is available in the annotator model (and takes less
             * space).
             */
            stableIntegerCountryCode?: number;
            /** Timezone if the feature is contained inside one. */
            timezone?: string;
            /** Information about the geographic location (center) extracted from the wikijoins. */
            wpLocation?: RepositoryWebrefWikipediaGeocode[];
        }
        interface RepositoryWebrefGeoMetadataProtoAddressSynonym {
            language?: string;
            name?: string;
            /** The type of the geocoded address. e.g. Road, Lake, Ocean, building. This comes from TypeCategory field in geostore/base/proto/feature.proto */
            type?: number;
        }
        interface RepositoryWebrefGlobalLinkInfo {
            /**
             * A short human-readable name/title of the entity, similar to what is displayed at the top of a Hume page. Do not use for any production purpose as it does not provide guarantees for
             * stability or policy checks (access requirements).
             */
            debugTitle?: string;
            /** Whether this is a BoostedPrimaryWeight link. For these links in some cases a higher weight is used for primary scoring. */
            isBoostedPrimaryWeightLink?: boolean;
            /** The mid of the linked entity. */
            targetMid?: string;
            /** The information about this link for each locale. */
            variantInfo?: RepositoryWebrefLinkInfo[];
        }
        interface RepositoryWebrefGlobalNameInfo {
            /** The normalized name. */
            normalizedName?: string;
            /** All the variants of this name together with associated information such as score, sources, etc. */
            variantInfo?: RepositoryWebrefNameInfo[];
        }
        interface RepositoryWebrefHumanRatings {
            annotationRatings?: RepositoryWebrefAnnotationRatings;
        }
        interface RepositoryWebrefImageQueryIndices {
            /**
             * The (canonical) image docid of the ImageData this image query is part of. Useful for identifying the ImageData even after doc_images are updated in between Webref annotation runs.
             * Use docid only when canonical_docid == 0.
             */
            canonicalDocid?: string;
            docid?: string;
            /**
             * WARNING: The doc_images in docjoins are subject to updates including non-deterministic reordering of doc_images and their image_nb_data extensions. This means that without
             * re-running WebrefAnnotator one cannot rely on the accuracy or even consistency of either image_index or query_index when parsing a cdoc from docjoins. In those situations one ought
             * to rely on canonical_docid (or docid when canonical_docid is absent viz. 0). The index of the source image in CompositeDoc::doc_images.
             */
            imageIndex?: number;
            /** Queries index in ImageData::image_data_navboost. */
            queryIndex?: RepositoryWebrefQueryIndices;
        }
        interface RepositoryWebrefJuggernautIndices {
            /**
             * Index within the proto. Several indices are necessary in case of nested repeated fields. The data can be accessed as follows: TOPICS: topic_annotations.kg_schema_topic(index(0))
             * .property_value(index(1)) .value(index(2)); TRIPLES: reconcile_request.triple(index(0));
             */
            index?: number[];
            type?: string;
        }
        interface RepositoryWebrefKCAttributeMetadata {
            /** Equivalent kc attribute id for the given entity if applicable. E.g. for Daughter (/m/029wnx) this will be 'kc:/people/person:daughter'. */
            equivalentAttributeId?: string;
        }
        interface RepositoryWebrefKGCollection {
            /** A human friendly identifier (collection hrid). NOTE: The field name is a misnomer, this is the preferred field to use in production. */
            debugId?: string;
            /**
             * Identifier of the collection, usually a MID (/m/xyz or /g/zyw). NOTE: In most cases, this is not the id that should be used, debug_id is the preferred identifier. The main reason is
             * the this is not a stable id (mid for collection sometimes shift around).
             */
            id?: string;
        }
        interface RepositoryWebrefLatentEntities {
            /** Latent entities with associated metadata including source of the relationship. This is pruned ("compacted") from the concept table and will never reach the annotator. */
            latentEntity?: RepositoryWebrefLatentEntity[];
            /** List of broader MIDs from the Sports Hierarchy. Named incorrectly, it does not contain all latent mids. */
            latentMid?: string[];
        }
        interface RepositoryWebrefLatentEntity {
            /** The relatedness score of the two entities corresponding to each source above. */
            broaderImportance?: number[];
            /** The mid of the latent entity. */
            mid?: string;
            /** The sources this generalization relationship is coming from. */
            sources?: string[];
        }
        interface RepositoryWebrefLexicalAnnotation {
            lexicalRange?: RepositoryWebrefLexicalRange[];
        }
        interface RepositoryWebrefLexicalRange {
            /** Byte offset of the begin of the |category|. */
            beginOffset?: number;
            category?: string;
            /** Direction defines the relation between the measurable aspect and the facet. */
            direction?: string;
            /** Byte offset of the end of the |category|. */
            endOffset?: number;
            /** The mid of the facet associated with ASPECT category. */
            facetMid?: string;
        }
        interface RepositoryWebrefLightweightTokensMatchedLightweightToken {
            /** The byte offset of the beging of the additional lightweight token match. e.g. the prefix pattern of the circumfix. */
            additionalBeginOffset?: number;
            /** The byte offset of the end of the additional lightweight token match. e.g. the suffix pattern of the circumfix. */
            additionalEndOffset?: number;
            /** The byte offset of the begin of the lightweight token match within each range. The default value of -1 (std::string::npos) means that there's no affix or adposition detected. */
            beginOffset?: number;
            /** The byte offset of the end of the lightweight token match within each range. The default value of 0 means that there's no affix or adposition detected. */
            endOffset?: number;
            /** Matched pattern Id which will be used to retrieve back pattern features. Pattern id is only populated for Enricher model. */
            patternId?: string;
            /**
             * The index of the source entity in the resulting WebrefEntities or WebrefEntitiesWrapper, to which the lightweight token rule is applied. This field is only populated at the end of
             * Qref scorer when we are sure which source entity should output.
             */
            sourceEntityIndex?: number;
            /** The type of the lightweight token match, which provides the semantic information. */
            type?: string;
        }
        interface RepositoryWebrefLightweightTokensPerMentionLightweightToken {
            matchedLightweightToken?: RepositoryWebrefLightweightTokensMatchedLightweightToken[];
        }
        interface RepositoryWebrefLightweightTokensPerNameLightweightToken {
            matchedLightweightToken?: RepositoryWebrefLightweightTokensMatchedLightweightToken[];
        }
        interface RepositoryWebrefLinkInfo {
            /** The score aggregated from all sources. */
            aggregatedScore?: number;
            /**
             * The EntityJoin keeps bi-directional links, but for some applications we only need them in one direction. This value indicates whether this is the preferred direction to keep. (We
             * usually prefer keeping the link from the less common to the more common entity for performance reasons). For categorical links the preferred direction is from child to parent.
             */
            isPreferredDirection?: boolean;
            /** The metadata associated with the link. */
            metadata?: RepositoryWebrefEntityLinkMetadata;
            /** The per-source scores. */
            source?: RepositoryWebrefEntityLinkSource[];
        }
        interface RepositoryWebrefLinkKindFlags {
            cluster?: string;
            geoContainment?: string;
            implication?: string;
            latentEntity?: string;
            mdvc?: string;
            property?: string;
            resolution?: string;
        }
        interface RepositoryWebrefLinkKindInfo {
            /** The flags associated with the link kind. */
            flags?: RepositoryWebrefLinkKindFlags;
            /** Link name extracted from Knowledge Card facts. */
            kcLinkName?: string;
            /**
             * If the link was extracted from a property, the name of the property. Can start with an exclamation mark "!" to indicate that the inverse relationship is specified. (e.g.
             * "!/tv/tv_series_episode/series" is the inverse of "tv/tv_program/episodes").
             */
            topicPropertyName?: string;
        }
        interface RepositoryWebrefLocalizedString {
            /** The domain name from which results come, e.g. "play.google.com". */
            domain?: string;
            /** FprintModifier describing the formatting of the string. If fprint_modifier is set, then original_string, language and region should not be set. */
            fprintModifier?: RepositoryWebrefFprintModifierProto;
            /** The language in the III standard (http://go/iii) */
            language?: string;
            normalizedString?: string;
            originalString?: string;
            /** The region in the III standard (http://go/iii) */
            region?: string;
            /** Which querybase pipeline the data comes from. */
            sourceType?: string;
        }
        interface RepositoryWebrefMdvcMetadata {
            /** Undergoing migration into the PerVertical message. Avoid using it. Concept ids of MDVC dimensions of this concept. */
            dimension?: string[];
            /**
             * Undergoing migration into the PerVertical message. Avoid using it. List of encoded mids to be expanded in WebRef/QRef output whenever this entity gets annotated. Will be populated
             * in the annotators once static data is deprecated. b/78866814.
             */
            expandedOutputConceptId?: string[];
            /** Undergoing migration into the PerVertical message. Avoid using it. Concept ids of MDVC generalizations of this concept. */
            generalization?: string[];
            /** True iff the topic is synthetically created during by MDVC extraction. */
            isSynthetic?: boolean;
            /** Data, specific to particular verticals. */
            perVertical?: RepositoryWebrefMdvcMetadataPerVertical[];
            /**
             * Undergoing migration into the PerVertical message. Avoid using it. Resolution priority for this entity. In case a query has many possible resolutions, only the ones with the highest
             * resolution priority are annotated.
             */
            resolutionPriority?: number;
        }
        interface RepositoryWebrefMdvcMetadataPerVertical {
            /** Concept ids compatible with this topic: specializations and/or ones having this concept as a dimension. Always includes the topic itself. */
            compatibleIds?: string[];
            /** Concept ids of the dimension values of this topic. */
            dimensionIds?: string[];
            /** Concept ids to annotate whenever this entity is annotated. */
            expandedOutputIds?: string[];
            /** Concept ids of the generalizations of this topic. */
            generalizationIds?: string[];
            /** True if the topic is considered a "core topic" for the vertical. */
            isCore?: boolean;
            /** If true, the entity is a dimension for some entities in the vertical. */
            isDimension?: boolean;
            /** If true, the entity is a generalization for some entities in the vertical. */
            isGeneralization?: boolean;
            /** Resolution priority for this entity. If there are many possible resolutions to a MDVC understanding, only the ones with the highest priority are annotated. */
            resolutionPriority?: number;
            /** Fingerprints that identify the topic's sub-verticals, if any. */
            subVerticalFp?: string[];
            /** Name of the vertical this message is about. */
            verticalName?: string;
        }
        interface RepositoryWebrefMention {
            /** Whether this mention was created by CloseAnswers on Postref. This bit is populated into corresponding intent_query through Aqua. */
            addedByCloseAnswers?: boolean;
            /** If the mention's range is discontinuous, additional ranges that are a part of the mention but are not included in the begin/end range above. */
            additionalExplainedRange?: RepositoryWebrefMentionAdditionalExplainedRange[];
            /**
             * The [begin, end) byte offset, compatible with the Goldmine DocState representation. - For CONTENT, TITLE, META_CONTENT_TAG and IMG_ALT_TAG segments, the offsets are relative to the
             * beginning of the document content. - For ANCHOR, QUERY, URL, IMAGE_QUERY, CONTEXT_ENTITY, CONTEXT_QUERY, SPORE_GRAPH, INSTANT_QUERY and VIDEO_TRANSCRIPT segments, the offsets are
             * relative to the beginning of the corresponding (sub-)segment or text from doc attachment. The (indexing.annotations.goldmine) options are marks for Goldmine AnnotationsFinder to
             * locate begin and end offsets in order to extract them
             */
            begin?: number;
            /**
             * The [begin end) token offsets in the Goldmine DocState. They follow similar rules as "begin" and "end" above, but for tokens rather than byte offsets. These fields are currently
             * only populated by the query annotator.
             */
            beginTokenIndex?: number;
            /**
             * For a compound mention, the references to the entity and mention of the components. Each compound_mention claims one or more 'mrf' fields from the WebrefEntity owning this mention.
             * Use QueryJoinToMeaningStructConverter to expand compound mentions into complete MRF.
             */
            compoundMention?: RepositoryWebrefMentionCompoundMention[];
            /**
             * A probabilistic score describing how certain the annotator is that this exact range in the document or query refers to the entity. Probability that a mention is correct corresponds
             * to confidence score roughly as follows: 0.3 -> 75% 0.5 -> 87% 0.7 -> 89% 0.9 -> 94% 1.0 -> 98% However if you consider all mentions with a score above 0.3, then most of these will
             * have scores close to 1, so the overall precision of these mentions is around 95%.
             */
            confidenceScore?: number;
            /** Debug information. */
            debugInfo?: RepositoryWebrefMentionDebugInfo;
            /** Additional detailed scores about this mention. */
            detailedMentionScores?: RepositoryWebrefDetailedMentionScores;
            end?: number;
            endTokenIndex?: number;
            /** Information used by the evaluation tools to mark mentions annotations as correct/incorrect. This will never be annotated in production (would be nice if was, though :-)). */
            evalInfo?: RepositoryWebrefMentionEvalInfo;
            /** DEPRECATED and not populated anymore. */
            interpretationNumber?: number[];
            /**
             * True if the entity is mentioned implicitly. Note that a mention can be implicit *and* have a non-empty range, for example if the entity is Sports, and this is inferred from the
             * mention of "gym".
             */
            isImplicit?: boolean;
            /** Provides a Wordgraph lexical signals for the mentioned range so it can be use in LooseParsing. Please don't use this field before consulting wordgraph-team. */
            lexicalAnnotation?: RepositoryWebrefLexicalAnnotation;
            /**
             * Qref & Postref only: Set to true for candidates part of qref candidate output for which there was no mention in qref. Internal to qref and LooseParsing. Do not use outside of these
             * systems.
             */
            lowConfidence?: boolean;
            /**
             * Refcon-only: Annotated span in Refcon-normalized textual format, corresponding to the [begin end) offset interval in the CDoc. It will only be populated for CDocs originated from
             * Docjoin extraction.
             */
            matchingText?: string;
            /** Metadata attatched to the name. */
            nameMetadata?: RepositoryWebrefConceptNameMetadata;
            /** Whether the mention is a non-locational reference to a geographical entity. Ranges from 0 (locational) to 1 (non-locational). */
            nonLocationalScore?: number;
            /** Provides concised access to all matched MatchedLightweightToken. */
            perMentionLightweightToken?: RepositoryWebrefLightweightTokensPerMentionLightweightToken;
            /** Additional personalization output scores about this mention. */
            personalizationContextOutputs?: RepositoryWebrefPersonalizationContextOutputs;
            /** The prior probability of the entity for this mention. */
            priorProbability?: number;
            /**
             * Whether the mention is a reference (e.g. it could be resolved to an entity coming from personal data) or not, currently only used for personal resolutions. Scores from 0 (not a
             * reference) to 1 (reference). Use at your own risk as they are subject to change, advised to talk to refx-personal first.
             */
            referenceScore?: number;
            /**
             * Whether the mention is a resolution or not, currently only used for personal resolutions. Scores from 0 (not a resolution) to 1 (resolution). Use at your own risk as they are
             * subject to change, advised to talk to refx-personal first.
             */
            resolutionScore?: number;
            /** Assorted things that can be added to a Mention. */
            stuff?: any;
            /** Identifies the sub-segment where the annotation occurs. See SubSegmentIndex for details. Not present in QRef, also deprecated for URL segment types. */
            subsegmentIndex?: RepositoryWebrefSubSegmentIndex;
            /**
             * Confidence for the time_offset_ms annotation, quantized to values in range 0-127 (see speech::VideoASRServerUtil::ConfidenceQuantize for how the quantization was done). Confidence
             * can be empty for special characters (e.g. spaces).
             */
            timeOffsetConfidence?: number;
            /**
             * Timestamp that this mention appeared in the video. The field is only populated for VIDEO_TRANSCRIPT when the byte offset is the same. It is extracted from
             * cdoc.doc_videos.content_based_metadata.transcript_asr.transcript.timestamp.
             */
            timeOffsetMs?: number;
            /** Confidence that this name is a trusted name of the entity. This is set only in case the confidence is higher than an internal threshold (see ConceptProbability). */
            trustedNameConfidence?: number;
        }
        interface RepositoryWebrefMentionAdditionalExplainedRange {
            /** Like begin/end, begin_token_index/end_token_index above. */
            begin?: number;
            beginTokenIndex?: number;
            end?: number;
            endTokenIndex?: number;
        }
        interface RepositoryWebrefMentionComponent {
            /**
             * The indices to identify the entity within the WebrefEntities.entities, the segment within its EntityAnnotations.segment_mentions, and the mention within that segment. entity_index
             * is always guaranteed to be set, but segment_mentions_index and mention_index are omitted if the component reference is implicit.
             */
            entityIndex?: number;
            /** The source of the compound has designated this component as the head. Only one of the components can be a head, but it's possible none are. */
            isHeadComponent?: boolean;
            mentionIndex?: number;
            segmentMentionsIndex?: number;
        }
        interface RepositoryWebrefMentionCompoundMention {
            /**
             * References to the component mentions which the MRF needs to be fully expanded. It is guaranteed that for a given set of components there exists only a single CompoundMention, i.e.
             * the CompoundMentions are deduped to be unique so each set of components is present only once. The ArgumentValue of the WebrefEntity.mrf refer to these components via
             * ComponentReference; it is guaranteed there are as many components as the MRF expression refers to.
             */
            component?: RepositoryWebrefMentionComponent[];
            /**
             * The WebrefEntity.mrf indices which this compound applies to. There can be at most one CompoundMention which claims an MRF index, but it is possible there are MRF expressions which
             * are not claimed by any CompoundMention.
             */
            mrfIndex?: number[];
        }
        interface RepositoryWebrefMentionDebugInfo {
            /** A clean version of text. This is mostly used for compatibility with other Goldmine annotators. */
            cleanText?: string;
            /** Optional debug information. */
            infoString?: string[];
            /**
             * A snippet of the parsed text (html tags removed) in the page around this mention. Useful for human evaluation of the quality of the annotations. Outputted by WebrefAnnotator if
             * --webref_output_mention_snippet_size is set to a value greater than 0.
             */
            snippet?: string;
            /** Original UTF-8 document text occurring in the range [begin, end). */
            text?: string;
        }
        interface RepositoryWebrefMentionEvalInfo {
            /** Weight of the mention used in the ATM score. */
            atmWeight?: number;
            /** The aggregate numerical rating of this mention. 0.0 means completely incorrect, and 1.0 completely correct. */
            rating?: number;
        }
        interface RepositoryWebrefMentionRatings {
            /** Byte offsets of the mention. */
            begin?: number;
            end?: number;
            mentionMatch?: string[];
            singleMentionRating?: RepositoryWebrefMentionRatingsSingleMentionRating[];
        }
        interface RepositoryWebrefMentionRatingsSingleMentionRating {
            /**
             * Set for mentions got from the new topicality template. True if the raters checked this range as being a good range for the entity. If the range is not correct we demote the mention
             * score. This field is only used in template version V1. From template version V2 and forward it is now set via phrase_refer.
             */
            isCorrectRange?: boolean;
            mentionMatch?: string;
            mentionRelevant?: string;
            phraseRefer?: string;
            /** Whether rater can understand the topic. */
            raterCanUnderstandTopic?: boolean;
            /** The source of the rating, possibly a golden set external to EWOK. */
            ratingSource?: string;
            resultCount?: number;
            taskData?: RepositoryWebrefTaskData;
            topicMentionedInResult?: string[];
        }
        interface RepositoryWebrefNameDebugInfo {
            /** List of per-candidate signals derived from annotation of this query. */
            candidates?: RepositoryWebrefNameDebugInfoCandidateInfo[];
            /** Query with region (language is set in parent NameInfo). */
            query?: RepositoryWebrefLocalizedString;
            /** Query weight used in learning. */
            weight?: number;
        }
        interface RepositoryWebrefNameDebugInfoCandidateInfo {
            /** Whether the entity is purely from strong result entities, and is matchless in query annotation. */
            isMatchlessResultContext?: boolean;
            /** Mid of the candidate entity or empty string for the full world. */
            mid?: string;
            /** Debug name of the entity (not usually populated). */
            name?: string;
            resultEntityScore?: number;
        }
        interface RepositoryWebrefNameInfo {
            /** The score aggregated from all sources. */
            aggregatedScores?: RepositoryWebrefAggregatedEntityNameScores;
            /** Information on categories annotated on the range. */
            annotatedCategory?: RepositoryWebrefAnnotatedCategoryInfo[];
            /** DEBUG ONLY: stores a list of queries with per-candidate scores about signals used for prior learning. */
            debugDetails?: RepositoryWebrefNameDebugInfo[];
            /** Field which decides if this NameInfo should be included in model creation. */
            includeInModel?: boolean;
            /** The specific name to which this information applies. */
            name?: RepositoryWebrefLocalizedString;
            /** N-gram data (e.g. n-gram IDF). */
            ngramData?: RepositoryWebrefUniversalNgramData;
            /** Lightweight token semantic metadata for inflected name. */
            perNameLightweightToken?: RepositoryWebrefLightweightTokensPerNameLightweightToken;
            /** The name-specific scores. These scores only depend on the name and are independent of the entity. */
            scores?: RepositoryWebrefNameScores;
            /** The per-source scores. */
            source?: RepositoryWebrefEntityNameSource[];
        }
        interface RepositoryWebrefNameScores {
            /**
             * Approximates volume of this name including entities we don't have in our set. This is useful to estimate the size of the "open world". For example, this field can be equal to the
             * total number of clicks for the query. Note that for now, we ignore the number of clicks but just use the idf if available.
             */
            completeWorldVolume?: number;
            /** The fringe score in [0, 1] for this context name. This is only populated for full-query context names. */
            contextFringeScore?: number;
            /** The amount of evidence available for this context name. */
            contextWeight?: number;
            /** The idf of this name. */
            idfScore?: number;
            /**
             * 'Raw' open world is computed based on ngram count data. For some names however, we modify the open world based on entities associated with them. This field contains the additive
             * open world modifier. open_world_volume = raw open world + open_world_volume_modifier
             */
            openWorldVolumeModifier?: number;
            /** The total score of that name/source. It describes how much data we have for that name/source. It can for example be the sum of all the entity scores for this name. */
            totalScore?: number;
        }
        interface RepositoryWebrefNgramContext {
            /** The entities that were annotated on the context */
            mention?: RepositoryWebrefNgramMention[];
            /** The context (original) text. */
            text?: string;
            /** The weight of the context on the document; depends on how many times we saw the string in the document. */
            weight?: number;
        }
        interface RepositoryWebrefNgramMention {
            /** The entity the mention was referring to. */
            mid?: string;
            /** The average score the mention was given across all occurrences of the n-gram. */
            score?: number;
        }
        interface RepositoryWebrefOysterType {
            /** The Oyster feature type, which provides a rough categorization. This is a value of the enum geostore.FeatureProto.TypeCategory. */
            featureType?: number;
            /**
             * Geo Ontology GConcept Instances from the FeatureProto. - Design doc linked off http://wiki/Main/GeoOntology - Use the accessor library to read this field:
             * geostore/base/public/gconcept_instance.h
             */
            gconcepts?: GeostoreOntologyRawGConceptInstanceContainerProto;
        }
        interface RepositoryWebrefPatternInfo {
            /** The confidence we can trust this pattern. */
            matchProbability?: number;
            /** Whether other slots is mentioned in annotator. If they is no other slot, it is set to true. */
            otherSlotsMentioned?: boolean;
            /** The corresponding patterns matched on this candidate, which contains the pattern string and the slot number of the candidate in this pattern, such as [|/athletes|vs|/athletes|]_1. */
            pattern?: string;
        }
        interface RepositoryWebrefPerDocRelevanceRating {
            contentRelevant?: string;
            /** How this rating is displayed in the evals, pre-computed from the other fields. */
            displayString?: string;
            /** The url of the ewok task that resulted in this rating. Example: https://furball.corp.google.com/project/view-item?itemId=1&projectId=2 */
            furballUrl?: string;
            itemId?: string;
            /** If the topic is about a business chain, whether the */
            pageIsAboutChain?: string;
            /** Metadata for task-level ratings. Not filled for aggregated doc-level ratings. */
            projectId?: string;
            /** Whether rater can understand the topic. */
            raterCanUnderstandTopic?: boolean;
            taskDetails?: RepositoryWebrefTaskDetails;
            taskId?: string;
            /** Whether the topic is about a business chain. */
            topicIsChain?: string;
        }
        interface RepositoryWebrefPerDocRelevanceRatings {
            /**
             * - In topicality ratings this is Fingerprint2011() of the normalized cdoc. - In query-mention ratings this is a hash of the QueryJoin. - In doc-content-mention ratings this is a hash
             * of a QueryJoin in which the mention rating task has been embedded. -
             */
            docFp?: string;
            entityNameRating?: RepositoryWebrefEntityNameRatings[];
            mentionRating?: RepositoryWebrefMentionRatings[];
            taskLevelRating?: RepositoryWebrefPerDocRelevanceRating[];
            /**
             * - In topicality ratings this is the url of the document. - In query-mention ratings this is the query in format "en:US:query text". - In doc-content-mention ratings this is %x:%s
             * where %x is the hex doc_fp of the cdoc (TODO(b/139799592) or sometimes the doc_fp below), and %s is the text of the eval range. - In entity-name ratings this is the MID of the
             * entity.
             */
            url?: string;
        }
        interface RepositoryWebrefPersonalizationContextOutput {
            /**
             * Score corresponding to some kind of biasing strength which was applied. The exact semantics of this score is subject to further changes. Don't make assumptions about specific values
             * or ranges. Values > 0 represents that a boost was applied. Values < 0 represents that a penalty was appled.
             */
            score?: number;
            type?: string;
        }
        interface RepositoryWebrefPersonalizationContextOutputs {
            /** Detailed output scores per personalization type. */
            outputs?: RepositoryWebrefPersonalizationContextOutput[];
        }
        interface RepositoryWebrefPreprocessingNameEntityMetadata {
            /**
             * There is a limit of entities per name for which we can keep name signals and score. This flag is set to true for names that by-passed per-name-scoring, as there were too many
             * entities for the name.
             */
            isBypassedName?: boolean;
            /** This name is a generated compound name to pass primary pruning. */
            isCompoundName?: boolean;
            /** Indicates special compound retrieval keys, like "Compound $mid1 $mid2" */
            isCompoundRetrievalKey?: boolean;
            /** This is set to true if the entity corresponds to a dictionary term. */
            isDictionaryTerm?: boolean;
            /** If true, this name is an event retrieval key. */
            isEventRetrievalKey?: boolean;
            /** This name is generated from other names. */
            isGeneratedName?: boolean;
            /** This name is a generated street name. */
            isGeneratedStreetname?: boolean;
            /** This name is added by name propagation in hierarchy. */
            isHierarchyPropagated?: boolean;
            /** This name is an ISBN. */
            isIsbn?: boolean;
            /** This name comes from recording lyrics content. */
            isLyricsContent?: boolean;
            /** This name is a phone number. */
            isPhoneNumber?: boolean;
            /** This name is used for refcon. */
            isRefconName?: boolean;
            /** This name is a reference name, only for internal usage, this name should not go into matching table without support of other signals. */
            isReferenceName?: boolean;
            /** This name is the URL of a reference page. */
            isRefpageUrl?: boolean;
            /** This name is generated from a reverse unique property of the entity. */
            isReverseUniquePropertyName?: boolean;
            /** This name is a strong identifier for this entity. */
            isStrongIdentifier?: boolean;
            /** Set if the name is coming from synonyms. */
            isSynonymOrFuzzyMatch?: boolean;
            /** If true, this name is a trusted name if it is in ALLCAPS. */
            isTrustedAllcapsName?: boolean;
            /** If true, do not do tokenization when compute fprint hash for this name. */
            isUnnormalizedName?: boolean;
            /**
             * This name is clearly not generated(aka. at least one source of this name is not generated). This field is added for simplifying generated name tag while merging. Do not use this
             * metadata directly.
             */
            notGeneratedName?: boolean;
            /** Original versions of the name (before normalization). Used as query for the entity by Explicit Entity Search. */
            originalNames?: RepositoryWebrefPreprocessingOriginalNames;
            /** Whether or not to suppress tokenization on this name. */
            suppressTokenization?: boolean;
        }
        interface RepositoryWebrefPreprocessingNameEntityScores {
            /**
             * An unnormalized measure of how much evidence we have that this name variant refers to the key entity. Should be comparable to all scores from the same source for: - other entities
             * having the same name variant - the open world score computed for this name variant
             */
            priorScore?: number;
            /** Prior score come from source that is quantifiable. artificial_score = prior_score - volume_based_score. */
            volumeBasedScore?: number;
        }
        interface RepositoryWebrefPreprocessingNameVariantSignals {
            /** Common prior_score/trust proto This field is shared by all sources providing this kind of data, the information has to be considered in context with the source. */
            scores?: RepositoryWebrefPreprocessingNameEntityScores;
            /** The source of this NameVariantSignals proto */
            source?: string;
        }
        interface RepositoryWebrefPreprocessingOriginalNames {
            /** The total number of original names that a normalized name has (all versions from all different sources). */
            count?: number;
            name?: RepositoryWebrefPreprocessingOriginalNamesOriginalName[];
        }
        interface RepositoryWebrefPreprocessingOriginalNamesOriginalName {
            /** The total number of different sources from where this version of the original name comes from. */
            count?: number;
            /** Score estimating how good this original name is: - some sources are considered more authoritative than others (e.g. KG) - a name found in more sources is better. */
            score?: number;
            /** The sources this name comes from. */
            source?: number[];
            /** One original name version. */
            text?: string;
        }
        interface RepositoryWebrefPreprocessingUrlMatchingMetadata {
            /** The sources the url was suggested by. */
            source?: RepositoryWebrefPreprocessingUrlSourceInfo[];
        }
        interface RepositoryWebrefPreprocessingUrlSourceInfo {
            deprecatedOldSchema?: RepositoryWebrefPreprocessingUrlSourceInfoOldSchema;
            newSchema?: RepositoryWebrefPreprocessingUrlSourceInfoNewSchema;
            originalUrl?: string;
            source?: string;
        }
        interface RepositoryWebrefPreprocessingUrlSourceInfoNewSchema {
            sourceProperty?: string;
        }
        interface RepositoryWebrefPreprocessingUrlSourceInfoOldSchema {
            isOfficial?: boolean;
        }
        interface RepositoryWebrefProcessorCounter {
            name?: string;
            value?: number;
        }
        interface RepositoryWebrefProcessorTiming {
            /** Cpu instructions spent. */
            cpuInstructions?: string;
            /** A string identifying the processor timing context. */
            name?: string;
            /** Document counters defined by processors. A processor can add and increment counters with NestedPerfCounter::IncrementCounterBy. See go/webref-annotator-metrics. */
            processorCounters?: RepositoryWebrefProcessorCounter[];
            /** Nested measurements, see NestedPerfCounter::ScopedPerfCounter. */
            processorTimings?: RepositoryWebrefProcessorTiming[];
            /** Wall time (in nanoseconds). */
            wallTimeNs?: string;
        }
        interface RepositoryWebrefProductMetadata {
            /**
             * Shopping product line ids (typically moka product line tag) of this entity. Represents shopping product lines, such as iPhone or Canon EOS. Typically, we expect only one id. But
             * keeping repeated, in case we want to merge or aggregate product lines. Using int64, as tag_id in commerce/datastore/processors/moka/proto/moka_annotations.proto.
             */
            productLineId?: string[];
            /** All ShoppingIds for this MID that need to be copied to IntentQuery (FunctionCall) if this MID is used in intent generation. See go/iql-shopping-ids for details. */
            shoppingIds?: KnowledgeAnswersIntentQueryShoppingIds;
            type?: string;
            /** All unique variant cluster ids (shopping's GPCs) of this entity. */
            variantClusterId?: string[];
        }
        interface RepositoryWebrefQueryIndices {
            /** The set of indices in the NavBoostQuery::features() array that belong to the collapsed features. */
            featuresIndex?: number[];
            /** The index of the query in NavBoostDocument::queries() array. */
            queriesIndex?: number;
        }
        interface RepositoryWebrefRangeAnnotations {
            /** The actual mentions. Note SegmentMentions contains some fields specific to entity annotation, and those are typically not populated here. */
            segmentMentions?: RepositoryWebrefSegmentMentions[];
            /** The type of ranges contained in this message. */
            type?: string;
        }
        interface RepositoryWebrefRangeMetadata {
            /** Start index of range (within the segment) being annotated. */
            beginOffset?: number;
            /** Number of tokens in the range being annotated. */
            tokenCount?: number;
        }
        interface RepositoryWebrefRefconDocumentMentionSpans {
            /** Per token mention spans. */
            mentionSpan?: RepositoryWebrefRefconMentionSpans[];
        }
        interface RepositoryWebrefRefconMentionSpans {
            /** Segment types in which the mention appears. Now deprecated, because we only care about CONTENT segments. */
            segment?: string[];
            /**
             * Fingerprinted tokens which form the mention span. We are using 32-bit instead of usual 64bit fingerprints - this greatly reduces the memory footprint while still keeping the chance
             * of collision reasonably low for our specific use case (1 in 4 billion).
             */
            shortToken?: number[];
            /** Fingerprinted tokens which form the mention span. */
            token?: string[];
        }
        interface RepositoryWebrefRefconQueryStats {
            /** Total query count for the document from all the query terms. Can be used to estimate the popularity of the document. */
            aggregatedQueryCount?: number;
        }
        interface RepositoryWebrefRefconRefconDocumentMetadata {
            queryStats?: RepositoryWebrefRefconQueryStats;
        }
        interface RepositoryWebrefRefconRefconNameInfo {
            confidence?: number;
            idfScore?: number;
            isGeneratedName?: boolean;
            isI18nName?: boolean;
            isStrongIdentifier?: boolean;
            isTranslatedName?: boolean;
            /** Languages of the name, unknown language is not kept. TODO(b/145976266) Don't use the deprecated language enum. */
            language?: number[];
            /** Name prior to use. We read this from the prior for the "unknown" language. */
            namePrior?: number;
            /** The normalized name. */
            normalizedName?: string;
            /** Filled only if different than normalized_name. */
            originalName?: string;
            score?: number;
        }
        interface RepositoryWebrefReferencePageScores {
            /** Stores score for later offline voting to choose reference pages. If zero, it's not a good book reference page. */
            bookScore?: number;
            /**
             * Fraction of importance_ratio (IR) that is explained by this entity and implied entities. E.g. a page about a song with IR 0.2 for the song and 0.5 for the artist actually has
             * explained_normalized_topicality 0.7 for the song.
             */
            explainedNormalizedTopicality?: number;
            /** The raw topicality score of the primary entity. */
            firstScore?: number;
            /** Whether the primary entity has any "special" links. Currently a link is considered special if it has a good implication probability and has no negative disambiguation probability. */
            hasSpecialLinks?: boolean;
            /** The median mentions core of the primary entity. */
            medianMentionScore?: number;
            /** The navboost token coverage ratio. All queries are taken into account. */
            navboostCoverage?: number;
            /** Reference page score used to select the reference page owner. */
            referencePageScore?: number;
            /** The score used to sort reference pages for a given entity. This score tries to assign higher scores to reference pages that are more useful to the model building. */
            referencePageSelectionScore?: number;
            /** True if the entity is selected as the reference page owner. */
            selected?: boolean;
            /** A score in [0, 1] which indicates the single topicness of the entity. */
            singleTopicness?: number;
            /** This should have the same semantic as single_topicness, and should replace it in the long term. */
            singleTopicnessV2?: number;
            /** =================================== Signals for the single topicness. Only filled in for the primary (i.e., top ranked) entity. The title token coverage ratio. */
            titleCoverage?: number;
            /** The sum of raw topicality scores for all entities in this page. */
            totalSum?: number;
        }
        interface RepositoryWebrefSegmentMention {
            mention?: RepositoryWebrefMention;
            segmentType?: string;
        }
        interface RepositoryWebrefSegmentMentions {
            /**
             * A list of all the places the entity in question was annotated within this segment. The (indexing.annotations.goldmine) option is for Goldmine AnnotationsFinder to include Mention
             * only when segment_type="CONTENT"
             */
            mention?: RepositoryWebrefMention[];
            segmentType?: string;
        }
        interface RepositoryWebrefSemanticDateRange {
            /** Indicates how confident we are this extracted range is relevant to a document (document to be infered from context). */
            confidence?: number;
            /** End date extracted from the entity along end_source_property. */
            end?: string;
            /** KG-property that links the entity to the end date. */
            endSourceProperty?: string;
            /** Entity from which this range was extracted. */
            sourceEntityMid?: string;
            /** Start date extracted from the entity along start_source_property. */
            start?: string;
            /** KG-property that links the entity to the start date. */
            startSourceProperty?: string;
        }
        interface RepositoryWebrefSimplifiedAnchor {
            /** The set of (equivalent from WebRef point of view) anchors used to produce this segment. */
            anchorIndices?: RepositoryWebrefAnchorIndices;
            /** The anchor text. Note that the normalized text is not populated. */
            anchorText?: RepositoryWebrefLocalizedString;
            /** The number of times we see this anchor text. */
            count?: string;
            /** Count, score, normalized score, and volume of offdomain anchors. */
            countFromOffdomain?: string;
            /** Count, score, normalized score, and volume of onsite anchors. */
            countFromOnsite?: string;
            /** The normalized score, which is computed from the score and the total_volume. */
            normalizedScore?: number;
            normalizedScoreFromOffdomain?: number;
            normalizedScoreFromOnsite?: number;
            /** The sum/aggregate of the anchor scores that have the same text. */
            score?: number;
            /** The sum/aggregate of the anchor scores that direct to a fragment and have the same text. */
            scoreFromFragment?: number;
            scoreFromOffdomain?: number;
            scoreFromOffdomainFragment?: number;
            scoreFromOnsite?: number;
            scoreFromOnsiteFragment?: number;
            /** The sum/aggregate of the anchor scores that direct to a different wiki title and have the same text. NOTE: url direct to a fragment score is not included in this value. */
            scoreFromRedirect?: number;
            /** The total score volume used for normalization. */
            totalVolume?: number;
            totalVolumeFromOffdomain?: number;
            totalVolumeFromOnsite?: number;
        }
        interface RepositoryWebrefSimplifiedAnchors {
            anchor?: RepositoryWebrefSimplifiedAnchor[];
        }
        interface RepositoryWebrefSimplifiedCompositeDoc {
            /** The composite doc anchors trimmed and transformed in a smaller data structure and aggregated (if they have the exact same text). */
            anchors?: RepositoryWebrefSimplifiedAnchors;
            /** IMPORTANT: do not access this field directly, use the simplified-cdoc-access library functions to get the composite doc out of this proto. */
            cdocContainer?: any;
            /** The composite doc spans which were annotated with entities by Webref. */
            documentMentionSpans?: RepositoryWebrefRefconDocumentMentionSpans;
            /** Metadata related to why this doc was matched to its owning entity. */
            matchingMetadata?: RepositoryWebrefPreprocessingUrlMatchingMetadata;
            obsoleteAnchorsWithoutInterwiki?: RepositoryWebrefSimplifiedAnchors;
            /** Additional document metadata needed by Refcon. */
            refconDocumentMetadata?: RepositoryWebrefRefconRefconDocumentMetadata;
            sourceSnapshotType?: string;
            /** The URL, populated independently of whether we have a CompositeDoc proto. If the cdoc exists, the url is the same as CompositeDoc.doc.url. */
            url?: string;
            webrefOutlinks?: any;
        }
        interface RepositoryWebrefSubSegmentIndex {
            /** Pointer to the exact set of anchors in the cdoc. */
            anchorIndex?: RepositoryWebrefAnchorIndices;
            /** Pointer to the Webref-internal Segment indices. Can't be mapped back to the CDoc. */
            genericIndex?: RepositoryWebrefGenericIndices;
            /** Pointer to the exact set of image navboost queries in the cdoc. */
            imageQueryIndex?: RepositoryWebrefImageQueryIndices;
            /** Pointer to the proto in the cdoc and index within the proto for Spore. */
            jgnIndex?: RepositoryWebrefJuggernautIndices;
            /** Pointer to the exact set of queries in the cdoc. */
            queryIndex?: RepositoryWebrefQueryIndices;
        }
        interface RepositoryWebrefSupportTransferRule {
            /**
             * If set to true, allow STBR targets to trigger intents like ShowEntity that do not have explicit lists of allowed collections, accepting entities with any collections instead. This
             * setting together with target_collection define what intents are allowed to be triggered by the STBR target. Be careful with setting this option to 'true', as in the case of our
             * example the query [france] would result in the knowledge panel for the monarch. Louis XIV might've wanted such a behaviour, but you are probably not him.
             */
            allowWildcardIntents?: boolean;
            /**
             * Name of Aqua grammar domain this STBR rule is restricted to. If the domain is set to anything other than "default", the STBR rule is only going to result in an annotation for the
             * STBR target inside of the Aqua domain of the corresponding name. If there is no such Aqua domain, the rule is going to be ignored. The default value of string "default" for domain
             * makes it possible for the STBR rule to be used inside Loose Parser.
             */
            domain?: string;
            /**
             * Whether this rule points from an STBR target to its STBR source. This field is an internal implementation detail that is not configurable by customers. Inside QRewrite we have to
             * keep track of relations between entities. Among other things it is useful to remember which STBR target a given STBR source came from. For that purpose we attach an STBR proto to
             * the STBR target, reversing the rule, i.e, putting STBR source's mid as the target etc. For this reversed rule we set is_reverse_link to true.
             */
            isReverseLink?: boolean;
            /**
             * STBR doesn't just create annotations for STBR targets. It also can modify search result support (useful in PostRef) in order for web pages supporting the STBR source to also support
             * the STBR target. Otherwise in PostRef annotations for STBR targets are going to be demoted, resulting in the STBR rule potentially not affecting anything. Regarding treatment of
             * this result support, STBR has 3 possible modes that for historical reasons are represented as 2 booleans - mentions_only and support_share. No more than one of these bools is
             * supposed to be set to 'true' for a rule. Setting both to 'true' at once would lead to undefined behaviour. These 3 modes are: 1. (default) All the support gets assigned to the STBR
             * target. The STBR source is left with no support. To be extra sure, interpretations that still managed to get triggered by STBR source are suppressed later unless STBR target has no
             * interpretations of its own. In other words this is "we are pretty sure that if France is mentioned in a query that might be talking about a person, we want to treat the query as if
             * it is about Louis XIV". This mode would result in a query [age of france] being treated as [age of louis xiv], while [population of france] still being about the country unless
             * [population of louis xiv] matches some intents. For this mode both mentions_only and support_share should be set to 'false'. 2. Support is shared between STBR source ans STBR
             * target. That allows both STBR source and STBR target to trigger some intents with KScorer later deciding which intent is better. In other words, this is "when it is not clear
             * whether a query is about France of Louis XIV, provide KScorer with both options and let it decide". For this mode mentions_only should be set to 'false' and support_share should be
             * set to 'true'. 3. While annotations for the STBR target are created, no support is given to those annotations. This is more like "we are mostly sure that a mention of France is
             * about the country, but just for a rare case it is about the monarch, we would like to have Louis XIV annotated". For this mode mentions_only should be set to 'true' and
             * support_share should be set to 'false'.
             */
            mentionsOnly?: boolean;
            supportShare?: boolean;
            /** Mid of the STBR target, e.g. "/m/04pwg" for Louis XIV. */
            target?: string;
            /**
             * Collection that is going to be assigned to the target when the annotation for the target is created. This setting together with allow_wildcard_intents define what intents are
             * allowed to be triggered by the STBR target. At the moment those annotations get created, we can not afford to fetch information about the STBR target from Topic Server, but the
             * target mid by itself doesn't mean much for the Search stack. Setting up the collection for that annotated mid allows us to provide at least some information to the stack on how to
             * treat the mid. This collection together with domain and allow_wildcard_intents fields (see below) defines what intents can be triggered by annotations created for this STBR target.
             * Intents that accept only entities of specific collections can only be triggered if the value of this field matches one of the allowed collections for that intent. In our example,
             * KGCollection.debug_id might be "/collection/people" if we care about context of the monarch as a person, e.g. if we would like to understand queries like [how many children does
             * france have] as [how many childred does lous xiv have]. Or, if we would like to be more restrictive and to only apply the rule to contexts that only make sense for monarch, e.g.
             * [how long did france reign], we might decide to use more specific "/collection/monarchs" instead.
             */
            targetCollection?: RepositoryWebrefKGCollection;
            /**
             * The user country this rule is for. Rules only take effect if the country is not set, set to an empty string or matches the country that is detected for the user - like the country
             * user issued the query from. E.g. "US" for the United States.
             */
            userCountry?: string;
            /**
             * User language this rule is for. Rules only take effect if the language is not set, set to an empty string or matches the language that is detected for the user's query. E.g. set it
             * to "en" if you want the STBR rule to only work for users working from computers with English being set as the main language. Keep it unset if you want the rule not to depend on
             * local language settings of user's computer.
             */
            userLanguage?: string;
        }
        interface RepositoryWebrefTaskData {
            /** Signals about quality of data that was shown to raters. If document/query and concept description are readable. */
            isReadable?: boolean;
            itemId?: string;
            projectId?: string;
            taskDetails?: RepositoryWebrefTaskDetails;
            taskId?: string;
        }
        interface RepositoryWebrefTaskDetails {
            /**
             * The id of the experiment in case we are dealing with a refx data experiment. Should only be set in case of data experiments to gather topicality ratings, in order to allow
             * separating these ratings from regular ratings.
             */
            experimentId?: string;
            lastSubmitTimestamp?: string;
            topicDescription?: string;
            topicName?: string;
            topicUrl?: string;
        }
        interface RepositoryWebrefTripleAnnotation {
            /** Triple annotation confidence_score (value between 0 and 1). Higher values correspond to higher confidence. */
            confidenceScore?: number;
            /** The information in this triple is implied by other triple(s) in the document. */
            isImplied?: boolean;
            /**
             * Set to true if this triple is present in the webref model as either a link or property value. This implies that the information is in the Knowledge Graph. Note that it can happen
             * that a triple is in KG but not present in the webref model.
             */
            kgVerified?: boolean;
            /** Occurrences of the triple on the document */
            mentions?: RepositoryWebrefTripleMention[];
            /** The mid of the predicate kg-property(-ies). In order, in the case of multihop links. */
            predMid?: string[];
            /**
             * Generic container to hold additional data such as signals, debug data etc. Data that can be stored in this field and their TypeIds: repository_webref::evaluation::ECMDebug (TypeId
             * 192627933), defined in repository/webref/evaluation/triple_annotations/triple-diff.proto Debugging data to be used in WebIt's ECM report.
             */
            stuff?: any;
            triple?: KnowledgeGraphTriple;
        }
        interface RepositoryWebrefTripleAnnotations {
            annotations?: RepositoryWebrefTripleAnnotation[];
        }
        interface RepositoryWebrefTripleMention {
            /** Document mention of the predicate */
            predMention?: RepositoryWebrefSegmentMention;
            /**
             * The [begin, end) byte offset of the document scope where this triple was annotated. This corresponds to a table row or a text sentence where the triple was identified. The
             * sub_mention can be outside the scope when the subject is inferred from the table title.
             */
            scopeBegin?: number;
            scopeEnd?: number;
            /** Fingerprint2011 of space-joined SAFT tokens in the scope. */
            scopeFprint?: string;
            /**
             * Generic container to hold additional data such as triple scoped signals. Data that can be stored in this field and their TypeIds: repository_webref::universal::webit::ScopeSignals
             * (TypeId 192754198), defined in repository/webref/universal/processors/understanding/webit.proto
             */
            stuff?: any;
            /** Document mention of the subject */
            subMention?: RepositoryWebrefSegmentMention;
            /** Document mention of the value */
            valueMention?: RepositoryWebrefSegmentMention;
        }
        interface RepositoryWebrefUniversalNgramData {
            /** IDF of the n-gram. */
            idf?: number;
            /** Probability that the n-gram is a plural form of a word. This information is extracted from SAFT annotations of queries. See HasPluralProperty(). */
            pluralProb?: number;
        }
        interface RepositoryWebrefWebrefAnnotationStats {
            /** The relative weight of the document, used when aggregating information from multiple documents. */
            docWeight?: number;
            /** Extracted n-grams context scores (in cdoc language, weighted by doc_weight) output if webref_populate_annotation_ngrams is enabled. */
            ngramContext?: RepositoryWebrefNgramContext[];
            /** The total number of candidates. */
            numCandidates?: string;
            /** The total number of concepts with at least 1 candidate. */
            numConceptsWithCandidates?: string;
            /** The total number of concepts with at least 1 mention. */
            numConceptsWithMentions?: string;
            /** The total number of RangeData objects with at least one candidate. */
            numRangesWithCandidates?: string;
            /** Statistics for each token type. */
            statsPerType?: RepositoryWebrefAnnotationStatsPerType[];
        }
        interface RepositoryWebrefWebrefAttachmentMetadata {
            /** Oyster Feature Type. */
            featureType?: string;
            /** Indicates which entity this message belongs to: encoded_mid[index]. */
            index?: number;
            /** Latitude and longitude of the location. Same format as geostore.PointProto. */
            latE7?: number;
            lngE7?: number;
            /** Oyster Feature ID of the location. */
            oysterId?: GeostoreFeatureIdProto;
            /**
             * This field is populated for at most one entity. If it is populated, it indicates how confident we are to claim that the page is only about this entity (either it's an official web
             * presence of the entity, or something like a wikipedia page about the entity). For space reasons this is represented as a fixed-point integer with two decimal points precision.
             * Convert it to the interval [0,1] using the following formula: float single_topicness = single_topicness_e2 / 100.f
             */
            singleTopicnessE2?: number;
        }
        interface RepositoryWebrefWebrefDocumentInfo {
            /** Information about the document copied from the docjoin. This will never be populated when WebrefEntities appears inside a CompositeDoc, but may we used when it stands alone. */
            documentMetadata?: RepositoryWebrefDocumentMetadata;
            /** Optional extensions (e.g. taxonomic classifications). */
            extensions?: any;
            /** Information about the outlinks of this document. */
            outlinkInfos?: RepositoryWebrefWebrefOutlinkInfos;
            /**
             * The content (CONTENT section 0) as parsed by WebrefParser. Only used by //r/w/postprocessing/idf/idf-pipeline for document ngram idf computation. Populated when the annotator is run
             * with webref_populate_parsed_content Each webref_parsed_content_sentence represents one sentence of the context where saft annotations were used to determine the sentence boundaries.
             * See r/w/universal/processors/saft/saft-sentence-helper.h for details.
             */
            webrefParsedContentSentence?: string[];
        }
        interface RepositoryWebrefWebrefEntities {
            /** Detailed annotation statistics that can, e.g., be used to tune the WebRef scoring logic based on existing (Model-0) annotations. */
            annotationStats?: RepositoryWebrefWebrefAnnotationStats;
            /** Fingerprints checkpointing annotator stages, can be used to track the source of diffs. */
            annotatorCheckpointFingerprints?: RepositoryWebrefAnnotatorCheckpointFprint[];
            /** Categories of the document or query. This replaces the category_score found under EntityAnnotations. */
            category?: RepositoryWebrefCategoryAnnotation[];
            /** Dates ranges that are most relevant to the document. E.g. on a document about Dune the 2021 movie, this might hold the release date of that movie. */
            dateRange?: RepositoryWebrefSemanticDateRange[];
            /** Information that applies globally to the document. The exclude_field option is for Goldmine AnnotationsFinder to exclude document_info from retrieving annotation entities */
            documentInfo?: RepositoryWebrefWebrefDocumentInfo;
            /**
             * The annotated entities, with associated confidence scores and metadata. This is the primary output of WebRef/QRef. In case of Webref output, entities are sorted by decreasing
             * topicality score.
             */
            entity?: RepositoryWebrefWebrefEntity[];
            /**
             * These messages contain non-entity annotations of ranges in the document. This might be used to hold part-of-speech annotations, stopword annotations, and other range based
             * information. The exclude_field option is for Goldmine AnnotationsFinder to exclude ranged_annotations from retrieving annotation entities
             */
            rangeAnnotations?: RepositoryWebrefRangeAnnotations[];
            /** The status message returned by the annotator. Might not be populated on success. */
            status?: RepositoryWebrefWebrefStatus;
            /** A generic container to hold extra result data. */
            stuff?: any;
            /**
             * Triples inferred from the document When the annotator recognizes phrases, lists or tables associated with a property or relationship for an entity it generates triples that encode
             * that information. This generated data is only substantiated by the document vs KG data which has been verified from multiple sources and/or human curators.
             */
            tripleAnnotations?: RepositoryWebrefTripleAnnotations;
        }
        interface RepositoryWebrefWebrefEntity {
            /** Information about links (e.g. implications) between the annotated entities. */
            annotatedRelationship?: RepositoryWebrefWebrefEntityRelationship[];
            /** All annotations of this entity on the given document. */
            annotations?: RepositoryWebrefEntityAnnotations;
            /** Information about the collections of this entity. */
            collections?: RepositoryWebrefWebrefEntityCollections;
            /** Metadata and raw signals used by the annotator. */
            entityJoin?: RepositoryWebrefEntityJoin;
            /** An identifier (usually a MID) for the entity. Consider using GetWebrefEntityMid() in the adjacent webref-entities-util.h to read this. */
            id?: RepositoryWebrefWebrefEntityId;
            /**
             * MRF equivalent representations of this entity as a compound, one for each unique MRF representation. Populated for compounds. Each MRF expression contains a minimum FunctionCall
             * structure wrapped in a nameless Argument without signals and range data. This is not meant to be directly usable as MRF, use QueryJoinToMeaningStructConverter to expand it into a
             * usable form. References to entities are made as component_reference ArgumentValue. Each compound Mention of this entity (not all of its mentions need be compounds, some may be plain
             * entity mentions) have one or more compound_value fields claiming these MRF expressions via their mrf_index. The compound_value has nested components, one for each unique
             * component_reference.index in the MRF expression. The processing expectation is that each ArgumentValue which has a component_reference has its contents discarded and replaced with
             * the MRF for the target entity and mention named by the compound_value.component. If the target is not a compound, the ArgumentValue becomes a simple mid value and the signals are
             * taken from the entity and the mention. If the target is a compound itself, the expansion continues recursively. If the target is a compound with multiple MRFs, a cartesian product
             * of recursive expansions may need to be produced. Along with the component_reference we also emit an example value, but this is purely for human consumption so it's easier to
             * understand what the full compound is like. The processing expectation remains that the ArgumentValue containing a component_reference is completely discarded and rebuilt with the
             * reference target value. If the target has more than one MRF expression, it's not specified which one will be used as an example, except that the choice is guaranteed to be
             * deterministic from run to run.
             */
            mrf?: KnowledgeAnswersIntentQueryArgument[];
        }
        interface RepositoryWebrefWebrefEntityCollections {
            collection?: RepositoryWebrefKGCollection[];
        }
        interface RepositoryWebrefWebrefEntityId {
            /** The MID in integer format. Nowadays, this field contains the equivalent representation of `freebase_mid`, i.e. what metaweb::ParseId() returns. */
            conceptId?: string;
            /** The MID in the same format that is returned by metaweb::MidToString(), e.g. "/m/02mjmr" or "/g/11b6vyscgb" or "/t/24bjj59_jbj9f". */
            freebaseMid?: string;
        }
        interface RepositoryWebrefWebrefEntityRelationship {
            /** The index of the entry in WebrefEntities.entity that the entity carrying this field is linked to. This field must be set. */
            entityIndex?: number;
            /** Information about the link. */
            linkMetadata?: RepositoryWebrefEntityLinkMetadata;
            /** The weight of the link. */
            linkWeight?: number;
        }
        interface RepositoryWebrefWebrefMustangAttachment {
            /** The confidence of the category. In the range [0, 100]. */
            categoryConfidenceE2?: number[];
            /**
             * See go/category-annotations-api about the story behind various types of category annotations that are provided using the catmid token and category_encoded_mid fields below. Some of
             * these annotation types are experimental, so please contact related-entities@ if you consider using this data. For production uses, please: 1. Add your use-case to go/hits-clients.
             * 2. Subscribe to hits-users@ to receive general updates and info about deprecations. To convert it to the string form use metaweb::MidToString(encoded_mid) defined in
             * metaweb/util/mid/mid.h The uint64-encoded MIDs of HitCat categories. See google3/repository/webref/hits/hitcat/category.textproto for the complete list of HitCat categories. Should
             * have the same number of elements as the category_confidence_e2 field.
             */
            categoryEncodedMid?: string[];
            /**
             * The confidence scores of all entities in the encoded_mid array. For space reasons this is also represented as a fixed-point integer with two decimal precision. Convert it to
             * confidence_score using the following formula: float confidence_score = confidence_e2 / 100.0f Should have the same number of elements as the encoded_mid field.
             */
            confidenceE2?: number[];
            /**
             * The int64-encoded MIDs of the entities in the document sorted by topicality score. To convert it to the string form use metaweb::MidToString(encoded_mid) defined in
             * metaweb/util/mid/mid.h Should have the same number of elements as the topicality_e2 field.
             */
            encodedMid?: string[];
            /** Per-entity metadata. Not packed (not every entity has metadata). If you'd like to add per-document metadata, see document_metadata instead. */
            entityMetadata?: RepositoryWebrefWebrefAttachmentMetadata[];
            /** A sub-proto to encode IQL expressions. To be used by Pianno page-level intents and Webref Compounds. */
            iqlAttachment?: KnowledgeAnswersIntentQueryIndexingIQLAttachment;
            /** The indices of all the reference entities in encoded_mid that are authors of the page. Not packed as in most cases when populated, it contains 1 element. */
            isAuthorIndex?: number[];
            /**
             * The indices of all the reference entities in encoded_mid that are publishers of the page (e.g. /m/cnn on "http://www.cnn.com/foo/bar"). Not packed as in most cases when populated,
             * it contains 1 element.
             */
            isPublisherIndex?: number[];
            /**
             * Only populated when the document is a reference page for an entity. Contains the indices of all reference entities in the encoded_mid and topicality_e2 arrays. Not packed as in most
             * cases when populated, it contains 1 element.
             */
            referencePageIndex?: number[];
            /**
             * The topicality scores of all entities in the encoded_mid array. For space reasons this is represented as a fixed-point integer with two decimal points precision. Convert it to
             * topicality_score using the following formula: float topicality_score = topicality_e2 / 100.f Should have the same number of elements as the encoded_mid field.
             */
            topicalityE2?: number[];
            /**
             * The uint64-encoded MID of the unbound intents generated by Pianno. An unbound intent is the annotation of an intent without slots arguments (e.g. Age) declared in Intent Catalog.
             * See go/pianno-asteroid-belt-migration for details. We only keep the top unbound intents with the highest orbit scores. Should have the same number of elements as
             * unbound_intent_score_e2.
             */
            unboundIntentMid?: string[];
            /**
             * The confidence of the unbound intent. represented as a fixed-point integer with two decimal precision. In the range [0, 100]. Should have the same number of elements as
             * unbound_intent_mid.
             */
            unboundIntentScoreE2?: number[];
            /** [Experimental code. Do not use ] Entities that webref identified as being the same concept (undermerged). */
            undermergedMembers?: RepositoryWebrefWebrefMustangAttachmentUndermergedMembers[];
        }
        interface RepositoryWebrefWebrefMustangAttachmentUndermergedMembers {
            /** Experimental code, do not use. */
            encodedMid?: string[];
        }
        interface RepositoryWebrefWebrefOutlinkInfo {
            /** The length in bytes of such a link (including internal spaces); e.g. if the link text is "click here" then the length is 10. */
            byteLength?: string[];
            /** The byte offset of the start of a link with this target URL, in the content of the annotated document. */
            byteOffset?: string[];
            /** Whether this is a nofollow link (https://en.wikipedia.org/wiki/Nofollow). If the page has multiple links to the same url, all of them must be nofollow to set this field. */
            isNofollow?: boolean;
            /** The topicality_weight for each link with this target URL. */
            topicalityWeight?: number[];
            /** The target URL of the link. */
            url?: string;
        }
        interface RepositoryWebrefWebrefOutlinkInfos {
            /** Information about each target URL referred to in the document's outlinks. If a given URL has multiple links, they are grouped in a single WebrefLinkInfo. */
            outlinkInfo?: RepositoryWebrefWebrefOutlinkInfo[];
        }
        interface RepositoryWebrefWebrefStatus {
            /**
             * The epoch of the Webref static data (the name-filter.data file). As of Dec 2020 in prod Goldmine (in webref_daily_full_model_static_data) this value is over from the alpha model
             * static data, since this is where most of the parts come from. I.e. the value does not correspond to the actual model being used.
             */
            dataEpoch?: string;
            /**
             * Error that occurred during the annotation. This field is only populated by QRef (i.e. under QueryJoin.status) and never by WebRef (i.e. under WebrefEntities.status) anymore, which
             * instead reports errors (and soon also taints) through standard Goldmine mechanisms.
             */
            utilStatus?: UtilStatusProto;
            /** The version number of the annotator (the cl the binary was built from). Must be enabled via a command line flag. See also the Goldmine's indexing::annotations::AnnotationMeta proto. */
            version?: number;
        }
        interface RepositoryWebrefWikipediaCategory {
            categoryName?: string;
        }
        interface RepositoryWebrefWikipediaGeocode {
            /** The location as extracted from the wikijoins. */
            location?: GeostorePointProto;
            /** The source contains the url field from the wikijoins. */
            sourceUrl?: string;
        }
        interface ResearchScamCoscamConjunction {
            /**
             * disjunction_id / is_positive *MUST* have the same length. They specify a set of disjunctions that make up this conjunction. The conjunction will be active iff *all* of the positive
             * disjunctions are active and *all* of the negative disjunctions are inactive.
             */
            disjunctionId?: string[];
            isPositive?: boolean[];
        }
        interface ResearchScamCoscamDisjunction {
            /** key - a uint64 key that uniquely identifies this disjunction. */
            key?: string;
            /** groups - the group:token tuples that make up this disjunction. The disjunction will be active if *any* off the group:token tuples are present in a request. */
            tokenGroups?: ResearchScamCoscamTokenGroup[];
        }
        interface ResearchScamCoscamEasyConjunction {
            /** disjunctions is the set of OR clauses that */
            disjunctions?: ResearchScamCoscamEasyDisjunction[];
        }
        interface ResearchScamCoscamEasyDisjunction {
            /** If is_positive is set to false, then the entire disjunction is negated, and will be true only if none of its members is true. */
            isPositive?: boolean;
            /** token_groups - the group:token tuples that make up this disjunction. The disjunction will be active if *any* off the group:token tuples are present in a request. */
            tokenGroups?: ResearchScamCoscamTokenGroup[];
        }
        interface ResearchScamCoscamEasyRestrictDefinition {
            /** conjunctions is the set of AND-of-ORs blocks. */
            conjunctions?: ResearchScamCoscamEasyConjunction[];
        }
        interface ResearchScamCoscamRestrictDefinition {
            /** conjunctions - each conjunction is an AND-of-ORs; if any of these conjunctions match, then the entire restrict matches. */
            conjunctions?: ResearchScamCoscamConjunction[];
            /** disjunctions - each disjunction is an OR clause. */
            disjunctions?: ResearchScamCoscamDisjunction[];
            /** subs_key - ignore. Only used for testing. */
            subsKey?: string;
        }
        interface ResearchScamCoscamRestrictTokensV2 {
            /** token_groups - group:token tuples, collated by group. */
            tokenGroups?: ResearchScamCoscamTokenGroup[];
        }
        interface ResearchScamCoscamTokenGroup {
            /** debug_token_strings - (optional) strings that should be used for human-friendly printing. NOT used by the matching engine! */
            debugTokenStrings?: string[];
            /** name - the name of the token group. */
            name?: string;
            /** tokens - a list of tokens, stored by their Fingerprint2011 hash. */
            tokens?: string[];
        }
        interface ResearchScamGenericFeatureVector {
            /** The class label of this datapoint. This should be populated if ScaM is being used for nearest-neighbor-based classification. */
            classLabel?: string;
            crowding?: ResearchScamGenericFeatureVectorCrowding;
            /**
             * Optional point id that can contain an arbitrary (unrestricted in content) value except when the data is provided via SSTable (sharded or not). In the case of SSTable the data_id_str
             * must be set for _all_ points in all shards or the SSTable keys will be used as the values for the data_id_str of the respective points. In either SSTable case--data_id_str provided
             * explicitly or via the key--the values must be unique across all shards.
             */
            dataIdStr?: string;
            /** A timestamp after which this datapoint is considered no longer valid and is eligible for deletion. The exact meaning varies with application/configuration. */
            expirationTimestamp?: string;
            /**
             * DEPRECATED: - this field can safely be left unspecified. For dense vectors, dimensionality is inferred from the number of values specified, and must be identical to this, or
             * unspecified. For sparse vectors, the default value is correct for most users, and allows use of 64-bit hash values for feature indices.
             */
            featureDim?: string;
            /** - for SPARSE vectors, specifies indices of the nonzero dimensions whose values are specified by the , , or field. This field is not used when specifying dense vectors. */
            featureIndex?: string[];
            /** Describes the type of feature values. */
            featureType?: string;
            featureValueDouble?: number[];
            /**
             * Actual feature vector. Only one of the following should be populated. This list has to be kept in sync with FeatureType enum. NOTES: Binary features are stored as ones or zeroes in
             * feature_value_int64. Floating point values (feature_value_float, feature_value_double) may not be NaN.
             */
            featureValueFloat?: number[];
            featureValueInt64?: string[];
            featureValueString?: string;
            fixedPointMetadata?: ResearchScamGenericFeatureVectorFixedPointMetadata;
            /** Describes if data has been normalized and the type. */
            normType?: string;
            /** copybara:strip_begin A field that contains metadata information when the datapoint is acting as a query. copybara:strip_end */
            queryMetadata?: ResearchScamQueryMetadata;
            restrictTokens?: ResearchScamGenericFeatureVectorRestrictTokens;
            tokens?: number[];
            /**
             * This field allows application-specific metadata to be stored in a GFV. This information may be used by custom binaries or in pre- or postprocessing outside of ScaM. Use cases
             * include but are not limited to: * Dataset IDs, if multiple datasets are multiplexed into one physical file or network location. * An alternative, possibly more human-readable
             * representation of the data represented by this GFV, for e.g. debugging purposes. * Outputting the contents of this field verbatim to the metadata field of the
             * NearestNeighbors.Neighbor proto.
             */
            userinfo?: string;
            /** DEPRECATED fields. Ignored by ScaM binaries. Do not use. */
            weight?: number;
        }
        interface ResearchScamGenericFeatureVectorCrowding {
            /**
             * The value of the crowding attribute for this document. The maximum number of neighbors to return per crowding attribute value (per_crowding_attribute_num_neighbors) is configured
             * per-query. This field is ignored if per_crowding_attribute_num_neighbors is larger than the total number of neighbors to return for a given query.
             */
            crowdingAttribute?: string;
        }
        interface ResearchScamGenericFeatureVectorFixedPointMetadata {
            /** The squared L2 norm of the original (pre-fixed-point transformation) GFV. Used for computing squared L2 distance. */
            squaredL2Norm?: number;
        }
        interface ResearchScamGenericFeatureVectorRestrictTokens {
            blacklistToken?: string[];
            /** DEPRECATED */
            definition?: ResearchScamCoscamRestrictDefinition;
            /** DEPRECATED */
            easyDefinition?: ResearchScamCoscamEasyRestrictDefinition;
            /** B) Token Definitions (V1 Restricts) In "forward" mode: defined on database points In "reverse" mode: defined on queries */
            tokenMembership?: string[];
            /** DEPRECATED */
            tokens?: ResearchScamCoscamRestrictTokensV2;
            /** Only ONE of the following sections should be used: A) V3 restricts. Defined in //research/scam/proto/restricts.proto */
            v3?: ResearchScamV3Restrict;
            /**
             * If this field is not empty, when query is in V1 restricts while database is in V3 restricts, SCaM will update V1 query to V3 automatically instead of sending error messages. When
             * updating query from V1 to V3, SCaM server will use this field to fillin the 'namespace' field.
             */
            v3CompatibleNamespace?: string;
            /** C) Whitelist / Blacklist Definitions (V1 Restricts) In "forward" mode: defined on queries In "reverse" mode: defined on database points */
            whitelistToken?: string[];
        }
        interface ResearchScamNearestNeighbors {
            /**
             * Data point for which we computed nearest neighbors. This field is set based on the data_id_str field in the QueryRequest GFV (or SSTable key if data_id_str is not present), and thus
             * can be arbitrary data, e.g. docid, URL, query string.
             */
            docid?: string;
            /**
             * Metadata about the query. This field is populated if and only if: 1) ScaM is running in offline query-database or online mode and; 2) The metadata is directly fetched from the
             * userinfo field inside GFV and; 3) MetadataConfig.userinfo.set_user_info_for_query is set to true. The field name is kept as "metadata" for consistency with neighbors.
             */
            metadata?: string;
            /** All its neighbors. */
            neighbor?: ResearchScamNearestNeighborsNeighbor[];
            /** Propagate neighbor selection override information during offline search. */
            neighborSelectionOverride?: ResearchScamNeighborSelectionOverride;
            /** The query vector for which we computed nearest neighbors. */
            query?: ResearchScamGenericFeatureVector;
            /** The version ID of the server that responded to this query, if one was specified. This field is not populated for offline (i.e. Flume rather than RPC) search. */
            retrievedVersion?: string;
        }
        interface ResearchScamNearestNeighborsNeighbor {
            /** If crowding is enabled, the crowding attribute of this neighbor will be stored here. */
            crowdingAttribute?: string;
            /** This could be exact or approximate distance. */
            distance?: number;
            /**
             * Neighbor data point. This field is set based on the data_id_str field in the GFV of the data point in the database (or SSTable key if data_id_str is not present), and thus can be
             * arbitrary data, e.g. docid, URL, query string.
             */
            docid?: string;
            /** Metadata about the neighbor. This is returned under some configurations as a serialized proto. The specific proto depends on which metadata is configured to be returned. */
            metadata?: string;
        }
        interface ResearchScamNeighborSelectionOverride {
            /**
             * The distance threshold to use for approximate search before exact reordering is performed, if exact reordering is performed. If this is not set and exact reordering is enabled, a
             * reasonable default value will be chosen using a heuristic specified in ScamConfig.ExactReordering.NeighborSelectionOverrideHeuristics. This field is ignored if exact reordering is
             * not enabled. This value must be non-NaN if set.
             */
            approxEpsilonDistance?: number;
            /**
             * The number of neighbors to find via approximate search before exact reordering is performed. If this is not set and exact reordering is enabled, a reasonable default value will be
             * chosen using the heuristic specified in ScamConfig.ExactReordering.NeighborSelectionOverrideHeuristics. This field is ignored if exact reordering is not enabled. This value must be
             * > 0 if set.
             */
            approxNumNeighbors?: number;
            /**
             * The maximum distance at which to return a neighbor. If this proto is used, at least one of this and num_neighbors must be set. The default is infinity, effectively returning
             * num_neighbors neighbors regardless of distance. This value must be non-NaN if set.
             */
            epsilonDistance?: number;
            /**
             * The maximum number of neighbors to return. If this proto is used, at least one of this and epsilon_distance must be set. The default is the largest value representable as an int32,
             * effectively returning all neighbors within epsilon_distance. This value must be > 0 if set.
             */
            numNeighbors?: number;
            /**
             * If populated, this is the maximum number of neighbors that may be returned from a single shard. If not populated, up to num_neighbors neighbors are returned from each shard. Setting
             * his to a smaller value than num_neighbors will increase speed at the expense of accuray by requiring cross-shard merging of fewer neighbors. If this value is set, num_neighbors must
             * also be set and this value must be <= num_neighbors and >= num_neighbors / number of shards. If set, this value must always be > 0.
             */
            numSingleShardNeighbors?: number;
            /**
             * The maximum number of neighbors to return for a single value of the crowding attribute. The crowding attribute is specified per-datapoint in the GenericFeatureVector proto, or the
             * Document proto for sparse logistic models. Crowding is described more thoroughly in research/scam/utils/crowding_top_n.h. NOTES: Crowding is effectivley enabled if this value is
             * less than num_neighbors.
             */
            perCrowdingAttributeNumNeighbors?: number;
            /**
             * The maximum number of neighbors to return from the approximate portion of the nearest-neighbor search algorithm, within each shard, for a single value of the crowding attribute,
             * before performing exact reordering. Ignored if exact reordering is disabled for this dataset.
             */
            perCrowdingAttributePreReorderingNumNeighbors?: number;
            /**
             * Note: currently not implemented for all database shard subclasses! Contact ScaM before using. Overrides max_spill_centers for tree-X hybrid searchers configured with
             * FIXED_NUMBER_OF_CENTERS spilling. The max_spill_centers in the ScaM config is used if this field isn't set. Only valid if: * Used on a tree-X hybrid ScaM config with
             * FIXED_NUMBER_OF_CENTERS. * Value is greater than zero and at most equal to num_children.
             */
            treeXHybridLeavesSearchedOverride?: number;
        }
        interface ResearchScamOnlineSearchLatencyStats {
            /**
             * An estimate of the CPU time used for this query on the machine associated with task_id, from when the query was received to when the response was ready to send, in seconds. Caveats:
             * 1. Does not account for CPU time spent serializing, deserializing, compressing or decompressing protos within Stubby. 2. Does not account for cleanup time after response has been
             * sent.
             */
            cpuTime?: number;
            /** Task number associated with response time measurements. */
            taskId?: number;
            /**
             * Wall time taken on the machine associated with task_id from when the query was received to when the response was ready to send, in seconds. This time excludes the time spent sending
             * the response and the time to perform cleanup operations after the response is sent.
             */
            wallTime?: number;
        }
        interface ResearchScamQueryMetadata {
            neighborSelectionOverride?: ResearchScamNeighborSelectionOverride;
        }
        interface ResearchScamQueryResponse {
            /**
             * Debugging fields: The wall and CPU time used by each query on each machine. For successful queries, there will be one entry here for each machine that the query used if
             * QueryRequest.enable_latency_stats was enabled. For unsuccessful queries, the contents of this field will be undefined. NOTE: The following accounting rules apply in batched mode,
             * assuming there are
             */
            latency?: ResearchScamOnlineSearchLatencyStats[];
            /**
             * The number of non-root machines for which a DEADLINE_EXCEEDED error occurred when they were contacted. This value does NOT include machines for which no reply was received because
             * their parent machine timed out. Therefore, num_total_machines may be larger than num_ok_machines + num_unreachable_machines + num_deadline_exceeded_machines.
             */
            numDeadlineExceededMachines?: number;
            /**
             * Number of machines that contributed to the results; this might be less than the total number of machines if a machine has failed. The impact of a single machine failure could be
             * larger than just one machine, if it happens to be one of the machines involved in distributing the query and collecting results.
             */
            numOkMachines?: number;
            /**
             * The number of machines used in this service for the dataset that was queried. If everything went right, this should be equal to num_ok_machines. If num_ok_machines <
             * num_total_machines, some neighbors may be missing from results.
             */
            numTotalMachines?: number;
            /**
             * The number of non-root machines for which an UNREACHABLE error occurred when they were contacted. This value does NOT include machines that were implicitly unreachable because their
             * parent machine was not reachable. Therefore, num_total_machines may be larger than num_ok_machines + num_unreachable_machines + num_deadline_exceeded_machines.
             */
            numUnreachableMachines?: number;
            /**
             * The number of "active" datapoints for each dataset, i.e. points that are whitelisted by restricts and could be returned if they were close enough to the query. For successful
             * queries, there will be one entry here for each dataset queried, if QueryRequest.enable_restrict_stats was true. For partially-successful successful queries, this field will contain
             * results
             */
            restrictStats?: ResearchScamRestrictStats[];
            /**
             * The results for each dataset searched. If per_dataset_parameters was empty in QueryRequest then this will have one entry, the results for dataset 0. If per_dataset_parameters was
             * not empty in QueryRequest, this will contain the results for each dataset queried, in order corresponding to the order of QueryRequest.per_dataset_parameters.
             */
            results?: ResearchScamNearestNeighbors[];
            /**
             * USEFUL ONLY IN CUSTOM BINARIES. In the stock ScaM server binary, all errors are relayed via the RPC's status. Thus, if RPC's status is ok, this field is guaranteed to be ok and if
             * RPC's status is an error, no QueryResponse will be returned. The status of this query. This is useful when using a batched postprocessing lambda, which may ignore erroneous
             * subqueries, continue postprocessing the valid ones and return OkStatus. In this case, this field will inform the client of any invalid subqueries.
             */
            status?: UtilStatusProto;
        }
        interface ResearchScamRestrictStats {
            /**
             * The number of datapoints that are whitelisted by restricts specified for this query, across all shards for which the query executed successfully. In other words, this represents the
             * number of datapoints that could potentially be returned if they were close enough to the query according to the selected distance measure. If restricts are disabled, this will be
             * equal to num_total_datapoints.
             */
            numActiveDatapoints?: string;
            /**
             * The number of total datapoints in all shards of this dataset for which the query executed successfully. This is returned for convenience so that a ratio can be easily computed, and
             * so that num_active_datapoints can be put in perspective for partially successful queries, i.e. queries where only some shards were successful.
             */
            numTotalDatapoints?: string;
        }
        interface ResearchScamTokenNamespace {
            /**
             * //////////////////////////////////////////////////////////////////////////// NAMESPACE - the string name of the namespace that this proto is specifying, such as "color", "shape",
             * "geo", or "tags". Recall that your overall query is an AND across namespaces.
             */
            namespace?: string;
            /**
             * //////////////////////////////////////////////////////////////////////////// BLACKLIST - Blacklisting can be used to implement more complex scenarios. The blacklist fields have
             * exactly the same format as the token fields, but represents a negation. When a token is blacklisted, then matches will be excluded whenever the other datapoint has that token. For
             * example, if a query specifies {color: red, blue, !purple}, then that query will match datapoints that are red or blue, but if those points are also purple, then they will be
             * excluded even if they are red/blue. Note that, due to symmetry, if one of the database points is {red, !blue}, that point will be excluded from queries that specify blue. Lastly,
             * note that namespaces with *only* blacklist tokens behave similar to empty namespaces, in that {color: !purple} would match blue or red datapoints, as long as those datapoints don't
             * also have the purple token.
             */
            stringBlacklistTokens?: string[];
            /**
             * //////////////////////////////////////////////////////////////////////////// TOKENS - Conceptually, each token names a set datapoints. The field(s) below are for declaring the
             * tokens that name the datapoint that this TokenNamespace proto is attached to. For convenience, we support either string or uint64 tokens. Internally, the restricts system is based
             * on uint64s, but for many applications, strings are the more natural format, and they should be preferred whenever this is the case. * When only uint64s are specified, they will be
             * used as-is. * When only strings are specified, they will be converted to uint64s via Fingerprint2011. (See "Note on the safety of Fingerprint2011"). * ADVANCED: When both fields are
             * specified, the uint64s are used as-is. Note that, when both fields are used, they *must* have the same number of entries, and the system will assume that your strings correspond 1:1
             * with the list of uint64 tokens. * EDGE CASE: All matching is done in the uint64 space, so, I'm not sure why you'd do this, but if, eg, your database uses strings, and your queries
             * specify the Fingerprint2011 hashes of those strings, matching will work, and this is a specified behavior. Note on the safety of Fingerprint2011: Unless you have well over 1M+
             * unique string tokens, you can safely assume that every string will map to a unique 64-bit token. Internally, both Mustang and PSI use Fingerprint2011 to hash arbitrary strings into
             * uint64 tokens, and assume, without validation, that each 64-bit token is unique. And the math backs up this assumption: If we are using a "perfect" hashing function (and
             * Fingerprint2011 is close-enough for our purposes), and we then hash 1M unique tokens into a 64-bit space, there's still better than 99.9999% odds that all tokens are collision-free,
             * nearly as good as the odds for the datacenter's continued existence. Scenarios for having both the string and uint64 token forms: * Probably none that matter to you. Just use the
             * strings directly. * You could have uint64 enum values, yet want to include the string values for debugging purposes. Note that it *is* supported to use a proprietary string =>
             * uint64 mapping, assuming that it is consistent, and that you always specify the uint64 values. * The mixer-tier in a multi-shard deployment might convert the strings into uint64s to
             * avoid redundant hashing overhead on the leaves, yet keep the string tokens to preserve proto-level debugging. * When strings are present, I reserve the right to use them for making
             * logging "better", but, thusfar, there are 0 examples of this.
             */
            stringTokens?: string[];
            uint64BlacklistTokens?: string[];
            uint64Tokens?: string[];
        }
        interface ResearchScamV3Restrict {
            /**
             * //////////////////////////////////////////////////////////////////////////// NAMESPACES - a repeating field, where each entry specifies the set of tokens, within a single namespace,
             * that apply to the query, or database point, on which this V3Restrict proto is defined. Note that: * Your overall query is an AND across namespaces. * Explicitly specifying a
             * namespace with 0 tokens is identical to omitting that namespace. ie, "{ns:}" == "". * It is an error to specify the same namespace more than once per instance of the V3Restrict
             * proto.
             */
            namespaces?: ResearchScamTokenNamespace[];
        }
        interface ResearchScienceSearchCatalog {
            /** catalog description */
            description?: string;
            /** catalog mid */
            mid?: string;
            /** catalog name */
            name?: string;
            /** catalog url */
            url?: string;
        }
        interface ResearchScienceSearchCitation {
            citation?: string;
            /** The citation after HTML sanitation. Used only by the front-end. */
            safeHtmlCitation?: WebutilHtmlTypesSafeHtmlProto;
        }
        interface ResearchScienceSearchDataDownload {
            /** Size of the download, as a string from the provider. May include units. */
            contentSize?: string;
            /** URL for downloading the data */
            downloadUrl?: string;
            /** File format at the link (ASCII, CSV, etc.) */
            fileFormat?: string;
            /** Pragmatic classification of file formats - for filtering purposes */
            fileFormatClass?: string;
            /** Parsed content size */
            parsedContentSize?: ResearchScienceSearchDataSize;
        }
        interface ResearchScienceSearchDataSize {
            /** Data size value, in the provided size unit */
            size?: number;
            /** The data size unit */
            unit?: string;
        }
        interface ResearchScienceSearchDate {
            formatted?: string;
            unformatted?: string;
        }
        interface ResearchScienceSearchFieldOfStudyInfo {
            /** The classification source that determines the field of study label. */
            classificationSource?: string;
            /** If set to true, it means that the probability is at least the threshold value specified from the corresponding saved model config. Thresholds for different fields may be different. */
            isAboveThreshold?: string;
            /** A label that represents the field of study. */
            label?: string;
            /** A score between [0, 1] outputted from the classifier indicating the probability for being a YES instance. */
            probability?: number;
        }
        interface ResearchScienceSearchLicense {
            /**
             * A fingerprint id generated based on the license_class, URL or text. Since the knowledge graph requires a unique string id for the license but any filed of license can be empty, a
             * fingerprint id can serve as a compact identifier representing the non-empty sub-fields.
             */
            id?: string;
            /**
             * A value from a controlled vocabulary that uniquely identifies a license. Unless this is set to LICENSE_CLASS_UNDEFINED_NO_MATCH or LICENSE_CLASS_UNDEFINED_CONTRADICTING_MATCHES
             * other fields in this message should be empty.
             */
            licenseClass?: string;
            /** mid for the license. */
            licenseMid?: string;
            /** The text (usually, the name) of the distribution license. */
            text?: string;
            /** The url for the distribution license. */
            url?: string;
        }
        interface ResearchScienceSearchLocation {
            /** Coordinates of the corners of the polygon in the form "lat1 long1 lat2 long2" */
            boxCoordinates?: string;
            /** Coordinates for the circle area defined by its center and radius: "lat long, radius" */
            circleCoordinates?: string;
            /** mids for locations that contain loctions in . */
            containedInMid?: string[];
            /** mids for locations covering the dataset, contained in the . A region may contain multiple locations that are identified by mids. */
            locationMid?: string[];
            /** Labels (in the preferred language of the dataset) for the mids in . */
            locationMidLabel?: string[];
            /** The original name for the area covered by the dataset. */
            locationName?: string;
            /** Latitude and longitude for a single point in the form of "lat,long". */
            pointCoordinates?: string;
            /** Unformatted coordinates describing the region. */
            unformattedCoordinates?: string;
        }
        interface ResearchScienceSearchNavboostQueryInfo {
            /** imp_count stores an estimate of the number of impressions for this tuple. */
            impCount?: number;
            /** lcc_count stores an estimate of the number of long clicks for this tuple. NOTE: It is similar to query_doc_count, but calculated in different manner. */
            lccCount?: number;
            /** The query string. */
            query?: string;
            /** The query_count stores the counts on this query. */
            queryCount?: number;
            /** The query_doc_count stores the number of long-clicks on this pair. */
            queryDocCount?: number;
        }
        interface ResearchScienceSearchOrganization {
            /** KG mid for the organization or person. */
            organizationMid?: string[];
            /** Label (in the preferred language of the dataset) for the mid. */
            organizationMidLabel?: string[];
            /** Unreconciled organization name. We store it here only if there are no organization_mid values present. */
            organizationName?: string;
            /** Original organization url */
            organizationUrl?: string;
            /** Original name before reconciliation; empty if not reconciled. */
            originalOrganizationName?: string;
        }
        interface ResearchScienceSearchReconciledMetadata {
            /** Alternate names and acronyms for the dataset. */
            alternateName?: string[];
            /**
             * A string representation of the authors of the dataset, collected from author and creator in raw metadata. The exact format (e.g., comma-separated, etc.) is up to the extender that
             * populates this field. The assumption is that this string may appear in the UI "as is".
             */
            authorList?: string;
            /** Catalog that this dataset is a part of. */
            catalog?: ResearchScienceSearchCatalog;
            /** Compact Identifiers (for example "RRID:SCR_002088") that can be resolved by Identifiers.org or N2T.net meta-resolvers. */
            compactIdentifier?: string[];
            /** Compact Identifier(s) extracted from the citation field. Like in the case of DOI(s) those identify the articles related to the dataset rather than the dataset itself. */
            compactIdentifierFromCitation?: string[];
            coverageEndDate?: ResearchScienceSearchDate;
            /**
             * The start and end date that the dataset covers. If the dataset covers a single timepoint, then start and end dates are the same. Use the ISO 8601 format for dates (e.g.,
             * 2006-05-23).
             */
            coverageStartDate?: ResearchScienceSearchDate;
            /** The dataset in downloadable form. There can be multiple data download entries for different file types. */
            dataDownload?: ResearchScienceSearchDataDownload[];
            /** A hash of the raw metadata fields used by the QualityExtender. */
            datasetClassificationFieldsHash?: string;
            /** Probability that the entity is in fact a dataset (in contrast to spam or website labelled as dataset that does not describe a dataset). */
            datasetClassificationScore?: number;
            /** The date when the dataset was created. */
            dateCreated?: ResearchScienceSearchDate;
            /** The date when the dataset was modified. */
            dateModified?: ResearchScienceSearchDate;
            /** The date when the dataset was published. */
            datePublished?: ResearchScienceSearchDate;
            /** Most recent of the three dates (published, created, modified) */
            dateUpdated?: ResearchScienceSearchDate;
            denylistStatus?: string[];
            /** Description of the dataset. */
            description?: string[];
            /** Description of the dataset converted to HTML. */
            descriptionInHtml?: string[];
            /** The DOI for the dataset. We assume that there is only one. */
            doi?: string;
            /** DOI(s) extracted from the citation field. In contrast to the "doi" field these DOIs identify the articles related to the dataset rather than the dataset itself. */
            doiFromCitation?: string[];
            /**
             * Field of study: a general, high-level classification of the dataset. This is only populated during indexing time and it is only populated if the classification_source is
             * KNOWLEDGE_GRAPH or it's above inference threshold.
             */
            fieldOfStudy?: ResearchScienceSearchFieldOfStudyInfo[];
            /** The fingerprint of basic fields from DatasetMetadata, including: - name - description DEPRECATED */
            fingerprint?: string;
            /** Funder of the dataset. */
            funder?: ResearchScienceSearchOrganization[];
            /** Indicates if the dataset has table summaries. This field is only populated during indexing time. */
            hasTableSummaries?: boolean;
            /** A unique id for the dataset. For the data from Spore, this is the spore id, such as, for example "http://accession.nodc.noaa.gov/8500223#__sid=js0" REQUIRED */
            id?: string;
            /** An identifier as provided by the dataset itself. */
            identifierFromSource?: string[];
            /** The image urls provided by the dataset (e.g., for thumbnail images). */
            imageUrl?: string[];
            /** Index of this dataset in its cluster of replicas. */
            indexInCluster?: number;
            /** Indicates if the dataset is available for free or behind a paywal http://schema.org/isAccessibleForFree */
            isAccessibleForFree?: string;
            /** A resource (most likely another dataset) from which this dataset is derived or from which it is a modification or adaption. http://schema.org/isBasedOn */
            isBasedOn?: string[];
            /** Indicates whether the metadata was inferred using an ML model rather than from the schema.org fields. */
            isInferred?: boolean;
            /** Keywords describing the dataset. */
            keyword?: string[];
            /** The 2-letter language code for the source page for the dataset. Same as the language code in source_url_docjoin_info. Populated only when generating output for indexing. */
            languageCode?: string;
            /** License for the dataset. */
            license?: ResearchScienceSearchLicense[];
            /** License for the dataset. DEPRECATED */
            licenseDeprecated?: string[];
            /**
             * A technique or technology used in a Dataset corresponding to the method used for measuring the corresponding variable(s) (described using variableMeasured).
             * http://schema.org/measurementTechnique
             */
            measurementTechnique?: string[];
            /** Mentioned URLs in the description. */
            mentionedUrls?: string[];
            metadataType?: string;
            /** The names of the dataset. */
            name?: string[];
            /** The number of datasets at the same source url as this dataset. */
            numberOfDatasetsAtSourceUrl?: number;
            /** The number of articles that reference this dataset. */
            numberOfScholarCitations?: number;
            publication?: ResearchScienceSearchCitation[];
            /** The url for the article that (likely) describes this dataset. */
            relatedArticleUrl?: string;
            /** The info of replicas of this dataset. */
            replica?: ResearchScienceSearchReplica[];
            /** Ids for other instances (not different versions) of this dataset. */
            sameAs?: string[];
            /**
             * For tables and figures, contains all of the metadata for a scholarly article that was the source of this table or figure. This field is populated only if metadata_type is 'TABLE' or
             * 'FIGURE'.
             */
            scholarlyArticle?: ResearchScienceSearchScholarlyArticle;
            /** Query string to send to Scholar to obtain the best approximation of citations to the dataset. */
            scholarQuery?: string;
            /** Source of the dataset: unifies provider, creator, author, publisher etc. */
            sourceOrganization?: ResearchScienceSearchOrganization[];
            /** Source url from which we gathered the metadata */
            sourceUrl?: string;
            /** All the information extracted from docjoin, for the source_url of this dataset, aka DatasetMetadata.source_url. */
            sourceUrlDocjoinInfo?: ResearchScienceSearchSourceUrlDocjoinInfo;
            /** Locations that describe spatial coverage of the data. If the data covers multiple locations then each value corresponds to one such location, describing its coordinates, mid, etc. */
            spatialCoverage?: ResearchScienceSearchLocation[];
            /** Top salient term labels that describe the dataset document body. */
            topSalientTermLabel?: string[];
            /** urls for the dataset, including doi. */
            url?: string[];
            /** Variables that the data in the dataset captures (e.g., pressure, salinity, temperature). For now, these are just strings. */
            variable?: string[];
            /**
             * Information on the version cluster that the dataset is a part of. This field is populated during the indexing time; the field is populated only if the dataset is part of a version
             * cluster.
             */
            versionClusterInfo?: ResearchScienceSearchVersionClusterInfo;
            /** A hash of the raw metadata fields used by the VersionEmbeddingExtender. */
            versionEmbeddingFieldsHash?: string;
            /** An embedding for the dataset to be used by the VersionAggregator. */
            versionEmbeddingVector?: number[];
        }
        interface ResearchScienceSearchReplica {
            /** The name of the catalog that the replica comes from. */
            catalogName?: string;
            /** The url of the catalog that the replica comes from. */
            catalogUrl?: string;
            /** The index of this replica in a cluster of replicas. */
            indexInCluster?: number;
            /** Url for the replica. */
            url?: string;
        }
        interface ResearchScienceSearchScholarlyArticle {
            /** Proto containing all of the Scholar Metadata for this article. */
            citation?: ScienceCitation;
            /** contains the image of the figure or table cropped out of the pdf page encoded as a PNG. */
            figureOrTableImage?: string;
            /** Contains the text (as detected by OCR) contained inside the image of the figure or table. */
            figureOrTableOcrText?: string;
            /** The url of the landing page for the scholarly article. */
            landingPageUrl?: string;
            /** The page number where the table and figure is located in the original pdf document. */
            pageNumber?: number;
            /** The url where the pdf file is located for the scholarly article. */
            pdfDownloadUrl?: string;
        }
        interface ResearchScienceSearchSourceUrlDocjoinInfo {
            dataSource?: string;
            /** The url used to display in the google search results. */
            displayUrl?: string;
            /** The docid of the document. */
            docid?: string;
            /**
             * Index tiers (BASE, UNIFIED_ZEPPELIN, etc) that the document belongs to. NOTE: Each document may belong to multiple tiers. NOTE: The original data type is an enum
             * CompositeDoc::SubIndexType. However we don't want to depend on segindexer/compositedoc.proto because the proto is too large. Instead, we use CompositeDoc::SubIndexType_Name(
             * subindexid) to convert into a string representation. To convert string back to CompositeDoc::SubIndexType, use CompositeDoc::SubIndexType_Parse.
             */
            indexTier?: string[];
            /**
             * The language of the document in the string representation of LanguageCode. Converts from Language Enum to LanguageCode through i18n/identifiers/langenclanguagecodeconverter.h Please
             * use i18n/identifiers/languagecodeconverter.h for converting between LanguageCode and string representation.
             */
            languageCode?: string;
            /** The syntactic date of a dataset document that reflects the publication date of the content. */
            latestPageUpdateDate?: string;
            /** A sequence of Navboost queries for the dataset source_url. */
            navboostQuery?: ResearchScienceSearchNavboostQueryInfo[];
            /** The page rank of the document. */
            pagerank?: number;
            /**
             * Petacat classifications for the web document. Normally the results from calling Petacat come in a PetacatResponse, which is very flexible and extensible. This proto takes most of
             * the flexibility away - only rephil clusters, taxonomic classifications, and binary classifications, with discretized weights.
             */
            petacatInfo?: FatcatCompactDocClassification;
            /** A set of salient terms extracted fromthe document. DEPRECATEAD. Moved to DatasetMetadata for performance reasons. */
            salientTerms?: QualitySalientTermsSalientTermSet;
            /** Science per-doc data for inclusion in websearch. */
            scholarInfo?: ScienceIndexSignal;
            /** A set of entities from WebRef annotations that are in SPORE_GRAPH. */
            sporeGraphMid?: string[];
            /** The title of the document. */
            title?: string;
            /** A set of top entities from WebrefAnnotation, top is defined by topicality score, see go/topicality-score for detail. DEPRECATED. See label_to_mids_map instead. */
            topEntity?: RepositoryWebrefWebrefEntity[];
            /** The url of the document. */
            url?: string;
            /** A set of entities copied from WebRefEntities on cDoc. */
            webrefEntity?: ResearchScienceSearchSourceUrlDocjoinInfoWebrefEntityInfo[];
        }
        interface ResearchScienceSearchSourceUrlDocjoinInfoWebrefEntityInfo {
            /** The English description of the mid from the KG. */
            description?: string;
            entityType?: string;
            /** The KG identifier of the WebrefEntity. */
            mid?: string;
        }
        interface ResearchScienceSearchVersionClusterInfo {
            /** Index of this dataset in its cluster of versions. */
            indexInVersionCluster?: number;
            /** The number of versions in a Version Cluster. This is equivalent to cluster size. */
            numVersions?: number;
            /** A fingerprint id of the cluster of versions this dataset belongs to. This is a hash of a dataset_id in the cluster. */
            versionClusterId?: string;
        }
        interface RichsnippetsDataObject {
            AccessKey?: string;
            attribute?: RichsnippetsDataObjectAttribute[];
            source?: string;
            /** The object type. */
            type?: string;
        }
        interface RichsnippetsDataObjectAttribute {
            cdata?: string;
            /**
             * idata holds integer data under the attribute name, and could be interpreted differently according to the attribute name. Example: stores the ImadeData.docid used to generate
             * thumbnails. idata will not be automatically converted into xml (the default behavior), but the behavior can be overwritten if necessary.
             */
            idata?: string;
            name?: string;
            /**
             * A data object can have other data objects nested inside it. This is needed to represent Microformats and RDFa which have nestings e.g., a review with a business with an address, or
             * a review with a rating object. See the Webmaster Central 2009/05 blog on "Introducing Rich Snippets".
             */
            subobject?: any;
            /** Whether we should tokenize the value and cdata when generating restricts from this attribute. */
            tokenize?: boolean;
            /** Either of cdata or value should be present. */
            value?: string;
        }
        interface RichsnippetsPageMap {
            DataObject?: RichsnippetsDataObject[];
            /** If ignore_data_object is set to true, pagemap attachment is processed regardless of whether data object is present or not. */
            ignoreDataObject?: boolean;
            src?: string;
            templatetype?: RichsnippetsPageMapTemplateType[];
        }
        interface RichsnippetsPageMapTemplateType {
            src?: string;
        }
        interface SafesearchInternalImageSignals {
            imageEntitiesViolenceScore?: number;
            /** Additional SafeSearch signals that are used to compute final scores. */
            starburstPornScore?: number;
            starburstViolenceScore?: number;
        }
        // tslint:disable-next-line:no-empty-interface
        interface SafesearchVideoClassifierOutput {
        }
        interface SafesearchVideoContentSignals {
            scores?: { [P in string]: number };
            versionTag?: string;
            /** Output of all SafeSearch video classifiers in Amarna. */
            videoClassifierOutput?: any;
        }
        interface ScienceCitation {
            AbstractDisplay?: string;
            /** Version of abstract field for display. Contains unsanitized XML/HTML. */
            AbstractHtml?: string;
            /** Leftovers from AbstractHtml. These are usually unrecognized xml/html entities or xml/html tags */
            AbstractHtmlLeftOver?: string;
            AbstractLanguage?: string;
            AbstractSource?: string;
            AbstractText?: string;
            accessurl?: ScienceCitationAccessURL[];
            alternateabstract?: ScienceCitationAlternateAbstract[];
            alternatetitle?: ScienceCitationAlternateTitle[];
            /**
             * Fingerprint of the URL after applying crawl and aggregate rewrites. Different citations with the same AlternateVersionID must have the same VersionID, but not necessarily vice
             * versa. Omitted when identical to the VersionID.
             */
            AlternateVersionID?: string;
            /** All the anchor text (before, after, formal, etc) for this citation in the referring page. */
            Anchors?: ScienceCitationAnchor[];
            /** e.g. hep-ph */
            ArxivSection?: string;
            author?: ScienceCitationAuthor[];
            /** whether this citation had an "et al" in the author list */
            AuthorListHasEtAl?: boolean;
            AuthorMetatagLeftOver?: string;
            /** Global document identifier - only available when building increments over a known base index. This id is from the base index. */
            BaseGlobalID?: string;
            /**
             * Set when building an incremental index. Whereas BaseGlobalID is the ID of the corresponding base cluster, the local ID is the ID of an individual citation within that base cluster
             * that corresponds to this reparse.
             */
            BaseLocalID?: string;
            /** one bit per author */
            BorrowedAuthors?: number;
            /** OR of FieldType */
            BorrowedFields?: number;
            category?: ScienceCitationCategory[];
            Chapter?: string;
            /** citation src: dblp/crossref/paper etc */
            CitationSource?: number;
            /** url where record came from */
            CitationSourceUrl?: string;
            /** DEPRECATED: use CitationSource */
            CitationSrc?: string;
            ClearedReason?: string;
            /**
             * Used for logging, recommendations, and sort-by-date. Contains the earliest discovery date of the cluster, adjusted for earlier publication dates. Stored in Universal time scale (100
             * ns ticks since 0001 AD) because Unix timestamp would lead to negative dates for pre-1970 docs.
             */
            ClusterDiscoveryDate?: string;
            /** Identifier for conference series - issn-lite */
            ConferenceId?: string;
            /** 27 in the "27th conference on magical realism" */
            ConferenceNumber?: number;
            /** If a citation is merged from a crawled version and a metadata version, keep the normal docid fp of the crawled version for clustering FP of normal docid of crawl version */
            CrawledDocid?: string;
            DblpId?: string;
            DEPRECATEDMetadataSourceFile?: string;
            /** these fields moved to DownloadURL where they belong */
            DEPRECATEDPublisherDisplayName?: string;
            /** Local document identifier - url fingerprint if we know the url, or fingerprint of all fields if we don't. Different urls have different local docids. */
            DocumentID?: string;
            /** Digital Object Identifier */
            DOI?: string;
            downloadurl?: ScienceCitationDownloadURL[];
            /** Dspace uses handle.net handles */
            DspaceID?: string;
            Edition?: string;
            Editor?: string[];
            FileCreationDay?: number;
            /** zero-indexed field */
            FileCreationMonth?: number;
            /** date of creation of the pdf/doc */
            FileCreationYear?: number;
            funding?: ScienceCitationFunding[];
            /** Is this article expected to have been indexed in the incremental? */
            IncrementalExpected?: boolean;
            ISBN?: string;
            ISBNVariant?: string[];
            ISSN?: string;
            ISSNVariant?: string[];
            JOI?: string;
            Keywords?: string[];
            Language?: string;
            /** library of congress call number */
            LCCN?: string;
            /**
             * The ScienceCitation is how metadata passes through the scholar system. For legal, we use the normal ScienceCitation for the metadata/citation of legal journals. For court/government
             * documents (like opinions or statues), we wrap it in the following embedded message
             */
            LegalCitation?: LegalCitation;
            /** If this is a target reference, the level of discussion of this reference. */
            LevelOfDiscussion?: number;
            /** random string data - unparsed */
            Note?: string;
            /** for display in gws */
            NumBackwardLinks?: number;
            /** hack for legal rollout */
            NumBackwardLinksFromLegal?: number;
            /** numcited in WoS */
            NumBackwardLinksInWoS?: number;
            /** can be 1-3 */
            Number?: string;
            /** for display in gws */
            NumForwardLinks?: number;
            /** good embedded refs */
            NumGoodEmbeddedRefs?: number;
            /**
             * If set, then we host this many pages of this citation's content. Note that this field may be set to 0, in which case we should be hosting this content but have failed. DEPRECATED,
             * moved to DownloadURL
             */
            NumHostedPages?: number;
            /** for display in gws */
            NumKeyQuotes?: number;
            /** for display in gws */
            NumRelated?: number;
            /** for experiments */
            NumRelated2?: number;
            /** for experiments */
            NumRelated3?: number;
            /** refs in marked section */
            NumSectionRefs?: number;
            /** for display in gws */
            NumVersions?: number;
            OnlineDay?: number;
            /** OnlineMonth is a zero-indexed field (0 is January). */
            OnlineMonth?: number;
            OnlineYear?: number;
            /** eg ERIC doc number or TR number */
            OtherID?: string;
            /** Using string to handle all kinds of page specifications. Internal structure is not really needed. */
            Pages?: string;
            ParseSource?: number;
            /**
             * Note that an issued patent has a PatentNumber and can also have a PatentApplicationNumber, whereas a patent application has a PatentApplicationNumber and can also have a
             * PatentPublicationNumber.
             */
            PatentApplicationNumber?: string;
            /** patent classification e.g., "B24B 3100" */
            PatentClassification?: string[];
            /** 2-letter country code where patent was issued, see ocean/metadata/patent_record.proto::Patent_Record::country_code for EPO one patent pertains to a list of countries. */
            PatentCountry?: string[];
            /** number according to USPTO/EPO/JPO scheme. */
            PatentNumber?: string;
            /** one of the above */
            PatentOffice?: number;
            PatentPublicationNumber?: string;
            PMCID?: string;
            /** Pubmed ID */
            PMID?: string;
            /** for patents, publicationD/M/Y is the date of issue, not application */
            PublicationDay?: number;
            /** month from bibtex PublicationMonth is a zero-indexed field (0 is January). */
            PublicationMonth?: number;
            /** where published - subsumes booktitle, howpublished and journal from bibtex */
            PublicationVenue?: string;
            PublicationVenueVariant?: string[];
            /** year from bibtext full year */
            PublicationYear?: number;
            /** address from bibtex */
            PublisherAddress?: string;
            PublisherId?: string;
            /** subsumes organization, school and institution from bibtex */
            PublisherOrg?: string;
            /** local journal number */
            PubvenueID?: string;
            referencediscussion?: ScienceCitationReferenceDiscussion[];
            /** bitmap of ReviewArticleTypeReasons */
            ReviewTypeReason?: number;
            Series?: string;
            SICI?: string;
            subject?: ScienceCitationSubject[];
            Title?: string;
            /** Version of title for display. Contains unsanitized HTML/XML. */
            TitleHtml?: string;
            /** Leftovers from TitleHtml. These are usually unrecognized xml/html entities or xml/html tags */
            TitleHtmlLeftOver?: string;
            translatedauthor?: ScienceCitationTranslatedAuthor[];
            /** etal marker for the translated author list - just in case */
            TranslatedAuthorListHasEtAl?: boolean;
            /** ArticleType */
            Type?: number;
            unioncatalog?: ScienceCitationUnionCatalog[];
            /** Email addresses found in the document that we weren't able to match */
            UnmatchedEmailAddr?: string[];
            /** Author affiliations found in the document that we weren't able to match up to specific authors. */
            UnmatchedInstitution?: string[];
            /**
             * Document version identifier - fingerprint of an id computed from the url, or of bibliographic data from a publisher. Different urls for the same article from the same source have
             * the same version id (e.g., abstract, pdf version, and html version).
             */
            VersionID?: string;
            Volume?: number;
            /** Is this version of the article world viewable? */
            WorldViewable?: boolean;
            /** Web of Science ID */
            WOSID?: string;
        }
        interface ScienceCitationAccessURL {
            AccessDay?: number;
            /** AccessMonth is a zero-indexed field (0 is January). */
            AccessMonth?: number;
            AccessYear?: number;
            UrlStr?: string;
        }
        interface ScienceCitationAlternateAbstract {
            AbstractDisplay?: string;
            /** Version of abstract field for display. This may contain XML/HTML tags. */
            AbstractHtml?: string;
            /** Leftovers from AbstractHtml. These are usually unrecognized xml/html entities or xml/html tags */
            AbstractHtmlLeftOver?: string;
            AbstractLanguage?: string;
            AbstractText?: string;
        }
        interface ScienceCitationAlternateTitle {
            Language?: string;
            Title?: string;
            /** Version of title for display. Contains unsanitized HTML/XML. */
            TitleHtml?: string;
            /** Leftovers from TitleHtml. These are usually unrecognized xml/html entities or xml/html tags */
            TitleHtmlLeftOver?: string;
        }
        interface ScienceCitationAnchor {
            /** Number of times this anchor text appears, only consider the text itself */
            count?: number;
            /** Fingerprint of the referral document. The fingerprint should resist to small variance in the document content. DO NOT USE IT! */
            DEPRECATEDSrcFP?: string;
            /** font face bitmask: kBold, kItalic, etc. */
            face?: number;
            /** font size, in px */
            size?: number;
            /** Space-delimited anchor words. Text that needs segmentation (like CJK or Thai) is unsegmented. Generated by ScienceParseUtils::AppendTokenSeqToString() */
            text?: string;
            /** one of the "Type" value defined below. */
            type?: number;
            /** weight of the anchor by looking where we get this anchor text. It can be PR, court level, year, or the combination of differerent aspects. weights are 1 - 128 defined as "Weights" */
            weight?: number;
        }
        interface ScienceCitationAuthor {
            Comment?: string;
            /** not in bibtex - from paper */
            Department?: string;
            Email?: string;
            /** Tracks the GuessNameOrder case used to parse this author name, defaults to 0 simply means that GuessNameOrder wasn't used. */
            GuessOrderType?: number;
            /** Author ID. Formatted as idtype:id */
            ID?: string[];
            /** not in bibtex - from paper */
            Institution?: string;
            IsCJKForeignName?: boolean;
            IsCorrespondingAuthor?: boolean;
            LastName?: string;
            OtherNames?: string;
            SourceText?: string;
            /** Type is one of the contributors types. Writers are the default. */
            Type?: number;
        }
        interface ScienceCitationCategory {
            Name?: string;
            /** ontology/set of categories for the category */
            Type?: string;
        }
        interface ScienceCitationDownloadURL {
            /** set if we know the landing page is broken */
            BrokenLandingPage?: boolean;
            CanonicalUrlfp?: string;
            /** checksum of the page */
            ContentChecksum?: string;
            /** makes gws display nicer :) */
            ContentType?: number;
            /** seconds since the epoch */
            CrawlTimestamp?: string;
            /** publisher display name */
            DisplayOrg?: string;
            /** display preference score */
            DisplayPriority?: number;
            /** metatag: URL; result was taken down */
            DMCANotice?: string;
            DownloadDay?: number;
            /** DownloadMonth is a zero-indexed field (0 is January). */
            DownloadMonth?: number;
            /** no abbrv */
            DownloadYear?: number;
            /** first few lines of abstract'ish excerpt */
            ExcerptContent?: string;
            /** label for excerpt (abstract, summary, ..) */
            ExcerptDebugLabel?: string;
            /** seconds since the epoch */
            FirstDiscovered?: string;
            /** explicit zero means hosting failed */
            HostedNumPages?: number;
            HostedStartPage?: number;
            /** html title of the page */
            HtmlTitle?: string;
            /** indexing preference score */
            IndexPriority?: number;
            /** is url included in a previous index */
            InPrevIndex?: boolean;
            /** e.g., in law_articles.pat */
            LegalMustInclude?: boolean;
            /** Whether this is likely the URL for an ahead print, at indexing time. */
            LikelyAheadPrint?: boolean;
            /** In the context of a given venue in Scholar Metrics, whether this URL likely does not link to the current venue. */
            LikelyDifferentMetricsVenue?: boolean;
            /** e.g., in legal_journals.pat */
            LikelyLegalJournal?: boolean;
            /** badurls_nocache at indexing time */
            LikelyNoCache?: boolean;
            /** badurls_noreturngws at indexing time */
            LikelyNoIndex?: boolean;
            /** Likely to be free-to-read for everyone, after accounting for library links etc. */
            LikelyWorldViewable?: boolean;
            /** number of long paragraphs */
            LongChunkCount?: number;
            /** Incremental only: mark as NoIndexed if this is a reparse and the base version is NoIndexed. */
            MaybeNoIndexReparse?: boolean;
            /** url of publisher metadata file */
            MetadataUrl?: string;
            /** e.g., in science_articles.pat */
            MustInclude?: boolean;
            /** metatag: don't show cached version */
            NoArchive?: boolean;
            /** metatag: don't display this url */
            NoIndex?: boolean;
            /** metatag: don't show snippet */
            NoSnippet?: boolean;
            /** describes whether url is viewable in ocean */
            OceanView?: ScienceOceanView;
            /** number of external URLs (in PDF). */
            OutLinkCount?: number;
            /** Number of pages in the pdf2html conversion output. Only set for PDFs. For a partitioned PDF, this is the page count of the entire volume. */
            PageCount?: number;
            /** were references parsed in a previous index */
            ReferencesInPrevIndex?: boolean;
            /** ArticleType for this particular url */
            Type?: number;
            UrlAfterRedirects?: string;
            UrlStr?: string;
            /** number of words in content/body */
            WordCount?: number;
            /** metatag: is viewable by world */
            WorldViewable?: boolean;
        }
        interface ScienceCitationFunding {
            /** values are from FundingAgency enum */
            Agency?: number;
            /** Text name of the agency. For analysis. Plus for agencies that don't have an enum. */
            AgencyName?: string;
            /**
             * Funding entries for the same agency and grant number can be merged during our extraction process so we maintain a record of all the deduped ExtractionInfo messages within the
             * remaining entry.
             */
            DebugExtractionInfo?: ScienceCitationFundingExtractionInfo[];
            /** Text block from which the funding entry was extracted. Intended to be used for offline analysis. DEPRECATED */
            DebugFundingTextBlock?: string;
            GrantNumber?: string;
            /** funding recipient */
            Recipient?: string;
            /** Original text for the funding acknowledgement */
            SourceText?: string;
            /** Whether this funding info was added because this article was at the exclusive repository for this agency. */
            UrlBasedFundingSource?: boolean;
        }
        interface ScienceCitationFundingExtractionInfo {
            /** Text block context from which the funding entry was extracted. Optionally filled and intended to be used for offline analysis. */
            DebugFundingTextBlock?: string;
            DocPart?: string;
            ParseSection?: string;
            Source?: string;
        }
        interface ScienceCitationReferenceDiscussion {
            Level?: number;
            TargetID?: string;
        }
        interface ScienceCitationSubject {
            /** e.g., "eng" */
            Name?: string;
            /** [0,1] */
            Probability?: number;
        }
        interface ScienceCitationTranslatedAuthor {
            Department?: string;
            Email?: string;
            GuessOrderType?: number;
            Institution?: string;
            Language?: string;
            LastName?: string;
            OtherNames?: string;
            SourceText?: string;
            Type?: number;
        }
        interface ScienceCitationUnionCatalog {
            CanonicalUrlfp?: string;
            /** url of catalog metadata file */
            MetadataUrl?: string;
            /** Information about the number of libraries the citation appears. It should be useful for ranking. */
            NumLibraries?: number;
            /** Categories classification of the citation */
            Subject?: string[];
            /** UnionCatalog url to display to users */
            Url?: string;
        }
        interface ScienceIndexSignal {
            author?: ScienceIndexSignalAuthor[];
            /** Subscriber Access feature: List of Holdings IDs associated with this document. Should be present only for the documents with 'VisiblePrefixTerms' being set. */
            HoldingsId?: string[];
            /** Fingerprint of the html title of the page. This is useful for checking if we have the same version of the page as websearch. */
            HtmlTitleFp?: string;
            /** Index selection score for websearch, bigger is better: (0.5,1.0] - prefer selection into the base index, (0.0,0.5] - prefer selection into the supplemental index. */
            IndexSelectionScore?: number;
            /** Summary statistics. */
            NumBackwardLinks?: number;
            NumRelated?: number;
            NumVersions?: number;
            PublicationDay?: number;
            PublicationMonth?: number;
            /** Publication date. */
            PublicationYear?: number;
            /** Remove this URL from the index - error page, broken landing page, etc. DEPRECATED, was never used or even filled correctly. */
            RemoveLink?: boolean;
            /** For links from websearch to scholar. */
            ScholarId?: string;
            /** Title of the article. Its only filled in when the html title of the page isn't good. */
            Title?: string;
            /**
             * Length of document prefix that most users are likely to see. Only filled in when we index subscription fulltext but most users see abstracts. This is a conservative guesstimate -
             * e.g., ACM shows fulltext to university/company subscribers (including Google employees) based on user's IP address, but we don't know subscriber IPs, so ACM's PDF pages would have
             * ~500 in this field (estimated length of abstract).
             */
            VisiblePrefixTerms?: number;
        }
        interface ScienceIndexSignalAuthor {
            LastName?: string;
            OtherNames?: string;
        }
        interface ScienceOceanView {
            countryview?: ScienceOceanViewCountryView[];
        }
        interface ScienceOceanViewCountryView {
            /** No CountryCode means default viewability. two letter code */
            CountryCode?: string;
            /** enum in ocean::LocaleViewability::ViewType */
            ViewType?: number;
        }
        interface SdrEmbedding {
            values?: number[];
            version?: number;
        }
        interface SdrPageAnchorsDocInfo {
            articleness?: number;
            pageAnchors?: SdrPageAnchorsSitelink[];
            qscore?: number;
            sitelinkWrapper?: SdrPageAnchorsSitelinkWrapper[];
            textRichness?: number;
        }
        interface SdrPageAnchorsSitelink {
            /** Needed for relevance scoring. */
            embedding?: SdrEmbedding;
            /** aggregate score from Section Geometry. */
            geometryScore?: number;
            /** Heading Abbreviation score. */
            headingAbbrvScore?: number;
            /** Needed for heading/passage filtering. */
            hpScore?: number;
            level?: number;
            scrollTo?: SdrScrollTo;
            /** Needed for Geometry Scoring and backoffs. from Section Geometry. */
            sectionHeight?: number;
            /** Heading/Reformulated text is needed to display. */
            text?: string;
        }
        interface SdrPageAnchorsSitelinkWrapper {
            abbreviatedHeadingText?: string;
            abbrvEmbedding?: SdrEmbedding;
            headingEmbedding?: SdrEmbedding;
            normalizedHeadingText?: string;
            passageEmbedding?: SdrEmbedding;
            passageText?: string;
        }
        interface SdrScrollTo {
            onpageMatches?: SdrScrollToOnPageMatches;
            /** Prefix to help with disambiguating between multiple text matches on page. Optional. */
            prefix?: string;
            /** Suffix to help with disambiguating between multiple text matches on page. Optional. */
            suffix?: string;
            /** End of the text span to be highlighted. Optional. */
            textEnd?: string;
            /** Start of the text span to be highlighted. */
            textStart?: string;
        }
        interface SdrScrollToOnPageMatches {
            text?: number;
            textWithPrefix?: number;
            textWithPrefixSuffix?: number;
            textWithSuffix?: number;
        }
        interface SearchPolicyRankableSensitivity {
            /**
             * Propagated from knowledge.answers.sensitivity.Sensitivity account_provenance. Any ambiguity between the data here and dasher_user should be resolved by the conversion to pToken in
             * http://source/search?q=symbol:CreatePTokenFromSensitivity
             */
            accountProvenance?: QualityQrewriteAccountProvenance[];
            attentionalEntity?: SearchPolicyRankableSensitivityAttentionalEntity;
            /** True iff the query is from a Dasher user. */
            dasherUser?: boolean;
            followon?: SearchPolicyRankableSensitivityFollowOn;
            prefilter?: SearchPolicyRankableSensitivityPrefilter;
            qu?: SearchPolicyRankableSensitivityQueryUnderstanding;
            /** Key of a sensitivity. */
            sensitivityMode?: string;
            syntheticIntent?: any;
            winningFulfillment?: any;
        }
        interface SearchPolicyRankableSensitivityAttentionalEntity {
            aeOrigin?: string;
        }
        interface SearchPolicyRankableSensitivityFollowOn {
            /** Should e2e search candidates running in parallel with QU (eg. GBot) be blocked. */
            blockNonV2SearchBackends?: boolean;
            /** Iff true this follow-on sensitivity will rank above the ones determined by query understanding (QU). */
            ignoreQueryUnderstanding?: boolean;
        }
        // tslint:disable-next-line:no-empty-interface
        interface SearchPolicyRankableSensitivityFulfillment {
        }
        interface SearchPolicyRankableSensitivityPrefilter {
            propagateOnly?: boolean;
        }
        interface SearchPolicyRankableSensitivityQueryUnderstanding {
            /**
             * QU dectects a sensitive intent with no sensitive content (eg., [Send email]). This flag is only used to trigger a sensitive feature because as a precaution all sensitive features
             * should check current sensitivity mode before triggering; but will NOT block any backends, which means all other features can compete fairly.
             */
            intentOnlyNoPii?: boolean;
            /** The rewritten query this sensitivity is for. Note different query rewrites could produce different sensitivities. */
            rewrittenQuery?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface SearchPolicyRankableSensitivitySyntheticIntent {
        }
        // tslint:disable-next-line:no-empty-interface
        interface SecurityCredentialsAllAuthenticatedUsersProto {
        }
        interface SecurityCredentialsCapTokenHolderProto {
            /**
             * The hash of the corresponding capability token. The value is defined to be identical to the one in acl.proto's CapTokenMetadata: 10-byte prefix of HMAC-SHA1 of the token. The HMAC
             * key is the following fixed (non-secret) 512-bit value: 79b1c8f4 82baf523 b8a9ab4a e960f438 c45be041 11f1f222 e8a3f64d aeb05e3d c3576acc ec649194 aede422c 4e48e0d1 ff21234a a6ed6b49
             * a7fa592e efd7bba3
             */
            tokenHmacSha1Prefix?: string;
        }
        interface SecurityCredentialsChatProto {
            /** Chat IDs consist of alphanumeric characters and colons. Currently required. */
            chatId?: string;
            /**
             * The type of Chat members to consider, e.g. "all members" vs. "invitee" These are defined by legacy_relation_id values in social.graph.storage.EdgeTypeEnum.EdgeType enum options in
             * social/graph/storage/proto/id.proto. See chat.pb (defined in production/config/cdd/socialgraph/mixer_config/prod/node_type_config) for all valid edge types associated with chat.
             * Currently required.
             */
            memberType?: number;
        }
        interface SecurityCredentialsCircleProto {
            /** Circle ID is unique only relative to the owner's Gaia ID. Currently required. */
            circleId?: string;
            /** The owner of the circle. Currently required. */
            ownerGaiaId?: string;
            /**
             * If present, then tests for membership in this circle must use data known to be at least as fresh as the given (FBS-assigned) timestamp. See
             * http://go/fbs-consistent-read-after-important-write Before using this, be sure that any service checking authorization against this circle supports checking consistency timestamps.
             * For example, as of 12/2011, Keystore only supports this for the Moonshine configuration, and in others authorization checks will fail if the timestamp is present.
             */
            requiredConsistencyTimestampUsec?: string;
        }
        interface SecurityCredentialsCloudPrincipalProto {
            /** Format: "{identity-pool}:{subject}#" Details: go/cloud-principal-identifiers */
            id?: string;
        }
        interface SecurityCredentialsContactGroupProto {
            /** Group ID is unique only relative to the owner's Gaia ID. */
            groupId?: string;
            ownerGaiaId?: string;
            /**
             * If present, then tests for membership in this ContactGroup must use data known to be at least as fresh as the given (FBS-assigned) timestamp. See
             * http://go/fbs-consistent-read-after-important-write Before using this, be sure that any service checking authorization against this group supports checking consistency timestamps.
             * For example, as of 12/2011, Keystore only supports this for the Moonshine configuration, and in others authorization checks will fail if the timestamp is present.
             */
            requiredConsistencyTimestampUsec?: string;
        }
        interface SecurityCredentialsEmailOwnerProto {
            email?: string;
        }
        interface SecurityCredentialsEventProto {
            /** Event IDs consist of alphanumeric characters and colons. Currently required. */
            eventId?: string;
            /**
             * The type of Event members to consider, e.g. "all members" vs. "owners" vs. "admins". These are defined by legacy_relation_id values in social.graph.storage.EdgeTypeEnum.EdgeType
             * enum options in social/graph/storage/proto/id.proto. See event.pb (defined in production/config/cdd/socialgraph/mixer_config/prod/node_type_config) for all valid edge types
             * associated with event. Currently required.
             */
            memberType?: number;
        }
        interface SecurityCredentialsGaiaGroupProto {
            groupId?: string;
        }
        interface SecurityCredentialsGaiaUserProto {
            userId?: string;
        }
        interface SecurityCredentialsHostProto {
            /** Lower-case, fully qualified hostname. */
            hostName?: string;
            /**
             * If present, then any checks that compare this Principal to LOAS peer info must confirm the peer's machine owner is equal to 'host_owner'. If absent, then any peer machine owner is
             * acceptable.
             */
            hostOwner?: string;
        }
        interface SecurityCredentialsLdapGroupProto {
            groupName?: string;
        }
        interface SecurityCredentialsLdapUserProto {
            userName?: string;
        }
        interface SecurityCredentialsMdbGroupProto {
            groupName?: string;
        }
        interface SecurityCredentialsMdbUserProto {
            /**
             * Do not set this field. Contact credentials-eng@ if you believe you absolutely need to use it. This is the @prod.google.com Gaia ID that corresponds to the MDB user, see
             * go/authn-merge for details. This field may always be safely ignored when performing an authorization check.
             */
            gaiaId?: string;
            userName?: string;
        }
        interface SecurityCredentialsOAuthConsumerProto {
            domain?: string;
        }
        interface SecurityCredentialsPostiniUserProto {
            postiniUserId?: string;
        }
        interface SecurityCredentialsPrincipalProto {
            /** scope = ALL_AUTHENTICATED_USERS */
            allAuthenticatedUsers?: any;
            /** scope = CAP_TOKEN_HOLDER */
            capTokenHolder?: SecurityCredentialsCapTokenHolderProto;
            /** scope = CHAT */
            chat?: SecurityCredentialsChatProto;
            /** scope = CIRCLE */
            circle?: SecurityCredentialsCircleProto;
            /** scope = CLOUD_PRINCIPAL */
            cloudPrincipal?: SecurityCredentialsCloudPrincipalProto;
            /** scope = CONTACT_GROUP */
            contactGroup?: SecurityCredentialsContactGroupProto;
            /** scope = EMAIL_OWNER */
            emailOwner?: SecurityCredentialsEmailOwnerProto;
            /** scope = EVENT */
            event?: SecurityCredentialsEventProto;
            /** scope = GAIA_GROUP */
            gaiaGroup?: SecurityCredentialsGaiaGroupProto;
            /** scope = GAIA_USER */
            gaiaUser?: SecurityCredentialsGaiaUserProto;
            /** scope = HOST */
            host?: SecurityCredentialsHostProto;
            /** scope = LDAP_GROUP */
            ldapGroup?: SecurityCredentialsLdapGroupProto;
            /** scope = LDAP_USER */
            ldapUser?: SecurityCredentialsLdapUserProto;
            /** scope = MDB_GROUP */
            mdbGroup?: SecurityCredentialsMdbGroupProto;
            /** scope = MDB_USER */
            mdbUser?: SecurityCredentialsMdbUserProto;
            /** scope = OAUTH_CONSUMER; */
            oauthConsumer?: SecurityCredentialsOAuthConsumerProto;
            /** scope = POSTINI_USER */
            postiniUser?: SecurityCredentialsPostiniUserProto;
            /** scope = RBAC_ROLE */
            rbacRole?: SecurityCredentialsRbacRoleProto;
            /** scope = RBAC_SUBJECT */
            rbacSubject?: SecurityCredentialsRbacSubjectProto;
            /** scope = RESOURCE_ROLE */
            resourceRole?: SecurityCredentialsResourceRoleProto;
            /** This is only optional because required enums cannot be extended. Currently required. */
            scope?: string;
            /** scope = SIGNING_KEY_POSSESSOR */
            signingKeyPossessor?: SecurityCredentialsSigningKeyPossessorProto;
            /** scope = SIMPLE_SECRET_HOLDER */
            simpleSecretHolder?: SecurityCredentialsSimpleSecretHolderProto;
            /** scope = SOCIAL_GRAPH_NODE */
            socialGraphNode?: SecurityCredentialsSocialGraphNodeProto;
            /** scope = SQUARE */
            square?: SecurityCredentialsSquareProto;
            /** scope = YOUTUBE_USER */
            youtubeUser?: SecurityCredentialsYoutubeUserProto;
            /** scope = ZWIEBACK_SESSION */
            zwiebackSession?: SecurityCredentialsZwiebackSessionProto;
        }
        interface SecurityCredentialsRbacRoleProto {
            name?: string;
            objectId?: string;
            /** DEPRECATED as of 01.11.2019 */
            rbacNamespace?: string;
            /**
             * Format: "role/z?" - "role" is the Sphinx globally unique name of the Sphinx role that provisions the RBAC role. - "/z?" suffix indicates which Zanzibar environment stores the role
             * membership data ("/zd": dev, "/zs": staging, "/zp": prod, "/zt": local test instance). Example: "mysystem_myrole/zp"
             */
            rbacRoleName?: string;
        }
        interface SecurityCredentialsRbacSubjectProto {
            /** Format "username" without "@domain", e.g., "bogdand". */
            username?: string;
        }
        interface SecurityCredentialsResourceRoleProto {
            applicationId?: string;
            objectId?: string;
            objectPart?: string;
            roleId?: number;
        }
        interface SecurityCredentialsSigningKeyPossessorProto {
            /** This value must be from the KeyMetadata.Type enum in keymaster.proto. */
            keymasterKeyType?: number;
            /** The actual verification key bytes corresponding to the above type. */
            serializedVerificationKey?: string;
            /**
             * The binary serialized Keymaster SerializedReader of a public keyset. The keyset must contain exactly one key. N.B.: If this field is populated, serialized_verification_key should be
             * set to the empty string and keymaster_key_type should be set to zero.
             */
            serializedVerificationKeyset?: string;
        }
        interface SecurityCredentialsSimpleSecretHolderProto {
            /** A descriptive label to help identify a relevant ACL entry or otherwise disambiguate this instance. */
            label?: SecurityCredentialsSimpleSecretLabelProto;
        }
        interface SecurityCredentialsSimpleSecretLabelProto {
            /**
             * ***DEPRECATED (3-Oct-2011) *** This field should be deleted when code stops using CAP_TOKEN labels. Used when type = CAP_TOKEN. When a CAP_TOKEN label appears in a
             * SimpleSecretHolder Principal, |capability_id| must be filled in to identify one of the capabilities on the ACL. When a CAP_TOKEN label appears in a SimpleSecret Authenticator, it is
             * NOT necessary to fill in |capability_id| -- ACL Service will find the ID by searching all capabilities on the ACL for one associated with the token given by the SimpleSecret's
             * secret data. If |capability_id| is specified, though, then the Authenticator will only be accepted if it actually matches that particular token ID.
             */
            capabilityId?: number;
            /** Used when type = GENERIC_SECRET */
            genericLabel?: string;
            /** Used when type == INVITE. */
            inviteId?: string;
            /** This is optional because required enums cannot be extended. */
            type?: string;
        }
        interface SecurityCredentialsSocialGraphNodeProto {
            /** The fields from ccc/socialgraph/socialgraphnode.proto:SgnNode that uniquely identify a social graph node. The 'ident' field is not included here because its value can be changed. */
            sgnDomain?: string;
            sgnPk?: string;
        }
        interface SecurityCredentialsSquareProto {
            /**
             * The type of Square members to consider, e.g. "all members" vs. "owners" vs. "admins". These are defined by legacy_relation_id values in social.graph.storage.EdgeTypeEnum.EdgeType
             * enum options in social/graph/storage/proto/id.proto. See square.pb (defined in production/config/cdd/socialgraph/mixer_config/prod/node_type_config) for all valid edge types
             * associated with square. Currently required.
             */
            memberType?: number;
            /** Currently required. */
            squareId?: string;
        }
        interface SecurityCredentialsYoutubeUserProto {
            youtubeUserId?: string;
        }
        interface SecurityCredentialsZwiebackSessionProto {
            zwiebackSessionId?: string;
        }
        interface SentenceBoundaryAnnotations {
            /**
             * Used for application-specific information about the whole set of SentenceBoundaryAnnotations. Example: SAFT Team uses this to store an nlp_saft.Document proto giving any processing
             * errors encountered.
             */
            info?: any;
            instance?: SentenceBoundaryAnnotationsInstance[];
        }
        interface SentenceBoundaryAnnotationsInstance {
            begin?: number;
            /** A clean version of .text() generated by using CleanText() and stripping unnecessary whitespace. */
            cleanText?: string;
            /** Plain text context from the page within which the annotation occurred. */
            context?: string;
            /** Byte offsets for the clean text context above. */
            contextBegin?: number;
            contextEnd?: number;
            end?: number;
            /** Used for application-specific information about this annotation. */
            info?: any;
            /** Original UTF-8 document text occurring in the range [begin, end). */
            text?: string;
            /** Used to mark the annotations selected to be indexed. */
            toIndex?: boolean;
        }
        interface SentimentSentiment {
            /** Polarity represents the sentiment towards the subject. */
            polarity?: string;
            userBehaviors?: SentimentSentimentBehaviors;
            /** The emotions that the user is feeling. */
            userEmotions?: SentimentSentimentEmotions;
        }
        interface SentimentSentimentBehaviors {
            /** The degree to which the user is showing politeness. */
            politeness?: number;
        }
        interface SentimentSentimentEmotions {
            anger?: number;
            disgust?: number;
            fear?: number;
            happiness?: number;
            sadness?: number;
            surprise?: number;
        }
        interface ShingleInfoPerDocData {
            /** Total number of shingles in the document. */
            numShingles?: number;
            /** A list of all sources. */
            source?: ShingleSource[];
        }
        interface ShingleSource {
            /** Hash-value of the URL. */
            id?: number;
            /** Number of shingles originating from this source. */
            numShingles?: number;
            /** First-seen timestamp of the source. */
            timestamp?: number;
        }
        interface ShoppingWebentityShoppingAnnotationInferredImage {
            inferredImageId?: string;
            inferredImageType?: string;
        }
        interface ShoppingWebentityShoppingAnnotationProductRating {
            /**
             * Number of ratings/reviews aggregated to create this product rating. If there are no ratings yet, this field will be explicitly set to zero, so whether this field is set should be
             * checked using has_count.
             */
            count?: string;
            maxValueMillis?: string;
            /**
             * The lower and upper bounds of the rating values that could be submitted for the product. (Note that it is not the min/max ratings submitted for the product, it is the min/max that
             * can hypothetically be submitted.)
             */
            minValueMillis?: string;
            source?: string;
            /** The value of this rating normalized between 0 and 5. This will not be set if count is set to 0. */
            value?: number;
            /** The non-normalized aggregated value of the ratings for this product. */
            valueMillis?: string;
        }
        interface ShoppingWebentityShoppingAnnotationSoriVersionId {
            f1CommitTimestampMicros?: string;
            opaqueSoriId?: AdsShoppingReportingOffersSerializedSoriId;
        }
        interface Sitemap {
            /**
             * DEPRECATED DEPRECATED DEPRECATED In case you didn't realize, these fields are (and have been for some time) deprecated. We'll stop pushing their data to production soon (probably
             * Feb/09) and after a few weeks we'll probably remove them.
             */
            DEPRECATEDSourceTitle?: string;
            deprecatedTarget?: SitemapDEPRECATED_Target[];
            /** This field is populated in the Sitemap MDU subpopulator from cdoc data. This is used to store page anchors information for TopicTagsScrolltoFlow. */
            pageAnchorsDocInfo?: SdrPageAnchorsDocInfo;
            /** Enable site search. */
            searchInSite?: boolean;
            sitemapType?: string;
            /** prevents cross-domain forwarding */
            sourceOrgfp?: string;
            sourceUrl?: string;
            /** This field is populated in the Sitemap MDU subpopulator from cdoc data. It's not set in the cdoc Sitemap. */
            subresultList?: QualitySitemapSubresultList;
            /**
             * One Sitemap can contain multiple TargetGroups, but only one of them will be displayed to the user - this decision will be made at displaying time and can take into account various
             * factors, such as the users' language and country, currently running experiments, etc.
             */
            TargetGroups?: QualitySitemapTargetGroup[];
        }
        interface SitemapDEPRECATED_Target {
            DEPRECATEDAnchor?: string;
            DEPRECATEDRunningAnchor?: boolean;
            DEPRECATEDTitle?: string;
            displaytitle?: string;
            /** optional, exclude to save space */
            score?: number;
            url?: string;
        }
        interface SmartphonePerDocData {
            /**
             * Indicates if the page is violating mobile ads density interstitial policy and the voilation strength. See go/interstitials-for-ads and http://ariane/268642 for details. To save
             * indexing space, we convert the double values in [0.0, 1.0] to intergers in range [0, 1000] by using floor(value * 1000).
             */
            adsDensityInterstitialViolationStrength?: number;
            /**
             * If set, this page is a smartphone dup, a page serving equivalent contents as another URL (desktop canonical), but in smartphone-optimized style. This field holds the docid of the
             * desktop canonical.
             */
            DEPRECATEDDesktopCanonicalDocid?: string;
            /** Mobile URL for homepages, predicted by the URL rewrite rules. See go/mobile-homepage-prediction. */
            DEPRECATEDMobileHomepageDocid?: string;
            /** Indicates if the page serves error to smartphone crawler. go/ramsey-sp404demotion */
            isErrorPage?: boolean;
            /** Indicates if the page has mobile N-1 redirection. go/ramsey-n1demotion */
            isN1Redirect?: boolean;
            /**
             * Indicates if the page is rendered in a friendly manner on smartphones. We use this field as tri-state: "unset" means the rendering result classification is not available, and "set
             * as false" means that the page is rendered in unfriendly manner on smartphones. See also go/modena-ranking.
             */
            isSmartphoneOptimized?: boolean;
            /** Indicates if the current URL serves error page to desktop crawler and non error page to smartphone crawler. */
            isWebErrorMobileContent?: boolean;
            /** The ratio of the area of the largest Flash to the render area. */
            maximumFlashRatio?: number;
            /** Mobile friendliness score in the range of [0, 100]. See go/modena-ranking. */
            mobileFriendlyScore?: number;
            /** Indicates if the page is violating mobile interstitial policy and should be demoted. See go/interstitials-ranking-dd for details. */
            violatesMobileInterstitialPolicy?: boolean;
        }
        interface SmearedWebLandingPageEntry {
            /** Source imagesearch docid */
            imagesearchDocid?: string;
            /** Docid of web landing page */
            webDocid?: string;
        }
        interface SnapshotBox {
            height?: number;
            width?: number;
            x?: number;
            y?: number;
        }
        interface SnapshotImageNode {
            boundingBox?: SnapshotBox;
            /**
             * An image is considered external iff both: 1. The image appears in a link that is not in the same org as the document, or the target URL is in a different org. 2. The image src is
             * not in the same org as the document.
             */
            isExternal?: boolean;
            /** The absolute url of the image as present in the page. */
            url?: string;
        }
        interface SnapshotSnapshotDocument {
            imageNode?: SnapshotImageNode[];
            metaNoPreview?: boolean;
            /** These are set from tags in the web page: */
            metaNoSnippet?: boolean;
            /** If this is present it supercedes all the above data. */
            teradoc?: TeragoogleDocumentInfo;
            textNode?: SnapshotTextNode[];
            title?: string;
        }
        interface SnapshotSnapshotMetadata {
            /**
             * The number of distinct resources fetched to render the content. This may aid the calculation of total page load time for user experience. For example, if total_content_length is
             * only a few dozen kilobytes, but that is from fetching 100 distinct resources, total page load time might be much higher than the total_content_length would otherwise infer.
             */
            countDistinctResources?: number;
            /**
             * The time at which the main resource of the Snapshot was fetched, in seconds since epoch. Note that the various page dependencies may have been fetched at much earlier points in time
             * (hours, maybe days) and that this could be off from the actual rendering time.
             */
            crawlTimestamp?: string;
            snapshotDocument?: SnapshotSnapshotDocument;
            /** The score here corresponds to the score in Snapshot, a number between 0.0 and 1.0 (higher the better). */
            snapshotQualityScore?: number;
            /**
             * Number of bytes fetched to render the content. For example, to render a web page, this value would include the HTML, stylesheets, images, and all other dependencies. This can be
             * used to calculate a coarse estimate of the total page load time a user might experience.
             */
            totalContentSize?: string;
        }
        interface SnapshotTextNode {
            boundingBox?: SnapshotBox;
            fontSize?: number;
            /** One if the current text node is within a link; otherwise zero/not present. */
            inLink?: number;
            /** A value in the range [0,7] (zero if not present) indicating the most "powerful" splitting tag since the last text node. See "enum Category" in mustang/snippets/taginfo.h. */
            maxSplit?: number;
            text?: string;
        }
        interface SnippetExtraInfo {
            /** Candidates are ordered by their id. */
            candidateInfo?: SnippetExtraInfoSnippetCandidateInfo[];
            /** Indicates that the snippet candidates all contain uesr quotes. */
            containUserQuotes?: boolean;
            /** Indicates if there are any vulgar snippet candidates. */
            containVulgarCandidates?: boolean;
            /** Indicates whether the query relevance features is disabled or not in Muppet scoring. */
            disableQueryFeatures?: boolean;
            /** Snippet candidate index selected by snippet brain model. This field will get populated in SnippetFlow in superroot. go/snippets-brain */
            snippetBrainSelectedCandidateIndex?: number;
            /** SnippetsBrain model information for snippets popup debug. */
            snippetsbrainModelInfo?: SnippetExtraInfoSnippetsBrainModelInfo;
        }
        interface SnippetExtraInfoSnippetCandidateInfo {
            /** Bolded ranges in the printed snippet lines. */
            boldedRanges?: QualitySnippetsTruncationSnippetBoldedRange[];
            /**
             * Candidate identifier number, unique among all snippet candidates under each document in each request. What does this number mean: - Muppet candidates: This equals to the candidate's
             * rank by Muppet snippets scorer. - Superroot candidates: No specific meaning, this number should be larger than that of Muppet candidates. This field is used to: - Verify whether
             * snippet brain chooses a different snippet from Muppet (the one chosen by Muppet is always in id 0). - Print debugging information and sort candidates in debug output.
             */
            id?: number;
            /** If this snippet is chosen by Muppet. */
            isMuppetSelectedSnippet?: boolean;
            /** If SnippetsBrain bolding model triggered and a bolding span is generated. */
            isSnippetBrainBoldingTriggered?: boolean;
            /** List information for this candidate, only populated for RADISH_LIST snippets. */
            listInfo?: MustangReposWwwSnippetsOrganicListSnippetResponse;
            scoringInfo?: SnippetExtraInfoSnippetScoringInfo;
            /** Muppet fills snippet lines in `snippet` field. */
            snippet?: string[];
            /** `snippet_text` will be filled by snippet brain flow in SR for model scoring and debugging purpose. */
            snippetText?: string;
            snippetType?: string;
        }
        interface SnippetExtraInfoSnippetsBrainModelInfo {
            ng3ModelName?: string;
            /** The below fields are populated by SnippetFlow in superroot. */
            snippetsbrainModelName?: string;
            snippetsbrainModelPartition?: string;
            snippetsbrainTokenizerType?: string;
        }
        interface SnippetExtraInfoSnippetScoringInfo {
            brainNg3Score?: number;
            /** The below fields are populated by SnippetFlow in superroot. Score generated from snippet brain model. go/snippets-brain */
            brainScore?: number;
            /** Snippets ranklab features generated by scorer V2. */
            features?: QualityPreviewRanklabSnippet;
            /** Final snippet score by chooser. */
            finalScore?: number;
            /** Final rank given by SnippetFlow. */
            rankBySnippetFlow?: number;
        }
        interface SnippetsLeadingtextLeadingTextAnnotation {
            piece?: SnippetsLeadingtextLeadingTextAnnotationPiece[];
            pieceType?: string;
            /** Type of this leading text. Should be an enum of LeadingTextInfo.LeadingTextType */
            type?: number;
        }
        interface SnippetsLeadingtextLeadingTextAnnotationPiece {
            /**
             * A piece of leading text is text within [begin, end). For example, a document is "ABCDEF". If we want to set leading text as 'CD', the value of begin is byte offset of 'C', the value
             * of end is byte offset of 'E'. end == -1 means to the end of document.
             */
            begin?: number;
            /** UTF8 text, for alignment when using reusableinfo. Those text are not available in docjoins. */
            beginText?: string;
            end?: number;
            endText?: string;
            /** Matched dom path string for debugging. */
            matchedPattern?: string;
        }
        interface SnippetsLeadingtextLeadingTextInfo {
            /** Leading text start position, byte offset of page content. The offset is got in ParseMaster. So it is the offset after the content is converted to UTF8. */
            beginPos?: number;
            /** Note: You can also use it to save multiple leading text candidates. */
            leadingtext?: SnippetsLeadingtextLeadingTextAnnotation[];
            /** UTF8 text, for alignment when using reusableinfo. The text is not available in docjoins. */
            text?: string;
            /** Type of leading text which is optimized for this type of document. */
            type?: string;
        }
        interface SocialCommonAttachmentAttachment {
            /** An embed represents an external entity. See go/es-embeds. */
            embedItem?: EmbedsEmbedClientItem;
            /** An id to uniquely identify an attachment when several attachments are in a collection. */
            id?: string;
        }
        interface SocialCommonFormatting {
            bold?: boolean;
            /** This indicates that the segment should be rendered as highlighted or visually emphasized. */
            highlight?: boolean;
            italics?: boolean;
            strikethrough?: boolean;
            /**
             * If set, this indicates that the segment should be rendered with the specified style. The absence of an explicit style represents "no style", i.e. the segment can be rendered with
             * the default style chosen by the application.
             */
            style?: string;
            underline?: boolean;
        }
        interface SocialCommonHashtagData {
            searchText?: string;
        }
        interface SocialCommonLinkData {
            /**
             * An Attachment represents the structured entity to which we are linking. It contains an Embed (apps/tacotown/proto/embeds/embed_client.proto) with fields specific to the appropriate
             * type of linked entity. For example, if we are linking to a photo album, the Embed may include the album ID and gaia ID of the creator. Clients that understand the Embed type within
             * the Attachment may construct and/or decorate their link appropriately e.g. to make use of type-specific functionality or first-party integrations. The link_target and (if
             * appropriate) display_url fields must still be set even when an Attachment is present, so that clients who do not know how to interpret the Attachment can fall back to those fields,
             * and render the Segment as an ordinary web link. N.B. Even when an Attachment is present, the intention of a "LINK" Segment is for the Segment to be presented inline with the rest of
             * the text of a post or comment, with a clickable link or other UI suitable for inlining (though the client may modify the UI based on Attachment data, e.g. to add appropriate hovers,
             * icons, etc.). When an entity is intended to be rendered separately from the main body of the post/comment, a separate Attachment proto can be added outside the set of Segments. N.B.
             * Within the Attachment, fields of EmbedClientItem have their own visibility annotations, which should be enforced separately from Segment visibility annotations. See:
             * apps/tacotown/proto/embeds/embed_annotations.proto
             */
            attachment?: SocialCommonAttachmentAttachment;
            /** The hint to use when rendering the associated attachment. Ignored if there is no associated attachment. */
            attachmentRenderHint?: string;
            /**
             * If we wish to show the user a different (e.g. shortened) version of the URL for display purposes, then that version should be set here. If this field isn't set, link_target will be
             * used for both purposes.
             */
            displayUrl?: string;
            /** link_target is the URL to navigate to when clicked. This could be the original URL, or a URL signed by the GWS URL signing service. */
            linkTarget?: string;
            /**
             * LinkType is an optional field that provides additional information regarding link target. For example, link type can be identified as the SELF_LINK when the request was executed
             * from the same link as the link target.
             */
            linkType?: string;
            /**
             * Title is an optional field that provides a short string that describes the link or its destination. User interfaces often use title as a tooltip or for accessibility purposes.
             * However, they are of course free to present this data in any form. This field is plain text.
             */
            title?: string;
        }
        interface SocialCommonSegment {
            /** Formatting to be applied when rendering the Segment. For all segment types, this is the standard way of representing that the Segment should be rendered in bold, italics, etc. */
            formatting?: SocialCommonFormatting;
            /** For HASHTAG type: */
            hashtagData?: SocialCommonHashtagData;
            /** Type-specific metadata. At most one of these should be populated, and the one that is populated should correspond to the type of the Segment. For LINK type: */
            linkData?: SocialCommonLinkData;
            /**
             * Text content of the Segment. As a general rule, this field should contain the actual text that should be rendered in the UI. Thus, for a hashtag, it should be "#Foo", and for a
             * link, it should be the display text. Clients that do not understand a particular segment type may use this text, along with the Formatting info below, as a fallback for display. The
             * field is not required -- if all relevant information is carried in other metadata fields and there is no need for a fallback, or it is not practical for a fallback to be provided
             * for any other reason, the field may be left blank. A standard example would be a user reference being transmitted between server layers, where a gaia-ID representation may be
             * sufficient and there is no need for a textual fallback. In such a case, it would be valid and useful - though not required - for servers to compute and populate a fallback on the
             * serving path.
             */
            text?: string;
            /** Type of Segment. */
            type?: string;
            /** For USER_MENTION type: */
            userMentionData?: SocialCommonUserMentionData;
        }
        interface SocialCommonSegments {
            segments?: SocialCommonSegment[];
        }
        interface SocialCommonUserMentionData {
            email?: string;
            /** If the principal is backed by a gaia id, DO NOT use this field. Use user_gaia_id/user_id fields instead. */
            user?: SecurityCredentialsPrincipalProto;
            /** An unobfuscated gaia ID: */
            userGaiaId?: string;
            /** An obfuscated gaia ID: */
            userId?: string;
        }
        interface SocialDiscoveryExternalEntityKey {
            email?: string;
            phone?: string;
            /** Obfuscated GAIA id. */
            profileId?: string;
        }
        interface SocialGraphApiAppContactData {
            /**
             * Set of column-name and value for the given mimetype. The semantic meaning of the column values is mime-type specific. For example they may contain app_specific_endpoint_ids for
             * WhatsApp. This is uploaded from CP2 http://go/cp2-data1 through http://go/cp2-data14.
             */
            data?: SocialGraphApiDataColumn[];
            /** The mimetype of the action defined by the third-party app. */
            mimetype?: string;
        }
        interface SocialGraphApiDataColumn {
            /** The name of the column in CP2 for raw_contact_data. */
            columnName?: string;
            /** The value of the data inside column. */
            value?: string;
        }
        interface SocialGraphApiProtoAndroidDeviceInfo {
            /** This string will represent either the device make and model in the case of FSA2, or the device model in the case of FSA1. */
            id?: string;
        }
        interface SocialGraphApiProtoBirthdayDecoration {
            birthdayDecorationVisibility?: string;
        }
        interface SocialGraphApiProtoContactCreateContext {
            mutationContext?: SocialGraphApiProtoContactMutationContext;
        }
        interface SocialGraphApiProtoContactDeletionContext {
            /** The general mutation context data */
            mutationContext?: SocialGraphApiProtoContactMutationContext;
        }
        interface SocialGraphApiProtoContactEditContext {
            mutationContext?: SocialGraphApiProtoContactMutationContext;
        }
        interface SocialGraphApiProtoContactMutationContext {
            /** Android device info should always be set when using either ANDROID_FSA1 or ANDROID_FSA2 as the source of the delete. */
            androidDeviceInfo?: SocialGraphApiProtoAndroidDeviceInfo;
            /** Host app info should always be set when using CONTACTS_COMPANION as the source. */
            hostAppInfo?: SocialGraphApiProtoHostAppInfo;
            /**
             * The source of a mutate should provide all needed information a user should know, and should be enough information for the front end to generate a proper human readable string to
             * describe the mutate to the user.
             */
            source?: string;
            /** Third party info should always be set when using THIRD_PARTY as the source. */
            thirdPartyInfo?: SocialGraphApiProtoThirdPartyInfo;
            /**
             * Timestamp representing when the contact was mutated. This should not be set on write, as it is the job of focus backend to determine this timestamp. This field will be populated on
             * read with the data written by FBS.
             */
            timestamp?: string;
        }
        interface SocialGraphApiProtoContactPromptSettings {
            /** Indicates if any reminders are active for entire contact. This will affect both connection reminders and date reminders such as birthday reminders. This is required. */
            contactActiveState?: string;
        }
        interface SocialGraphApiProtoContactState {
            /** A trashed contact may have deletion context set, which indicates where and when the contact was trashed. Deletion context is cleared when the contact is untrashed. */
            deletionContext?: SocialGraphApiProtoContactDeletionContext;
            deletionState?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface SocialGraphApiProtoDailyRecurrence {
        }
        interface SocialGraphApiProtoDelegatedGroupId {
            /** Required. The id for a delegated group. */
            id?: string;
        }
        interface SocialGraphApiProtoDisplayNameSource {
            source?: string;
        }
        interface SocialGraphApiProtoHostAppInfo {
            /** This string will represent the info for the host app to the Companion sidebar */
            hostAppName?: string;
        }
        interface SocialGraphApiProtoLimitedProfileNameSettings {
            /**
             * Required. Describes which shortening option the user implicitly chose for their limited profile. E.g., if 'John Doe' chose 'John D.', they implicitly chose: partial_name_options {
             * given_name_spec { show_all: true } family_name_spec: { show_initial: true truncation_indicator: PERIOD } } While we'll in all cases serve the actual name chosen by the user for
             * limited profiles (stored below), we'll use this information to recompute the default limited profile to be rendered to users when they change their core name.
             */
            partialNameOptions?: SocialGraphApiProtoPartialNameOptions;
            /**
             * The actual textual name that was chosen by the user in the UI. E.g., if 'John Doe' chose 'John D.', this holds 'John D.'. While `partial_name_options` allows the limited profile
             * name to be computed from the core name, the resulting shortened name might change across different versions of the name shortening logic, and we want to preserve the user's choice
             * verbatim whenever possible. This field will be cleared when the two conditions below are met: (1) A successful core name change is not accompanied by a limited profile settings
             * update and (2) The shortened name computed from `partial_name_options` yields a different result than what is originally stored in `verbatim_full_name`. When this happens, the
             * limited profile is effectively *disabled*. E.g., if 'John Doe' from the example above changes their name to 'Jane Doe' and no LimitedProfileSettings are provided, `Jane D.` is the
             * resulting shortened name. Therefore `verbatim_full_name` will be cleared and the limited profile settings will be disabled. On the other hand, if they change their name to `John
             * Dõe`, the resulting shortened name remains `John D.`, and `verbatim_full_name` is kept as is.
             */
            verbatimFullName?: string;
        }
        interface SocialGraphApiProtoLimitedProfilePictureSettings {
            profilePictureOption?: string;
        }
        interface SocialGraphApiProtoLimitedProfileSettings {
            /**
             * Indicates why the limited profile has been disabled. Will be set iff the limited profile is disabled. This field can only be set server-side and must not be used by external clients
             * when mutating LimitedProfiles.
             */
            disableReason?: string;
            /** Created with user input in GPay OOBE. */
            gpayOobe?: boolean;
            /** Timestamp indicating when the settings were last stored. Read-only field. */
            lastUpdateTime?: string;
            /** A user who had legacy discoverability had a Limited Profile autogenerated for them, either through a healer or in the live path in FBS. */
            legacyDiscoverability?: string;
            /** Created with user input in MyAccount UI. */
            myAccount?: boolean;
            /** Required. Defines how the name should be formatted in the limited profile. */
            nameSettings?: SocialGraphApiProtoLimitedProfileNameSettings;
            /** DEPRECATED. Profile picture choices are controlled through the ACL of the Photo field. */
            profilePictureSettings?: SocialGraphApiProtoLimitedProfilePictureSettings;
        }
        interface SocialGraphApiProtoMonthlyDayRecurrence {
            /**
             * Absolute day of the month (if positive) or relative day from the end of the month (if negative). Example: 2nd and 20th of the month [2, 20]. Example: Last day of the month [-1].
             * Positive values should correspond to actual calendar day number (indexing starts at 1).
             */
            monthDay?: number[];
            /** If true, month_day beyond the end of month (i.e. month_day=31 in February) will default to the last day of the month. */
            useLastDayIfMonthDayPastEnd?: boolean;
        }
        interface SocialGraphApiProtoMonthlyRecurrence {
            monthlyDayRecurrence?: SocialGraphApiProtoMonthlyDayRecurrence;
            monthlyWeekdayRecurrence?: SocialGraphApiProtoMonthlyWeekdayRecurrence;
        }
        interface SocialGraphApiProtoMonthlyWeekdayRecurrence {
            /** The nth occurrence of week_day to match. I.e. For 3rd Wednesday of the month, week_day = WEDNESDAY and week_day_number = 3. Values beyond the end of the month are skipped. */
            weekDay?: string;
            weekDayNumber?: number;
        }
        interface SocialGraphApiProtoNotificationTrigger {
            /** Positive number of days before active date. The value 0 will denote a notification on the same day. */
            daysBeforeActiveDate?: number;
            /** Time of day that notification is sent to user. This is local to the user's device. */
            notificationTimeOfDay?: GoogleTypeTimeOfDay;
        }
        interface SocialGraphApiProtoPartialNameOptions {
            /**
             * IETF BCP-47 language code that should be used for localizing the name computation (go/bcp-47). If not provided, we'll use the name origin detector to infer it. If unable to detect,
             * "en" will be assumed.
             */
            language?: string;
            parsedDisplayNameSpec?: SocialGraphApiProtoPartialNameOptionsParsedDisplayNameSpec;
            twoPartNameSpec?: SocialGraphApiProtoPartialNameOptionsTwoPartNameSpec;
        }
        interface SocialGraphApiProtoPartialNameOptionsNamePartSpec {
            /** Completely omit that part of the name. */
            hideAll?: boolean;
            /**
             * Show the complete name. Note that this does not express the same semantics as show_first_n_chars=length_of_name, because when regenerating a shortened name the new name could have
             * more characters, thus yielding a different result.
             */
            showAll?: boolean;
            /** Show first `n` characters. Same note about characters referring to "grapheme_clusters" applies. */
            showFirstNChars?: number;
            /** Show only the initial, i.e., a single character. Note that "character" refers to "user-perceived" characters, aka a "grapheme cluster". See go/morphology for more details. */
            showInitial?: boolean;
            /** Which truncation indicator to use after the shortened piece of the name. Will be ignored for the `hide_all` or `show_all` options. */
            truncationIndicator?: string;
        }
        interface SocialGraphApiProtoPartialNameOptionsParsedDisplayNameSpec {
            /** Extract an initial from each parsed name. For example, "Niels Henrik David Bohr" yields "N. H. D. B.". Other special cases are treated as follows: */
            allInitialsFromParsedName?: boolean;
            /** Show the initial of the very first name and the first last name, e.g. "Hugo Daniel Hernandez Garcia" yields "H. Hernandez". */
            firstInitialAndFirstLastName?: boolean;
            /** Show the initial of the very first name and the very last name, e.g. "Ana Maria Silva" yields "A. Silva". */
            firstInitialAndVeryLastName?: boolean;
            /** Shorten the display name using the Knowledge Graph name shortener (go/short-names). */
            knowledgeGraphNameShortening?: boolean;
            /** Which truncation indicator to use after each shortened part of the name. Will be ignored for the `knowledge_graph_name_shortening` option. */
            truncationIndicator?: string;
            /** Show the full very first name and all the other initials, e.g. "Ana Maria Silva" yields "Ana M. S.". */
            veryFirstNameAndAllInitials?: boolean;
            /** Show the very first name only, e.g. "Ana Maria Silva" yields "Ana". */
            veryFirstNameOnly?: boolean;
        }
        interface SocialGraphApiProtoPartialNameOptionsTwoPartNameSpec {
            familyNameSpec?: SocialGraphApiProtoPartialNameOptionsNamePartSpec;
            givenNameSpec?: SocialGraphApiProtoPartialNameOptionsNamePartSpec;
        }
        interface SocialGraphApiProtoPrompt {
            /** Indicates if this prompt is active regardless of its reccurrence date, dismiss date or notification triggers. This is required. */
            activeState?: string;
            content?: SocialGraphApiProtoPromptContent;
            /** The most recent day the user dismissed this prompt. Empty means the user has never dismissed the prompt. */
            lastDismissDate?: GoogleTypeDate;
            /**
             * If this is empty, only the "Prompt Spark" will be displayed (in the time-range read from per type config), no push notifications will be shown. If push notification are configured
             * with this field, the "Prompt Spark" time-range will be determined by earliest notification value here.
             */
            notificationTriggers?: SocialGraphApiProtoNotificationTrigger[];
            /** Read-only. This is derived from the containing field value. */
            purpose?: string;
            /** How frequently will this prompt occur and how many times. */
            recurrence?: SocialGraphApiProtoRecurrence;
            /** Prompt ID is generated by server on initial mutate. */
            uniquePromptId?: string;
        }
        interface SocialGraphApiProtoPromptContent {
            /** Title of prompt/spark being sent. */
            title?: string;
        }
        interface SocialGraphApiProtoPronounData {
            pronounEntry?: SocialGraphApiProtoPronounEntry[];
        }
        interface SocialGraphApiProtoPronounEntry {
            /** Locale option in which the pronouns were set, in the BCP-47 format. Set by the client at write time. */
            languageCode?: string;
            /** The pronoun entry type that the user has selected. This indicates which locale-independent classification of pronoun was selected (or optionally, if it is a custom field). */
            pronounType?: string;
            /**
             * The user's preferred pronouns. Eg. "they / them". This is a human-readable string to be displayed as the user's pronoun. Set at write-time, regardless of pronoun-type. Value is
             * returned as it was set (no localization).
             */
            value?: string;
        }
        interface SocialGraphApiProtoPronunciation {
            /** All pronunciations with the same learning_session_id were learnt in the same learning flow, e.g. multiple name segments learnt simultaneously from a recording in the Your People UI. */
            learningSessionId?: string;
            learningSource?: string;
            /** The locale used when learning the pronunciation. BCP-47 language code, e.g. "en-US". */
            locale?: string;
            /**
             * Phoneme sequence representing how the user pronounces |token|. Format is specified by the phonology_type type field, e.g. go/psampa is the preferred phonology type used by the TTS
             * team.
             */
            phonemes?: string;
            phonologyType?: string;
            /** An optional user-specified spelling of this token, to improve pronunciation learning success rate. E.g. the token may be "Jana" and the spelling hint "jah-nah". */
            spellingHint?: string;
            /**
             * Corresponds to a word segment of the contact name. E.g. for a contact with given name "John Doe", last name "Smith" and nickname "Best Dad", |token| can be any of {John, Doe, Smith,
             * Best, Dad}.
             */
            token?: string;
        }
        interface SocialGraphApiProtoPronunciations {
            pronunciation?: SocialGraphApiProtoPronunciation[];
        }
        interface SocialGraphApiProtoRecurrence {
            dailyRecurrence?: any;
            /**
             * Multiplier on the frequency of the recurrence. Use this to specify patterns that recur every X days, months, years, etc. Must be a positive int. Example: [remind me to call mom
             * every 2nd week]. If this field isn't set, it will default to 1 (every day,every week, etc). This field is ignored when recurrence_data is a SingleRecurrence. Optional.
             */
            every?: number;
            monthlyRecurrence?: SocialGraphApiProtoMonthlyRecurrence;
            /** Ends at abstract DateTime. (inclusive) */
            recurrenceEndDate?: GoogleTypeDateTime;
            /** The start of the recurrence can be represented as a DateTime. This field is ignored when recurrence_data is a SingleRecurrence. */
            recurrenceStart?: GoogleTypeDateTime;
            /**
             * Will repeat only a finite number of times. This is the original number of times the recurrence will repeat and not how many times are left for it to repeat. This end type is not
             * currently supported.
             */
            repeatCount?: number;
            /** Will continue to repeat until prompt is deleted. */
            repeatForever?: any;
            singleRecurrence?: SocialGraphApiProtoSingleRecurrence;
            weeklyRecurrence?: SocialGraphApiProtoWeeklyRecurrence;
            yearlyRecurrence?: SocialGraphApiProtoYearlyRecurrence;
        }
        // tslint:disable-next-line:no-empty-interface
        interface SocialGraphApiProtoRecurrenceRepeatForever {
        }
        interface SocialGraphApiProtoSearchProfileData {
            /** A free-text summary that the user inputs. E.g. "Coder by day, jazz guitarist by night." */
            description?: string;
            education?: SocialGraphApiProtoSearchProfileEducation[];
            interest?: SocialGraphApiProtoSearchProfileEntity[];
            /** Indicates the language of this search profile. Use ISO-639 2-letter language code to specifying the language that this profile is created in. */
            language?: string;
            location?: SocialGraphApiProtoSearchProfileLocation[];
            metadata?: SocialGraphApiProtoSearchProfileMetadata;
            occupation?: SocialGraphApiProtoSearchProfileEntity[];
            /** This is the email that the user has chosen to display on their "SearchCard" publicly. */
            publicEmail?: string[];
            /** This is the phone number that the user has chosen to display on their "SearchCard" publicly. */
            publicPhoneNumber?: string[];
            socialLink?: SocialGraphApiProtoSearchProfileSocialLink[];
            website?: string[];
            workplace?: SocialGraphApiProtoSearchProfileWorkplace[];
        }
        interface SocialGraphApiProtoSearchProfileEducation {
            endTime?: GoogleTypeDate;
            fieldOfStudy?: SocialGraphApiProtoSearchProfileEntity[];
            institution?: SocialGraphApiProtoSearchProfileEntity;
            startTime?: GoogleTypeDate;
        }
        interface SocialGraphApiProtoSearchProfileEntity {
            /** Corresponding country code. Refer to go/people-search-dashboard for code list. */
            countryCode?: string;
            /** Corresponding mid in KG. */
            entity?: string;
            /** Custom name of entity if there is no corresponding place/entity in KG (mid) */
            name?: string[];
        }
        interface SocialGraphApiProtoSearchProfileLocation {
            endTime?: GoogleTypeDate;
            lengthOfStay?: string;
            place?: SocialGraphApiProtoSearchProfileEntity;
            point?: SocialGraphApiProtoSearchProfileLocationInfo;
            startTime?: GoogleTypeDate;
            type?: string;
        }
        interface SocialGraphApiProtoSearchProfileLocationInfo {
            /** Degrees [-90 .. 90] */
            lat?: number;
            /** Degrees [-180 .. 180] */
            lon?: number;
            /** Meters */
            radius?: number;
        }
        interface SocialGraphApiProtoSearchProfileMetadata {
            /**
             * Unique contributor account id allocated by presence/janata infrastructure. This will be used in the frontend for various actions like reporting errors, photo uploads etc.,
             * go/boba-janata, go/cleanup-contributor-creation
             */
            accountId?: string;
            /**
             * Account KG entity mid assigned to this user required by old janata serving stack. This is not required anymore for serving. But might need it for historical purposes. See
             * https://hume.google.com/edit/g/11gg6cyvch for more details.
             */
            accountMid?: string;
            /** Ares id used for tracking the auto moderation. */
            aresId?: string;
            /** Current state of the Search Profile. */
            state?: SocialGraphApiProtoSearchProfileState[];
        }
        interface SocialGraphApiProtoSearchProfileSocialLink {
            link?: string;
            type?: string;
        }
        interface SocialGraphApiProtoSearchProfileState {
            /** Timestamp of when the state was changed. */
            changeTimestamp?: string;
            /** This will be used to display status to the user at a set time. If set to a value after `change_timestamp`, the change will not be 'reflected' until this time. */
            displayTimestamp?: string;
            /** State that the UserProfile was changed to. */
            type?: string;
        }
        interface SocialGraphApiProtoSearchProfileWorkplace {
            company?: SocialGraphApiProtoSearchProfileEntity;
            endTime?: GoogleTypeDate;
            startTime?: GoogleTypeDate;
        }
        interface SocialGraphApiProtoSingleRecurrence {
            date?: GoogleTypeDate;
        }
        interface SocialGraphApiProtoSyncInfo {
            /** CP2 sourceid column. */
            sourceId?: string;
            /** CP2 sync1 column. */
            sync1?: string;
            /** CP2 sync2 column. */
            sync2?: string;
            /** CP2 sync3 column. */
            sync3?: string;
            /** CP2 sync4 column. */
            sync4?: string;
        }
        interface SocialGraphApiProtoThirdPartyInfo {
            /** Not to be used. We have since moved to a lookup string at read time approach as opposed to storing data at write time. b/146072927 */
            clientName?: string;
            /**
             * Project number of the third party application performing the delete to be looked up via ClientAuthConfig during display time for users to know the current name of an application
             * which has deleted contact data.
             */
            projectNumber?: string;
        }
        interface SocialGraphApiProtoUsageInfo {
            /** Last time a contact was contacted. */
            lastTimeContacted?: string;
            /** Number of times a contact was contacted. */
            timesContacted?: string;
        }
        interface SocialGraphApiProtoWeeklyRecurrence {
            /** Set of weekdays the recurrence applies to. */
            weekDay?: string[];
        }
        interface SocialGraphApiProtoYearlyRecurrence {
            /** The monthly pattern to recur. */
            monthlyPattern?: SocialGraphApiProtoMonthlyRecurrence;
            /** The months of the year to apply the pattern. */
            months?: string[];
        }
        interface SocialGraphWireProtoPeopleapiAffinityMetadata {
            /** Information regarding client interactions. */
            clientInteractionInfo?: SocialGraphWireProtoPeopleapiAffinityMetadataClientInteractionInfo;
            /** Device information about the candidate available in the cloud. */
            cloudDeviceDataInfo?: SocialGraphWireProtoPeopleapiAffinityMetadataCloudDeviceDataInfo;
            /** Affinity score for the cloud contact. */
            cloudScore?: number;
        }
        interface SocialGraphWireProtoPeopleapiAffinityMetadataClientInteractionInfo {
            /** Whether this suggestion is an edge directly from the client. E.g., a suggestion with which the user shared a photo on photos app. */
            isDirectClientInteraction?: boolean;
        }
        interface SocialGraphWireProtoPeopleapiAffinityMetadataCloudDeviceDataInfo {
            /** The partial affinity score only counting device features. */
            deviceScore?: number;
            /** Whether device data about this candidate were available in the cloud. */
            isDeviceDataKnown?: boolean;
        }
        interface SocialGraphWireProtoPeopleapiExtensionAppsWaldoExtendedData {
            availabilities?: GoogleInternalAppsWaldoV1alphaUserAvailabilities;
        }
        interface SocialGraphWireProtoPeopleapiExtensionDynamiteExtendedData {
            /** Avatar image URL for a Google Group, based on the member count. */
            avatarUrl?: string;
            /** Short description of this bot. Only set if EntityType == BOT. */
            description?: string;
            /** Display name of bot developer. Only set if EntityType == BOT. */
            developerName?: string;
            dndState?: string;
            entityType?: string;
            /** Number of members (direct or indirect) in a Google Group. Only an estimate for large groups (currently > 1K direct / indirect members). */
            memberCount?: string;
            /** NEXT TAG: 9 */
            organizationInfo?: AppsDynamiteSharedOrganizationInfo;
            presence?: string;
        }
        interface SocialGraphWireProtoPeopleapiExtensionPaisaExtendedData {
            /** Actor ID of the person, if available (if the person has used the Paisa app). */
            actorId?: string;
            /**
             * Display subtitle, which may be used in suggestion/autocompletion results. Generally, this will be the Actor's registered Paisa phone number, in unmasked or masked form (e.g. +1
             * ***-***-1234) depending on visibility rules.
             */
            subtitle?: string;
        }
        interface SocialGraphWireProtoPeopleapiExtensionPeopleStackExtendedData {
            /**
             * Whether the person is in the same family as the requesting user. Family here refers to https://families.google.com/families. This information is read from SuperGlue, and can be
             * consumed by clients, e.g. Assistant and Photos. If this field is not set, the person is not in the user's family.
             */
            familyStatus?: string;
            /**
             * The full list of hidden keys associated with this person. These are the external equivalent to the keys stored by the ConnectionLabelService, and they can be passed to the
             * MutateConnectionLabel endpoint to unhide this person. This field will only be set if hide_type is HIDDEN.
             */
            hiddenKeys?: SocialDiscoveryExternalEntityKey[];
            /** If this field is not set, the person is visible (implicit). */
            hideType?: string;
        }
        interface SocialGraphWireProtoPeopleapiExtensionPeopleStackPersonExtendedData {
            /** Whether the person has birthday field populated. */
            birthdayStatus?: string;
            /**
             * Whether the person is in the same family as the requesting user. Family here refers to https://families.google.com/families. This information is read from SuperGlue, and can be
             * consumed by clients, e.g. Assistant and Photos. If this field is not set, the person is not in the user's family.
             */
            familyStatus?: string;
            /**
             * The full list of hidden keys associated with this person. These are the external equivalent to the keys stored by the ConnectionLabelService, and they can be passed to the
             * MutateConnectionLabel endpoint to unhide this person. This field will only be set if hide_type is HIDDEN.
             */
            hiddenKeys?: SocialDiscoveryExternalEntityKey[];
            /** If this field is not set, the person is visible (implicit). */
            hideType?: string;
        }
        interface SocialPersonalizationKnexAnnotation {
            item?: SocialPersonalizationKnexAnnotationItem[];
        }
        interface SocialPersonalizationKnexAnnotationItem {
            confidence?: number;
            /** Description of the item for debugging. Note that this field is populated only in a few select places. */
            description?: string;
            /**
             * If this field exists, then there exists a commonly used MID (typically a public MID, i.e., one in /m/) that approximates the meaning for this particular k'nex topic. For example,
             * the value of this field for k'nex topic Tennis (/t/236) is /m/07bs0. The difference between k'nex /m/07bs0 and webref /m/07bs0 is as follows. If a content is annotated with webref
             * /m/07bs0, then the content has to explicitly mention "Tennis" in some way, whereas if a content is annotated with k'nex /m/07bs0, then the content simply needs to talk about stuff
             * related to tennis. Note that this field is not populated for all queries. For example, the compound concept "Tennis in California" does not have an associated mid. This field is
             * intended to help external clients transit to k'nex.
             */
            equivalentMid?: string;
            /**
             * A score that measures how broad / narrow a topic is, independent of the document and/or user profile. This is an experimental score and is not populated by default. Currently, it is
             * in the range of [0, 1], where the higher the score is, the more general a topic is. Please talk to sherlock-dev@ before using this score. Populated when debug_level > 0.
             */
            generality?: number;
            /** This is an MID in the /t/ namespace. We will migrate them to /g/ in Q3'15. */
            mid?: string;
            relatedEntity?: SocialPersonalizationKnexAnnotationItemTopic[];
            topicality?: number;
        }
        interface SocialPersonalizationKnexAnnotationItemTopic {
            mid?: string;
            score?: number;
        }
        interface SocialStanzaDeliveryRestriction {
            doNotPublish?: boolean;
        }
        interface SocialStanzaModerationInfo {
            /** The reason why this stanza was moderated provided by client. */
            moderationReason?: string;
            moderator?: SecurityCredentialsPrincipalProto;
            /**
             * Type of moderation. Semantically REQUIRED, http://go/required At write time, only ModeratorType.AUTO_MODERATOR is allowed. For all other cases, this information is inferred from the
             * request at write time.
             */
            moderatorType?: string;
        }
        interface SocialStanzaStanzaRestriction {
            /** The abuses. */
            abuseTypes?: AbuseiamAbuseType[];
            /** The appeal state. */
            appealState?: string;
            /**
             * Field to explain various restrictions of the Stanza. Some examples of restrictions are: - Not permitted because of legal restrictions of geography/country of viewer or creator. -
             * Content not suitable for current viewer i.e. porn, abusive, racy. - Creator restricted the content to an age group. - etc...
             */
            contentRestriction?: AbuseiamContentRestriction;
            /** Delete reasons. This is a repeated field because an stanza can be deleted multiple times due to different reasons such as user_delete, admin_delete. */
            deleteReason?: string[];
            /** Delivery restrictions, if present. */
            deliveryRestriction?: SocialStanzaDeliveryRestriction;
            destinationStream?: AppsPeopleActivityBackendDestinationStream;
            /**
             * The moderation info. At write time, this field is only allowed to be set when moderator_type is AUTO_MODERATOR. For other moderator types, moderation_reason is the only field that
             * can be set by clients.
             */
            moderationInfo?: SocialStanzaModerationInfo;
            /** The moderation state. */
            moderationState?: string;
        }
        interface SpamBrainData {
            /** Sitechunker site granularity for this result */
            site?: string;
            /** Versioned scores of SB classifiers */
            versionedData?: SpamBrainScore[];
        }
        interface SpamBrainScore {
            /** The value corresponding to this version. */
            sbScore?: number;
            /** The version id. */
            versionId?: number;
        }
        interface SpamCookbookAction {
            dropInServing?: boolean;
        }
        interface SpamMuppetjoinsMuppetSignals {
            hackedDateNautilus?: number;
            hackedDateRaiden?: number;
            raidenScore?: number;
            site?: string;
        }
        interface SpeechS3LanguageIdentificationResult {
            /**
             * The end time of the input audio that this result refers to. This value should increase across LanguageIdentificationResult emitted by the Greco server running LangId, and reflects
             * the server having processed more of the input audio.
             */
            endTimeUsec?: string;
            /** Ranked list of top-N language codes. Ranking is based on ConfidenceIntervals of supported languages, and N is defined in the LanguageIdentificationConfig. */
            rankedTopSupportedLanguages?: SpeechS3Locale[];
            /** Global start time. This value should be fixed across all LanguageIdentificationResults for a given utterance. */
            startTimeUsec?: string;
            /** Confidence interval of the top recognized language. */
            topLanguageConfidence?: string;
            /**
             * Identifies when the provided audio sample does or doesn't contain voiced samples. E.g. an unvoice utterance happens when the EOS signal is received before any frame because all
             * frames were filtered by the endpointer. For events where voiced_utterance is false, ranked_top_supported_languages is defined but scores are not to be trusted. All
             * LanguageIdentificationResults contains a valid value of voiced_utterance.
             */
            voicedUtterance?: boolean;
        }
        interface SpeechS3Locale {
            /** The format of the string in "locale". Should be one of LocaleFormat. */
            format?: number;
            locale?: string;
        }
        // tslint:disable-next-line:no-empty-interface
        interface StorageGraphBfgAuthorityFeedbackMetadata {
        }
        interface StorageGraphBfgLegalRequestMetadata {
            /** The buganizer ID associated with this legal request. This is required. */
            bugId?: string;
        }
        interface StorageGraphBfgLivegraphProvenanceMetadata {
            /** Identifies the LG internal writers that asserted the triple. This is the same as 'origin_id' in LG. This will only be populated by the LG writers to FactStore */
            lgInternalWriterId?: string;
            /**
             * Whether this provenance is a provenance only addition or not. A provenance is considered an "addition" if it belongs to a triple that we expect FactStore to contain on its own (i.e
             * through some inference), and thus we will *not* attempt to write it explicitly. This is a composer only populated field. Clients are not expected to populate this field.
             */
            provenanceOnlyAddition?: boolean;
            /**
             * Triples typically have a single triangulation key. This field supports > 1 keys to allow staged transition to a different key scheme. To successfully triangulate in the Livegraph
             * Composer, the triple must have >=3 instances and each triple instance having a pairwise disjoint set of triangulation keys. The triangulation keys supplied for a single input triple
             * are treated part of the same set, so a single triple cannot self-triangulate, regardless of how many triangulation keys it has. Note2: If a triple has multiple provenances, each one
             * is expected to set the same triangulation_keys.
             */
            triangulationKey?: string[];
            /**
             * WARNING! The feature is still under active development and the exact semantics may be subject to change pending KE Design Review. Data marked as weak will be less preferred to
             * regular data which does not have the marker. This allows ingesting data with a lower chance of negatively affecting existing features and products, at the cost of potentially not
             * showing the data when competing data is available. Specifically, weak data is less preferred by conflict resolution inside of Livegraph composition. Additionally, RefX triggering
             * will prefer to trigger based on signals computed from regular data. Aside from data providers choosing to mark their data as weak, Livegraph and RefX are the only horizontal systems
             * expected to use this information. Please contact livegraph-team@ if you see a need for this to change. See go/weak-data for more information.
             */
            weakData?: boolean;
        }
        interface StorageGraphBfgLmsPolicyMetadata {
            clientIdsAllowed?: string[];
            isEditorial?: boolean;
            /** Int values corresponds to the values of image_repository.licensed.api.restrictions.Modification enum. */
            modificationsAllowed?: string[];
            regionsAllowed?: KeGovernanceTypedRegions;
            regionsDisallowed?: KeGovernanceTypedRegions;
            requiresAttribution?: boolean;
            requiresFirstPartyOnly?: boolean;
            requiresLinkback?: boolean;
            requiresShareAlike?: boolean;
        }
        interface StorageGraphBfgPolicyMetadata {
            /** Timestamp after which data with this policy cannot be used. This value must be strictly larger/later than availability_start_time, if both are set. */
            availabilityEndTimestamp?: string;
            /** Timestamp before which data with this policy cannot be used. This value must be strictly smaller/earlier than availability_end_time, if both are set. */
            availabilityStartTimestamp?: string;
            /**
             * List of regions in which the data with this policy is allowed to be used, while the data need to be removed in all regions outside this list according to legal request. This field
             * should be used when the data is only allowed in a few regions and it is inconvenient to enumerate all of the regions in `legal_removal_regions` field. `legal_allowed_regions` and
             * `legal_removal_region` together should include all possible regions, setting one field implies the other. Please set only one of them so the other field's values are implied. See
             * details: http://go/ke-allowed-countries-policy-1p WARNING: This field is for legal purposes only. Please do not populate it without consulting ke-data-governance@.
             */
            legalAllowedRegions?: KeGovernanceTypedRegions[];
            /**
             * List of regions in which the data with this policy need to be removed according to legal request. WARNING: This field is for legal purposes only. Please do not populate it without
             * consulting ke-data-governance@.
             */
            legalRemovalRegions?: KeGovernanceTypedRegions[];
            /** Policy metadata fields for LMS data. Only expected to be used by LMS providers -- please consult ke-data-governance@ before populating this field. */
            lmsPolicyMetadata?: StorageGraphBfgLmsPolicyMetadata;
            /** Policy metadata are VERTICAL by default. Vertical policy makers / providers does not need to set this field explicitly. */
            policySourceType?: string;
            /** Policy metadata fields for UMP data. Only expected to be used by UMP providers -- please consult ke-data-governance@ before populating this field. */
            umpPolicyMetadata?: StorageGraphBfgUmpPolicyMetadata;
        }
        interface StorageGraphBfgPublicInformationMetadata {
            /** Publicly-visible URLs claiming this fact. Can not be empty -- at least one URL must be provided. */
            attributionUrl?: string[];
            /** Most recent date at which 'attribution_url's were verified, as UNIX epoch time in milliseconds. This is required. */
            lastVerifiedDate?: string;
        }
        interface StorageGraphBfgSpiiCertification {
            /** This fact was provided via KGO / Entity Authority. */
            authorityFeedback?: any;
            /** This fact was provided via a legal request. */
            legalRequest?: StorageGraphBfgLegalRequestMetadata;
            /**
             * This fact is public information. (See go/kg-spii-certification for a description of what qualifies as public information -- simply finding a fact online is not sufficient to certify
             * a fact as public.)
             */
            publicInformation?: StorageGraphBfgPublicInformationMetadata;
        }
        interface StorageGraphBfgTripleProvenance {
            /** Data providers shall use this to specify access requirement. */
            accessRequired?: string;
            /**
             * For KE internal use only. Data providers shall *not* set this. At ingress, LG Record service will read access_required and properly translate it to access_required_int. KE
             * horizontal systems shall use this field instead of access_required; so that binaries would not depend on the release of a newly introduced AccessRequirement enum.
             * (go/easy-ar-onboarding)
             */
            accessRequiredInt?: number;
            authoringTimestamp?: string;
            /** Freebase: the freebase user id in the form '/user/userid' KG: the Google LDAP of the developer or MDB group that set up the triplification and import pipeline for this data source. */
            creator?: string;
            /** Freebase & KG: the dataset the assertion was loaded from */
            dataset?: string;
            extractionPattern?: string;
            extractionTimestamp?: string;
            /** Below are deprecated Provenance fields. They are not indexed or served in KE infrastructure (they are stripped at ingress in Livegraph). */
            freebaseAttribution?: string;
            /**
             * Indicates that the corresponding data is supporting evidence for reconciliation only, and is *not* an assertion that should be visible to other systems or to external users. Note
             * that this also means that no provenances indicating supporting data will be visible in the composed graph. Please see go/supporting-kg-triples-design-doc for additional details and
             * background. If a triple is sent to Livegraph with multiple provenances each of them must have is_supporting_data bit set for it to be considered valid supporting evidence triple.
             */
            isSupportingData?: boolean;
            /**
             * Internal metadata used by Livegraph and possibly other horizontal KG infra systems. This is not part of the logical triple or its provenance, and contents may not be visible
             * downstream of LG.
             */
            lgMetadata?: StorageGraphBfgLivegraphProvenanceMetadata;
            /**
             * Metadata specifying data governance policies. This information will be processed and enforced in KE systems. For more context, see go/ke-triple-dg-policy-and-metadata. WARNING: This
             * field is WIP and please do not populate it without consulting ke-data-governance@.
             */
            policyMetadata?: StorageGraphBfgPolicyMetadata;
            /**
             * Used to uniquely identify data sources. Freebase: the OAuth application KG: the name of the source directory the triple was loaded from (eg, "amg", "tms ", "collections"). KV:
             * identifier of an extraction system, e.g., SAFT or Tractzor.
             */
            process?: string;
            provenanceExtension?: any;
            /**
             * 'ranking_token' (which must be accompanied by the 'process' field above or will be ignored) is used to distinguish subsets of data within a single process, solely for the purposes
             * of composition in Livegraph. This field is useful when partitioning of data is needed, but using a separate process is intractable due to organizational or infrastructure
             * limitations. For example, if a process such as "geo" wishes to distinguish some of their /type/object/name triples as higher priority in Composer's conflict resolution rules, then
             * they can add a config entry with a dedicated ranking_token and tag the relevant triples with that ranking_token. This field should only be used in conjunction with a Composer-side
             * configuration to use it for value selection. It is not appropriate to use this field as free-form metadata. This value must match [[:alnum:]][[:alnum:]_-]{0,127} (i.e.,
             * [a-zA-Z0-9]+[a-zA-Z0-9_-]* and must be less than 128 characters in length) , or else its containing triple will be considered malformed and will be rejected by Livegraph at ingress.
             * As of 2018-02-14, this field is used within Livegraph's Composer and is exposed in Livegraph's Lookup APIs to aid debugging, but it is not indexed or served by TopicServer.
             */
            rankingToken?: string;
            /**
             * When specified as part of triples input to Livegraph (go/livegraph), this indicates that the triple needs to be triangulated by 3 different sources before it can be served in
             * production. A triple's source is identified by its URL(provenance.source).host(). Please see go/baike-triangulation for more background on this. WARNING: If you're a new client
             * trying to enable triangulation for your feed, please contact lg-composition@/kashk@ before using this feature.
             */
            requiresTriangulation?: boolean;
            restrictions?: string[];
            /**
             * Freebase & KG: if the triples were extracted from the web, the source URL where the assertion was found. (generally empty in freebase-sourced triples) TopicServer will
             * serve/populate/retain if REQUIRES_CITATION is also set, or if the process is explicitly allowed. http://g/topic-server/vn9PBWtVKqI/arQEDqKTAgAJ
             */
            source?: string;
            sourceCategory?: string[];
            sourceDocId?: string[];
            spiiCertification?: StorageGraphBfgSpiiCertification;
        }
        interface StorageGraphBfgUmpPolicyMetadata {
            /** Timestamp after which data with this policy cannot be used. */
            availabilityEnds?: string;
            /** Timestamp before which data with this policy cannot be used. */
            availabilityStarts?: string;
            regionsAllowed?: KeGovernanceTypedRegions;
        }
        interface SuperrootPodcastsRecommendationsPodcastRecsFeatures {
            /** Average duration listened per episode. Ignores duration < 10s. Computed offline */
            averageDurationSecondsEpisode?: string;
            /** Average duration listened per show. Ignores duration < 10s. Computed offline */
            averageDurationSecondsShow?: string;
            /** Average fraction of podcast listened per episode. Ignores duration < 10s. Computed offline */
            averageFractionEpisode?: number;
            /** Average fraction of podcast listened per show. Ignores duration < 10s. Computed offline */
            averageFractionShow?: number;
            /** Per cluster lift where the lift_squashing_factor is set to 0.4 */
            balancedLift?: number;
            /** category_match is a 0 to 1 score depicting how much of the user's listening history matches the categories of this podcast recommendation. */
            categoryMatch?: number;
            /** The total minutes listened to this podcast show by users in this cluster */
            clusterFeedMinutes?: string;
            /** This captures the probability that this show could have been listened by the user in lieu of what they have subscribed or listened to. */
            colistenedShowColistenAffinity?: number;
            /** This captures the rank of the podcast show in the colisten candidate generator. */
            colistenedShowLevelRank?: string;
            convAiToxicitySevereScore?: number;
            /** Score of csai safe search score go/safesearch */
            csaiScore?: number;
            /**
             * Ordinal rank features like this have been found to be useful in Hermione Recipes, where the top ranked items from a candidate generator is always retained. Ranks are integral values
             * starting with 1 for the highest affinity show.
             */
            dnnShowLevelRank?: string;
            /** Dot product of user embedding and podcast show embedding from the two tower model v2a */
            dnnV2aScore?: number;
            /** Sigmoid of the score obtained by dot product of user embedding and show embedding. See https://b.corp.google.com/issues/158602034#comment2 for intuition. */
            dnnV2aScoreSigmoid?: number;
            /** Total duration listened for this episode by all users. Ignores duration < 10s. Computed offline */
            durationTotalSecondsEpisode?: string;
            /** Total duration listened for this show by all users. Ignores duration < 10s. Computed offline */
            durationTotalSecondsShow?: string;
            /**
             * The duration of a single episode, in seconds. - For show documents, this is a duration of a typical recent episode, or an approximation thereof. - For episode documents, this is the
             * duration of the episode itself.
             */
            episodeDurationSec?: string;
            /** Number of all episode impressions. */
            episodeImpressions?: string;
            /** Number of episode impressions during the past week. */
            episodeImpressionsPastWeek?: string;
            /** How frequently are podcasts published by this show. To see publishing frequency calculation go here: http://shortn/_6zzfyEpBRq */
            episodesPublishedPerMonth?: string;
            /** Whether the show is marked as explicit by the authors */
            explicitShow?: string;
            /** Scaled pagerank score for the feed url in [0..1]. Not to be confused with pagerank above, which measures the pagerank for the feed's homepage. */
            feedPagerank?: number;
            /**
             * final reaction boost score computed from positive_reaction_boost_score and negative_reaction_boost_score. The score will be applied as a multiplier on the ranking score to adjust
             * the ranking.
             */
            finalReactionBoostScore?: number;
            /** Some of all fraction of this listened by users. Ignores duration < 10s. Computed offline */
            fractionTotalEpisode?: number;
            /** Some of all fraction of this show listened by users. Ignores duration < 10s. Computed offline */
            fractionTotalShow?: number;
            /** Score of fringe safe search score go/safesearch */
            fringeScore?: number;
            /** Probability of a random user listening to this podcast randomly */
            globalProb?: number;
            /** Probability of a random user from this cluster listening to this podcast randomly (K-means specific feature) */
            inClusterProb?: number;
            /** A binary value based on whether this is a canonical source for a cluster. */
            isCanonical?: boolean;
            /** Ranks are integral values starting with 1 for the highest affinity show. */
            kmeansShowLevelRank?: string;
            /** How much of user listening history match the language of this episode */
            languageMatch?: number;
            /** Ownership verification status for the episode page URL. */
            linkOwnershipVerified?: boolean;
            /** The rank of the show in the top listened shows candidate generator. Ranks are integral values starting with 1 for the highest affinity show. */
            listenedShowLevelRank?: string;
            /** This captures the fraction of total listening time accounted for by this show. */
            listenedShowListeningAffinity?: number;
            /** Number of minutes of podcasts listened by the user */
            listenTimeMin?: number;
            /** Feature ID of a location. For more info, see go/feature-id. */
            locationFeatureId?: string;
            /** Match score between user listening mids and episode webref entities, where the listening can have happened at any time in the past. Values are in a 0.0 to 1.0 range. */
            longUserListeningWebrefSimilarity?: number;
            /** Score of medical safe search score go/safesearch */
            medicalScore?: number;
            /** Match score between user listening mids and episode webref entities, where the listening is limited to last two mohths activity. Values are in a 0.0 to 1.0 range. */
            mediumUserListeningWebrefSimilarity?: number;
            /**
             * boost score from the similarity between the candidate and the shows with user negative feedback, currently the score will be applied directly to the final ranking score:
             * go/podcast-reaction-reranking-v1, but can be used as reranker model feature in the future.
             */
            negativeReactionBoostScore?: number;
            /** Per cluster lift where the lift_squashing_factor is set to +2 */
            nicheLift?: number;
            /** The number of users in this k-means cluster. */
            numListenersInKmeansCluster?: string;
            /** The number of users in the k-means cluster who have listened to this feed. */
            numListenersToShowInKmeansCluster?: string;
            /** Number of podcasts listened by the user */
            numListens?: number;
            /** From: indexing/speech/proto/colisten-matrix.proto The number of subscribers for this podcast series. */
            numSubscribersShow?: string;
            /** From: indexing/speech/proto/colisten-matrix.proto Absolute number of unique listeners during the past month. */
            numUniqueListenersShow?: string;
            /** Score of offensive safe search score go/safesearch */
            offensiveScore?: number;
            peDurationScoreEpisode?: number;
            peDurationScoreShow?: number;
            peDurationTotalScoreEpisode?: number;
            peDurationTotalScoreShow?: number;
            peFractionScoreEpisode?: number;
            peFractionScoreShow?: number;
            peFractionTotalScoreEpisode?: number;
            peFractionTotalScoreShow?: number;
            peListenScoreEpisode?: number;
            /** Anima User Embedding based features. Dot product of Anima User Embedding and podcast embeddings from UserEmbeddingBasedSignals (podcasts/quality/proto/ranking_signals.proto) */
            peListenScoreShow?: number;
            peListenTotalScoreEpisode?: number;
            peListenTotalScoreShow?: number;
            /** Per cluster lift where the lift_squashing_factor is set to -3 */
            popularLift?: number;
            /** Score of porn safe search score go/safesearch */
            pornScore?: number;
            /**
             * boost score from the similarity between the candidate and the shows with user positive feedback, currently the score will be applied directly to the final ranking score:
             * go/podcast-reaction-reranking-v1, but can be used as reranker model feature in the future.
             */
            positiveReactionBoostScore?: number;
            /** This is the language extracted from the query_language. */
            queryLanguage?: string;
            /** The index in the list of most popular podcasts. */
            rank?: string;
            /**
             * rank_percent_contrib = 100 / ( 1 + rank_percent ) Here rank_percent was derived from show level data in Wernicke corpus So if rank_percent of a feed was 3, then the feature value
             * would be: 100 / (1 + 3) = 25. This indicator falls off quickly from 100 to almost 1 as we go from rank_percent 0 to 100.
             */
            rankPercentContrib?: number;
            /** Match score between user listening mids and episode webref entities, where the listening is limited to recent activity. Values are in a 0.0 to 1.0 range. */
            recentUserListeningWebrefSimilarity?: number;
            /**
             * A reranking feature showing the age of the episode that is being recommended. This is computed as (current time - publication_time) publication_time of the episode is defined:
             * (http://shortn/_S46Ouk5ZWW) publication_time is specified as seconds since Unix Epoch.
             */
            secondsSincePublication?: string;
            /** Base quality of the document, used as a multiplier for the query-specific score. Should be in [0, 1] range. See: http://g3doc/indexing/moonshine/generic/g3doc/doc/scoring */
            showBaseQuality?: number;
            /** Number of show episode impressions. */
            showImpressions?: string;
            /** Number of show impressions during the past week. */
            showImpressionsPastWeek?: string;
            /** Language of the show from show data. */
            showLanguage?: string;
            /** Show only impressions. Doesn't include shows of episode impressions. */
            showOnlyImpressions?: string;
            showOnlyImpressionsPastWeek?: string;
            /** Expresses the absolute popularity rank within all documents. */
            showPopularRank?: string;
            /** Score of spoof safe search score go/safesearch */
            spoofScore?: number;
            /** This captures the fraction of total listening time accounted for by this subscribed show. */
            subscribedShowListeningAffinity?: number;
            /** The rank of the show in the subscription candidate generator. Ranks are integral values starting with 1 for the highest subscribed affinity show. */
            subscriptionShowLevelRank?: string;
            surface?: string;
            /** Show level trending score percent from Wernicke corpus. */
            trendingScorePercent?: string;
            /** Inferred language preferences of the user with their probabilities. */
            ulpLanguage?: SuperrootPodcastsRecommendationsPodcastRecsFeaturesUserLanguage[];
            /** How much of ulp match the language of this episode */
            ulpLanguageMatch?: number;
            /** The distance between user's Anima embedding and the centroid of the cluster in k-means. */
            userClusterDistance?: number;
            /** Match score between user interest mids and episode salient entities. in a 0.0 to 1.0 range. */
            userInterestsSalientSimilarity?: number;
            /** Match score between user interest mids and episode webref entities. in a 0.0 to 1.0 range. */
            userInterestsWebrefSimilarity?: number;
            /** Language of shows in user history and how much they listened to each. */
            userLanguage?: SuperrootPodcastsRecommendationsPodcastRecsFeaturesUserLanguage[];
            /** Score of violence safe search score go/safesearch */
            violenceScore?: number;
            /** Score of vulgar safe search score go/safesearch */
            vulgarScore?: number;
        }
        interface SuperrootPodcastsRecommendationsPodcastRecsFeaturesUserLanguage {
            lang?: string;
            score?: number;
        }
        interface TelephoneNumber {
            /** The local "area code", if there is such a concept. */
            areaCode?: string;
            /** The international direct dialing code for the country, as per ITU E.164: http://www.itu.int/itudoc/itu-t/ob-lists/icc/e164_763.html */
            countryCode?: number;
            /** Extension (to be dialed after connection). */
            extension?: string;
            /**
             * To call this number from within the same country, the national call prefix may be necessary. This is 1 in the US, 0 in the UK, etc. In the US, it's reasonable to omit the leading 1
             * when writing the number, but in other countries it is less optional.
             */
            nationalPrefix?: string;
            /**
             * The actual number, broken down into sections as per local convention. Note that the actual formatting of these sections (hyphen vs space, usage of parentheses) will vary according
             * to local custom.
             */
            number?: string[];
        }
        interface TeragoogleDocumentInfo {
            attachment?: TeragoogleDocumentInfoAttachment[];
            /** The average weight of terms in the document. If not available, there will be no term weight averaging: font sizes will be taken literally from the document HTML. */
            averageTermWeight?: number;
            /** The document itself. If present, the docservers parse the contents to create a mustang repository. */
            doc?: GDocumentBase;
            /** The serialized ExtendedDocId, needed to construct a proper docinfo response if the docinfo request is missing it and it's present. */
            extendedDocid?: string;
            /** the global docid, we need it in the docservers (Continuum mode) to construct proper docinfo response when the docinfo request does not contain a valid global docid */
            globalDocid?: string;
            /** If the original encoding isn't UTF8 */
            originalEncoding?: number;
            section?: TeragoogleDocumentInfoSection[];
            /** Indicates format of 'tokens' field in all Section entries. */
            sectionType?: string;
        }
        interface TeragoogleDocumentInfoAttachment {
            name?: string;
            options?: TeragoogleRepositoryAttachmentOptions;
            value?: string;
        }
        interface TeragoogleDocumentInfoSection {
            /** List of field repository (subsection) names within the section. */
            fieldName?: string[];
            name?: string;
            tokens?: string;
        }
        interface TeragoogleRepositoryAttachmentOptions {
            compression?: string;
        }
        interface TitleSizeParams {
            /** Total max length of title in deciems */
            muppetTitleLengthInDeciems?: number;
            /** Number of lines for title */
            muppetTitleNumLines?: number;
        }
        interface ToolBarPerDocData {
            /** Indicates how many distinct toolbar visitors this page had in the past day. Will only be present if the number is reasonably large. */
            VisitorsPastDay?: number;
        }
        interface TravelFlightsAirlineConfig {
            /** Populated using airlines_company_ids.csv for AdWords company map */
            adwordsCid?: number;
            /** STAR_ALLIANCE */
            alliance?: string;
            /** Default url for baggage fee information. */
            baggageCarryonLimitationsUrls?: TravelFlightsNameCatalogProto;
            /** Default url for baggage fee information. */
            baggageFeeUrls?: TravelFlightsNameCatalogProto;
            /** ISO 3166-1 alpha-2 country code in which this airline is domestic. */
            countryCode?: string;
            /**
             * LocalizedContactInfo allows localization by country and language. Once the data is ready, we will start filling both fields. After that the old field will be deprecated and deleted
             * at some point.
             */
            countryContactInfo?: TravelFlightsAirlineConfigCountryContactInfo[];
            /** true, if this carrier's IATA code is a "controlled duplicate" (goto/controlled-duplicate). */
            dupFlag?: boolean;
            fareFamilyUrls?: TravelFlightsNameCatalogProto;
            /** IATA codes of airlines who this airline's travel can be credited to for mileage accrual. */
            fqtvPartnerCode?: string[];
            /**
             * Note that some iata_codes are reused (`dup_flag` field). For details, including how to resolve collisions for airlines shown in Google Flights, see: go/controlled-duplicate
             * go/flights-data/airlines#resolving-iata-code-collisions cs/go/controlled-duplicate U2 - some have no IATA code
             */
            iataCode?: string;
            /** EZY - some have no ICAO code */
            icaoCode?: string;
            /** U2! - with optional dedup sign ('!') */
            innovataCode?: string;
            localizedContactInfo?: TravelFlightsAirlineConfigLocalizedContactInfo[];
            /** Note: fields #16 and #17 are ununused. The identifier of the airline, e.g. /m/07y2s for United Populated using airlines_mids.csv. */
            mid?: string;
            /** EasyJet/イージージェット */
            names?: TravelFlightsNameCatalogProto;
            /** Default url for passenger assistance information. */
            passengerAssistanceUrls?: TravelFlightsNameCatalogProto;
            /** Number of flights with this airline over the next 180 days. */
            popularity?: number;
            /** KLM - instead of 'KLM Royal Dutch Airlines' */
            shortNames?: TravelFlightsNameCatalogProto;
            type?: string;
            /** http://www.airfrance.us/ */
            urls?: TravelFlightsNameCatalogProto;
            /** Default url for waiver information. */
            waiverSummaryUrls?: TravelFlightsNameCatalogProto;
        }
        interface TravelFlightsAirlineConfigContactInfo {
            /** Typically, formatted phone number. */
            data?: string;
            type?: string;
        }
        interface TravelFlightsAirlineConfigCountryContactInfo {
            contactInfo?: TravelFlightsAirlineConfigContactInfo[];
            /** Two char country code, e.g. "US" */
            countryCode?: string;
        }
        interface TravelFlightsAirlineConfigLocalizedContactInfo {
            contactInfo?: TravelFlightsAirlineConfigContactInfo[];
            /** IETF BCP-47, e.g. "en" or "zh-HK-Hant" */
            language?: string;
        }
        interface TravelFlightsNameCatalogEntry {
            language?: string;
            text?: string;
        }
        interface TravelFlightsNameCatalogProto {
            name?: TravelFlightsNameCatalogEntry[];
        }
        interface TrawlerClientServiceInfo {
            clientLabels?: TrawlerClientServiceInfoClientLabels[];
            /**
             * Project delegation name to support bandwidth enforcement. Harpoon will call SetDelegatedUser() with the specified DelegatedProjectName and a domain associated with the RequestorID
             * provided in the client capatibility file.
             */
            DelegatedProjectName?: string;
            ServiceClientID?: string;
        }
        interface TrawlerClientServiceInfoClientLabels {
            /** ======================== End of Deprecated Part ======================== */
            labelsDeprecated?: { [P in string]: TrawlerClientServiceInfoClientLabelsClientLabelValues };
            name?: string;
            values?: string[];
        }
        interface TrawlerClientServiceInfoClientLabelsClientLabelValues {
            value?: string[];
        }
        interface TrawlerContentRangeInfo {
            EndPos?: string;
            /** In ContentRange, the first byte is 0 (rather than 1), and the positions are inclusive. Thus, length is EndPos+1-StartPos */
            StartPos?: string;
            TotalLength?: string;
        }
        interface TrawlerCrawlTimes {
            /** fetched from the web. Time when the page was last */
            NotChangedTimeMs?: string;
            /** Time when the page was */
            OriginalCrawlTimeMs?: string;
            /** checked but found to be the same as before. If set, timestamp to indicate */
            ReuseTimeMs?: string;
        }
        interface TrawlerEvent {
            ID?: string;
            Msg?: string;
            NumOccurrences?: number;
            /** Limited to 3. */
            OldestTimeStampInUS?: string[];
            TimeStampInUS?: string;
        }
        interface TrawlerFetchBodyData {
            compression?: string;
            content?: string;
            /** Size hint. Set if compression != NO_COMPRESSION */
            uncompressedSize?: string;
        }
        interface TrawlerFetchReplyData {
            /**
             * This field, if non-empty, contains the SSL certificate chain from the server. The filed should be serialized SSLCertificateInfo protobuf, although it used to be text format. Hence,
             * one should ideally use trawler::CertificateUtil to check this field and understand in more detail. This field is populated in two cases: (1) something is wrong with the server
             * certificate and we cannot verify the server's identity. In this case the URL most likely won't display in a browser; (2) if you turned on WantSSLCertificateChain in the
             * FetchRequest. In this case the server certificate may be perfectly fine (despite the field name). This is for the initial hop; additional hops are in Redirects group.
             */
            BadSSLCertificate?: string;
            /**
             * Some client specific data that's set by client in the FetchRequest, and we just copy it here verbatim. This is similar to ClientInfo that we copy from FetchRequest to FetchReply,
             * but this is copied to FetchReplyData, thus stored in trawler logs so can be useful for debugging cases.
             */
            ClientServiceInfo?: TrawlerClientServiceInfo;
            /** Is the associated body compressed ? */
            CompressedBody?: boolean;
            crawldates?: TrawlerFetchReplyDataCrawlDates;
            CrawlTimes?: TrawlerCrawlTimes;
            /** Transfer operation detailed report. */
            deliveryReport?: TrawlerFetchReplyDataDeliveryReport;
            /**
             * Sometimes the hostid and destination IP in the FetchReplyData are not for the hostname in the url. If that's the case DNSHost will be the host that we have used when resolving
             * hostid and DNS. Right now there are two cases: (1) malware team provides a proxy IP:Port to us, so DNSHost will be the proxy IP; and (2) PSS team provides a reference DNS host; so
             * DNSHost will be the reference DNS host.
             */
            DNSHost?: string;
            /**
             * The download time for this fetch (ms). This is the RTT time between fetcher and HOPE, note it does not include time from redirects, just initial hop. If you want the sum of the
             * DownloadTime values for all fetches in the redirect chain, then use the DownLoadTime value in the FetchStats.
             */
            DownloadTime?: number;
            /** If present, the edge region that we have used. */
            EgressRegion?: string;
            /**
             * If present, it means this host might be eligible for geo crawl. However, this does not mean we enable geo-crawl for this request. Check "GeoCrawlEgressRegion" instead to see if this
             * fetch is conducted via geo crawl.
             */
            EligibleGeoCrawlEgressRegion?: string;
            /**
             * ------- If fetched, the IP from which we fetched, as well as source IP and ports. It is recommended to use trawler::DestinationIP()/HasDestinationIP() accessors, which return a
             * proper IPAddress.
             */
            Endpoints?: TrawlerTCPIPInfo;
            Events?: TrawlerEvent[];
            /**
             * With the introduction of fetch pattern based hostload exceptions, one hostid may have multiple hostload buckets, each with its own hostload. In this case, FetchPatternFp will be set
             * to identify the hostload bucket within the hostid. Note this field is only meaningful for the HostBucketData which is recorded only when the client requests to have as part of
             * reply. However, this field is useful for certain stats gathering, so we choose to always record it if its value is available during the fetch.
             */
            FetchPatternFp?: string;
            fetchstats?: TrawlerFetchReplyDataFetchStats;
            /** If present, fetch was conducted using floonet and this is the location of floonet egress point we used. */
            FlooEgressRegion?: string;
            /**
             * If present, the last hop of the fetch was conducted using floonet and this is the location of floonet egress point. It is different from EgressRegion and FlooEgressREgion because it
             * is a Trawler transparent routing configured in the geo crawl rules(go/da-geo-crawl).
             */
            GeoCrawlEgressRegion?: string;
            /**
             * Whether we fallback from geo crawl to local crawl during fetch. The fallback could happen in any hops and there can be at most one fallback because once fallback happens, we will
             * not try geo-crawl anymore.
             */
            GeoCrawlFallback?: boolean;
            /** Set only when GeoCrawlFallback is true. Logs the geo crawl location we attempted but failed for this request. */
            GeoCrawlLocationAttempted?: string;
            /** Returns the cache key used when doing cache lookup/update, on a per-hop basis (initial hop) Note this field will not be set if cache lookup/update is disabled/skipped. */
            HopCacheKeyForLookup?: string;
            HopCacheKeyForUpdate?: string;
            /**
             * Returns trawler::ReuseInfo with status of IMS/IMF/cache query, on a per-hop basis (initial hop) For example, if the URL redirect chain is [URL A] --> [URL B] --> [URL C], this field
             * stores the reuse info of [URL A].
             */
            HopReuseInfo?: string;
            /** Extra information in robots.txt for this page (integer: or'ed together of type trawler::RobotsInfo) on a per-hop basis (initial hop) */
            HopRobotsInfo?: number;
            /** Data about the host bucket this request is in (if desired) Please talk with Trawler team before considering using this, since what we fill in here is subject to change. */
            HostBucketData?: TrawlerHostBucketData;
            /** If known, the trawler::HostId that identifies the host (initial hop). */
            HostId?: string;
            /**
             * Set to: o HSTS_STATUS_NONE if there was no HSTS policy match for the URL's host. o HSTS_STATUS_AVAILABLE if there was an HSTS policy, but the URL was not rewritten from HTTP to
             * HTTPS because enable_hsts was not set in client capability config. o HSTS_STATUS_REWRITTEN if the HSTS policy was followed and url was rewritten from HTTP to HTTPS. This field only
             * pertains to the current URL fetch and does not explain a redirect's HSTS status. However, FetchReplyData.Redirects have their own HSTSInfo.
             */
            HSTSInfo?: string;
            /** The http protocol we send to fetch this URL. This will only be set if the request is using http */
            HttpProtocol?: string;
            /** The HTTP headers we sent to fetch this URL (initial hop). Not normally filled in, unless FetchParams.WantSentHeaders is set. */
            HttpRequestHeaders?: string;
            /**
             * HTTP headers from the response (initial hop). Trawler does not fill this in; this is intended as a placeholder for crawls like webmirror that fill in and want to track this across
             * redirect hops.
             */
            HttpResponseHeaders?: string;
            /** The received HTTP trailers if available. */
            HTTPTrailers?: TrawlerFetchReplyDataHTTPHeader[];
            /** Stores the HTTP version we used in the final hop. */
            HttpVersion?: string;
            /** Same as the ID of the matching request (used for matching internal fetchclient data in request/reply) */
            ID?: string;
            /** Crawl status of the last url on chain */
            LastUrlStatus?: TrawlerFetchStatus;
            /**
             * If the input url in FetchRequest is Amazon S3 protocol or Apple Itunes protocol, we will translate it into https url and log it as https url. In the meantime we will store the
             * original s3/itunes url in this field. Before sending back to client, the Url will be translated back to s3 and this field will be cleard.
             */
            originalProtocolUrl?: string;
            partialresponse?: TrawlerFetchReplyDataPartialResponse;
            /**
             * Trawler can optionally add a policy label to a FetchReply. Some uses: - "spam" label via trawler_site_info - "roboted:googlebot" label as a signal to crawls supporting multiple
             * useragents that it's not safe to share the fetch replies with googlebot crawls.
             */
            PolicyData?: TrawlerPolicyData[];
            /**
             * If the fetch uses HTTP POST, PUT, or PATCH protocol, and WantPostData is true, the POST data will be copied here. This is only for initial hop. If there are redirects, HTTP POST
             * will be changed to GET on subsequent hops, and the PostData will be cleared. There is only one exception, if the HTTP response code to the POST request is 307 (a new code introduced
             * in RFC7321, sec. 6.4.7), we will preserve the request method and the PostData for the next hop.
             */
            PostData?: string;
            /**
             * This is available only if a fetch results in TIMEOUT_WEB, and we were able to predict, based on content length and bandwidth we were using, how much time (in ms) would be needed to
             * download the entire content.
             */
            PredictedDownloadTimeMs?: number;
            protocolresponse?: TrawlerFetchReplyDataProtocolResponse;
            /**
             * Whether we fallback from HTTP/2 to HTTP/1.1 during fetch. The fallback could happen in any hops and there can be at most one fallback because once fallback happens, we will not try
             * HTTP/2 anymore.
             */
            ProtocolVersionFallback?: boolean;
            redirects?: TrawlerFetchReplyDataRedirects[];
            /** If this fetch was a result of a redirect, we populate the parent ID here. */
            RedirectSourceFetchId?: string;
            /** RequestorId is the same on as in the request that triggers this reply -- mainly for diagnostics purpose */
            RequestorID?: string;
            /** Machine that sent Trawler this request, for logging. An IPAddress object, packed as a string. */
            RequestorIPAddressPacked?: string;
            /**
             * -------- Returns trawler::ReuseInfo with status of IMS/IMF/cache query. Consider using HopReuseInfo instead, which has per-redirect hop detail. If there's URL redirection, this
             * field stores the reuse info of the last hop. For example, if the and URL redirect chain is [URL A] --> [URL B] --> [URL C], this field stores the reuse info of [URL C].
             */
            ReuseInfo?: string;
            /**
             * Extra information in robots.txt for this page (ORed together bits from trawler::RobotsInfo). e.g. nosnippet vs. noarchive vs nofollow vs noindex vs disallow Consider using
             * HopRobotsInfo instead, which has per-redirect hop detail.
             */
            RobotsInfo?: number;
            /**
             * Status of the robots.txt fetch. Currently, this is present if: - Certain robots error cases, such as URL_TIMEOUT-TIMEOUT_ROBOTS or URL_UNREACHABLE-UNREACHABLE_ROBOTS_ERROR. - If
             * WantRobotsBody is set in the FetchParams.
             */
            RobotsStatus?: TrawlerFetchStatus;
            /**
             * The robots.txt we used for this URL (initial hop). Not normally filled in unless WantRobotsBody is set. This is mostly for debugging purposes and should not be used for large
             * volumes of traffic.
             */
            RobotsTxt?: string;
            /** Status of the fetch - refers to the final status at the end of the redirect chain. */
            Status?: TrawlerFetchStatus;
            /** If present, Client API will enforce the contained constraints */
            ThrottleClient?: TrawlerThrottleClientData;
            /** Sometimes we throw away content because we cannot store it in the internal buffers. These is how many bytes we have thrown away for this factor. */
            ThrownAwayBytes?: string;
            /** When this reply came back from fetcher NOTE: TimestampInMS is used for internal debugging. To see when a document was crawled, check CrawlDates. */
            TimestampInMS?: string;
            /**
             * How many raw bytes we read from the connection to the server when we fetched the page. Includes everything: HTTP headers, overhead for HTTP chunked encoding, whatever
             * compressed/uncompressed form (i.e. gzip/deflate accept-encoding) the content was sent in, etc. This is NOT the same as the size of the uncompressed FetchReply::Body - if the
             * webserver used gzip encoding, this value might be much smaller, since it only counts the compressed wire size. To illustrate, think of 3 sizes: 1) TotalFetchedSize - amount Trawler
             * read over the wire from the server. If they used gzip/deflate, this might be 4-5x smaller than the body. 2) UnTruncatedSize/CutoffSize - how big is the full document, after
             * uncompressing any gzip/deflate encoding? If truncated, this is reflected in CutoffSize. 3) FetchReply::Body size - most crawls enable Trawler compression to save storage space (gzip
             * + a google html dictionary). The body size that the end Trawler client sees is post-compression.
             */
            TotalFetchedSize?: string;
            /** Traffic type of this fetch. */
            trafficType?: string;
            /** If the url got rewriten by transparent rewrites, here it is the series of rewrites it got through. The fetched one is the last */
            TransparentRewrites?: string[];
            /** For logging only; not present in the actual fetcher response */
            TrawlerPrivate?: TrawlerTrawlerPrivateFetchReplyData;
            /**
             * The original url in the request we are answering. Even though "optional," url must be filled in on all well-formed replies. Trawler guarantees that it is filled in, and basically
             * every client expects it (CHECKs in some cases). -> Not filling this field in is a bug, if you share this data with other crawls/pipelines. You should expect everybody else to
             * require a url.
             */
            Url?: string;
            /** Encoding info for the original url itself. Bitfield encoding; see UrlEncoding::{Set,Get}Value in webutil/urlencoding. */
            UrlEncoding?: number;
            /**
             * Use the special compression dictionary for uncompressing this. (trawler::kHtmlCompressionDict. Use trawler::FetchReplyUncompressor to uncompress;
             * crawler/trawler/public/fetchreply-util.h)
             */
            UseHtmlCompressDictionary?: boolean;
        }
        interface TrawlerFetchReplyDataCrawlDates {
            /** fetched from the web. Timestamp indicates when */
            NotChangedDate?: number;
            /** Timestamp when the page was */
            OriginalCrawlDate?: number;
            /** the page was last checked but found to be the same as before. If set, timestamp to indicate */
            ReuseDate?: number;
        }
        interface TrawlerFetchReplyDataDeliveryReport {
            /** The events store the detail of messages (usually error). */
            events?: TrawlerEvent[];
            /**
             * The complete path (include the file name) of the file downloaded. For requests that require delivery, this path will be the user specified location. For requests that use Multiverse
             * default storage, this path will be the managed by Multiverse.
             */
            filePath?: string;
            /** Status of the transfer action. */
            status?: string;
        }
        interface TrawlerFetchReplyDataFetchStats {
            /** Overhead spent RPCing with the Bot/proxy. */
            BotOverheadMS?: number;
            ClientControlflowStats?: TrawlerFetchReplyDataFetchStatsClientStateStats;
            /**
             * Report only with first request on connection, so that we keep track of the connect time with a host. Sometimes a connection is initiated by a prior request that times out before the
             * connection is established. Another request can get scheduled on a connection that is already in the process of being established but has no request scheduled onto it. We want to
             * keep track of the entire connect time even if a request didn't need to wait for the entire connection establishment time. Sometimes a connection may get established before the first
             * request uses it. We tag along the connect time with the first request using the connection. ConnectTimeMs also includes SSL negotiation time.
             */
            ConnectTimeMs?: number;
            ControlflowStats?: TrawlerFetchReplyDataFetchStatsStateStats;
            /** DownLoadTime = Share of connect time + ServerResponseTimeMs + TransferTimeMs (see below) in ms */
            DownLoadTime?: number;
            /** Overhead spent routing the request from HOPE to edge egress nodes, which open connection to webservers. This is only set for edge fetches (e.g., through Floonet egress nodes). */
            EdgeEgressOverheadMs?: number;
            /**
             * Time between the request send and the receipt of the first fragment of the response. For HTTP responses the first fragment is the first fragment of the response payload (the headers
             * are ignored).
             */
            ServerResponseTimeMs?: number;
            /** ConnectTimeMs includes TCP connect time + SSL time, whereas SSLConnectTimeMs includes only the latter. */
            SSLConnectTimeMs?: number;
            /** Time to receive the entire response payload starting the clock on receiving the first fragment. */
            TransferTimeMs?: number;
        }
        interface TrawlerFetchReplyDataFetchStatsClientStateStats {
            WaitContentCacheUsec?: number;
        }
        interface TrawlerFetchReplyDataFetchStatsStateStats {
            EndTrackingTimeUsec?: string;
            /** Start and end timestamp tracking the delays for this request. */
            StartTrackingTimeUsec?: string;
            WaitCompressTimeUsec?: number;
            WaitContentCacheUsec?: number;
            WaitCredentialTimeUsec?: number;
            WaitDNSTimeUsec?: number;
            WaitFetchClientUsec?: number;
            WaitForCachedContentStreamingUsec?: number;
            WaitForFetchUsec?: number;
            WaitHostIdTimeUsec?: number;
            WaitNextFlowUsec?: number;
            /** obsolete. Not set. */
            WaitRobotsCacheTimeUsec?: number;
            /** obsolete. Not set. */
            WaitRobotsFetchTimeUsec?: number;
            WaitRobotsTimeUsec?: number;
            WaitScheduleTimeUsec?: number;
        }
        interface TrawlerFetchReplyDataHTTPHeader {
            key?: string;
            value?: string;
        }
        interface TrawlerFetchReplyDataPartialResponse {
            /**
             * If set, indicates where the fetched body is, e.g. a CNS file path. FetchReply.Body should be empty in this case. In the case where client does not support streaming but the content
             * is too large to be accumulated in memory, we keep writing the streaming chunks to some storage unit and notify client when it is done.
             */
            BodyLocation?: string;
            /** Fetch number in this series of fetches */
            ChunkNumber?: number;
            /** If there is a Content-Range header, the ranges in it */
            ContentRange?: TrawlerContentRangeInfo;
            /** Any ETag seen in the headers */
            ETag?: string;
            /** ID which links all partial fetches for this url */
            FetchID?: string;
            /** Is this the final response for this fetch? */
            IsFinalResponse?: boolean;
        }
        interface TrawlerFetchReplyDataProtocolResponse {
            /**
             * Response code. We emulate the HTTP response codes for all protocols that we know. -- HTTP: response code for the downloaded page. -- FTP: similar with HTTP: 200 - OK, 40X - errors
             * (not found, etc), 500 - server unavailable
             */
            Code?: number;
            /** Content type as inferred by the fetcher (webutil/http/content-type.proto) */
            ContentType?: string;
            /** Where did we cut off? Includes headers plus truncated but uncompressed content. Present if and only if we truncated the document. */
            CutoffSize?: string;
            /** DEPRECATED, see field 113. Stores the HTTP version we used in the final hop. */
            HttpVersion?: string;
            /**
             * DEPRECATED, see field 114. Whether we fallback from HTTP/2 to HTTP/1.1 during fetch. The fallback could happen in any hops and there can be at most one fallback because once
             * fallback happens, we will not try HTTP/2 anymore.
             */
            ProtocolVersionFallback?: boolean;
            /**
             * The amount of data we got from the webserver before any truncation, but after undoing any HTTP gzip/deflate encoding. For HTTP, this includes headers and uncompressed content.
             * Content size is excluded if content was not successfully fetched. See description above TotalFetchedSize for comparison.
             */
            UnTruncatedSize?: string;
        }
        interface TrawlerFetchReplyDataRedirects {
            /** The server SSL certificate chain in SSLCertificateInfo protobuf format. See this field in FetchReplyData (i.e., the initial hop) for more description on when it will be populated. */
            BadSSLCertificate?: string;
            /** Per redirect hop timestamps. This */
            CrawlTimes?: TrawlerCrawlTimes;
            /** Download time of this fetch (ms) */
            DownloadTime?: number;
            /** ## stats If fetched, ip info. */
            Endpoints?: TrawlerTCPIPInfo;
            /**
             * Extra trawler::PageNoIndexInfo for this hop. Integer: ORed together bits from trawler::PageNoIndexInfo. The information specified by this field comes from the http header or content
             * of the source url, not the "TargetUrl" in this Redirects group.
             */
            HopPageNoIndexInfo?: number;
            /** trawler::ReuseInfo with status of IMS/IMF/cache query, for this hop. */
            HopReuseInfo?: string;
            /** Extra trawler::RobotsInfo for this hop. Integer: ORed together bits from trawler::RobotsInfo */
            HopRobotsInfo?: number;
            /** If known, the hostid for this hop */
            HostId?: string;
            /**
             * This specifies if the url in a redirect was rewritten to HTTPS because of an HSTS policy for the domain. See comments on FetchReplyData.HSTSInfo for how this field's values. A
             * redirect that was rewritten with HSTS will have HSTS_STATUS_REWRITTEN ## here.
             */
            HSTSInfo?: string;
            /** The http headers we sent for fetching this redirect hop. Not normally filled in, unless FetchParams.WantSentHeaders is set. */
            HttpRequestHeaders?: string;
            /**
             * The HTTP response code for this hop. We need this since multiple response codes may have the same redirect type (e.g., 302 and 307 are both REDIRECT_TEMPORARILY), but clients may
             * want to know which one was received. Note this is set only for the hops that are followed (i.e., TargetUrl is present). If the last redirect hop was not followed the fetch status
             * will be URL_NOT_FOLLOWED, and the response code will be in the top level ProtocolResponse field.
             */
            HTTPResponseCode?: number;
            /**
             * The http headers we received from this redirect hop. Trawler does not fill this in; this is intended as a placeholder for crawls like webmirror that fill in and want to track this
             * across redirect hops.
             */
            HttpResponseHeaders?: string;
            /** bytes: can contain bad encoding. */
            RawTargetUrl?: string;
            /** Refresh time in meta redirect tag */
            RefreshTime?: number;
            /** The robots.txt we used for this fetch. Not normally filled in unless WantRobotsBody is set. */
            RobotsTxt?: string;
            /** For meta-redirects, this field may contain the body of the source document. Currently only filled client side and not implemented (yet) for server-side redirects. */
            SourceBody?: TrawlerFetchBodyData;
            /**
             * Difference between the following two fields: TargetUrl is set when we have followed the redirect target, and the url is canonicalized. RawTargetUrl is set in either of the following
             * two cases: (1) The url has not be been followed. For example, the redirect is intended to be handled by the client. In the fetch reply response, you will see the url's status as
             * URL_NOT_FOLLOWED-NOT_FOLLOWED*. (2) The extracted redirect url is different from its *canonicalized* form. For example, if the target url contains fragments, then this RawTargetUrl
             * will have the fragments. Redirect target
             */
            TargetUrl?: string;
            /** URL and redirect type */
            Type?: string;
        }
        interface TrawlerFetchStatus {
            /**
             * The Reason field gives further clarifying details about why or how the fetch had the given outcome. For instance, if State is URL_ERROR - was it a 404/NotFound or a DNS error? The
             * Reason field is present iff State != URL_CRAWLED. For a given crawl status of URL_FOO, the Reason value will be one of the various FetchFooReason enum values from
             * crawler/trawler/trawler_enums.proto
             */
            Reason?: number;
            /**
             * The State field describes the basic outcome of a fetch (URL_CRAWLED, URL_ROBOTED, URL_ERROR, etc). The value is one of the UrlStatusType enum values from
             * crawler/trawler/trawler_enums.proto Note, there are several combinations of this Status/Reason tuple that could mean that your content is crawled or can be bucketed in a particular
             * type of error. So instead of comparing the enumeration values manually, we suggest to use the predicate functions such as IsContentCrawled() provided in
             * crawler/trawler/public/basictypes.h (see details there).
             */
            State?: string;
        }
        interface TrawlerHostBucketData {
            /** How much existing traffic */
            ClientTrafficFraction?: number;
            /** belong to the client How much weight the client */
            ClientWeightFraction?: number;
            /** How many connections are actively used for downloading ? */
            CurrentActiveConnections?: number;
            /** Is this bucket currently full ? */
            IsFull?: boolean;
            /** How many ms ago we last scheduled a url */
            LastScheduleIntervalMs?: string;
            /** The current hostload value (# of connections) - if negative does not apply */
            MaxActiveConnections?: number;
            /** The load the recent times (the actual hostload that we apply is MaxActiveConnections / MediumTermLoad) - a hostload of 1.00 is normal, while over 1.0 is higher than normal load */
            MediumTermLoad?: number;
            /** The min delay between requests (in secs) - if negative does not apply */
            MinInterRequestSecs?: number;
            /** If is full, when is becoming non-full (in ms) */
            NonFullIntervalMs?: string;
            /**
             * The following four fields attempt to make things simpler for clients to estimate available capacity. They are not populated yet as of 2013/08/21. Even after they are populated, they
             * may change. So talk to trawler-dev@ before you use the fields. Total qps for this hostid
             */
            TotalCapacityQps?: number;
            /** Currently used qps */
            TotalUsedQps?: number;
            urllist?: TrawlerHostBucketDataUrlList[];
        }
        interface TrawlerHostBucketDataUrlList {
            /** Is this client/requestorid allowed to crawl now? (based on resource use) */
            ClientCanCrawl?: boolean;
            /** Is this the 'default' user's list */
            IsDefaultNode?: boolean;
            /** Was this the list that a given request landed in? */
            IsListForUrl?: boolean;
            /** # of current active fetches */
            NumCurrentFetches?: number;
            /** # of urls currently in the queue */
            NumUrls?: number;
            /** The fp64 of the requestor string */
            RequestorFp?: string;
            /** The type of the request (low latency vs. high throughput) */
            RequestType?: string;
        }
        interface TrawlerLoggedVPCDestination {
            cloudRegion?: string;
            vnid?: NetFabricRpcVirtualNetworkId;
        }
        interface TrawlerMultiverseClientIdentifier {
            topicName?: string;
            trafficType?: string;
        }
        interface TrawlerOriginalClientParams {
            clientCell?: string;
            clientIp?: string;
            /** through which RPC request */
            clientRpcType?: string;
            clientUsername?: string;
        }
        interface TrawlerPolicyData {
            /** in roboted case, the RobotsInfo */
            ExtraData?: number;
            /** "spam" or "roboted:googlebot" */
            Label?: string;
        }
        interface TrawlerSSLCertificateInfo {
            /**
             * ALPN negotiated protocol, see https://tools.ietf.org/html/rfc7301 The value will either be empty, or one of the protocol names sent by the client that the server accepted. Examples
             * include "h2" and "acme-tls/1".
             */
            ALPNNegotiatedProtocol?: string;
            /**
             * If present, this consists of the remote webserver's X.509 certificate chain in DER format. The chain stored here is the *reversed* result of SSL_get_peer_cert_chain(). That is to
             * say, it is the chain presented by the peer (which may differ from the chain that was built and verified), but in leaf-last order. Typically the root cert will not be included. But
             * do not assume anything, because servers do all manner of weird things. (For example on the beginning of the chain, there might be also some irrelevant certificates besides the root
             * certificate.) Certificates may be the empty string, indicating an encoding failure. See also |IsTruncated|. Certs can be loaded with util/sig/cert.h Cert::LoadBinaryCert(),
             * converted to ASCII PEM format (CertificateUtil::CertificateToPEM()) or shown as text at the commandline by piping them into 'openssl x509 -text -inform DER'.
             */
            CertificateChain?: string[];
            /**
             * ErrorMessages contains errors from HTTPS validation. Examples of such errors include invalid certificates, failure to build a certificate chain, certificates that do not match the
             * expected hostname, and internal errors. If ErrorMessages is empty, HTTPS validation succeeded. Otherwise, it failed. This is the only guarantee about the contents of this field,
             * though legacy code exists that embeds invalid assumptions, b/70904498. New code should not do anything with this field other than test whether it is empty and display its value to
             * humans. If you need to know more about the details of a particular HTTPS validation, you can revalidate |CertificateChain| independently.
             */
            ErrorMessages?: string[];
            /** This SSLCertificateInfo had its fields truncated because it was too large. It is no longer set (cl/205356251) but may be true in old records. */
            IsTruncated?: boolean;
            /**
             * Stapled OCSP response obtained during the TLS handshake, if any. An OCSP (Online Certificate Status Protocol) response is an indication, signed by the issuing CA, that the
             * certificate has not been revoked. A TLS handshake extension allows servers to "staple" a response to the certificate served in the handshake, saving the need for the client to fetch
             * it itself from the CA. This field contain the stapled OCSP response if the server served one. See RFC6066, Section 8 for the data format:
             * https://tools.ietf.org/html/rfc6066#section-8
             */
            OCSPResponse?: string;
            /** SCTList obtained during the TLS handshake, if any. See RFC6962, Section 3.3 for the data format: https://tools.ietf.org/html/rfc6962#section-3.3 */
            SCTList?: string;
            SSLCipherSuite?: number;
            SSLCipherSuiteName?: string;
            /** Details about the SSL/TLS protocol and cipher. See RFC5246 and google3/crawler/trawler/hope/proto/ssl.proto for more details. */
            SSLProtocolVersion?: number;
            /** The names of the SSL protocol version and cipher suite. These strings are implementation defined and may be subject to change. */
            SSLProtocolVersionName?: string;
        }
        interface TrawlerTCPIPInfo {
            /** Address of the destination host. Extract with trawler::DestinationIP() or decode with PackedStringToIPAddress(). */
            DestinationIPAddressPacked?: string;
            DestinationPort?: number;
            /** Source address of the crawl machine we originated the fetch from. Extract with trawler::SourceIP() or decode with PackedStringToIPAddress(). */
            SourceIPAddressPacked?: string;
            SourcePort?: number;
        }
        interface TrawlerThrottleClientData {
            IsBandwidthThrottle?: boolean;
            /** Max doc_requestor urls/second allowed from this client to this fetcher. */
            MaxAllowedRate?: number;
        }
        interface TrawlerTrawlerPrivateFetchReplyData {
            /** Stores the OAuth authentication method. */
            authenticationInfo?: string;
            /** If we fetched using BotFetchAgent, what is the BotGroupName? */
            BotGroupName?: string;
            /**
             * This is the HOPE server that we sent the url to. We log the HOPE backend cell and hope server shard number (e.g., 'qf:6'). This allows us to understand how we are balancing our load
             * to the HOPE servers.
             */
            BotHostname?: string;
            /** Corresponds to AcceptableAfterDate field in FetchParams. */
            cacheAcceptableAfterDate?: number;
            /** Corresponds to AcceptableAge field in FetchParams. */
            cacheAcceptableAge?: number;
            /** Only set if the fetch uses cache content (is_cache_fetch is true). */
            cacheHitType?: string;
            /** Present if the reply is from the trawler cache. This is the requestorid of the trawler client that populated the cache with the data we are reusing. */
            CacheRequestorID?: string;
            cdnProvider?: string;
            /** How many concurrent streams are on the connection when the request finishes (including this request). Export this value to monitor the stream multiplexing for HTTP/2. */
            concurrentStreamNum?: string;
            /** Dependent fetch type */
            dependentFetchType?: string;
            /** If the response header contains Content-Disposition header "attachment; filename="google.zip": the download_file_name would be "google.zip" */
            downloadFileName?: string;
            /** Which Trawler fetcher task fetched this URL. */
            FetcherTaskNumber?: number;
            HadInMemCacheHit?: boolean;
            /**
             * If we do not have Endpoints in FetchReplyData (e.g., url rejected due to hostload limit), do we have a guess of the server IPAddress (e.g., from robots fetch)? This helps us
             * classify URLs based on country code, etc. The field is filled with IPAddress::ToPackedString().
             */
            HintIPAddress?: string;
            /** HTTP Strict-Transport-Security (RFC6797) header value. We log this so we can generate a list of hosts that prefer HTTPS over HTTP. */
            HSTSHeaderValue?: string;
            /** Stores the HTTP version we used in the last hop. */
            httpVersion?: string;
            /**
             * Represents if the HostId belongs to HostId set in 5xx url patterns, it can work as a tag when emitting requestor minute summary, this helps us to aggregate traffic affected by 5xx
             * patterns, and test if there are any fetching changes.
             */
            Is5xxHostId?: boolean;
            /** Whether this is a bidirectional streaming fetch. */
            isBidiStreamingFetch?: boolean;
            /**
             * Whether or not this is a Floonet fetch request. Floonet requests have inherent lower availability (due to HOPE rejections when HOPE is in degraded mode, and other Floonet specific
             * reasons). Therefore, it is important for debugging and for our availability SLO to know whether of not it is a floonet fetch. IMPORTANT NOTE: This field is only currently set for
             * traffic that explicitly requires Floonet and can not failover to use Googlebot (i.e. "transparent" or "implicit" Floonet fetches).
             */
            isFloonetFetch?: boolean;
            /** Whether or not this response is sent from gRPC proxy service. */
            isFromGrpcProxy?: boolean;
            /** Was this an internally-initiated robots.txt fetch? */
            IsRobotsFetch?: boolean;
            /** Set if the fetch goes through the virtual private cloud path so we can track the VPC traffic. */
            isVpcTraffic?: boolean;
            /** Set to the hit location (CNS filename) if cache comes from large store. */
            largeStoreHitLocation?: string;
            /** Multiverse client information */
            multiverseClientIdentifier?: TrawlerMultiverseClientIdentifier;
            /** Number of times we drop the content of a stream reply or the final reply, which can only be caused by REJECTED_NO_RPC_BUFFERS now. */
            numDroppedReplies?: string;
            /** Store the original client information. */
            originalClientParams?: TrawlerOriginalClientParams;
            /** What's the post data size (in bytes) if it's a post request. */
            PostDataSize?: string;
            /**
             * Note TrawlerPrivateFetchReplyData is never sent back to clients. The following field is just for Trawler and Multiverse internal tracking, and clients should not look at this field
             * at all.
             */
            Producer?: string;
            /** If set, this fetch was done through a proxy (e.g., fetchproxy). */
            ProxyInstance?: string;
            /**
             * Log the loas username in trawler private to help with debugging. Store the username in trawler private so clients won't see it from FetchReply. To reduce disk usage, we only log the
             * loas username if the requestorid being used does not have ClientUsernameRestrictions.
             */
            RequestUserName?: string;
            /** If the requestor shares resource bucket with other requestorids, we will store the resource bucket name in these fields. */
            resourceBucket?: string;
            /** The number of bytes we sent back to the client. */
            ResponseBytes?: string;
            /**
             * If this was a robots.txt fetch (IsRobotsFetch above), this may contain the robots.txt body. (It may not, for instance, 404s are omitted; current policy is URL_CRAWLED + partially
             * crawled) This includes http headers + body.
             */
            RobotsBody?: string;
            /** RPC deadline left at the end of url control flow. Can be useful for debugging rpc deadline exceeded error received by clients, this field is only recorded if it's small enough. */
            RpcEndDeadlineLeftMs?: number;
            /**
             * RPC deadline left at the start of url control flow. Can be useful for debugging rpc deadline exceeded error received by clients, this field is only recorded if RpcEndDeadlineLeftMs
             * is small enough.
             */
            RpcStartDeadlineLeftMs?: number;
            /** An arbitrary string signature identifying the remote server type/version. In the case of HTTP, this would be the contents of the "Server:" header. */
            ServerSignature?: string;
            subResourceBucket?: string;
            /** Service tier info will be used in traffic grapher for ploting per tier graph. */
            tier?: string;
            /** Which Trawler cell was this response fetched in? (e.g. "HR" or "YQ") */
            TrawlerInstance?: string;
            /** The useragent string sent to the remote webserver. It corresponds to UserAgentToSend field in FetchParams. */
            UserAgentSent?: string;
            /** The fp2011 of useragent sent to the remote webserver, note it corresponds to UserAgentToSend field in FetchParams */
            UserAgentSentFp?: string;
            /** The following are vpc information that's only set if is_vpc_traffic is true. */
            vpcDestination?: TrawlerLoggedVPCDestination;
        }
        interface UniversalsearchNewPackerKnowledgeResultSupport {
            /** A debug message that summarizes how the score was computed. Populated if result was matched and in debug mode. */
            debug?: string;
            /** The docid of the result, if available. */
            docid?: string;
            /**
             * The naviness for this result. Each matcher can determine the naviness to use for the result. This can be copied directly from the result, or estimated based on clicks or some other
             * heuristic. The value should be between 0 and 1 and should indicate the probability that the user will click on that result. The estimated_naviness is used to break ties when between
             * results with the same rank.
             */
            estimatedNaviness?: number;
            /** All provenances of this result support. */
            provenance?: UniversalsearchNewPackerKnowledgeResultSupportProvenance[];
            /**
             * The 0 based rank for this result. When the source is MAIN_GSR this corresponds to the index of the result in the generic search response specific in AddKnowledgePackerPreprocessors.
             * Otherwise, the rank should be estimated so the result is closest in importance to the web result at the same rank.
             */
            rank?: number;
            /** A score from 0 to 1 inclusive that represents the strength of the result support. A score of one indicates this result is entirely about this interpretation. */
            score?: number;
            /** The source of the result support. */
            source?: string;
            /** The result url when available. */
            url?: string;
        }
        interface UniversalsearchNewPackerKnowledgeResultSupportProvenance {
            /** Entity group type of the supported entity. This field should only be set for support on entities. */
            entityGroupType?: string;
            /** ===== Deprecated Fields ===== The bool flag indicating whether the ResultSupport comes from answer entities. */
            fromAnswer?: boolean;
            /** The provenance provider name. */
            name?: string;
        }
        interface UrlPoisoningData {
            /** fetched from the web. Time when the page was last */
            NotChangedTimeMs?: string;
            numSpamSiblings?: number;
            /** Time when the page was */
            OriginalCrawlTimeMs?: string;
            /** checked but found to be the same as before. If set, timestamp to indicate */
            ReuseTimeMs?: string;
            /** when it is fetched from the repository. URL of the document for debugging */
            url?: string;
        }
        interface UtilStatusProto {
            /** The canonical error code (see codes.proto) that most closely corresponds to this status. May be missing. */
            canonicalCode?: number;
            /** Numeric code drawn from the space specified below. Often, this is the canonical error space, and code is drawn from google3/util/task/codes.proto */
            code?: number;
            /** Detail message */
            message?: string;
            /** message_set associates an arbitrary proto message with the status. */
            messageSet?: any;
            /** The following are usually only present when code != 0 Space to which this status belongs */
            space?: string;
        }
        interface VendingConsumerProtoTrustedGenomeAnnotation {
            /** The list of trusted genome policy. */
            policy?: VendingConsumerProtoTrustedGenomePolicy;
            /** The list of test code, used to log when serving. The test code is set in both control and experiment annotations when they are different. */
            testCode?: string[];
            /** The list of trusted genome hierarchy. One trusted_genome_hierarchy may contain one or multiple entities. This is required for TG 2.0 tags. */
            trustedGenomeHierarchy?: VendingConsumerProtoTrustedGenomeHierarchy[];
        }
        interface VendingConsumerProtoTrustedGenomeEntity {
            /** The category id matching this trusted genome entity. e.g. Action tag with id /m/025zzc matches category of id GAME_ACTION */
            categoryId?: string;
            /** The identifier of a play trusted genome entity. Required. */
            id?: string;
            /**
             * The level of the entity. E.g. in hierarchy like Action -> Platformer > Endless Runner. Action is level 1, Platformer is level 2 and Endless Runner is level 3. Currently, only
             * APP_TAXONOMY and GAME_TAXONOMY type may have the levels. For entity that does not have hierarchy, its level is 1. Required.
             */
            level?: number;
            /** The name of the relation between the app and the entity. Required. */
            predicateName?: string;
            /** The localized query string for this trusted genome entity. This query will be used when we want to bring users to SERP on click. */
            queryText?: string;
            /** The confidence score of the entity to the app. */
            score?: number;
            /** The localized title. Required. */
            title?: string;
            /** This boolean is used to decide whether this entity will be shown on user-facing features in the Store or not. */
            userVisible?: boolean;
        }
        interface VendingConsumerProtoTrustedGenomeHierarchy {
            /**
             * List of entities (one or multiple) that belong in the same hierarchy. The entries will be ordered such that the first entry will be of level 1, and the second entry will be of level
             * 2, and so on. Required
             */
            entity?: VendingConsumerProtoTrustedGenomeEntity[];
            /**
             * The (hierarchy-level) type of this Trusted Genome hierarchy. Will only be populated when meeting certain criteria, e.g. 'GD2_Game_Main' means this hierarchy of entities can serve as
             * the main game genre for Game Discovery 2.0.
             */
            hierarchyType?: string;
            /** The source of this Trusted Genome hierarchy. */
            source?: string;
            /** The (entity-level) type of trusted genome entities in this hierarchy. Required. */
            trustedGenomeType?: string;
        }
        interface VendingConsumerProtoTrustedGenomePolicy {
            /**
             * Override text for region for special treatment. Override will be used in special cases for example regions are too long to show in UI, the override will be "CA/NV/..." to cut it
             * short. By keeping a region override string we'll have more flexibility to adjust what we show on UI. Optional.
             */
            localizedRegionOverride?: string;
            /** Policy type. e.g. Government Endorsed, Apollo Required. */
            policyType?: string[];
            /** Contains target region for the current policy. Optional */
            targetRegion?: VendingConsumerProtoTrustedGenomePolicyTargetRegion[];
        }
        interface VendingConsumerProtoTrustedGenomePolicyTargetRegion {
            /** Localized name for targeted regions. e.g. San Francisco Bay Area Required. */
            localizedRegion?: string;
            /** Associated KG entity mid for region. e.g. /m/06pvr */
            mid?: string;
        }
        interface VideoAmbisonicsAmbisonicsMetadata {
            /**
             * Maps channel indexes of an audio stream to indexes corresponding to the specified ambisonics channel ordering scheme. For example: A 1st order pheriphonic ambisonics format is
             * configured with 4 audio channels corresponding to ambisonic components W, X, Y, Z respectively. The channel_ordering scheme is specified as CHANNEL_ORDERING_ACN (which implies a W,
             * Y, Z, X ordering). Therefore the channel_map is [0, 3, 1, 2].
             */
            channelMap?: number[];
            channelOrdering?: string;
            nonDiegeticStereo?: boolean;
            normalization?: string;
            numChannels?: number;
            order?: number;
            type?: string;
            version?: number;
        }
        interface VideoAssetsVenomACL {
            /** REQUIRED: the current owner of this video. Please note that owner does not get implicit reader/writer access. You must set them explicitly. */
            owner?: string;
            /** Allowed readers of this video. */
            reader?: string[];
            /** Allowed writers of this video. */
            writer?: string[];
        }
        // tslint:disable-next-line:no-empty-interface
        interface VideoAssetsVenomSettings {
        }
        interface VideoAssetsVenomTransition {
            /** The objective this transition is about. REQUIRED. */
            objective?: string;
            /** Whether the objective is reached or not. REQUIRED. */
            outcome?: string;
            /**
             * An optional debug string indicating the reason for this transition. This is typically omitted for OUTCOME_SUCCESS. e.g. "The video's content is invalid due to failed blobstore
             * cloning."
             */
            reason?: string;
        }
        interface VideoAssetsVenomVideoId {
            /**
             * REQUIRED. IDs have some constraints: - 32 bytes max: this is enforced by the server - for the time being, must be parseable as a youtube ID (basically a base64-encoded string which
             * maps to a 64-bit integer). This restriction will eventually be lifted.
             */
            id?: string;
            /** LINT.ThenChange( //depot/google3/googledata/production/playbooks/video-assets/clients.md ) REQUIRED. */
            ns?: string;
        }
        interface VideoAudioStream {
            /** Audio bitrate in bits/s. */
            bitrate?: string;
            /** Number of audio channels. */
            channels?: number;
            /**
             * Audio codec ID. Uses the numeric value corresponding to the CodecId enum object, in order to avoid the dependency on vsi/videostreaminfo.proto.
             * http://cs/symbol:CodecId%20f:google3/video/vidproc/vsi/videostreaminfo.proto
             */
            codecId?: number;
            /**
             * Content type of the stream. Only populated with valid "acont" xtag values at the moment. Supported acont xtag values can be found in google3/video/storage/common/xtag_validation.cc.
             * Examples: "original", "dubbed", "descriptive", "commentary", etc.
             */
            contentType?: string;
            /** Language, examples: "eng", "en", "enG", etc. */
            language?: string;
            /**
             * Audio length, in seconds. This value is derived from metadata in the source video, and often differs from the actual duration of any given transcode. In videos without valid
             * timestamps, this value is not calculable, and is reported as zero.
             */
            lengthSec?: number;
            loudness1770Lkfs?: number;
            /** Audio sample rate. */
            sampleRate?: string;
            /** Index of the stream in the file, 0-based. */
            streamIndex?: string;
        }
        interface VideoClipInfo {
            key?: string;
            value?: string;
        }
        interface VideoClosedCaptions {
            videoHasClosedCaptions?: boolean;
        }
        interface VideoContentSearchAnchorCommonFeatureSet {
            /** QBST distance between the anchor and the top navboost query of the video if exists, or the video title otherwise. */
            anchorQbstDistance?: number;
            /** Features needed for Bleurt inference. */
            bleurtFeatures?: VideoContentSearchBleurtFeatures;
            /** The Bleurt inference score generated using the bleurt_features. */
            bleurtScore?: number;
            /** Descartes similarity score between video title and anchor label. */
            descartesScoreWithTitle?: number;
            /**
             * The predicted descriptiveness and usefulness rating scores generated by the Unified Dolphin model. Rating template:
             * experimental/video/video_anchors_oneside_without_thumbnail/template.jhtml
             */
            dolphinDescriptivenessScore?: number;
            /** If the dolphin model is an ensemble model, this contains the scores associated to each individual ensemble model. */
            dolphinEnsembleScore?: VideoContentSearchDolphinEnsembleScore[];
            /** The features used to generate the Dolphin score. */
            dolphinFeatures?: VideoContentSearchDolphinFeatures;
            /** The score generated by the Dolphin callout model. */
            dolphinScore?: number;
            dolphinUsefulnessScore?: number;
            /** A phrase embedding for the anchor label. The model used to generate the embedding can be found in VideoAnchorSets: video_score_info.common_features.label_phrase_embedding_model */
            labelPhraseEmbedding?: number[];
            /** The predicted descriptiveness of the anchor using the MUM unified scoring model. */
            mumDescriptivenessScore?: number;
            /** The predicted usefulness of the anchor using the MUM unified scoring model. */
            mumUsefulnessScore?: number;
            /**
             * A score that is correlated with retention probability of the interval associated with this anchor (start time to end time). Retention probability of an interval is 1 - (probability
             * the user does not watch the interval all the way through, given they started watching it). This score may be predicted by a model, or calculated from actual retention data.
             */
            retentionScore?: number;
            /** A saft document generated from the anchor label. */
            saftDocument?: NlpSaftDocument;
            /** For annotating labels and their timing and context info. For example, this is used for anchor labels within a passage. */
            timedLabelFeatures?: VideoContentSearchCaptionLabelFeatures[];
            timestamp?: VideoContentSearchAnchorCommonFeatureSetLabelSpanTimestamp[];
            /** Babel similarity between the anchor and the video title. */
            titleAnchorBabelMatchScore?: number;
        }
        interface VideoContentSearchAnchorCommonFeatureSetLabelSpanTimestamp {
            /** The ASR confidence for the label span, if available. */
            asrConfidence?: number;
            /** Whether or not this token is the first token in a sentence. */
            isSentenceStart?: boolean;
            /** The character index range for the span. The end index is exclusive. */
            labelBeginCharIndex?: string;
            labelEndCharIndex?: string;
            /** The time of the span. */
            timeMs?: string;
        }
        interface VideoContentSearchAnchorsCommonFeatureSet {
            /** A summary of the Dolphin descriptiveness scores of the anchors in the set. */
            dolphinDescriptivenessStats?: VideoContentSearchMetricStats;
            /** A summary of the Dolphin usefulness scores of the anchors in the set. */
            dolphinUsefulnessStats?: VideoContentSearchMetricStats;
            /** A summary of the MUM descriptiveness scores of the anchors in the set. */
            mumDescriptivenessStats?: VideoContentSearchMetricStats;
            /** A summary of the MUM usefulness scores of the anchors in the set. */
            mumUsefulnessStats?: VideoContentSearchMetricStats;
        }
        interface VideoContentSearchAnchorsThumbnailInfo {
            /** Whether or not any of the anchor thumbnails have missing Starburst embeddings. */
            hasMissingStarburst?: boolean;
            /** Whether or not any of the anchors have missing thumbnails. */
            hasMissingThumbnails?: boolean;
            /** A score representing how diverse a set of thumbnails is. This is currently defined as one minus the median pairwise cosine similarity between thumbnail Starburst embeddings. */
            thumbnailDiversity?: number;
        }
        interface VideoContentSearchAnchorThumbnail {
            /** Serving docid for the thumbnail in the images-tbn tables. */
            imagesearchDocid?: string;
            /** Set to true when no thumbnail could be generated for this anchor. */
            isThumbnailMissing?: boolean;
            /** Metadata about the anchor thumbnail computed by Amarna, including dimensions and the size in bytes. */
            servingMetadata?: ImageBaseThumbnailMetadata;
            /** Information about the thumbnail anchor. */
            thumbnailInfo?: VideoContentSearchAnchorThumbnailInfo;
            /** Millisecond timestamp of the frame used for the thumbnail. */
            timestampMs?: number;
        }
        interface VideoContentSearchAnchorThumbnailInfo {
            /** Entropy of the clustered color distribution. */
            colorEntropy?: number;
            /** Thumbnail image data for SafeSearch classification. */
            imageData?: ImageData;
            /** Convenience field that consolidates signals for whether this thumbnail is safe. */
            isUnsafe?: boolean;
            /** 64d float vector of starburst v4 embedings. */
            starburstV4Embedding?: DrishtiDenseFeatureData;
            /** The raw data for a thumbnail. */
            thumbnailBytes?: string;
        }
        interface VideoContentSearchAspect {
            /** Product aspect to be used if non of the other aspects exist. */
            fallbackAspect?: string;
            /** Product aspect produced by running SAFT annotation. */
            saftAspect?: string;
        }
        interface VideoContentSearchAsrCaption {
            /** The confidence score of the token: between 0 and 1. */
            confidence?: number;
            /** The duration that the token is spoken for. */
            durationMs?: number;
            /** The time in the video at which the token starts being spoken. */
            startTimeMs?: number;
            /** The speech token. */
            text?: string;
        }
        interface VideoContentSearchBleurtFeatures {
            candidate?: string;
            reference?: string;
        }
        interface VideoContentSearchCaptionEntityAnchorFeatures {
            /** If the description anchor has been recognized as an entity and that entity has also been mention in the ASR, this is the mention text from the ASR. */
            asrMentionText?: string;
            /**
             * The start index of the ASR entity mention from the beginning of the ASR transcript. The index is included so that individual mentions that share the same mid and time can be
             * distinguished which happens when an entity is mentioned multiple times in an ASR sentence. Each mid/asr_mention_transcript_offset will be unique.
             */
            asrMentionTranscriptOffset?: number;
            /** The nearest ASR sentence. */
            asrSentence?: string;
            /** The begin time in ms of the ASR sentence. */
            asrStartTime?: number;
            /** The result of the BERT inference using the title, ASR sentence and entity mention text. */
            bertScores?: number[];
            /** A score to help determine how specific this entity is. */
            broadness?: number;
            /** The percentage of the video covered by the span of the first mention to the last mention. */
            durationCoverage?: number;
            /** The webref connectedness score of the entity. */
            entityConnectedness?: number;
            /** A short text describing the entity. */
            entityDescription?: string;
            /** Information about how many documents the entity occurred in and how many total mentions the entity has across the entire video corpus. */
            entityInfo?: VideoContentSearchCaptionEntityDocInfo;
            /** Whether or not the entity mention text appears in the description of the video. */
            entityMentionInDescription?: boolean;
            /** The estimated begin time in ms of the entity mention using the text offset divided by the ASR duration. */
            estimatedMentionTime?: number;
            /** Average similarity between this anchor and other anchors in the set. */
            groupCohesion?: number;
            /** The confidence of the hypernym used as the set label. */
            hypernymConfidence?: number;
            /** Number of hypernyms used for calculating similarity. */
            hypernymCount?: number;
            /** The cosine similarity between the document salient terms and the hyperpedia hypernyms for a given entity. */
            hyperpediaSalientTermsSimilarity?: number;
            /** Whether or not this entity is in the webref entities. */
            inWebrefEntities?: boolean;
            /** True if the given entity appears as an Oracle followup query. */
            isOracleEntity?: boolean;
            /** Whether this entity counts as a 'product' for the purpose of dividing entities between the 'related topics' and 'products in this video' features. */
            isProduct?: boolean;
            /** The maximum confidence of all of the entity mentions in the transcript. */
            maxMentionConfidence?: number;
            /** The confidence that the ASR mention matches the given mid. */
            mentionConfidence?: number;
            /** Number of times an entity is mentioned in the ASR transcript. */
            mentions?: number;
            /** The duration in ms between this anchor and the previous anchor or the beginning of the video if this is the first anchor. */
            msFromLastAnchor?: number;
            /** The ASR sentence after asr_sentence or "" if it is the last sentence. */
            nextAsrSentence?: string;
            /** The ASR text of each mention of the entity. */
            otherAsrMentionText?: string[];
            /** Each time the entity was mentioned. */
            otherEstimatedMentionTimes?: number[];
            /** The ASR sentence before asr_sentence or "" if it is the first sentence. */
            previousAsrSentence?: string;
            /** The confidence that the ASR mention is a trusted name. */
            trustedNameConfidence?: number;
            /** The webref entity topicality score if the entity is a webref entity and 0 if not. */
            webrefEntityTopicality?: number;
        }
        interface VideoContentSearchCaptionEntityAnchorSetFeatures {
            /** The total score used for filtering and selecting entity sets. */
            aggregateScore?: number;
            /** The prefiltered size of the entity set. */
            clusterSize?: number;
            /** The number of entities in the anchor set that are in the webref entities. */
            entitiesInWebrefEntities?: number;
            /** The number of anchors where the entity mention text appears in the description of the video. */
            entityMentionInDescriptionCount?: boolean;
            /** The average cosine similarity between hypernyms of members of the set. */
            groupCohesion?: number;
            /** The most prominent hypernym across the entities in the set. */
            hypernym?: string;
            /** The salience of the best hypernym for the set. */
            hypernymSalience?: number;
            /** Median number of times any member of the set was mentioned in the ASR transcript. */
            medianMentions?: number;
            /** Mentions divided by the total number of entity mentions in the video. */
            mentionSalience?: number;
            /** Salience of the set computed by aggregating the hypernyms from each member and calculating the cosine similarity with the salient terms. */
            salience?: number;
            /** The top N hypernyms for the entities in the set. */
            topHypernym?: string[];
            /** Number of times any member of the group was mentioned in the ASR transcript. */
            totalMentions?: number;
        }
        interface VideoContentSearchCaptionEntityDocInfo {
            /** The number of documents where this entity was mentioned at least once. */
            entityDocCount?: string;
            /** The number of times the entity was mentioned across the entire corpus. */
            entityMentionCount?: string;
            /** The entity id. */
            mid?: string;
            /** The number of documents in the corpus. */
            totalDocCount?: string;
            /** The number of mentions of any entity across the entire corpus. */
            totalMentionCount?: string;
        }
        interface VideoContentSearchCaptionInfo {
            asrCaption?: VideoContentSearchAsrCaption[];
            saftDocument?: NlpSaftDocument;
        }
        interface VideoContentSearchCaptionLabelFeatures {
            /** OCR anchors with overlapping time-window with this anchor */
            alignedOcrTexts?: VideoContentSearchOCRText[];
            /** The time stamp in milliseconds for the reference text (e.g. description anchor time). */
            alignedTime?: string;
            /** Text around the aligned_time of a long duration, say [-15 minutes, +15 minutes] */
            contextText?: string;
            /** The main label text for the feature. */
            labelText?: string;
            /** Identified matching text by similarity. */
            textSimilarityFeatures?: VideoContentSearchTextSimilarityFeatures;
            /** The text span in the passage starting from the aligned time. */
            textSpanAtAlignedTime?: string;
        }
        interface VideoContentSearchCaptionSpanAnchorFeatures {
            /** The features used to construct the inference example. */
            dolphinFeatures?: VideoContentSearchSpanDolphinFeatures;
            /** The inference result from the Dolphin span model. */
            dolphinScores?: VideoContentSearchSpanDolphinScores;
            /** Embedding distances (e.g. cosine distance) to the other anchors of the same video. */
            embeddingDistance?: number[];
            /** Time gap in ms to the next anchor. Always positive number. */
            postGapInMs?: number;
            /** Time gap in ms to the previous anchor. Always a positive number. */
            preGapInMs?: number;
            /** The range of tokens in video_info.saft_doc for the anchor label. */
            saftBeginTokenIndex?: number;
            saftEndTokenIndex?: number;
            saftTranscriptEndCharOffset?: number;
            /** The range of characters in video_info.saft_transcript for the anchor label. */
            saftTranscriptStartCharOffset?: number;
            /** A summary of the ASR confidence for the selected candidate. */
            spanAsrConfidenceStats?: VideoContentSearchMetricStats;
            /** A summary of the Dolphin span token scores for the selected candidate. */
            spanDolphinScore?: VideoContentSearchMetricStats;
            /** Word count of the span text, tokenized with SAFT. */
            wordCount?: number;
        }
        interface VideoContentSearchCaptionSpanAnchorSetFeatures {
            /** A summary of the dolphin scores over the anchor set. */
            anchorSetDolphinScoreStats?: VideoContentSearchMetricStats;
        }
        interface VideoContentSearchCommentAnchorSetFeatures {
            replies?: VideoContentSearchCommentAnchorSetFeaturesComment[];
            rootComment?: VideoContentSearchCommentAnchorSetFeaturesComment;
        }
        interface VideoContentSearchCommentAnchorSetFeaturesComment {
            /** The ID that YouTube uses to uniquely identify the comment. */
            commentId?: string;
            /** The total number of likes (positive ratings) the comment has received. */
            likeCount?: number;
            /** The MiniStanza object that represents the comment. If populated, all other fields in this message may be empty. */
            miniStanza?: YoutubeCommentsClusteringMiniStanza;
            /** The date and time when the comment was orignally published, specified in ISO 8601 format. */
            publishedAt?: string;
            /** The comment's text, in HTML. */
            textDisplay?: string;
            /** The original, raw text of the comment. */
            textOriginal?: string;
            /** The date and time when the comment was last updated, specified in ISO 8601 format. */
            updatedAt?: string;
        }
        interface VideoContentSearchDescriptionAnchorFeatures {
            /** When the description anchor text has been recognized as an entity, how much of the description anchor text is covered by the entity mention. */
            entityTextCoverage?: number;
            /** Whether or not a mention of the description anchor exists in the ASR. */
            inAsr?: boolean;
            /** Whether or not the anchor was created from the description for use in training data. This will be set to true for positive examples and false for negative examples. */
            isDescriptionAnchor?: boolean;
            /** The distance from the ASR sentence to the description anchor time in ms. */
            spanToAsrTime?: number;
        }
        interface VideoContentSearchDescriptionAnchorSetFeatures {
            /** The number of description anchors that were matched to captions in the ASR. */
            asrAnchorCount?: number;
            /** The fraction of anchors that were matched to captions in the ASR. */
            asrAnchorFraction?: number;
            /** The number of unique mids which where matched to description anchors. */
            uniqueAsrMidCount?: number;
        }
        interface VideoContentSearchDescriptionSpanInfo {
            /** The number of tokens in the context (sentence) where the description span is extracted from. */
            contextTokenCount?: number;
            /** The inference result from the Dolphin span model if the anchor's source is description span. */
            dolphinScores?: VideoContentSearchSpanDolphinScores;
            /**
             * A summary of the Dolphin span token scores for the selected candidate. Currently, dolphin_scores in DescriptionSpanInfo would only contain a single span candidate so this field is
             * essentially the copy of the score_stats for that span candidate.
             */
            spanDolphinScoreStats?: VideoContentSearchMetricStats;
            /**
             * The number of tokens in the description span. The description span is formed from non-contiguous segment spans of a sentence (context), where each segment span's score satifsies the
             * min span thresholds.
             */
            spanTokenCount?: number;
            /** The ratio of span_token_count / context_token_count. */
            spanTokenCountRatio?: number;
        }
        interface VideoContentSearchDolphinEnsembleScore {
            /** The score generated by the Dolphin callout model. */
            dolphinScore?: number;
            modelName?: string;
        }
        interface VideoContentSearchDolphinFeatures {
            /** The alt query used for building the Dolphin example. */
            altQuery?: string;
            /** The answer used for building the Dolphin example. */
            answer?: string;
            /** The query used for building the Dolphin example. */
            query?: string;
            /** The time stamp of the video anchor in milliseconds. */
            timeMs?: string;
            /** The title used for building the Dolphin example. */
            title?: string;
            /** The url of the video. */
            url?: string;
        }
        interface VideoContentSearchDolphinScoringConfig {
            /** The output put keys for Dolphin PredictResponse */
            descriptivenessOutputKey?: string;
            /** If the dolphin model is an ensemble model (e.g. Video QnA model which consists of 4 teacher models), stores each individual model name. */
            ensembleModelNames?: string[];
            /** The inference batch size to use for inference methods that handle batching. */
            inferenceBatchSize?: number;
            /** The method to use for inference. This must be set or inference will fail. */
            inferenceMethod?: string;
            /** Holds value of flag --max_rpc_retries. */
            maxRpcRetries?: number;
            /** Model name used for ModelSpec in PredictRequest used in the PredictionService API. */
            modelName?: string;
            /** Only used when using the bulk_inference API. See go/dolphin-models to learn about the different dolphin models. */
            modelPath?: string;
            /** TODO(alexiaxu) To deprecate this field in the future Output key for Dolphin PredictResponse. */
            outputKey?: string;
            /** Holds value of flag --rpc_deadline (converted to seconds). */
            rpcDeadlineSeconds?: number;
            /** Tensorflow inference BNS address when using PredictionService API. */
            serviceBns?: string;
            usefulnessOutputKey?: string;
        }
        interface VideoContentSearchEntityAnnotations {
            /** The Webref category that this entity belongs to e.g. "/moka/software". */
            category?: string;
            /** The overall confidence that this entity is annotated somewhere in the label. */
            confidence?: number;
            /** Whether or not this entity belongs to a set of blocklisted categories. */
            isRestricted?: boolean;
            /** The Webref entity mid. */
            mid?: string;
        }
        interface VideoContentSearchEntityGroupInfo {
            /** Collection id. */
            collectionId?: string;
            /** Label for this anchor group. */
            label?: string;
        }
        interface VideoContentSearchFrameSimilarityInterval {
            /** Timestamp in milliseconds for the last frame in this frame interval. */
            framesEndTimestampMs?: string;
            /** The similarity between this topic and starburst features for frames in [frames[frame_level_starburst_start_index], frames[frame_level_starburst_start_index + len(frame_similarity)]. */
            frameSimilarity?: number[];
            /** The index of the first frame within this interval of similar frames. VideoMultimodalTopicFeatures.frame_starburst_data. */
            framesStarburstStartIndex?: number;
            /** Timestamp in milliseconds for the first frame in this frame interval. */
            framesStartTimestampMs?: string;
        }
        interface VideoContentSearchFrameStarburstData {
            /** Raw float feature vector of the starburst representation. */
            denseVector?: number[];
            /** Starburst version. Possible values are: STARBURST_TEXT_V4 STARBURST_TEXT_V4_5 STARBURST_TEXT_V4_PLC STARBURST_TEXT_V5 */
            sbVersion?: string;
            /** Timestamp in milliseconds for this frame. */
            timestampMs?: string;
        }
        interface VideoContentSearchGenerativePredictionFeatures {
            /** Features for inferences from generative models. */
            passage?: string;
            /** Inference results. */
            predictions?: string[];
            target?: string;
        }
        interface VideoContentSearchGenerativeTopicPredictionFeatures {
            /** This field is present if we already have a ground truth topic from the training data. */
            groundTruthTopic?: string;
            /** The name of the model where the predictions come from. */
            modelName?: string;
            /** Inference results from the prediction service. Since we generally use beam search with beam_size > 1, this field is repeated to capture all the generated topic beams. */
            predictions?: string[];
        }
        // tslint:disable-next-line:no-empty-interface
        interface VideoContentSearchInstructionAnchorFeatures {
        }
        interface VideoContentSearchInstructionTrainingDataAnchorFeatures {
            /**
             * The match info about the description anchor matches with the ASR n-grams in the instruction passage. Each element represents the best match between a given description anchor and
             * all qualified n-grams within the passage.
             */
            bestAsrAndDescriptionAnchorsMatchInfo?: VideoContentSearchSimilarityMatchInfo[];
            /**
             * The match info about the description anchor matches with the instruction anchors in a instruction passage. Each element represents the best match between a given description anchor
             * and all the instruction anchors in the passage.
             */
            bestDescriptionAndInstructionAnchorsMatchInfo?: VideoContentSearchSimilarityMatchInfo[];
            /**
             * The match info about the instruction steps matches with the ASR. Each instruction step corresponds to a step extracted from a web doc. Each instruction passage can contain multiple
             * instruction step matches thus the repeated field.
             */
            instructionAnchorsMatchInfo?: VideoContentSearchSimilarityMatchInfo[];
        }
        interface VideoContentSearchListAnchorFeatures {
            /** The babel match info of the list anchor with its matched ASR text. */
            babelMatch?: VideoContentSearchTextMatchInfo;
            /** The description span metadata about list anchor when the anchor source is DESCRIPTION_SPANS. */
            descriptionSpanInfo?: VideoContentSearchDescriptionSpanInfo;
            /** The list item index of this anchor in the video description. */
            listItemIndex?: number;
            /** The metadata about this list item's matches with different ASR snippets. This is currently used in the base model (DTW) to generate candidate anchors. */
            matchScores?: VideoContentSearchMatchScores[];
            /** The score from the pretrigger model. */
            pretriggerScore?: number;
            /** Babel similarity between the anchor and the video title. */
            titleAnchorBabelMatchScore?: number;
        }
        interface VideoContentSearchListAnchorSetFeatures {
            /** The following fields are used for description span anchors, The aggregated span token texts over all the span candidates of the anchor set. */
            aggregatedSpanText?: string;
            /** A summary of the span scores over the anchor set. This summary is calculated over the aggregation of the individual token spans belonging to the span candidates of anchors. */
            anchorSetSpanScoreStats?: VideoContentSearchMetricStats;
            /** Median, average and standard deviation of babel_match_score among anchors in the same VideoAnchors cluster. */
            babelMatchScoreStats?: VideoContentSearchMetricStats;
            /** A summary of the context token counts over the anchor set. */
            contextTokenCountStats?: VideoContentSearchMetricStats;
            /**
             * The ratio of anchors timespan duration over the total duration of the video. Anchors timespan duration is defined as the time span from the first anchor to the last anchor in
             * VideoAnchors.
             */
            durationSpanRatio?: number;
            /** Median, average and standard deviation of duration_to_predicted_time_ms among anchors in the same VideoAnchors cluster. */
            durationToPredictedTimeMsStats?: VideoContentSearchMetricStats;
            /** The source of anchors extracted from the video descriptions. */
            listAnchorSource?: string;
            /** The total number of list items mentioned in the video description. Not all these list items are necessarily found as list anchors. */
            listDescriptionItemsSize?: number;
            /**
             * The number of matched anchors in the list anchors over the total number of post-filtering list items in the video description, i.e. matched_list_description_anchors_ratio =
             * matched_list_description_anchors_size / post_filtering_list_description_items_size.
             */
            matchedListDescriptionAnchorsRatio?: number;
            /**
             * The number of matched list anchors found in the ASR. The matched list anchors are a subset of the post-filtering list items in the video description, and as such
             * matched_list_description_anchors_size <= post_filtering_list_description_items_size.
             */
            matchedListDescriptionAnchorsSize?: number;
            /**
             * The total number of list items in the video description that are actually considered for matching. This is a subset of list items in the video description that passed filterings
             * such as language filtering, i.e. post_filtering_list_description_items_size <= list_description_items_size
             */
            postFilteringListDescriptionItemsSize?: number;
            /** Median, average and standard deviation of pretrigger_score among anchors in the same cluster. */
            pretriggerScoreStats?: VideoContentSearchMetricStats;
            /** A summary of the span token count ratios over the anchor set. */
            spanTokenCountRatioStats?: VideoContentSearchMetricStats;
            /** A summary of the span token counts over the anchor set. */
            spanTokenCountStats?: VideoContentSearchMetricStats;
        }
        interface VideoContentSearchListTrainingDataAnchorFeatures {
            /** The timestamp of when the description anchor is annotated to appear in the video in ms. */
            descriptionAnchorTimeMs?: number;
            /** The time gap of when the description anchor is annotated to appear in the video (description_anchor_time_ms) from when it's matched in the ASR as the list anchor. */
            descriptionAnchorTimeToMatchedTimeMs?: string;
            /**
             * Closest edit distance between the anchor generated by description span and the description anchor where the span anchor must be within small threshold time difference of the
             * description anchor timestamp.
             */
            editDistance?: number;
            /** edit_distance over the description anchor's label length. */
            editDistanceRatio?: number;
            /** The description anchor text used for matching to Span anchor text. */
            matchedDescriptionText?: string;
            /** The description span anchor text that was the best match for the nearby description anchor. */
            matchedSpanText?: string;
        }
        interface VideoContentSearchListTrainingDataSetFeatures {
            /** Summary of the edit_distance_ratios of the description spans from their best matched description anchor texts. */
            editDistanceRatioStats?: VideoContentSearchMetricStats;
            /** Summary of the edit_distances of the description spans from their best matched description anchor texts. */
            editDistanceStats?: VideoContentSearchMetricStats;
            /**
             * Median, average and standard deviation of time gaps of when the description anchors is annotated to appear in the video (description_anchor_time_ms) from when they are matched in
             * the ASR as the list description anchors.
             */
            matchedDescriptionAnchorsTimegapStats?: VideoContentSearchMetricStats;
            /** Number of description anchors in the description of this video. */
            numDescriptionAnchors?: number;
        }
        interface VideoContentSearchMatchScores {
            matchInfo?: VideoContentSearchTextMatchInfo[];
            /** The method used for matching, e.g. 'babel', 'nlp', 'neon', ßß'phonetic'. */
            method?: string;
        }
        interface VideoContentSearchMetricStats {
            max?: number;
            mean?: number;
            median?: number;
            min?: number;
            stddev?: number;
            sum?: number;
        }
        interface VideoContentSearchMultimodalTopicFeatures {
            /**
             * The list of frame sequence similarities to this topic. The list of frames are picked to be around the topic timestamp. The set of frames selected are thresholded at a value to
             * ensure the selected frame intervals are similar to the query.
             */
            frameSimilarityInterval?: VideoContentSearchFrameSimilarityInterval[];
            /** The inference results from the prediction services that generate the topics. */
            generativeTopicPredictionFeatures?: VideoContentSearchGenerativeTopicPredictionFeatures[];
            /** Features related to queries generated using document navboost data with timed anchors. Only populated if the query was generated using this approach. */
            navboostAnchorFeatures?: VideoContentSearchNavboostAnchorFeatures;
            /** The text of the generated topic. */
            topic?: string;
            /** End time of the topic. */
            topicEndMs?: string;
            /** Start time of the topic. */
            topicStartMs?: string;
            /** How the query was generated. */
            videoQuerySource?: string;
        }
        interface VideoContentSearchMultimodalTopicTrainingFeatures {
            /**
             * The similarity info for the frame with maximum similarity to the topic in its visual interval. The repeated similarity field in this proto has a single value corresponding to the
             * maximum similarity. This similarity score is used to filter and pick the training data examples.
             */
            maxFrameSimilarityInterval?: VideoContentSearchFrameSimilarityInterval;
            /** The topic/query normalized for Navboost and QBST lookups as well as fetching of the Rankembed nearest neighbors. */
            normalizedTopic?: string;
            /** QBST terms overlap features for a candidate query. */
            qbstTermsOverlapFeatures?: VideoContentSearchQbstTermsOverlapFeatures;
            /** Rankembed similarity features for a candidate nearest neighbor rankembed query. */
            rankembedNearestNeighborsFeatures?: VideoContentSearchRankEmbedNearestNeighborsFeatures;
            /** The information about the saft entity annotation for this topic. */
            saftEntityInfo?: VideoContentSearchSaftEntityInfo;
            /** Raw float feature vector of the topic's co-text embedding representation in the Starburst space. */
            topicDenseVector?: number[];
        }
        interface VideoContentSearchNamedEntity {
            /** Type name: e.g. /saft/person for a person's name. */
            entityType?: string;
            /** Text referring to an entity of type entity_type; */
            text?: string;
        }
        interface VideoContentSearchNavboostAnchorFeatures {
            /** The anchor text used in the generated query. */
            anchorText?: string;
            /** The navboost query used in the generated query. */
            navboostText?: string;
            /** How the navboost-anchor query was constructed. */
            source?: string;
        }
        interface VideoContentSearchOcrAsrFeature {
            /** The minimum char edit distance between the normalized OCR text and candidate word strings taken from a time window around the OCR appearance. */
            minCharEditDistance?: number;
            /** The matched ASR candidate for minimum char edit distance. */
            minCharEditDistanceAsrText?: string;
            /** The min_char_edit_distance divided by the length of the OCR string. */
            minCharEditDistancePercent?: number;
            /** The normalized OCR text which was used to match the candidate. */
            ocrTextNormalizedForCharMatch?: string;
            /** The length of the normalized OCR text. */
            ocrTextNormalizedForCharMatchLength?: number;
            /** The score from the pretrigger model. */
            pretriggerScore?: number;
            /** The ASR text that was used for the word overlap calculation. */
            wordOverlapAsrText?: string;
            /** The number of words found both in the OCR text and the ASR in a time window around OCR appearance. */
            wordOverlapCount?: number;
            /** The word_overlap_count divided by the number of words in the OCR text. */
            wordOverlapPercent?: number;
        }
        interface VideoContentSearchOcrAsrSetFeature {
            /** The word_overlap_score divided by the greatest word_overlap_score for any cluster in the VideoAnchorSets. */
            normalizedWordOverlapScore?: number;
            /** A score based on the number of overlapped words between the OCR and ASR for anchors in the cluster. */
            wordOverlapScore?: number;
        }
        interface VideoContentSearchOcrDescriptionTrainingDataAnchorFeatures {
            /** The string edit distance from the anchor label to the nearest OCR text. */
            editDistance?: number;
            /** edit_distance over the description anchor's label length. */
            editDistanceRatio?: number;
            /** The description anchor text used for matching to OCR text. */
            matchedDescriptionText?: string;
            /** The time of the selected OCR frame in ms. The best frame in a window around the target description anchor will be selected. */
            matchedFrameTimeMs?: number;
            /** The OCR text that was the best match for the nearby description anchor. */
            matchedOcrText?: string;
        }
        interface VideoContentSearchOcrDescriptionTrainingDataSetFeatures {
            /** The max edit distance of any description anchor to its closest OCR text. */
            maxEditDistance?: number;
            /** The maximum of (edit distance of any description anchor to its closest OCR text over description anchor label length). */
            maxEditDistanceRatio?: number;
            /** The median edit distance of any description anchor to its closest OCR text. */
            medianEditDistance?: number;
        }
        interface VideoContentSearchOCRText {
            /** Additional details about position/font/color etc. for the OCR text */
            ocrFeature?: VideoContentSearchOnScreenTextFeature;
            /** The OCR recognized text label */
            ocrText?: string;
            /** The time in ms at which the OCR text appears on the frame */
            timeMs?: string;
        }
        interface VideoContentSearchOcrVideoFeature {
            /** Average text area ratio throughout video frames. Text area ratio for a frame is defined by sum(text area) / image area. */
            averageTextAreaRatio?: number;
            /** Cluster id to the num of frames in each cluster. */
            clusterIdToFrameSize?: { [P in string]: number };
            /** Total time of this video in milliseconds. */
            durationInMs?: number;
            /** Video level detected language by lang id, aggregated from each frame. */
            langIdDetectedLanguage?: string;
            /** The number of ShotInfo clusters. */
            numClusters?: number;
            /** The number of video frames contained in ShotInfo cluster. */
            numFrames?: number;
            /** Video level detected language, aggregated from each frame. */
            ocrDetectedLanguage?: string;
        }
        interface VideoContentSearchOnScreenTextClusterFeature {
            /** Average confidence. */
            averageConfidence?: number;
            averageDurationRatio?: number;
            averageHorizontalPosition?: number;
            /**
             * Deprecated. Please use ocr_text_length_stats.median instead. The average length of anchor labels. average_ocr_text_length is deprecated, because now ocr_text_length_stats has a
             * field for holding the same value.
             */
            averageOcrTextLength?: number;
            /**
             * Deprecated. Please use text_height_ratio_stats.mean instead. Average value of text height ratio (over image height), which is taken average over the same text.
             * average_of_average_text_height_ratio is deprecated, because now text_height_ratio_stats has a field for keeping the same value.
             */
            averageOfAverageTextHeightRatio?: number;
            /** Average of label center position. */
            averageVerticalPosition?: number;
            /** The number of anchors in the cluster over the number of anchors in the video. */
            clusterRatio?: number;
            /** The number of anchors in the cluster. */
            clusterSize?: number;
            /** The number of anchors that had a counting number over the number of anchors in total. */
            countingNumberRatio?: number;
            /** Median, average and standard deviation of duration_ms among anchors in the same cluster. */
            durationMsStats?: VideoContentSearchMetricStats;
            /** Frame size ratio over total frames in video. */
            frameSizeRatio?: number;
            /** Average and standard deviation of logarithm of the length of labels among anchors in the same cluster. */
            logOcrTextLengthStats?: VideoContentSearchMetricStats;
            /** Average and standard deviation of log(1000 + duration_ms) among anchors in the same cluster. Since duration_ms can be zero, 1000 is added before applying logarithm. */
            logp1000DurationMsStats?: VideoContentSearchMetricStats;
            /** Average and standard deviation of log(average_text_height_ratio) among anchors in the same cluster. */
            logTextHeightRatioStats?: VideoContentSearchMetricStats;
            /** Stats for ratio of frame time intervals, over total video time. */
            maximumDurationRatio?: number;
            /** The maximum ratio of duration between two consecutive anchors to video duration. This is calculated after all anchor filtering has been completed. */
            maxVideoDurationRatioBetweenAnchors?: number;
            /** The median cluster distance for the anchors in the cluster. The way the distance is calculated will vary depending on the clustering method. */
            medianClusteringDistance?: number;
            medianDurationRatio?: number;
            /**
             * Deprecated. Please use text_height_ratio_stats.median instead. Median value of text height ratio (over image height), which is taken average over the same text.
             * median_of_average_text_height_ratio is deprecated, because now text_height_ratio_stats has a field for keeping the same value.
             */
            medianOfAverageTextHeightRatio?: number;
            /** Features for the overlap between OCR and ASR. */
            ocrAsrFeature?: VideoContentSearchOcrAsrSetFeature;
            /** Median, average and standard deviation of the length of labels among anchors in the same cluster. */
            ocrTextLengthStats?: VideoContentSearchMetricStats;
            stddevDurationRatio?: number;
            /** Median, average and standard deviation of average_text_height_ratio among anchors in the same cluster. */
            textHeightRatioStats?: VideoContentSearchMetricStats;
        }
        interface VideoContentSearchOnScreenTextFeature {
            /** The average of rotation angles (degree) of texts. */
            averageAngle?: number;
            /** Average value of confidence. */
            averageConfidence?: number;
            /** Font size or weight information. This is extracted from internal message, so may not be available in future. */
            averageFontsize?: number;
            averageFontweight?: number;
            averageHeightRatio?: number;
            backgroundBlue?: number;
            backgroundGray?: number;
            backgroundGreen?: number;
            backgroundRed?: number;
            boxHeightRatio?: number;
            /**
             * Box width and height ratio, against to the frame size, so the value range is [0, 1]. If this text feature consists of multiple text boxes, the box width / height is a union of each
             * text box.
             */
            boxWidthRatio?: number;
            /** Horizontal position of the center of this text, by ratio [0.0, 1.0]. */
            centerHorizontalPositionRatio?: number;
            /** Vertical position of the center of this text, by ratio [0.0, 1.0]. */
            centerVerticalPositionRatio?: number;
            /** Counting number in this anchor's original label. */
            countingNumber?: number;
            /** # of numbered anchors that are not out-of-order / # of all the numbered anchors. If no counting number is detected, this will be empty. */
            countingNumberOooRatio?: number;
            /** Prefix for counting number in this anchor's label. If no counting number is detected, this will be empty. */
            countingNumberPrefix?: string;
            /** Suffix for counting number in this anchor's label. If no counting number is detected, this will be empty. */
            countingNumberSuffix?: string;
            /** Duration time in millisec. */
            durationMs?: number;
            foregroundBlue?: number;
            /**
             * Color information, normalized to [0-1]. This color information is extracted from the largest word in the line entities of PageLayout message. See goodoc::PageLayoutEntity::Colors
             * for details.
             */
            foregroundGray?: number;
            foregroundGreen?: number;
            foregroundRed?: number;
            /** Whether or not this anchor had URL in its label before the label fixing step. */
            hadUrlInLabel?: boolean;
            /** # of LINE entities that are recognized as handwritten texts over # of merged LINE entities. */
            handwrittenTextRatio?: number;
            /** Whether or not the counting number in this anchor's label is out-of-order. If no counting number is detected, this will be empty. */
            isCountingNumberOoo?: boolean;
            /**
             * Languages predicted by OCR. "repeated" is employed for this field because LINE entities of PageLayout message are sometimes annotated with multiple languages, and also two
             * VideoAnchor that are annotated with different languages can be merged into one VideoAnchor. When two VideoAnchor are merged into one, the weight field values of the new VideoAnchor
             * will be the average of weight field values weighted by merged_line_count.
             */
            languages?: GoodocLanguageCombinationLanguage[];
            /** Left position of this text, by ratio [0, 1]. */
            leftPositionRatio?: number;
            /** The median distance between this anchor and other anchors in the cluster. The way the distance is calculated will vary depending on the clustering method. */
            medianClusteringDistance?: number;
            /** The number of LINE entities used for this text. */
            mergedLineCount?: number;
            /** # of OCR texts that appear in the same frame. If duration of this OCR text is not zero, the maximum number among multiple frames where this OCR text appears is set to this field. */
            nTextsInSameFrame?: number;
            /** The number of OCR texts that have the same text among temporally-merged OCR texts. */
            occurrenceCount?: number;
            /** occurrence_count over the number of anchors merged to this anchor. */
            occurrenceRatio?: number;
            /** Features for the overlap between OCR and ASR. */
            ocrAsrFeature?: VideoContentSearchOcrAsrFeature;
            /** The label this VideoAnchor originally had before label clearning steps. */
            originalLabel?: string;
            relativeShotTimeMsPosteriorToEndTime?: number;
            relativeShotTimeMsPosteriorToStartTime?: number;
            relativeShotTimeMsPriorToEndTime?: number;
            /**
             * Shot boundary time nearest to OnScreenText's start and end time. The time is relative to each OnScreenText's start / end time (ex. -1 means shot time exists prior to the start / end
             * time). If shot time and start/end time is the same, 0 is set in 'prior' field. If no shot info is available, the below fields are not set.
             */
            relativeShotTimeMsPriorToStartTime?: number;
            shotInfoCountDuringText?: number;
            /** OCR language that has the highest weight. */
            topOcrLanguage?: string;
            /** Note that top-left position is (0, 0) for position values. Top position of this text, by ratio [0, 1]. */
            topPositionRatio?: number;
        }
        interface VideoContentSearchQbstTermsOverlapFeatures {
            /** Fraction of salient terms of original query covered by anchor text. */
            qbstAnchorOverlap?: number;
            /** Fraction of salient terms of original query covered by top navboost query of the video. */
            qbstNavboostOverlap?: number;
        }
        interface VideoContentSearchQnaAnchorFeatures {
            /** Segment of text from the ASR. */
            answer?: string;
            descartesDotScore?: number;
            descartesRankingScore?: number;
            dolphinModelType?: string;
            /** Dolphin score calculated using the question as the query, the ASR passage as the answer. See go/dolphin-models to learn more. */
            dolphinScore?: number;
            /** Edit distance of the question and the title from 0 to 1 where 1 is most similar. */
            editDistance?: number;
            /** End time in milliseconds relative to the beginning of the video. */
            endMs?: string;
            ensembleScore?: number;
            /** True if question_title_similarity is less than 0.2. */
            isDuplicateOfTitle?: boolean;
            /** Neon similarity of question and title. */
            neonScore?: number;
            /** Pointwise GAP normalized score. Score ranges from 0 to 1 and corresponds to GAP precision. See go/wa-cgap-to-pgap-migration to learn more. */
            pointwiseNormalizedGapScore?: number;
            /** QBST similarity of question and title. */
            qbstScore?: number;
            /** NavBoostFeature f_query_count for questions that are NavBoost queries. */
            queryCount?: number;
            /** NavBoostFeature f_query_doc_count for questions that are NavBoost queries. */
            queryDocCount?: number;
            /** Question from Related Questions SSTable or NavBoost. */
            question?: string;
            questionTitleSimilarity?: number;
            questionType?: string;
            /** Start time in milliseconds relative to the beginning of the video. */
            startMs?: string;
            /** Duration of the video. */
            videoDurationMs?: string;
            /** Video title. */
            videoTitle?: string;
            /** Mid corresponding to the WebRef entity from the CDoc that was used to source the question. */
            webrefMid?: string;
            /** The WebRef entity topicality score. Learn more about this score at: http://go/topicality-score */
            webrefTopicalityScore?: number;
        }
        interface VideoContentSearchQnaAnchorSetFeatures {
            /** Path to Descartes background encoding in the form of a serialized drishti.DenseFeatureData proto. This is generated by the flume_generate_background_encoding binary. */
            backgroundEncodingPath?: string;
            /** This field is used for debugging which model the decartes_model_score is generated from. You can learn more about the Descartes model at go/descartes-qa. */
            descartesModelVersion?: string;
            /** Descartes score threshold for determining whether to output a QA pair as an anchor. This currently effects only the Descartes ranking score. */
            descartesScoreThreshold?: number;
            /** The configuration used for fetching Dolphin scores. */
            dolphinConfig?: VideoContentSearchDolphinScoringConfig;
            /** Path to Ranklab ensemble model used in post-trigger step. */
            ensembleModelPath?: string;
            /**
             * Minimum score for video anchor to pass the post-trigger step. Calculated by training a logisitic regression model with 95% precision. Training colab can be found at
             * go/video-qa-ensemble.
             */
            ensembleModelScoreThreshold?: number;
            /** Threshold for determining whether to consider an entity from a CDoc for sourcing questions on that topic. Learn more about this score at: http://go/topicality-score */
            minEntityTopicalityScore?: number;
            /** Threshold for determining whether questions belong in the same cluster. */
            minQuestionDistance?: number;
            /** Path to the Related Questions SSTable that maps entities to questions. */
            relatedQuestionsSstablePath?: string;
            /** The duration threshold for merging captions. */
            spanDurationSecs?: string;
        }
        interface VideoContentSearchRankEmbedNearestNeighborsFeatures {
            /** Rankembed similarity between the rankembed neighbor and the video anchor. */
            anchorReSimilarity?: number;
            /** Rankembed similarity between the rankembed neighbor and the top navboost query of the video. */
            navQueryReSimilarity?: number;
            /** Rankembed similarity between the rankembed neighbor and the original query candidate. */
            reSimilarity?: number;
        }
        interface VideoContentSearchSaftEntityInfo {
            /** Representative canonical name for the entity. */
            canonicalEntityName?: string;
            /** Score indicating the saliency (centrality) of this entity to the original_text. */
            entitySalience?: number;
            /** The type name, like "/saft/person", "/saft/art". See README.entity-types for the inventory of SAFT type tags. */
            entityTypeName?: string;
            /** Representative entity name mention extracted from original_text. */
            mentionText?: string;
            /** SAFT Mention type. */
            mentionType?: string;
            /**
             * Freebase MID for entity if this the saft entity corresponds to a Webref KG mid. This field is not always populated and is taken from FREEBASE_MID mid in EntityProfile in the saft
             * entity annotation.
             */
            mid?: string;
            /** The original input text (e.g. the anchor text) where the saft entity annotation was run on. */
            originalText?: string;
        }
        interface VideoContentSearchShoppingOpinionsAnchorFeatures {
            /** The anchor label. */
            anchorLabel?: string;
            /**
             * The first anchor_label mention position (word index, 0-based). It is computed from the snippet_sub_segment if exists. Otherwise it is computed from the snippet. It is not populated
             * if there is no such mention.
             */
            anchorLabelFirstMentionPos?: number;
            /**
             * The sentiment score of the anchor label, with range: [-1, 1]. If using Lumin Pro/Con tags as the anchor labels, the "Pro" Lumin tag will have a score of 1 and Con Lumin tag will
             * have a score of -1.
             */
            anchorLabelSentiment?: number;
            /** The number of times words in anchor label (that is not a stopword) being mentioned in the snippet. */
            anchorLabelWordsMentions?: number;
            /** The smaller number of anchor_label_first_mention_pos and lumin_aspect_first_mention_pos. */
            anchorOrAspectFirstMentionPos?: number;
            /**
             * The number of times words in anchor label or Lumin aspect (that is not a stopword) being mentioned in the snippet. If a word exists in both anchor label and Lumin aspect, it shall
             * be only counted once for a mention in the snippet.
             */
            anchorOrAspectWordsMentions?: number;
            /** Product aspect being discussed by this Shopping Opinions. */
            aspect?: VideoContentSearchAspect;
            /** The asr with sentence break that was used for pro/con extraction. */
            asrForProConExtraction?: string;
            /** The Babel similarity score between the snippet and the anchor label. */
            babelSimilarityScore?: number;
            /** The classification score of the anchor being a con opinion. */
            conScore?: number;
            /** The score from the Grampus model if the pro/con is extracted by Grampus. */
            grampusScore?: number;
            /** Whether the anchor is classified as a con opinion. */
            isCon?: boolean;
            /** Whether the anchor is classified as a pro opinion. */
            isPro?: boolean;
            /** True if the anchor is considered as pro or con when extracted from MUM. */
            isProConWhenExtractedFromMum?: boolean;
            /** The lumin aspect of the Pro/Con Lumin tag. e.g. "weight". */
            luminAspect?: string;
            /**
             * The first Lumin aspect mention position (word index, 0-based). It is computed from the snippet_sub_segment if exists. Otherwise it is computed from the snippet. It is not populated
             * if there is no such mention.
             */
            luminAspectFirstMentionPos?: number;
            /** The number of times words in Lumin aspect (that is not a stopword) being mentioned in the snippet. */
            luminAspectWordsMentions?: number;
            /** The Lumin model score for the anchor label against the segment. */
            luminScore?: number;
            /** The product aspect of the pro/con generated using the MUM model. */
            mumProductAspect?: string;
            /** The score from the MUM model if the pro/con anchor is extracted by MUM. */
            mumScore?: number;
            /**
             * Scores from Opinions Dolphin scorer. Opinions Dolphin scorer is built by finetuning the Dolphin-based Video Anchor Unified Scorer V2 on the Opinions anchors ratings. It outputs two
             * scores, which are optimized for descriptiveness and usefulness ratings respectively. 'descriptiveness_score' measures how well the anchor label describes the video section.
             * 'usefulness_score' measures how useful the anchor label is for jumping to an important section in the video. go/vs-opinions-migration-report
             */
            opinionsDolphinDescriptivenessScore?: number;
            opinionsDolphinUsefulnessScore?: number;
            /** The product name from title extracted by the grampus model. */
            productNameFromTitle?: string;
            /** The classification score of the anchor being a pro opinion. */
            proScore?: number;
            /** The question used to score this video segment. */
            question?: string;
            /** The ASR for the selected segment window. */
            snippet?: string;
            /** The QA model score for the selected segment window against the question. */
            snippetQaScore?: number;
            /** The go/scarlett sentiment score of the selected segment window. Positive score represents positive sentiment. Negative score represents negative sentiment. */
            snippetSentimentScore?: number;
            /** The ASR for the best matched sub segment inside the selected segment. */
            snippetSubSegment?: string;
            /** The QA model score for the best sub segment against the question. */
            snippetSubSegmentQaScore?: number;
            /** The go/scarlett sentiment score of the best matched sub segment. Positive score represents positive sentiment. Negative score represents negative sentiment. */
            snippetSubSegmentSentimentScore?: number;
            /** The number of words in the ASR for the best matched sub segment. */
            snippetSubSegmentWordCount?: number;
            /** The number of words in the ASR for the selected segment window. */
            snippetWordCount?: number;
        }
        interface VideoContentSearchSimilarityMatchInfo {
            /** The timestamp of when the first token in the token sequence is spoken in the video. */
            instructionStartMs?: number;
            /** The instruction step text coming from the web document. Currently only populated for best_description_and_instruction_anchors_match_info. */
            instructionText?: string;
            /** The reference text used for matching against token_sequence (e.g. description anchor text or instruction step text). */
            referenceText?: string;
            /**
             * The timestamp of when the reference text is pointing in the video (e.g. this is the description anchor timestamp when reference_text is description anchor. For instruction step used
             * as the reference, no timestamps exists and thus this field is not populated).
             */
            referenceTextTimeMs?: number;
            /** Similarity scorer name. */
            scoringMethodName?: string;
            /** The similarity score given by the scoring method specified by the message scoring_method_name. */
            similarityScore?: number;
            /** The index of the step in HowToInstructions that this token_sequence corresponds to. */
            stepIndex?: number;
            /** The matched token sequence text in ASR. */
            tokenSequence?: string;
            /** The length of the tokens in the token sequence. */
            tokenSequenceLength?: number;
            /** The token offset of the matched token sequence from the beginning of the document. */
            tokenStartPos?: number;
        }
        interface VideoContentSearchSpanDolphinFeatures {
            /** The text passage from ASR. */
            passage?: string;
            /** The title of the video. */
            title?: string;
        }
        interface VideoContentSearchSpanDolphinScores {
            /** The span candidates extracted from the list of span tokens. Each token is added to a span if its score is above a certain threshold. */
            spanCandidate?: VideoContentSearchSpanDolphinScoresSpanCandidate[];
            /** The token-score pairs for the passage. */
            spanToken?: VideoContentSearchSpanDolphinScoresSpanToken[];
        }
        interface VideoContentSearchSpanDolphinScoresSpanCandidate {
            /** A summary of the token asr_confidence scores that make up the candidate. */
            asrConfidenceStats?: VideoContentSearchMetricStats;
            /** A summary of the token scores that make up the candidate. */
            scoreStats?: VideoContentSearchMetricStats;
            /**
             * The passage text from which this span candidate belongs to. In case of description spans, this field stores the sentence containing the span candidate where the sentence is a subset
             * of the passage used for generating the span candidate.
             */
            sourcePassage?: string;
            /** The span candidate text. */
            text?: string;
            /** The start time for the span candidate. */
            timeMs?: string;
        }
        interface VideoContentSearchSpanDolphinScoresSpanToken {
            /** The ASR confidence for the token, if available. */
            asrConfidence?: number;
            /** Whether or not this token is the first token in a sentence. */
            isSentenceStart?: boolean;
            /** A score correlated with the probability that the token is part of a span candidate. */
            score?: number;
            /** The token text. */
            text?: string;
            /** The start time of the passage with this token. */
            timeMs?: string;
        }
        interface VideoContentSearchSportsKeyMomentsAnchorSetFeatures {
            /** The Prefilter classification label associated with the video that contains the VideoAnchorSets this object is asociated with. E.g. "basketball". */
            prefilterClassificationLabel?: string;
            /** Version of the underlying TensorFlow model. */
            tensorflowModelVersion?: string;
        }
        interface VideoContentSearchTextMatchInfo {
            /** The time gap of the matched_time_ms from the predicted timestamp of when this anchor should appear in the video. */
            durationToPredictedTimeMs?: string;
            /** The start token offset from the beginning of ASR where matched_asr_text starts. */
            matchedAsrStartPos?: number;
            /** The ASR text that was a candidate match for the list anchor. */
            matchedAsrText?: string;
            /** The timestamp of the matched ASR in the video in milliseconds. */
            matchedAsrTimeMs?: string;
            /** The ratio of the matched_asr_time_ms over the total duration of the video. */
            matchedAsrTimeRatio?: number;
            /** The number of tokens in matched_asr_text */
            matchedAsrTokenCount?: number;
            /** The ratio of the video description item index this match corresponds to over the total number of list description items for the video. */
            matchedDescriptionItemIndexRatio?: number;
            /** The video description text matched with the ASR that's used as the anchor label. */
            matchedDescriptionText?: string;
            /** The number of tokens in matched_description_text. */
            matchedDescriptionTokenCount?: number;
            /** The float similarty score from the anchor label to matched_asr_text. */
            matchScore?: number;
        }
        interface VideoContentSearchTextSimilarityFeatures {
            /** The hypothesis text that was used for the token overlap calculation. */
            hypothesisText?: string;
            /** The time in ms for the hypothesis_text. */
            hypothesisTextTime?: string;
            referenceText?: string;
            /** Similarity scorer name. */
            scoringMethodName?: string;
            /** The similarity score given by the scoring method specified by the message scoring_method_name. */
            similarityScore?: number;
            /** Token by token matching stats. Exact matched token count. */
            tokenMatchCount?: number;
            /** The token_overlap_count divided by the number of tokens in the hypothesis text. */
            tokenMatchPercent?: number;
            /** Word by word alignment. */
            wordAlignment?: VideoContentSearchTokenAlignment[];
        }
        interface VideoContentSearchTokenAlignment {
            /** Index of the token in hypothesis text. */
            hypothesisIndex?: number;
            /** Token in hypothesis. */
            hypothesisToken?: string;
            /** Index of the word in reference. */
            referenceIndex?: number;
            /** Token in label. */
            referenceToken?: string;
            /** Whether it's a perfect match. */
            tokenIsMatched?: boolean;
        }
        interface VideoContentSearchTokenTimingInfo {
            /**
             * Generated from th PseudoVideoData Timestamp Confidence field, which is quantized values in range 0-127. To convert to range 0-1 this field divides the PseudoVideoData Timestamp
             * Confidence field by 127.
             */
            confidence?: number;
            durationMs?: string;
            startMs?: string;
            /** Should be a single token. */
            text?: string;
        }
        interface VideoContentSearchVideoActions {
            /** startOffset_input name as defined in https://schema.org/SeekToAction */
            skipPatternStartOffsetInput?: string;
            /** Skip to time pattern as defined in https://schema.org/SeekToAction */
            skipToTimePattern?: string;
        }
        interface VideoContentSearchVideoAnchor {
            /** The score indicating anchor confidence. */
            anchorScore?: number;
            /** Specifies the type of the anchor. */
            anchorType?: string;
            /** Context text from ASR of long duration, used for longT5 models. */
            contextText?: string;
            /** When set, this is the link that should be used when clicking on a video anchor. This should jump to the given time in the video. */
            destinationUrl?: string;
            /** The duration of the video anchor in milliseconds. */
            duration?: string;
            /** The score indicating the usefulness of the entity identified by 'mid'. */
            entityScore?: number;
            /** If is_filtered is true, this field illustrates the reasons. */
            filterReason?: string[];
            /** If true, the anchor is filtered and not served online. */
            isFiltered?: boolean;
            /** Convenience field that consolidates signals for whether this label is safe. */
            isSafe?: boolean;
            /** whether this label is bad by go/scuti */
            isScutiBad?: boolean;
            /** The text label of the video anchor. */
            label?: string;
            /** The score indicating label confidence. */
            labelScore?: number;
            /** The mid of the video anchor. */
            mid?: string;
            /** Specifies named enitities the label has. */
            namedEntity?: VideoContentSearchNamedEntity[];
            /** The precision for which the anchor should trigger. For example, if the desired precision is 95%, anchors with precision_score < 0.95 should be removed. */
            precisionScore?: number;
            /** Additional scoring info used for debugging. */
            scoreInfo?: VideoContentSearchVideoAnchorScoreInfo;
            /** Visual tokens for the anchor. Eg. starbust feature vectors for several frames concatenated together. */
            starburstFeatures?: VideoContentSearchVisualFeatures;
            /** Data about the thumbnail to display for this anchor. */
            thumbnail?: VideoContentSearchAnchorThumbnail;
            /** The url for a frame to display for this anchor. */
            thumbnailUrl?: string;
            /** The time stamp of the video anchor in milliseconds. */
            time?: string;
            /** Timing info for each token in the anchor label. */
            tokenTimingInfo?: VideoContentSearchTokenTimingInfo[];
        }
        interface VideoContentSearchVideoAnchorRatingScore {
            /** Average score of bookmark usefulness. */
            averageBookmarkUsefulness?: number;
            /** Average score of description quality. */
            averageDescriptionQuality?: number;
            /** Furball URL(s) of the rating score (may have been rated more than once) */
            furballUrl?: string[];
        }
        interface VideoContentSearchVideoAnchors {
            anchorType?: string;
            /** The list of entity groups derived from the caption entities. */
            entityGroupInfo?: VideoContentSearchEntityGroupInfo;
            /** Same as above, but used for experimenting with new models. */
            experimentalPredictedQuerylessTocUsefulness?: number;
            /** If is_filtered is true, this field illustrates the reasons. */
            filterReason?: string[];
            /** If true, the anchor set is filtered and not served online. */
            isFiltered?: boolean;
            /** The anchor sources being used to generate this merged anchors. This field is filled only when this is a merged anchor. */
            mergedAnchorsSources?: string[];
            /** The score that predicts the usefulness of this anchor set on the Huh table of contents eval without considering the query. */
            predictedQuerylessTocUsefulness?: number;
            /** The quality of the anchor set. */
            score?: number;
            /** Additional scoring info used for debugging. */
            scoreInfo?: VideoContentSearchVideoAnchorsScoreInfo;
            /** Whether or not thumbnails should be displayed when serving anchors. */
            shouldServeThumbnails?: boolean;
            /** This field indicates that the thumbnail should be hidden but is forced to show. */
            thumbnailForced?: boolean;
            /** Information about the set of thumbnails. */
            thumbnailSetInfo?: VideoContentSearchAnchorsThumbnailInfo;
            videoAnchor?: VideoContentSearchVideoAnchor[];
            /** Information about the video's introduction segment. */
            videoIntroduction?: VideoContentSearchVideoIntroduction;
        }
        interface VideoContentSearchVideoAnchorScoreInfo {
            /** Common features for any anchor types. */
            anchorCommonFeatureSet?: VideoContentSearchAnchorCommonFeatureSet;
            /** Additional attachments which extend MessageSet. */
            attachments?: any;
            /** The path to the particular babel checkpoint */
            babelCheckpointPath?: string;
            /** Training features and debug info for caption entity anchors. */
            captionEntityAnchorFeatures?: VideoContentSearchCaptionEntityAnchorFeatures;
            /** Features for caption span anchors for use in training. */
            captionSpanAnchorFeatures?: VideoContentSearchCaptionSpanAnchorFeatures;
            /** Description anchor features for use in training. */
            descriptionAnchorFeatures?: VideoContentSearchDescriptionAnchorFeatures;
            /** Whether or not the anchor will be removed in the final proto. */
            filtered?: boolean;
            /** A description of why the anchor was removed. This is intended for debugging anchor sets which use multiple heuristics to filter anchors. */
            filterReason?: string[];
            /** Generated predictions from generative models */
            generativeFeatures?: VideoContentSearchGenerativePredictionFeatures[];
            /** Anchor level features for Instruction anchors. */
            instructionAnchorFeatures?: any;
            /** Training data features for Instruction anchors. */
            instructionTrainingDataAnchorFeatures?: VideoContentSearchInstructionTrainingDataAnchorFeatures;
            /** Detected language of label */
            labelLanguage?: string;
            labelTransformation?: VideoContentSearchVideoAnchorScoreInfoLabelTransformation[];
            /** List anchor features. */
            listAnchorFeatures?: VideoContentSearchListAnchorFeatures;
            /** Anchor level metadata about the description anchors used to build training data for list anchors. */
            listTrainingDataAnchorFeatures?: VideoContentSearchListTrainingDataAnchorFeatures;
            /** Multimodal features for a generated topic. */
            multimodalTopicFeatures?: VideoContentSearchMultimodalTopicFeatures;
            /** Features for a generated topic used to build training data for multimodal topics. */
            multimodalTopicTrainingFeatures?: VideoContentSearchMultimodalTopicTrainingFeatures;
            /** Normalized babel embedding of anchor.label(). If the label has more than one sentences, the embedding will be the averaged normalized embedding of each sentence. */
            normalizedBabelEmbedding?: number[];
            /** OCR anchor features. */
            ocrAnchorFeature?: VideoContentSearchOnScreenTextFeature;
            /** Anchor level metadata about the join of description anchors and OCR data which is used to build training data. */
            ocrDescriptionTrainingDataAnchorFeatures?: VideoContentSearchOcrDescriptionTrainingDataAnchorFeatures;
            /** Shopping Opinions anchor features. */
            opinionsAnchorFeatures?: VideoContentSearchShoppingOpinionsAnchorFeatures;
            /** Q&A anchor features for use in training. */
            qnaAnchorFeatures?: VideoContentSearchQnaAnchorFeatures;
            /** Human rating score, used for training. */
            ratingScore?: VideoContentSearchVideoAnchorRatingScore;
            /** The output of Safe Search's MultiLabelClassifier. */
            safeSearchClassifierOutput?: ClassifierPornQueryMultiLabelClassifierOutput;
            /** ASR matching feature for any anchor types. */
            textSimilarityFeatures?: VideoContentSearchTextSimilarityFeatures[];
            /** Information about the thumbnail anchor. */
            thumbnailInfo?: VideoContentSearchAnchorThumbnailInfo;
        }
        interface VideoContentSearchVideoAnchorScoreInfoLabelTransformation {
            /** A label for the transformation. */
            description?: string;
            /** The label that was transformated from. */
            sourceLabel?: string;
        }
        interface VideoContentSearchVideoAnchorSetRatingScore {
            /** Average score of set level description quality. */
            averageSetDescriptionQuality?: number;
            /** Average score of how useful the set is for navigation. */
            averageSetNavigationUsefulness?: number;
        }
        interface VideoContentSearchVideoAnchorSets {
            videoActions?: VideoContentSearchVideoActions;
            videoAnchors?: VideoContentSearchVideoAnchors[];
            videoInfo?: VideoContentSearchVideoInfo;
            videoScoreInfo?: VideoContentSearchVideoScoreInfo;
        }
        interface VideoContentSearchVideoAnchorsScoreInfo {
            /** Common set-level features for any anchor types. */
            anchorsCommonFeatureSet?: VideoContentSearchAnchorsCommonFeatureSet;
            /** Training features and debug info for caption entity anchors. */
            captionEntityAnchorSetFeatures?: VideoContentSearchCaptionEntityAnchorSetFeatures;
            captionSpanAnchorSetFeatures?: VideoContentSearchCaptionSpanAnchorSetFeatures;
            /** Set-level features for comment anchors. */
            commentAnchorSetFeatures?: VideoContentSearchCommentAnchorSetFeatures;
            /** Description anchor features for use in training. */
            descriptionAnchorSetFeatures?: VideoContentSearchDescriptionAnchorSetFeatures;
            /** Whether or not the anchors will be removed in the final proto. */
            filtered?: boolean;
            /** Set-level features for list anchors. */
            listAnchorSetFeatures?: VideoContentSearchListAnchorSetFeatures;
            /** Set level metadata about the description anchors used to build training data for List Description anchors. */
            listTrainingDataSetFeatures?: VideoContentSearchListTrainingDataSetFeatures;
            /** OCR anchor cluster features. */
            ocrAnchorClusterFeature?: VideoContentSearchOnScreenTextClusterFeature;
            /** Set level metadata about the join of description anchors and OCR data which is used to build training data. */
            ocrDescriptionTrainingDataSetFeatures?: VideoContentSearchOcrDescriptionTrainingDataSetFeatures;
            /** Metadata such as model versions for Q&A anchors. */
            qnaAnchorSetFeatures?: VideoContentSearchQnaAnchorSetFeatures;
            /** Human rating score, used for training. */
            ratingScore?: VideoContentSearchVideoAnchorSetRatingScore;
            sportsKeyMomentsAnchorSetFeatures?: VideoContentSearchSportsKeyMomentsAnchorSetFeatures;
        }
        interface VideoContentSearchVideoCommonFeatures {
            /** The total number of anchors in all video anchor sets. */
            anchorCount?: number;
            /** The caption data for the video transcript. The models used for unified scorer. Should be a filepath that contains saved_model.pb and a variables/ folder */
            captionInfo?: VideoContentSearchCaptionInfo;
            /** The model used for generating label_phrase_embedding. */
            labelPhraseEmbeddingModel?: string;
            unifiedScoringBertModels?: string[];
        }
        interface VideoContentSearchVideoGeneratedQueryFeatures {
            /** A description of why the video was removed. This is intended for debugging generated queries that are filtered at the video level. */
            filterReason?: string[];
            /**
             * The total number of passages that were input to generating queries for this video. This count might be bigger than the total number of anchors in the video as some of the anchors
             * might have been filtered by the pipeline.
             */
            prefilteredPassageCount?: number;
            /**
             * Entity annotations for one of the mids representing the video title. This entity is either one of the blocklisted entities if at least of the mentioned entities in the title belongs
             * to the blocklisted categories, or is the highest confidence entity for the title.
             */
            titleEntityAnnotations?: VideoContentSearchEntityAnnotations;
            /** The total number of queries that belong to the blocklisted categories for this video. */
            totalRestrictedQueries?: number;
        }
        interface VideoContentSearchVideoInfo {
            /** A hash of the video bytes used as a key to Amarna's video_metadata table. */
            amarnaDocid?: string;
            /** Language information, extracted from content_based_metadata.speech_properties. */
            asrLanguage?: string;
            /** Craps data from the video cdoc. */
            crapsData?: QualityNavboostCrapsCrapsData;
            /** Video description. */
            description?: string;
            /** Language information, extracted from DocProperties. */
            docLanguage?: string;
            /** Video duration in ms. */
            durationMs?: number;
            /** Whether or not automatic speech recognition has been generated for this video. */
            hasAsr?: boolean;
            /** Whether or not the video has description anchors. */
            hasDescriptionAnchors?: boolean;
            /** Convenience field that is false if any of the video's anchors have their is_safe field set to false. */
            isSafe?: boolean;
            /** Whether or not this is watchpage. */
            isWatchpage?: boolean;
            /** Navqueries for the video. */
            navqueries?: string[];
            /** NSR for the video page document. */
            nsr?: number;
            /** Number of views. */
            numViews?: string;
            /** ASR with timing info for each token copied from doc_videos.content_based_metadata.transcript_asr. */
            pseudoVideoData?: PseudoVideoData;
            /** The Saft document generated from the anchor labels. */
            saftDoc?: NlpSaftDocument;
            /** The transcript used to generate the Saft doc. */
            saftTranscript?: string;
            /** Salient term set from the document. This message contains a lot of data and dependencies, so sub-messages are disabled in model evaluation in scorer. */
            salientTermSet?: QualitySalientTermsSalientTermSet;
            /** The subindexid from the cdoc. Stored as an int to avoid a cyclical dependency. Should be convertible to CompositeDoc.SubIndexType. */
            subindexid?: number[];
            /** Video title. */
            title?: string;
            /** Video title language Language information, set automatically by the SAFT LangID. */
            titleLanguage?: string;
            /** Transcript annotations that include information about the ASR including timing and entity mentions. */
            transcriptAnnotations?: QualityWebanswersTranscriptAnnotations;
            /** Number of unique visits in Chrome. */
            uniqueChromeViews?: number;
            /** Document url. */
            url?: string;
            /** Top petacat verticals of the video produced by indexing/ml/vertical, sorted in descending order by vertical confidence. */
            verticalItem?: IndexingMlVerticalVerticalItem[];
            /** Genre of the video from the page metadata. Concatenate all with a comma separator if there are multiple genres. */
            videoGenre?: string;
            videoType?: string;
            /** Video url. Note that VideoInfo::url is a page url that has this video, while this is a video file url. */
            videoUrl?: string;
            /** Represents a collection of entities returned by the WebRef service. This message contains a lot of data and dependencies, so sub-messages are disabled in model evaluation in scorer. */
            webrefEntities?: RepositoryWebrefWebrefEntities;
        }
        interface VideoContentSearchVideoIntroduction {
            /** If set to true, it means the video has an introduction spanning from intro_start_ms to intro_end_ms. */
            hasIntro?: boolean;
            /**
             * Timestamp of the end of an introduction. Will only be set if has_intro is true. Indicates video may be skipped to this timestamp with minimal impact on understanding the overall
             * video contents.
             */
            introEndMs?: string;
            /** Timestamp of the beginning of an introduction. Will only be set if has_intro is true. This value may be nonzero. */
            introStartMs?: string;
        }
        interface VideoContentSearchVideoMultimodalTopicFeatures {
            /** Starburst vectors. Sorted by timestamp. */
            frameStarburstData?: VideoContentSearchFrameStarburstData[];
        }
        interface VideoContentSearchVideoScoreInfo {
            /** Anchor scoring features that apply to all anchor types. */
            commonFeatures?: VideoContentSearchVideoCommonFeatures;
            /** OCR specific video level feature. */
            ocrVideoFeature?: VideoContentSearchOcrVideoFeature;
            /** The output of Safe Search's MultiLabelClassifier for video title. */
            safeSearchClassifierOutput?: ClassifierPornQueryMultiLabelClassifierOutput;
            /** The version of this VideoAnchorSets in spanner. */
            version?: string;
            /** Video-level features that apply to all the generated queries within this VideoAnchorSets. */
            videoGeneratedQueryFeatures?: VideoContentSearchVideoGeneratedQueryFeatures;
            /** Video-level features for Multimodal topics. */
            videoMultimodalTopicFeatures?: VideoContentSearchVideoMultimodalTopicFeatures;
        }
        interface VideoContentSearchVisualFeatures {
            /** Starburst features semantic or visual/ */
            features?: number[];
            starbustVersion?: string;
            /** Starburst visual tokens */
            tokens?: number[];
        }
        interface VideoCrawlVideoInlinePlaybackMetadata {
            /** Timestamp (measured in seconds since epoch) when a video may not be used for inline playback in the interest feed. */
            expirationTimestampSec?: string;
            /** Publisher's Google Analytics Id to which we can report view metrics. */
            googleAnalyticsId?: string;
            /** All two-letter codes for countries where this video may NOT be played. */
            playbackCountryBlacklist?: string[];
            /** All two-letter codes for countries where this video may be played. If empty, then all countries not on the blacklist are allowed for playback. */
            playbackCountryWhitelist?: string[];
            /** Set of transcodes which are available for the video. */
            transcodeItags?: number[];
            /** VAST tag for ads to be played along with this video. Currently, we only support VAST tags from Doubleclick and FreeWheel. */
            vastTag?: string;
            /**
             * Identifier video is known by in the video infrastructure. The format given here is the YoutubeId format (base-64) used in Venom; for Viper/Bandaid/ StreamingURLService, convert to
             * ContentIdHex.
             */
            videoId?: string;
            /** Set if the video is hosted on an external CDN, in which case it is not to be transcoded and hosted at Google for the Interest Feed. */
            videoUrlOnExternalCdn?: string;
        }
        interface VideoDoViDecoderConfiguration {
            /** If a track contains the base layer substream. */
            blPresentFlag?: boolean;
            /** Whether the stream is compatible with other sets of standard. */
            dvBlSignalCompatibilityId?: number;
            dvLevel?: number;
            dvProfile?: number;
            /** Specifies the major version number of the Dolby Vision specification that the stream complies with. */
            dvVersionMajor?: number;
            /** Specifies the minor version number of the Dolby Vision specification that the stream complies with. */
            dvVersionMinor?: number;
            /** If a track contains the enhancement layer substream. */
            elPresentFlag?: boolean;
            /** dvhe, dvh1, dvav, dva1: https://screenshot.googleplex.com/ipMGXFqLX9E */
            fourccTag?: string;
            /** If a track contains the reference picture unit substream. */
            rpuPresentFlag?: boolean;
        }
        interface VideoFileColorInfo {
            matrixCoefficients?: string;
            primaries?: string;
            range?: string;
            transferCharacteristics?: string;
        }
        interface VideoFileContentLightLevel {
            /** Defines the maximum content light level (in cd/m^2) over the entire video. */
            maxContentLightLevel?: number;
            /** The maximum (over entire video) of the frame average light level. */
            maxFrameAverageLightLevel?: number;
        }
        interface VideoFileFramePackingArrangement {
            /** Grid positions */
            gridOffset0Horizontal?: number;
            gridOffset0Vertical?: number;
            gridOffset1Horizontal?: number;
            gridOffset1Vertical?: number;
            /** Content interpretation */
            interpretation?: string;
            /** Quincunx sampling flag indicating if quincunx sampling is used */
            quincunxSampling?: boolean;
            /** Arrangement type */
            type?: string;
        }
        interface VideoFileHDR10PlusStats {
            /** Application version is set to max version over all frames. */
            applicationVersion?: number;
            /** The average of the nominal maximum display luminance of the targeted system display over all frames. */
            averageTargetedSystemDisplayMaximumLuminance?: number;
            /** This flag is set if any frame has it. */
            masteringDisplayActualPeakLuminanceFlag?: boolean;
            maxNumWindows?: number;
            /** This flag is set if any frame has it. */
            targetedSystemDisplayActualPeakLuminanceFlag?: boolean;
        }
        interface VideoFileMasteringDisplayMetadata {
            /** Coordinates of the blue primary of the mastering display. */
            blue?: VideoFileMasteringDisplayMetadataCIE1931Coordinate;
            /** Coordinates of the green primary of the mastering display. */
            green?: VideoFileMasteringDisplayMetadataCIE1931Coordinate;
            /** Maximum luminance of the display (in cd/m^2). */
            maxLuminance?: number;
            /** Minimum luminance of the display (in cd/m^2). */
            minLuminance?: number;
            /** Coordinates of the red primary of the mastering display. */
            red?: VideoFileMasteringDisplayMetadataCIE1931Coordinate;
            /** Coordinates of the white point of the mastering display. */
            whitePoint?: VideoFileMasteringDisplayMetadataCIE1931Coordinate;
        }
        interface VideoFileMasteringDisplayMetadataCIE1931Coordinate {
            x?: number;
            y?: number;
        }
        interface VideoFileSphericalMetadata {
            /** Like above, but with high-pass motion filtering applied and yaw rotation limited to +/- 15-degrees */
            clampedOptimalFovBounds?: VideoFileSphericalMetadataFOVBounds;
            cubemap?: VideoFileSphericalMetadataCubemapProjection;
            deprecatedCroppedArea?: VideoFileSphericalMetadataCroppedArea;
            /** InitialView is from v1 spec, and is more or less equivalent to Pose from v2 spec. Therefore, InitialView found in xml metadata would populate the pose field in this proto. */
            deprecatedInitialView?: VideoFileSphericalMetadataViewDirection;
            equirect?: VideoFileSphericalMetadataEquirectProjection;
            fullPanoHeightPixels?: number;
            /** Dimensions of the full video frame. */
            fullPanoWidthPixels?: number;
            mesh?: VideoFileSphericalMetadataMeshProjection;
            /** Metadata source v2(svhd) */
            metadataSource?: string;
            /**
             * If video contains Wally-sanitized mesh and camera motion metadata (see go/wally-format ), this contains the optimal FOV (smallest FOV that encompass all combinations of input mesh
             * FOV and rotations). This field will only be present if full FfmpegAnalyze is performed.
             */
            optimalFovBounds?: VideoFileSphericalMetadataFOVBounds;
            pose?: VideoFileSphericalMetadataPose;
            /**
             * Mapping type used to map the sphere to the rectangular video E.g., "equirectangular", http://en.wikipedia.org/wiki/Equirectangular_projection This is kept as string so that we can
             * retain values that are unknown to us.
             */
            projectionType?: string;
            /** The number of camera sources used to generate this video. */
            sourceCount?: number;
            /** Whether the video is spherical or not. */
            spherical?: boolean;
            /** The stereo mode. */
            stereoMode?: string;
            /** Whether the video has already been stitched. */
            stitched?: boolean;
            /** The stitching software. */
            stitchingSoftware?: string;
            /** Epoch Timestamp of when the first frame in the video was recorded */
            timestamp?: string;
        }
        interface VideoFileSphericalMetadataCroppedArea {
            height?: number;
            left?: number;
            top?: number;
            width?: number;
        }
        interface VideoFileSphericalMetadataCubemapProjection {
            /**
             * Values 0 to 255 are reserved for current and future layouts. Value of 0 corresponds to a grid with 3 columns and 2 rows as follows: | right face | left face | up face | | down face
             * | front face | back face |
             */
            layout?: number;
            /** Number of pixels to pad from the edge of each cube face */
            padding?: number;
        }
        interface VideoFileSphericalMetadataEquirectProjection {
            projectionBoundsBottom?: number;
            projectionBoundsLeft?: number;
            projectionBoundsRight?: number;
            projectionBoundsTop?: number;
        }
        interface VideoFileSphericalMetadataFOVBounds {
            endTiltInDegrees?: number;
            endYawInDegrees?: number;
            startTiltInDegrees?: number;
            startYawInDegrees?: number;
        }
        interface VideoFileSphericalMetadataMeshProjection {
            /** Once mesh is analyzed, this field contains the bounds of the mesh(es) In case of stereo mesh, this will be the aggregate of both eye meshes */
            bounds?: VideoFileSphericalMetadataFOVBounds;
            content?: string;
            /** The mesh type field will only be populated when we have done analysis on the mesh. If this field is missing, mesh analysis has not been done. */
            type?: string;
        }
        interface VideoFileSphericalMetadataPose {
            headingDegrees?: number;
            pitchDegrees?: number;
            rollDegrees?: number;
        }
        interface VideoFileSphericalMetadataViewDirection {
            headingDegrees?: number;
            pitchDegrees?: number;
            rollDegrees?: number;
        }
        interface VideoLegosLegosAnnotationsSet {
            featureSetName?: string;
            legosAnnotations?: YoutubeDiscoveryLegosLegosAnnotations;
        }
        interface VideoLegosLegosAnnotationsSets {
            annotationsSet?: VideoLegosLegosAnnotationsSet[];
        }
        interface VideoMediaInfo {
            /** Each entry corresponds to one audio stream in the original media file. */
            audioStream?: VideoAudioStream[];
            /**
             * Container type of the file, e.g. FLV, H264, MP3. Uses the numeric value corresponding to the ContainerId enum objects, in order to avoid the dependency on vsi/videostreaminfo.proto.
             * http://cs/symbol:ContainerId%20f:google3/video/vidproc/vsi/videostreaminfo.proto
             */
            containerId?: number;
            /** Media file size in bytes. */
            fileSize?: string;
            /** This is a high-level description of the media. It does not contain PII. */
            overview?: VideoMediaOverview;
            /** Each entry corresponds to one video stream (usually just one) in the original media file. */
            videoStream?: VideoVideoStream[];
        }
        interface VideoMediaOverview {
            aspectRatio?: string;
            audioOverview?: VideoMediaOverviewAudioOverview[];
            authoringTool?: string;
            colorDynamicRange?: string;
            /** Creation timestamp of this media_info, in Unix timestamp since epoch. */
            creationTimeStampUsec?: string;
            dataOverview?: VideoMediaOverviewDataOverview[];
            frameRate?: string;
            /** Currently used by originals replacement pipeline to exclude all videos containing chapter info. */
            hasChapters?: boolean;
            mediaClipInfoOverview?: VideoMediaOverviewMediaClipInfoOverview;
            orientation?: string;
            origin?: string;
            projection?: string;
            resolution?: string;
            spatialAudioMode?: string;
            stereoMode?: string;
            timedtextOverview?: any[];
            videoOverview?: VideoMediaOverviewVideoOverview[];
            /** This only applies when: projection = PROJECTION_PARTIALLY_SPHERICAL */
            wallyMeshType?: string;
        }
        interface VideoMediaOverviewAudioOverview {
            /** Number of audio channels. */
            channels?: number;
            /**
             * Content type of the audio track extracted from VSI. This is only populated with valid "acont" xtag values at the moment, i.e., if VSI reports an invalid string, we ignore it.
             * Supported acont xtag values can be found in google3/video/storage/common/xtag_validation.cc. Examples: "original", "dubbed", "descriptive", "commentary", etc.
             */
            contentType?: string;
            /** Language of the audio track extracted from VSI. Populated if it's deemed a valid code by ISO639-2b, ISO639-2t or III library. */
            language?: string;
            loudness1770Lkfs?: number;
            /** Approximate audio length, has the same caveats as its video equivalent. */
            roundedUpOriginalDurationSec?: number;
            spatialAudioMode?: string;
        }
        interface VideoMediaOverviewDataOverview {
            /** Whether the data stream has camera motion metadata (dynamic) or not (static). Some Wally/VR180 videos do. */
            hasCameraMotionMetadata?: boolean;
            /**
             * If true, source contains metadata for OZO spatial audio support. See b/62393568 for more information about the OZO spatial audio format. Note that SpatialAudioMode is independent of
             * this format.
             */
            hasOzoAudio?: boolean;
        }
        interface VideoMediaOverviewMediaClipInfoOverview {
            /** Corresponds to vsi.video_clip_info().has_geolocation() */
            hasGeolocation?: boolean;
        }
        // tslint:disable-next-line:no-empty-interface
        interface VideoMediaOverviewTimedTextOverview {
        }
        interface VideoMediaOverviewVideoOverview {
            aspectRatio?: string;
            /** Prefer average_fps to match the logic used in transcoder for format profile frame rate checks. First added for Photos, see b/165839654. */
            averageFps?: number;
            codecId?: number;
            colorDynamicRange?: string;
            fps?: number;
            height?: number;
            resolution?: string;
            /**
             * Approximate video length. Data is rounded up to the next second, to avoid being PII. (Long ago, YTFE set a precedent of rounding up durations, rather than rounding to the closest
             * second.) This value is derived from metadata in the source video, and often differs from the actual duration of any given transcode. In videos without valid timestamps, this value
             * is not calculable, and is reported as zero. Prefer the value from MediaInfo::VideoStream over this value, which was added to resolve b/202864365.
             */
            roundedUpOriginalDurationSec?: number;
            videoHasClosedCaptions?: boolean;
            width?: number;
        }
        interface VideoPerDocData {
            coreSignals?: MediaIndexVideoCoreSignals;
            frames?: MediaIndexVideoFrames;
        }
        interface VideoPipelineViperThumbnailerColumnData {
            /** The blobRef where the representative frame is stored. This is repeated in order to support multiple thumbnails in the future. */
            frameBlobRefs?: BlobstoreBlobRef[];
            /** Video frame files (based on file_dir_to_save_frames parameter) */
            frameFileList?: VideoThumbnailsFrameFileList;
            /** Frame type generated (VR/360/3D/default). */
            frameTypeGenerated?: string;
            /** True if the thumbnails are generated from drishti_thumbnailer. */
            generatedFromDrishtiThumbnailer?: boolean;
            highResPreviewThumbnailGenerated?: boolean;
            /** hq720.jpg is a 1280x720 pixel image generated only when the input video resolution is 1280x720 or higher. */
            hq720Generated?: boolean;
            /** The flags below indicate whether certain optional thumbnail images were generated. hqdefault.jpg is a 480x360 pixel high quality image which should normally be always generated. */
            hqdefaultGenerated?: boolean;
            /** True if a set of backup HVC thumbnails is generated. */
            hvcBackupGenerated?: boolean;
            /** True if the thumbnails are generated with background crop and scrim. */
            improvedVerticalGenerated?: boolean;
            /** maxresdefault.jpg is an image of the same resolution as the input video. It is generated only when the input video is significantly higher-resolution than 640x480. */
            maxresdefaultGenerated?: boolean;
            /** Height of the generated maxresdefault thumbnail. */
            maxresdefaultHeight?: number;
            /** Width of the generated maxresdefault thumbnail. */
            maxresdefaultWidth?: number;
            /** True if moving thumbnails are generated. */
            movingThumbnailGenerated?: boolean;
            /** True if private thumbnails were generated and stored in the thumbnail database. */
            privateThumbnailsGenerated?: boolean;
            /** True if public thumbnails were generated and stored in the thumbnail database. */
            publicThumbnailsGenerated?: boolean;
            /** Analysis result of running the rerun thumbnailer */
            rerunStatus?: string;
            /** sddefault.jpg is a 640x480 pixel image generated only when the input video resolution is 640x480 or higher. */
            sddefaultGenerated?: boolean;
            /** This flag indicates if storyboard mosaic images were generated and stored in the thumbnail database. */
            storyboardGenerated?: boolean;
            /** Number of levels of storyboard generated (0 if policy default). */
            storyboardNumLevels?: number;
            /** Policy number that governed the storyboard generation. If zero, no policy was used and the storyboard format is not fully specified by the parameters contained in this message. */
            storyboardPolicy?: number;
            /** Version of the storyboard. */
            storyboardVersion?: number;
            /** Video duration of the video. */
            storyboardVideoDurationMs?: number;
            /** Height of the video that was storyboarded. */
            storyboardVideoHeight?: number;
            /** Width of the video that was storyboarded. */
            storyboardVideoWidth?: number;
            /** This flag indicates if images in WebP format were created and stored in the thumbnail database. */
            webpGenerated?: boolean;
        }
        interface VideoPipelineViperVSIColumnData {
            info?: VideoVideoStreamInfo;
            /** Total time taken in seconds to read the input */
            inputReadTime?: number;
            /** Was the VSI computed on a partial file ? */
            partialFile?: boolean;
            /** Total time (of all attempts) taken in seconds to compute VSI */
            totalVsiTime?: number;
            vsiStats?: VideoPipelineViperVSIColumnDataVsiStats[];
        }
        interface VideoPipelineViperVSIColumnDataVsiStats {
            /** True if the output vsi is a partial vsi. */
            partialVsi?: boolean;
            /** The time (in secondes) from vsi_engine init to vsi written to output buffer. */
            vsiTime?: number;
        }
        interface VideoRational32 {
            denominator?: number;
            numerator?: number;
        }
        interface VideoSEIMessage {
            /** message count of each payloadtype */
            count?: number;
            /** If the video stream has multiple SEI messages with the same payload type, this is the sum of all these payloads' sizes. */
            cumulativeSize?: string;
            /** use int type in case there are payload types that are not included in the SEIPayloadType enum below. The enum can be used for lookup */
            payloadtype?: number;
        }
        interface VideoStorageLoudnessData {
            /** Loudness measured using ITU-R BS. 1770 */
            itu1770LoudnessDb?: number;
            /** Perceived loudness of audio measured using replaygain. */
            perceptualLoudnessDb?: number;
        }
        interface VideoThumbnailsFrameFile {
            filename?: string;
            height?: number;
            msOffset?: number;
            width?: number;
        }
        interface VideoThumbnailsFrameFileList {
            frameFiles?: VideoThumbnailsFrameFile[];
        }
        interface VideoThumbnailsThumbnailScore {
            /** Checksum of the thumbnail bytes used to identify which image the score belongs to. Only filled when thumbnail version is 0. */
            checksum?: string;
            /** Color sampling score encoded as uint32. Encode/Decode using youtube::color::RgbToUint / UIntToRgb. Field is only relevant for TYPE_COLOR_SAMPLING. */
            colorSampling?: number;
            /** Thumbnail dense features. */
            denseFeatures?: number[];
            /** FeatureExtra extension for dense features. */
            denseGeneralExtraFeatures?: any;
            /** If true, score is manually assigned. */
            isAssigned?: boolean;
            /** If true, score will be instantly indexed by YouTube search indexer. */
            isInstant?: boolean;
            modelVersion?: string;
            overwriteReason?: string;
            /** Thumbnail quantized dense features, available in TYPE_STARBURST_COMPRESSED */
            quantizedFeatures?: string;
            score?: number;
            /** Thumbnail sparse features, available in TYPE_STARBURST */
            sparseFeatures?: DrishtiSparseFeatureData;
            thumbnailSet?: string;
            /** Version number of the thumbnail. Should be consistent with the version number in the ytimg_content column family. */
            thumbnailVersion?: string;
            type?: string;
        }
        interface VideoTimedtextS4ALIResults {
            /** The complete list of language scores, sorted from high score to low. */
            langResults?: VideoTimedtextS4LangScore[];
            /** What kind of speech (if any) was detected. */
            speechClass?: string;
        }
        interface VideoTimedtextS4LangScore {
            /**
             * A score between 0.0 and 1.0; the relative probability that this is the language of the video. This should not be interpreted as an absolute probability. For instance, scores may be
             * calculated for all languages even for videos for which no speech was detected.
             */
            confidence?: number;
            /** The language code for one of the languages supported by automatic language identification. */
            langCode?: string;
        }
        interface VideoUserDataRegisteredItuTT35 {
            /** Counts itu-t t.35 message with the same country code and provider code */
            count?: number;
            countryCode?: number;
            providerCode?: number;
        }
        interface VideoUserDataUnregistered {
            /**
             * Counts user data with the same uuid and payload If payload size is larger than limit, the payload will be 'Payload size is larger than limit: ' + limit size Count will be for user
             * data with same uuid and payload exceeds limit in this case
             */
            count?: number;
            /** Payload may not be filled in Payload may contain user data */
            payload?: string;
            uuid?: string;
        }
        interface VideoVideoClipInfo {
            /** Lists the artist of the original subject of the file. */
            artist?: string;
            /** Audio vendor ID */
            audioVendorId?: string;
            /** Different containers use different video clip info. The following fields include info from popular formats: AVI, MOV, and WMV. */
            author?: string;
            comment?: string;
            /** Lists the name of the person or organization that commissioned the subject of the file. */
            commissioned?: string;
            /** Records the copyright information for the file. */
            copyright?: string;
            digitizationTime?: string;
            director?: string;
            /** The engineer who worked on the file. */
            engineer?: string;
            /** Optional geo-location information in WGS 84. */
            geolocation?: VideoVideoGeoLocation;
            info?: string;
            /** Provides a list of keywords that refer to the file or subject of the file. */
            keywords?: string;
            /** The camera make such as Apple, Samsung etc. */
            make?: string;
            /** Describes the original subject of the file. */
            medium?: string;
            /** Container level metadata */
            metadata?: VideoClipInfo[];
            /** The camera model such as iPhone7 or Pixel, etc. */
            model?: string;
            performer?: string;
            producer?: string;
            requirements?: string;
            /** Identifies the name of the software packages used to create the file. */
            software?: string;
            /** Identifies the name of the person or organization who supplied the original subject of the file. */
            sourceProvider?: string;
            /** Describes the contents of the file. */
            subject?: string;
            /** Identifies the technician who digitized the subject file. */
            technician?: string;
            title?: string;
            /** Video vendor ID */
            videoVendorId?: string;
        }
        interface VideoVideoGeoLocation {
            /** Altitude is in meters and multiplied by 100 (i.e., in centimeters). Up till 10 km this fits in 3 bytes. */
            altitudeE2?: number;
            /** Latitude and longitude are in degrees and multiplied by 10^7. This gives the worst precision of about 1 cm at the equator. */
            latitudeE7?: number;
            longitudeE7?: number;
        }
        interface VideoVideoStream {
            /** Video bitrate in bits/s. */
            bitrate?: string;
            /**
             * Video codec ID. Uses the numeric value corresponding to the CodecId enum object, in order to avoid the dependency on vsi/videostreaminfo.proto.
             * http://cs/symbol:CodecId%20f:google3/video/vidproc/vsi/videostreaminfo.proto
             */
            codecId?: number;
            /**
             * Video frame per second, obtained by parsing video header information. The value can be inaccurate for some types of codecs. See comments at
             * http://cs/symbol:video_fps%20f:google3/video/vidproc/vsi/videostreaminfo.proto
             */
            fps?: number;
            height?: number;
            /**
             * Video length, in seconds. This value is derived from metadata in the source video, and often differs from the actual duration of any given transcode. In videos without valid
             * timestamps, this value is not calculable, and is reported as zero.
             */
            lengthSec?: number;
            /** Index of the stream in the file, 0-based. */
            streamIndex?: string;
            /** video width and height. */
            width?: number;
        }
        interface VideoVideoStreamInfo {
            /** audio bitrate in bits/s */
            audioBitrate?: number;
            /** audio channels */
            audioChannels?: number;
            /**
             * Primary audio codec information Fields 15-20, 41-42, 48, 52-53 for audio will be obsolete soon. Please start using the new repeated audio_stream and video_stream. For now,
             * audio_stream(0) will match these fields. Primary audio codec information starts:
             */
            audioCodecId?: string;
            audioEndTimestamp?: string;
            /** audio frame size */
            audioFrameSize?: string;
            /**
             * audio length in seconds Note that when the VSI is from users videos, it is not guaranteed to be the same as transcode lengths and it could be 0 when the full VSI cannot compute the
             * length from the source header and timestamps (for example when header and timestamps are too broken).
             */
            audioLength?: number;
            /**
             * Number of audio frames. Ffmpeg does not report the number of frames accurately. video::TranscodedVideoFileInformation calls Google's analyzer to get information of both audio and
             * video frame numbers.
             */
            audioNumberOfFrames?: string;
            /** audio sample rate */
            audioSampleRate?: string;
            /**
             * Number of meaningful bits per decoded audio sample. This is an implicit conceptual meaning. This is *NOT* the same as ffmpeg's internal sample format that is used when actually
             * decoding with ffmpeg.
             */
            audioSampleSize?: number;
            audioStartTimestamp?: string;
            audioStream?: VideoVideoStreamInfoAudioStream[];
            audioStreamCodecTag?: string;
            /** Audio-Video interleaving distance between packets (in bytes) */
            avDistance?: number;
            /** Average video fps from analyzing entire file. */
            averageVideoFps?: number;
            /**
             * Audio and video length in seconds. It's the max of the audio and video length. Note that when the VSI is from users videos, it is not guaranteed to be the same as transcode lengths
             * and it could be 0 when the full VSI cannot compute the length from the source header and timestamps (for example when header and timestamps are too broken).
             */
            avLength?: number;
            /** Build label of the VSI mpm. */
            buildLabel?: string;
            /** Container Id. */
            containerId?: string;
            /** Name of the container format guessed by ffmpeg. */
            containerType?: string;
            /** If the video contains chapters info. */
            containsChapters?: boolean;
            dataStream?: VideoVideoStreamInfoDataStream[];
            displayHeight?: number;
            /** final display video width and height if explicitly set in the video otherwise this can be calculated from source width/height and video_pixel_aspect_ratio */
            displayWidth?: number;
            /** Input file header fingerprint */
            fileHeaderFingerprint?: string;
            /**
             * The file type string returned by libmagic, a third party library. It might accidentally include some user content. Some normal file_magic examples: -- RIFF (little-endian) data,
             * AVI, 1016 x 696, 30.00 fps, video: XviD, audio: (stereo, 48000 Hz) -- MPEG sequence, v2, program multiplex -- ISO Media, MPEG v4 system, iTunes AVC-LC -- Microsoft Windows Movie
             * Maker project file
             */
            fileMagic?: string;
            /** Input file modification time */
            fileModifiedTime?: string;
            /** Input file name. DEPRECATED; don't expect the file name to be correct. */
            fileName?: string;
            /** Input file size in bytes */
            fileSize?: string;
            /** High-level file type guessed by looking at the file headers and libmagic. */
            fileType?: number;
            imageStream?: VideoVideoStreamInfoVideoStream[];
            /** True if the video is likely to be an ASF file. */
            isAsf?: boolean;
            /** True if the video is actually an image file (JPEG, PNG, GIF, etc) and not a video file. */
            isImageFile?: boolean;
            /** Check if a video size insane or not. It is set if the input file is an MOV file. */
            isVideoInsaneSize?: boolean;
            level?: number;
            metadata?: VideoVideoStreamInfoMetadata;
            /** Total number of audio streams in the file */
            numAudioStreams?: number;
            /** Total number of data streams in the file */
            numDataStreams?: number;
            /** Total number of image streams in the file */
            numImageStreams?: number;
            /** Total number of timedtext streams in the file */
            numTimedtextStreams?: number;
            /** Total number of video streams in the file */
            numVideoStreams?: number;
            /**
             * If this field is not set, then only base video file information has been generated (and ffmpeg parsing hasn't yet been done). If this is set to 'false', then ffmpeg failed to parse
             * the file - otherwise it will set to 'true'
             */
            parsedByFfmpeg?: boolean;
            /** By default we assume that the entire file was given computing the VSI - if that is not true this flag should be set to true. */
            partialFile?: boolean;
            /** Pixel format for the video stream. */
            pixFmt?: string;
            /** video profile */
            profile?: string;
            timedtextStream?: VideoVideoStreamInfoTimedTextStream[];
            /** video bitrate in bits/s */
            videoBitrate?: number;
            /** Video clip information, such as copyright, title, and author. */
            videoClipInfo?: VideoVideoClipInfo;
            /**
             * Primary video codec information Fields 1-2, 4-10, 28, 37, 44, 49, 51, 54-55, 57-62, 69 will be obsolete soon. Please start using the new repeated video_stream. For now,
             * video_stream(0) will match these fields. Note however that some of the fields in VideoStream are not populated correctly yet in videostreaminfo.cc, but that will be handled
             * gradually.
             */
            videoCodecId?: string;
            videoEndTimestamp?: string;
            /**
             * video frame per second, obtained by parsing video header information. It could be inaccurate for some types of codecs, notably, WMV, ASF, and FLV. It will be inaccurate for videos
             * that does not have constant frame rate since it is the smallest framerate that can accurately represent all timestamps (see ffmpeg doc for AVStream.r_frame_rate). Also frame rate
             * can be parsed from headers and can be wrong if it is not available there since ffmpeg uses a heuristic for determining it.
             */
            videoFps?: number;
            /** video frame size */
            videoFrameSize?: string;
            /** video has b frames */
            videoHasBFrames?: boolean;
            /** video (MOV) has fragments */
            videoHasFragments?: boolean;
            /** video (MOV) has moov atom before mdat atom allowing streaming transcoding */
            videoHasLeadingMoovAtom?: boolean;
            /** video has non-monotonic DTS (potential problem) */
            videoHasNonMonotonicDts?: boolean;
            /** video has non-monotonic PTS. */
            videoHasNonMonotonicPts?: boolean;
            /** video (MOV) has a possibly av desync issue due to edit lists not starting at 0 */
            videoHasNonZeroStartEditList?: boolean;
            /** video has possible open GOP */
            videoHasPossibleOpenGop?: boolean;
            /** video has frames with different aspect ratios. */
            videoHasVariableAspectRatio?: boolean;
            videoHeight?: number;
            /** Information on interlaced video. */
            videoInterlace?: string;
            /**
             * video length in seconds Note that when the VSI is from users videos, it is not guaranteed to be the same as transcode lengths and it could be 0 when the full VSI cannot compute the
             * length from the source header and timestamps (for example when header and timestamps are too broken).
             */
            videoLength?: number;
            /**
             * Number of Video frames Warning: running video::FfmpegVideoFileInformation() won't set this info Ffmpeg tool does not report the number of frames accurately. We can't rely on fps and
             * video length. So we will set this after we processed every frame using the filter framework
             */
            videoNumberOfFrames?: string;
            /**
             * Invisible frame count Keep a count of frames that are not displayed should the full frame count be needed for the video stream. The only codec currently reporting this value is VP8
             * with alternate reference frames enabled
             */
            videoNumberOfInvisibleFrames?: number;
            /** video pixel aspect ratio */
            videoPixelAspectRatio?: number;
            /** Is the video rotated ? */
            videoRotation?: string;
            /** Start/end timestamps of audio/video in ms. */
            videoStartTimestamp?: string;
            videoStream?: VideoVideoStreamInfoVideoStream[];
            videoStreamCodecTag?: number;
            /** Version number of the videostreaminfo application that generated this protobuf. */
            videostreaminfoVersion?: number;
            /** source video width and height */
            videoWidth?: number;
            /** Luma PSNR of the transcoded file. */
            yPsnr?: number;
        }
        interface VideoVideoStreamInfoAudioStream {
            /** Optional ambisonics metadata. */
            ambisonics?: VideoAmbisonicsAmbisonicsMetadata;
            /** audio bitrate in bits/s */
            bitrate?: string;
            channelPosition?: string[];
            /** number of audio channels */
            channels?: number;
            /** some container allows for a clock discontinuity. In this case, the end_timestamp may not be the correct DTS of the stream. */
            clockDiscontinuityUs?: string;
            codecFourcc?: string;
            /** Primary audio codec information */
            codecId?: string;
            /** RFC6381 Codec string. */
            codecString?: string;
            /** Specifies the content_type of the audio stream as given in the metadata. */
            contentType?: string;
            /** The bytes offset of the end of the first decodable packet. */
            decodeOffset?: string;
            endTimestamp?: string;
            /** audio frame size */
            frameSize?: string;
            /** Specifies the language of the audio stream as given in the metadata. */
            language?: string;
            /**
             * audio length in seconds Note that when the VSI is from users videos, it is not guaranteed to be the same as transcode lengths and it could be 0 when the full VSI cannot compute the
             * length from the source header and timestamps (for example when header and timestamps are too broken).
             */
            length?: number;
            /** Metadata for audio elementary stream; */
            metadata?: VideoClipInfo[];
            /** Number of audio frames. */
            numberOfFrames?: string;
            profile?: string;
            /** audio sample rate */
            sampleRate?: string;
            /**
             * Number of meaningful bits per decoded audio sample. This is an implicit conceptual meaning. This is *NOT* the same as ffmpeg's internal sample format that is used when actually
             * decoding with ffmpeg.
             */
            sampleSize?: number;
            /** Start/end timestamps of audio in ms. */
            startTimestamp?: string;
            streamCodecTag?: string;
            /** Index of the stream in the file. it is 0 based. */
            streamIndex?: string;
        }
        interface VideoVideoStreamInfoDataStream {
            codecFourcc?: string;
            /** Codec information */
            codecId?: string;
            streamCodecTag?: string;
            /** Index of the stream in the file */
            streamIndex?: string;
        }
        interface VideoVideoStreamInfoMetadata {
            luts?: VideoVideoStreamInfoMetadataLutAttachments;
            /** Information on Frame Packing arrangement */
            videoFpa?: VideoFileFramePackingArrangement;
        }
        interface VideoVideoStreamInfoMetadataLutAttachments {
            lut?: VideoVideoStreamInfoMetadataLutAttachmentsLut3D[];
        }
        interface VideoVideoStreamInfoMetadataLutAttachmentsLut3D {
            /** Lut data, sanitized and encoded in google's binary coded form of 3D look-up tables. */
            data?: string;
            /** Original file name of the lut (present in the original file) */
            fileName?: string;
            /**
             * The size (in each dimension) of the lut. For a 3D cube of size NxNxN, this will be N. If the value is -1, then the file was determined to be invalid. This is useful for logging
             * files where the input could not be parsed, and is useful for to indicate info of the 3D lut without having to decode/inspect the binary data.
             */
            size?: number;
        }
        interface VideoVideoStreamInfoTimedTextStream {
            /** Codec information. */
            codecId?: string;
            /** Metadata for the stream. */
            metadata?: VideoClipInfo[];
            streamCodecTag?: string;
            /** Index of the stream in the file. it is 0 based. */
            streamIndex?: string;
        }
        interface VideoVideoStreamInfoVideoStream {
            /**
             * This represents the canonical frame rate of the video. This is named average_fps for historical reasons, and may not actually be the arithmetic mean. For variable frame rate videos,
             * the algorithm may change again in future. Currently, full vsi set it with arithmetic mean, and partial vsi set it with median.
             */
            averageFps?: number;
            /** video bitrate in bits/s */
            bitrate?: string;
            /**
             * Contains the color information obtained after inspection of the bitstream in cases where there may be inconsistencies between container and coded bitstream that are resolved in
             * favor of the container.
             */
            bitstreamColorInfo?: VideoFileColorInfo;
            cleanAperture?: VideoVideoStreamInfoVideoStreamCleanAperture;
            /** some container allows for a clock discontinuity. In this case, the end_timestamp may not be the correct DTS of the stream. */
            clockDiscontinuityUs?: string;
            closedCaptions?: VideoClosedCaptions;
            /**
             * closed_gop_size refers to chunkable boundaries for each specified codec and may actually contain one or more GOPs, e.g. for H.264, closed_gop_size will denote the distance (frame
             * count) between two IDR frames.
             */
            closedGopSize?: VideoVideoStreamInfoVideoStreamStatistics;
            codecFourcc?: string;
            /** Primary video codec information */
            codecId?: string;
            /** RFC6381 Codec string. */
            codecString?: string;
            colorInfo?: VideoFileColorInfo;
            contentLightLevel?: VideoFileContentLightLevel;
            /** The bytes offset of the end of the first decodable packet. */
            decodeOffset?: string;
            displayHeight?: number;
            /** final display video width and height if explicitly set in the video otherwise this can be calculated from source width/height and video_pixel_aspect_ratio */
            displayWidth?: number;
            /** Dolby Vision configuration if stream is compatible. */
            doviConfiguration?: VideoDoViDecoderConfiguration;
            endTimestamp?: string;
            /** Should the video be mirrored horizontally / vertically? When rotation and flip both are present for a video, it is assumed that the flip is applied first, and then the rotation. */
            flip?: string;
            /**
             * video frame per second, obtained by parsing video header information. It could be inaccurate for some types of codecs, notably, WMV, ASF, and FLV. It will be inaccurate for videos
             * that does not have constant frame rate since it is the smallest framerate that can accurately represent all timestamps (see ffmpeg doc for AVStream.r_frame_rate). Also frame rate
             * can be parsed from headers and can be wrong if it is not available there since ffmpeg uses a heuristic for determining it.
             */
            fps?: number;
            /** video frame size */
            frameSize?: string;
            /** Statistics about gop sizes of the video. */
            gopSize?: VideoVideoStreamInfoVideoStreamStatistics;
            /** video has b frames */
            hasBFrames?: boolean;
            /** Stats on HDR10+ over video frames. */
            hdr10PlusStats?: VideoFileHDR10PlusStats;
            height?: number;
            /** Information on interlaced video. */
            interlace?: string;
            /** Check if a video size insane or not. It is set if the input file is an MOV file. */
            isInsaneSize?: boolean;
            /** User data registered Itu-T T.35 SEI message */
            ituTT35?: VideoUserDataRegisteredItuTT35[];
            /**
             * video length in seconds Note that when the VSI is from users videos, it is not guaranteed to be the same as transcode lengths and it could be 0 when the full VSI cannot compute the
             * length from the source header and timestamps (for example when header and timestamps are too broken).
             */
            length?: number;
            level?: number;
            masteringDisplayMetadata?: VideoFileMasteringDisplayMetadata;
            /** Maximum instantaneous frame rate seen from analyzing the entire stream. */
            maxFps?: number;
            /** Metadata for video elementary stream; */
            metadata?: VideoClipInfo[];
            /** Minimum instantaneous frame rate seen from analyzing the entire stream. */
            minFps?: number;
            /** Number of video frames. */
            numberOfFrames?: string;
            /**
             * Invisible frame count Keep a count of frames that are not displayed should the full frame count be needed for the video stream. The only codec currently reporting this value is VP8
             * with alternate reference frames enabled
             */
            numberOfInvisibleFrames?: number;
            /** video pixel aspect ratio */
            pixelAspectRatio?: number;
            /** Pixel format for the video stream. */
            pixFmt?: string;
            profile?: string;
            /** The nominal frame rate ('fps' field) represented as a fraction. */
            rationalFps?: VideoRational32;
            /** Is the video rotated ? */
            rotation?: string;
            /** video SEI payload types and total payload size of a type this is only for H.264 and H.265 */
            seiMessage?: VideoSEIMessage[];
            /** Optional spherical video information. */
            spherical?: VideoFileSphericalMetadata;
            /** Start/end timestamps of audio/video in ms. */
            startTimestamp?: string;
            streamCodecTag?: string;
            /** Index of the stream in the file. it is 0 based. */
            streamIndex?: string;
            /** User data unregistered SEI message */
            userDataUnregistered?: VideoUserDataUnregistered[];
            /** source video width and height */
            width?: number;
        }
        interface VideoVideoStreamInfoVideoStreamCleanAperture {
            height?: number;
            horizontalOffset?: number;
            verticalOffset?: number;
            width?: number;
        }
        interface VideoVideoStreamInfoVideoStreamStatistics {
            max?: string;
            mean?: number;
            min?: string;
        }
        interface VideoYoutubeCommentsClassificationProtoSmartSuggestion {
            /** Diversification threshold used in prediction. Additional responses which are closer than the threshold to the already selected responses will be skipped. */
            diversificationThreshold?: number;
            /** Bias weight used in prediction. */
            likelihoodBiasWeight?: number;
            /** Content of the reply snippet (could include emoji as well as text). */
            replyContent?: string;
            /** Model score for the predicted reply snippet. */
            score?: number;
        }
        interface VideoYoutubeCommentsClassificationProtoYouTubeCommentSmartReply {
            /** The order of the reply snippets in the list determines how they should be displayed in the UI and the client is not supposed to re-order the list using the scores. */
            smartSuggestions?: VideoYoutubeCommentsClassificationProtoSmartSuggestion[];
            /** Identifier (language_code, channel_id, etc) for the suggestion list from which the top k suggestions are selected. */
            suggestionListIdentifier?: string;
        }
        interface VideoYoutubeCommentsRankingCTRMetrics {
            downvotes?: string;
            impressions?: string;
            measureWindow?: string;
            teaserClicks?: string;
            teaserImpressions?: string;
            upvotes?: string;
        }
        interface WatchpageLanguageWatchPageLanguageResult {
            /** The language predicted by the WatchPage Language model. */
            watchpageLanguage?: string;
        }
        interface WeboftrustLiveResultDocBoostData {
            /**
             * Identifies the degree to which the existence of this LiveResult should boost a query's score (when the query is performed within the hot_times range). This field is always in the
             * range [0,1]. A missing field, a value of 0, or a value outside the legal range indicates that no boosting is performed. A value of 1 indicates that the maximum level of boosting
             * will be applied. This field will be updated from time to time based on CTR and other signals.
             */
            boostLevel?: number;
            /**
             * Specifies the time range within which this LiveResult is relevant. Used for deciding whether the rank of the corresponding page should be boosted. For example, this range can be set
             * to encompass a few days before and after a sports game to which the page refers. If this field is missing, no boosting is performed. Specifying that a page should always be boosted
             * is not recommended, but can be accomplished by setting hot_times.start_unix_time=0 and hot_time.end_unix_time=0x7fffffff. Note that multiple time ranges can be implemented by adding
             * several LiveResultDocBoostData messages to the LiveResultsDocAttachments proto. If overlapping time ranges are used, the proto containing the highest boost level will be used.
             */
            hotTimes?: WeboftrustTimeRange;
        }
        interface WeboftrustLiveResultProviderDocAttachment {
            providerId?: string;
            /**
             * Tag that specifies the use-case within provider's data. It appears as a string in Alexandria signal and in the DocJoins. During the indexing stage this field will be converted to a
             * 64-bit fingerprint to save space. See the "tag_fp" field, below.
             */
            tag?: string;
            /** A fingerprint of the "tag" field, automatically calculated during the indexing stage. Will be used as a key for fetching the data. */
            tagFp?: string;
        }
        interface WeboftrustLiveResultsDocAttachments {
            /** Information about potential rank boosting for the document by virtue of its Live Result feed. */
            docBoost?: WeboftrustLiveResultDocBoostData[];
            /** Identifies a Live Result which is to be attached to the document. */
            providerAttachment?: WeboftrustLiveResultProviderDocAttachment[];
        }
        interface WeboftrustTimeRange {
            endUnixTime?: string;
            /** Start and end times should always appear. Marked as optional to avoid breaking code. */
            startUnixTime?: string;
        }
        interface WebutilHtmlTypesSafeHtmlProto {
            /**
             * IMPORTANT: Never set or read this field, even from tests, it is private. See documentation at the top of .proto file for programming language packages with which to create or read
             * this message.
             */
            privateDoNotAccessOrElseSafeHtmlWrappedValue?: string;
        }
        interface WirelessTranscoderFetchFetchMetadata {
            name?: string;
            value?: string;
        }
        interface WirelessTranscoderFetchFetchSourceInfo {
            /** Provides fetcher-specific detail about how source satisfied the request. */
            detail?: string;
            /** The fetcher that ultimately satisfied this fetch request. */
            source?: string;
        }
        interface WWWDocInfo {
            /** Additional stats output by SafeSearch. See classifier/porn/public/porn-attachments.h. */
            additionalSafesearchStats?: number[];
            /** Sometimes called secureid */
            authMethod?: number;
            /** Bad meta flag */
            badMetadescription?: boolean;
            /** Size of document */
            bodySize?: number;
            bodyTitleLanguages?: string[];
            boilerplateMetadescription?: boolean;
            /** Detected color in the image in RGB565 format in the lower 16 bits. */
            colorDetectionResult?: number;
            /** If not present, then the type */
            contentType?: string;
            /** Url of coupled doc (e.g. image) */
            coupledUrl?: string;
            coupledUrlEncoding?: number;
            /** Last time this doc crawled */
            crawlTime?: string;
            /** Thumbnail cropping information. */
            cropData?: number;
            dataVersion?: string;
            /** Fields generated by the docserver, but whose meaning is unclear. Sometimes last crawl time */
            docVersionId?: string;
            encoding?: string;
            /** fails_safe_search is never filled in production. */
            failsSafeSearch?: string;
            /** If converted to TEXT or HTML */
            fileTypeId?: string;
            /** Indicate if the meta description in a different language than its page. */
            foreignMetadescription?: boolean;
            fuzzyMetadescription?: boolean;
            /** Addition to support google label per-search-result annotation. */
            googleLabelData?: string;
            /** If true, the original document has a bad SSL certificate. */
            hasBadSslCertificate?: boolean;
            /** image height */
            imageHeight?: number;
            /** Image license info such as license url and how to acquire the license. */
            imageLicenseInfo?: ImageSearchImageLicenseInfo;
            imagePublisher?: string;
            /** size in bytes; */
            imageSize?: number;
            /** image width */
            imageWidth?: number;
            /**
             * The timestamp (the time since the Epoch, in microseconds) when the docjoin is exported from indexing. This is mainly exported and used by Youtube Search. See
             * MustangBasicInfo.indexing_ts for more details.
             */
            indexingTs?: string;
            /**
             * If ipaddr is set, ip should be ignored (it should not be set). Ipaddr should be either 4- or 16-byte string for IPv4 or IPv6 addresses. If ipaddr is not set, ip is set to the IPv4
             * address for the host.
             */
            ip?: number;
            ipaddr?: string;
            /** Is this image animated? */
            isAnimated?: boolean;
            /** Hosted Images related fields. */
            isHostedImage?: boolean;
            /** Doc porn classification. */
            isPorn?: boolean;
            /** Is disallowed for crawling according to host's robots.txt. */
            isRoboted?: boolean;
            /** Consider the page classification is_porn as an alternative for is_site_porn, and talk to safesearch@google.com for additional information if needed. */
            isSitePorn?: boolean;
            /** Doc softporn classification. */
            isSoftporn?: boolean;
            /** go/iii-td b/130371355 */
            language?: string;
            /**
             * This returns the most probable language for the document. The complete set of languages is in the GenericSearchResponse. (If some future use requires all languages from the doc
             * request, note that fetching that will require decoding the entire per-doc data attachment, which is a performance hit) Use docinfo-util.h to set & read language fields. Language tag
             * as defined by http://www.unicode.org/reports/tr35/#Identifiers and https://tools.ietf.org/html/bcp47 If not present, then use language.
             */
            languageTag?: string;
            /** Unused by gws */
            lastModTime?: string;
            /** Indicates the web-master opt-in state of this image. This project is still in MVP stage, please contact us licensed-media-team@ before use. */
            licensedWebImagesOptInState?: string;
            lowQualityMetadescription?: boolean;
            /**
             * If meta description/body title were detected to be in a different language from the document language (the 'language' field above) in RosettaLanguageAnnotator, the detected
             * languages are populated here. Note: as of ariane/154728, no more than one language is populated for each field.
             */
            metaDescriptionLanguages?: string[];
            /** Nearby text of the image on landing page. Used to construct Scroll to Image urls. */
            nearbyText?: string;
            /** If not 0, we should not show the image in overlay mode in image snippets. */
            noimageframeoverlayreason?: number;
            partialBoilerplateMetadescription?: boolean;
            /** 'porn_stats' is used in porn demotion and filtering. See classifier/porn/public/porn-attachments.h. */
            pornStats?: number;
            /** Quality score (also known as QScore, see go/qscore-faq). */
            qualityWithoutAdjustment?: number;
            /** Url of referring doc */
            referrerUrl?: string;
            relatedimages?: WWWDocInfoRelatedImages[];
            /** True if the meta-description is duplicated on many other pages and this page is the rootpage of such pages which have the same meta-description. */
            rootpageDuplicateMetadescription?: boolean;
            /** Has noarchive meta robots flag */
            seenNoarchive?: boolean;
            /** Has noindex meta robots flag */
            seenNoindex?: boolean;
            /** NOTE(kinoue): ODP/GWD snippet is unlaunched as of June 2017. This is no longer used. */
            seenNoodp?: boolean;
            /** Has nopreview meta robots flag */
            seenNopreview?: boolean;
            /** Has nosnippet meta robots flag */
            seenNosnippet?: boolean;
            /** Has notranslate meta robots flag */
            seenNotranslate?: boolean;
            shoppingAttachment?: QualityShoppingShoppingAttachment;
            /** Shopping offer info from Inventory & Policy Service. */
            shoppingOffers?: ImageMustangShoppingOffer[];
            /** Subindex id of the document should be one of the values defined by enum CompositeDoc::SubIndexType. Used for superroot/gws logging if a shard has documents from multiple indices. */
            subindex?: number;
            /** thumbnail height */
            thumbHeight?: number;
            thumbnail?: WWWDocInfoThumbnail[];
            /** Additions for image search. */
            thumbWidth?: number;
            /** Landing page title. */
            title?: string;
            unionBuildTime?: string;
            /** Url */
            url?: string;
            /** empty => same as url */
            urlAfterRedirects?: string;
            /** See webutil/urlencoding */
            urlEncoding?: number;
            /** If an image request, was the coupled image visible on the page? */
            visibleImage?: boolean;
            /** Is this doc visual RTL? See enum VisualType in visualtype.h. Default is NOT_VISUAL_DOCUMENT. */
            visualType?: string;
        }
        interface WWWDocInfoRelatedImages {
            imageDocid?: string;
            thumbHeight?: number;
            thumbType?: string;
            thumbWidth?: number;
        }
        interface WWWDocInfoThumbnail {
            expirationTimestampMicros?: string;
            height?: number;
            /** The type here corresponds to image_base::ThumbnailType defined in image/base/thumbnail-type.proto. */
            type?: number;
            width?: number;
        }
        interface WWWMetaTag {
            content?: string;
            name?: string;
        }
        interface WWWResultInfoSubImageDocInfo {
            additionalSafesearchSignals?: number[];
            /** The best thumbnail type is either 300K or 50K. */
            bestThumbnailType?: string;
            crops?: number;
            /** Deepcrop thumbnail cropping hints. */
            deepCropBytes?: string;
            docid?: string;
            documentTrust?: number;
            /**
             * EQ* is a unified signal to capture the emotional quality (e.g. inspiration, lifestyle, context, etc.) of an image. For more information, please refer to
             * go/image-inspiration-ranking-framework.
             */
            eqStar?: number;
            /** Estimated Image Relevance ranging between 0.0 (Off-Topic) to 1.0 (Very Useful). */
            estRelevance?: number;
            flowOutput?: ImageContentFlowProtoProd;
            height?: number;
            height50k?: number;
            /** DeepTags human model score. go/VisualShoppingImageAttributes */
            humanModelScore?: number;
            imageUrl?: string;
            pamirNormalizedScore?: number;
            /** Encoded Safe Search annotations of the image. See image/safesearch/overall/public/image_porn_attachments.h for decoding functions. */
            pornSignals?: number;
            /**
             * Result is not on the Images Universal blacklist. For more comprehensive filtering of IU images, including this bit, see
             * superroot/impls/images/quality/safesearch/iu_inappropriate_filter_lib.h
             */
            safeForUniversal?: boolean;
            /** Salient score, indicating how important an image is to the page it's on. Check go/salient-images-design-doc for details. */
            salience?: number;
            /**
             * 4-bytes: (low order on the left) RRRRRRRR GGGGGGGG BBBBBBBB SS where R: 8-bits encoding color 'r' G: 8-bits encoding color 'g' B: 8-bits encoding color 'b' S: 2-bits encoding the
             * color source - 00 = from color detection result - 01 = from cairo This field has the salient color information.
             */
            salientColorInfo?: number;
            score?: number;
            /** TQ* is a signal to capture the technical quality (e.g. exposure, sharpness, composition, etc.) of an image. For more information, please refer to go/tqstar. */
            tqStar?: number;
            tradFrac?: number;
            width?: number;
            /** Width and height of the AREA_50K thumbnail for this image. */
            width50k?: number;
        }
        interface WWWSnippetResponse {
            /**
             * A list of answers that had at least one hit in the document. Answers are identified by their index into the QRewriteQueryParams_AnswerSnippetInfo array (see
             * //query/proto/query-params.proto).
             */
            answerDocMatches?: number[];
            /** Tidbits chosen from the document body. Consists of repeated [begin, end) half-open ranges in token offsets from the beginning of the document. */
            chosenBodyTidbits?: number[];
            docInfo?: WWWDocInfo;
            /** DocPreviewRestrictions for canonical url. */
            docPreviewRestrictions?: QualityDniDocPreviewRestrictions;
            /** DocPreviewRestrictions for amp result. */
            docPreviewRestrictionsForAmp?: QualityDniDocPreviewRestrictions;
            /** Bitfield of snippet events and the various events. See SnippetEvents in ./snippets/defines.h for details on the contents. */
            events?: string;
            /** If requested, the extra snippet info */
            extraInfo?: ExtraSnippetInfoResponse;
            /**
             * A bitvector of the tidbits in the snippet that are appropriate for the Quick Scroll (Findy) Chrome extension. Typically these contain "extra body matches", i.e., important query
             * items not in the title.
             */
            findyTidbits?: number;
            /** Additional available data (message type ids) */
            hasMessageType?: number[];
            /** Additional data. Currently, this is used for sitelinks, localinfo, manybox, discussion metadata, richsnippets, similarpages and breadcrumbs. */
            info?: any;
            /** True if the document represents a login page. */
            isLoginPage?: boolean;
            /** Assume this is true unless we discover that the result doesn't match the the query, in which case this result is invalid despite having returned docinfo. */
            isValidResult?: boolean;
            /** Document keywords */
            keyword?: string[];
            /** List snippet data. */
            listSnippet?: ListSnippetResponse;
            /** List summary phrase for list pages. */
            listSummary?: string;
            /** Returned if want_long_structured_snippets. If present, caller should ignore the normal snippet. */
            longStructuredSnippet?: LongStructuredSnippet;
            /** Bitmap representing matches to leaf query terms within document (body section and url). It gets populated if query_matches_info = true. */
            matchesBitmapEncoded?: string;
            matchesBitmapSize?: number;
            /** Meta tags */
            metaTags?: WWWMetaTag[];
            numberOfPages?: number;
            /**
             * Similar to num_tokens_skipped_by_in_doc_restrictions_in_scoring, but this number is for tokens skipped during printing, since printer owns its own token info manager which populates
             * tokens.
             */
            numTokensSkippedByInDocRestrictionsInPrinting?: number;
            /**
             * Number of tokens that is skipped because of in doc restrictions during scoring. This is an estimate, as the list of tokens is cached in TokenInfoManager. We should only monitor the
             * cases where this number is too big or non-zero.
             */
            numTokensSkippedByInDocRestrictionsInScoring?: number;
            /** LocalWWWInfo */
            obsoleteLocalinfo?: string;
            /** ManyboxData */
            obsoleteManybox?: string;
            /**
             * These fields were previously optional messages, but CL 2388905 moved them into the MessageSet. However, at this time, old Mustang binaries are still deployed in production and
             * probably will be around for awhile. So, servers which need to talk to old binaries and need to use these fields need to check both the obsolete versions and the MessageSet version.
             * Sitemap
             */
            obsoleteSitemap?: string;
            /** Was odp used in the snippets? DEPRECATED - this is no longer populated as of June 2017. */
            odp?: boolean;
            /** DEPRECATED If requested, the orion entities */
            orionEntities?: OrionDocEntitiesProto;
            /** Abbreviated bibliographic data from Google Scholar. */
            scienceInfo?: ScienceIndexSignal;
            sectionHeadingAnchorName?: string;
            /**
             * If requested, the snippet generator may take note of query items present in an entry in an on-page table-of-contents (i.e. a series of on-page links to named anchors.) If so, these
             * two fields contain the formatted and highlighted entry and the name of the on-page anchor it links to, respectively. This may be used by GWS to show a direct link to that named
             * anchor on the page.
             */
            sectionHeadingText?: string;
            /** Did a negative query term match the meta description? */
            seenNotTerm?: boolean;
            /** DEPRECATED Sentiment snippets */
            sentimentSnippets?: RepositoryAnnotationsMustangSentimentSnippetAnnotations[];
            /**
             * The display name of the document's domain used as the first part of VisUrl, e.g, "Google > play > store" is the VisUrl of "https://play.google.com/store/". Wherein, "Google" is
             * site_display_name of the domain "google.com". See go/site-display-name for more details.
             */
            siteDisplayName?: string;
            /** Byline date for time sensitive snippets. Most of the time it originates from quality_timebased::SyntacticDate and it is floored to PT midnight. */
            snippetBylineDate?: string;
            snippetExtraInfo?: SnippetExtraInfo;
            /**
             * A hash for duplicate detection. Two results with the same content can return different snippets if, for example, one has an ODP entry and the other does not. Gws can use this value
             * reliably to filter duplicates. It is a hash of body only tidbits.
             */
            snippethash?: string;
            /**
             * List of bitmaps representing matches to leaf query terms within each of the highlighted snippet text fragments. Consecutive bitmaps correspond to consecutive text fragments. It gets
             * populated iff return_query_snippet_highlight_matches = true. Example: document body section: "This cafe has pet friendly patio." squery: (a (o dog :o pet :syn:general) friendly :o
             * (o restaurant :o cafe :syn:general)) Let's assume the returned snippet text contains the whole document body section where two fragments get highlighted as follows: "This *cafe* has
             * *pet friendly* patio." Then, the returned snippet_highlight_matches_bitmap[] list will have two bitmaps: bitmap[0] = <"cafe" -> leaf term with index 4> = {encoded:
             * DenseEncode("00001"), size: 5} bitmap[1] = <"pet" and "friendly" -> leaf terms with indexes 1 and 2> = {encoded: DenseEncode("011"), size: 3}
             */
            snippetHighlightMatchesBitmap?: WWWSnippetResponseBitmapPB[];
            /** If requested the page number on which the snippet begins. (Only for documents such as PDFs where page numbers are well-defined.) */
            snippetPageNumber?: number;
            /** Character counts of snippet prefix, if any. E.g. section heading, list summary, byline date. */
            snippetPrefixCharCount?: number;
            /** How tokens are rendered in generating snippet. */
            snippetRenderedToken?: MustangSnippetsRenderedToken[];
            /** Records features to analyze titles/snippets in ranklab. */
            snippetsRanklabFeatures?: MustangReposWwwSnippetsSnippetsRanklabFeatures;
            /** This field is never set. */
            squeryFingerprint?: string;
            /** True if the title length is already adjusted for the browser width. If it is true, GWS needs not truncate the title. */
            titleLengthAdjustedForBrowserWidth?: boolean;
            /**
             * How tokens are rendered in generating title. Note: In rendering a title, the page title part and the site/host/domain title part can be flipped after initial rendering. The flip, if
             * happend, may not be reflected in this field. That is, this field may contain the tokens in the original, pre-flip, order.
             */
            titleRenderedToken?: MustangSnippetsRenderedToken[];
            /** Will only be set when `title_use_num_of_chars` is false. */
            titleSizeParams?: TitleSizeParams;
            /** Only for desktop web search. Please refer to Title.keep_original_title_and_populate_truncated_one for more details. */
            truncatedTitle?: string;
        }
        interface WWWSnippetResponseBitmapPB {
            encoded?: string;
            size?: number;
        }
        interface YoutubeBackstageSuperVodCommentInfo {
            /** Currency code the user uses to purchase this Super VOD item. */
            currencyCode?: string;
            /** The ID of the Super VOD entitlement. It uniquely identifies a Super VOD purchase. */
            entitlementId?: string;
            /** Price of Super VOD item the user purchases in micros. */
            priceInMicros?: string;
            /** The Super VOD item the user purchases, it represents price tier. */
            superVodItemId?: string;
            /** Which version of experiment this Super VOD comment is posted in. */
            version?: string;
        }
        interface YoutubeCommentsClusteringMiniStanza {
            /** TnS Ansible scores map. Keyed by various model names. */
            ansibleScores?: { [P in string]: number };
            /** Automod scores map. Keyed by various model names. */
            automodScores?: { [P in string]: number };
            /** The blarney stone score. */
            blarneyStoneScore?: YoutubeDistillerBlarneyStoneScores;
            /** The channel this channel discussion comment belongs to. Note that this will match channel_id for such comments. */
            channelDiscussionId?: string;
            /** The channel of the video this comment belongs to. */
            channelId?: string;
            /** Channel profile quality scores map. Keyed by various model names. */
            channelProfileQualityScores?: { [P in string]: number };
            /** Char entropy of the comment. */
            charEntropy?: number;
            /** Comment classification mapping all secondary keys to values. E.g. {"joke_v1":0.8, "joke_v2":0.7, "question_v1":0.3}. */
            commentClassification?: { [P in string]: number };
            /** List of pre-defined classification score buckets to which the comment belongs. E.g. satisfaction_v1_percentile_80. */
            commentClassificationBuckets?: string[];
            /** Comment classification for ranking mapping all secondary keys to values. E.g. {"joke_v1":0.8, "joke_v2":0.7, "question_v1":0.3}. */
            commentClassificationRanking?: { [P in string]: number };
            /** Whether the comment is on a video, post, or other product. */
            commentType?: string;
            /** The text content of the comment. */
            content?: string;
            /**
             * The stanza content last update timestamp, as observed by the server. Note that for many comments older than Nov. 2014 this is unset in the original stanza. MiniStanza tries to be
             * consistent with the original so for such comments it remains unset in MiniStanza. If you use this field you should check has_content_update_timestamp().
             */
            contentUpdateTimestamp?: string;
            /** Whether or not this comment is eligible for comment classifier coverage sampling (in Kapla). Refer to go/coverage-monitoring-for-kapla-comment-classifiers for more information. */
            coverageSamplingEligible?: boolean;
            /** The creation device. Derived from shares:yt_creation_device */
            creationDevice?: string;
            /** The time when the comment is created. */
            creationTimeInSeconds?: string;
            /** The language code with extra script details. This is derived from detailed_language_code if it's populated, otherwise the same as language_code. E.g. mr-Latn */
            detailedLanguageCode?: string;
            /** All distiller engagements like reports and downvotes. */
            distillerEngagements?: AppsPeopleActivityStreamqualityDistillerEngagements;
            /** The qualified comment teaser filters that this comment is eligible for. Refer to go/comment-teaser-design for more information. */
            eligibleQualifiedTeaserFilters?: string[];
            /** Comments empirical CTRs. */
            empiricalCtrs?: VideoYoutubeCommentsRankingCTRMetrics;
            /** Fountain Discovery Score, which represents the reputation of the author. */
            fds?: number;
            /** Indicator for whether there is creator heart on this comment. */
            hasCreatorHeart?: boolean;
            /** If the comment has a creator reply. */
            hasCreatorReply?: boolean;
            /** If the author is a channel member (sponsor). */
            isAuthorSponsor?: boolean;
            /** Whether a comment is from deleted shares. See stanza_restrictions for more specific information and is_publicly_visible for comments which are allowed to be seen by everyone. */
            isDeleted?: boolean;
            /** Whether the comment is pinned. This is derived from the DestinationStreamDump. */
            isPinned?: boolean;
            /** If the post is publicly visible. */
            isPubliclyVisible?: boolean;
            /** Whether the comment is a reply. */
            isReply?: boolean;
            /** If the comment author is publicly subscribed to the channel. */
            isSubscriber?: boolean;
            /**
             * Unicode CLDR language code of the segments, as implemented by //depot/google3/java/com/google/i18n/identifiers/LanguageCode.java This is derived from user_content and should be
             * considered the canonical language code of the comment.
             */
            languageCode?: string;
            /** The time when last reply is created. */
            lastReplyTimestampUsec?: string;
            /** Low quality decisions. Keyed by decision types corresponding to secondary keys. */
            lowQualityDecisions?: { [P in string]: boolean };
            /** Timed comments for the "mentioned" secondary key. */
            mentionedTimestampCommentSecond?: number;
            /** Misinfo scores map. Keyed by various model names. */
            misinfoScores?: { [P in string]: number };
            /** Number of dislikes the comment has. */
            numDislikes?: number;
            /** Number of likes the comment has. */
            numLikes?: number;
            /** Number of different repliers the comment has. */
            numRepliers?: number;
            /** Number of non-abusive replies the comment has. */
            numReplies?: number;
            /** Bucketed number of subscribers held by comment author. */
            numSubscribersBucket?: number;
            /** Offline engagement scores map. Keyed by various model names. */
            offlineEngagementScores?: { [P in string]: number };
            /**
             * The parent stanza's stanza_id, empty for top-level posts (non-replies). Prefer is_reply field for checking if a comment is a reply since that is unaffected by surrogatization. For
             * replies to replies, this is the root stanza_id (not guaranteed AFAIK).
             */
            parentId?: string;
            /** The post this comment belongs to. */
            postId?: string;
            /**
             * The language code stored in the KV pair ranking:post_language. This should usually be the same as language_code but is not guaranteed to be identical. The KV pair is needed because
             * ranking can't consume user_content.
             */
            rankingPostLanguage?: string;
            /** A textual content for the context. */
            segments?: SocialCommonSegments;
            /**
             * Sensitivity scores map for smart reply sensitivity scores. Keyed by model names. See (g3doc/company/teams/expander/research/conversation/sensitive.md) for more information on
             * sensitivity scores.
             */
            sensitivityScores?: { [P in string]: number };
            /**
             * Sentiment. This omits entity_sentiment and keeps only the polarity, magnitude, and score. Sentiment as currently implemented is not debiased and has limited language coverage.
             * Please read go/comments-sentiment-access before using.
             */
            sentiment?: YoutubeCommentsSentimentSentiment;
            /** Smart replies for this comment. Keyed by model names. */
            smartReplies?: { [P in string]: VideoYoutubeCommentsClassificationProtoYouTubeCommentSmartReply };
            /** Refers to the stanza this data is derived from. */
            stanzaId?: string;
            /** Contains various restriction information about a stanza. */
            stanzaRestrictions?: SocialStanzaStanzaRestriction[];
            /** The author of the comment */
            subject?: SecurityCredentialsPrincipalProto;
            /** Whether the comment is authored by the creator. */
            subjectIsVideoOwner?: boolean;
            /** The timestamp (in seconds) when the author subscribed to the channel. */
            subscriptionTimestamp?: string;
            /** Super Thanks related info if a comment is posted through a Super Thanks purchase. */
            superThanksInfo?: YoutubeBackstageSuperVodCommentInfo;
            /** Comment text embedding. */
            textEmbedding?: { [P in string]: YoutubeCommentsRankingYouTubeCommentTextEmbedding };
            /** Text length of the comment. */
            textLength?: number;
            /** Predicted probability of the comment being flagged based on the text. */
            textQualityScores?: YoutubeCommentsRankingYouTubeCommentTextQualityAnnotation;
            /** Predicted probability of the comment being flagged based on the text. For testing the new annotation process only. */
            textQualityScores2?: YoutubeCommentsRankingYouTubeCommentTextQualityAnnotation;
            /** The video this comment belongs to. */
            videoId?: string;
            /**
             * Unique video timestamps in seconds sorted by timestamp. This is derived from text Segments, not from a KV. These may exceed the length of the video since that isn't checked at
             * segmentation time. The segmentation rules have changed over time e.g. in the past "10:00 PM" was treated as a timestamp.
             */
            videoTimestamps?: number[];
            /** Word entropy of the comment. */
            wordEntropy?: number;
            /** The youtube channel id of the comment author. */
            ytAuthorChannelId?: string;
            /** Existing quality corpus scores. */
            ytCommentQualityScore?: number;
            ytCommentQualityScore2?: number;
            ytCommentQualityScore3?: number;
            /** For replies to replies, this contains the parent reply's id. The parent_id field is actually the root stanza_id (not guaranteed AFAIK). */
            ytReplyToItemId?: string;
        }
        interface YoutubeCommentsRankingYouTubeCommentTextEmbedding {
            /** Comment text embedding. */
            textEmbedding?: number[];
        }
        interface YoutubeCommentsRankingYouTubeCommentTextQualityAnnotation {
            /** Score produced by the user flag prediction model. */
            flagPredictionScore?: number;
            /** Version identifier of the flag prediction model. */
            flagPredictionVersion?: string;
        }
        interface YoutubeCommentsSentimentSentiment {
            entitySentiment?: YoutubeCommentsSentimentSentimentEntitySentimentAnnotation[];
            /** Total magnitude of the sentiment. A positive number representing the total intensity of sentiment regardless of positive vs negative polarity. */
            magnitude?: number;
            /** Polarity of the sentiment. Value is between -1.0 and 1.0 inclusive, with larger numbers representing more positive sentiment and negative numbers representing negative sentiment. */
            polarity?: number;
            /** The average score over sentences. This combines the polarity and magnitude signals into one value. Bounded between -1.0 and 1.0. */
            score?: number;
        }
        interface YoutubeCommentsSentimentSentimentEntitySentimentAnnotation {
            /** The representative entity name. This can be blank for cases when there is no explicit name like "I" or "it". The mentions' tokens can be used to get more details about each entity. */
            entityName?: string;
            /** Total magnitude of the sentiment. */
            magnitude?: number;
            mentionSentiment?: YoutubeCommentsSentimentSentimentEntitySentimentAnnotationMentionSentimentAnnotation[];
            /** MID for this entity, if available. */
            mid?: string;
            /** Polarity of the sentiment. See above for detail. */
            polarity?: number;
            /** The per entity score between -1.0 and 1.0. Combines the signal from polarity and magnitude values. */
            score?: number;
        }
        interface YoutubeCommentsSentimentSentimentEntitySentimentAnnotationMentionSentimentAnnotation {
            /** Token end index in corresponding SAFT document (inclusive). */
            endToken?: string;
            /** Total magnitude of the sentiment. */
            magnitude?: number;
            /** Polarity of the sentiment. See above for detail. */
            polarity?: number;
            /** The per mention score between -1.0 and 1.0. Combines the signal from polarity and magnitude values. */
            score?: number;
            /** Token start index in corresponding SAFT document. */
            startToken?: string;
        }
        interface YoutubeDiscoveryLegosLegosAnnotation {
            /** The entity annotating the document. */
            entity?: YoutubeDiscoveryLegosLegosEntity;
            /** The annotation is a format annotation, i.e. it tells the format of the video. */
            format?: YoutubeDiscoveryLegosLegosFormatRelationship;
            /** The annotation is present in the video. Semantic Legos and Presence Legos naturally overlap and can contain the same entities. However, we do not enforce a strict subset relation. */
            present?: YoutubeDiscoveryLegosLegosPresentRelationship;
            /**
             * The annotation is a semantic annotation, i.e. it tells what the document is about and what the reasons to watch the video are. The annotation should be valid for the complete
             * annotated document, not simply a part of the document such as a video segment.
             */
            semantic?: YoutubeDiscoveryLegosLegosSemanticRelationship;
            /** The annotation is a taxonomic annotation, i.e. it tells to which class of the Legos taxonomy the document belongs to. */
            taxonomic?: YoutubeDiscoveryLegosLegosTaxonomicRelationship;
        }
        interface YoutubeDiscoveryLegosLegosAnnotations {
            /** The annotations for this document. For a given (entity, relationship type) pair, there will be at most one annotation. The list has no particular order. */
            annotations?: YoutubeDiscoveryLegosLegosAnnotation[];
        }
        interface YoutubeDiscoveryLegosLegosEntity {
            /**
             * DO NOT USE THIS FIELD. The entity name here can be random garbage and when it's actually a name it will be in a random language (most of the time English but not always). This field
             * is going away soon. For a replacement you should probably use the following RPC: cs/symbol:Ytpedia.GetNames please read go/ytks-calling details on how to call it and don't hesitate
             * to write to us for help with this (or in any case before starting to send real traffic to us) at: g/yt-knowledge-service
             */
            debugName?: string;
            /** The ID of the Knowledge Graph entity. Note: this is the primary ID at generation time. See https://sites.google.com/a/google.com/knowledge-graph/data/primary_ids */
            kgId?: string;
        }
        interface YoutubeDiscoveryLegosLegosFormatRelationship {
            /**
             * Format classification confidence score, in the 0-1 range. A score of XX% means that we expect at least XX% of the documents annotated with this format to be correctly annotated;
             * i.e. thresholding at XX% yields a precision of at least XX%.
             */
            confidence?: number;
        }
        interface YoutubeDiscoveryLegosLegosPresentRelationship {
            /** Confidence score. Thresholding at the confidence score at 0.XX yields annotations of precision of at least XX%. */
            confidence?: number;
            /**
             * Extra context about how the entity relates to the document. Typically vertical-specific. Please refrain from populating this field as we're working on migrating most of the use
             * cases to the LegosEntity proto so clients don't have to scan all relationships to know which annotations they may be interested in.
             */
            contexts?: YoutubeDiscoveryLegosLegosSemanticRelationshipContext[];
        }
        interface YoutubeDiscoveryLegosLegosSemanticRelationship {
            /**
             * Confidence score. Thresholding at the confidence score at 0.XX yields annotations of precision of at least XX%. Only filled in the intent definition Legos. Please use
             * IsSemanticAnnotationAtConfidenceThreshold() from video/youtube/discovery/legos/annotations/public/legos_annotations_util.h to obtain only intent definition Legos. For more
             * information on the migration please look at go/legos-intent-migration.
             */
            confidence?: number;
            contexts?: YoutubeDiscoveryLegosLegosSemanticRelationshipContext[];
            /** DEPRECATED. Please use confidence instead. Will be set to the same value as confidence in early January 2019. See go/legos-intent-migration for more information. */
            topicalityScore?: number;
        }
        interface YoutubeDiscoveryLegosLegosSemanticRelationshipContext {
            /** The subject of the semantic relationship. This is set when the relationship is derived from some other entity. The exact meaning of this field depends on the ContextType. */
            subject?: YoutubeDiscoveryLegosLegosEntity;
            /** The type of semantic relationship between the document and the entity. This allows one to retrieve vertical-specific fine-grained information about the document. */
            type?: string;
        }
        interface YoutubeDiscoveryLegosLegosTaxonomicRelationship {
            /**
             * Set to true if the taxonomy annotation is redundant amongst the set of other taxonomy annotations for the same document, i.e. if there is at least one other taxonomy annotation that
             * is a child node of this one.
             */
            isRedundant?: boolean;
            /** A score, in the 0-1 range, used to rank taxonomy annotations. */
            score?: number;
        }
        interface YoutubeDistillerBlarneyStoneScores {
            familySafeV1Score?: number;
            mildHateHarassV1Score?: number;
            mildHateHarassV2Score?: number;
            /** The scores corresponds to each of the abe_models in /cns/yk-d/home/blarneystone/model0/config-2015-11-20.pbtxt */
            modelScores?: YoutubeDistillerModelScore[];
            severeHateHarassV1Score?: number;
        }
        interface YoutubeDistillerModelScore {
            /** The classifier trained with tensor flow. */
            classifier?: string;
            /** The model trained with dist belief [going to be deprecated]. */
            model?: string;
            score?: number;
        }
        interface DocumentLinksResource {
            /** Create a link between a source document and a target document. */
            create(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /**
                 * Required. Parent of the document-link to be created. parent of document-link should be a document. Format:
                 * projects/{project_number}/locations/{location}/documents/{source_document_id}.
                 */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1CreateDocumentLinkRequest;
            }): Request<GoogleCloudContentwarehouseV1DocumentLink>;
            create(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /**
                 * Required. Parent of the document-link to be created. parent of document-link should be a document. Format:
                 * projects/{project_number}/locations/{location}/documents/{source_document_id}.
                 */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1CreateDocumentLinkRequest): Request<GoogleCloudContentwarehouseV1DocumentLink>;
            /** Remove the link between the source and target documents. */
            delete(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** Required. The name of the document-link to be deleted. Format: projects/{project_number}/locations/{location}/documents/{source_document_id}/documentLinks/{document_link_id}. */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1DeleteDocumentLinkRequest;
            }): Request<{}>;
            delete(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** Required. The name of the document-link to be deleted. Format: projects/{project_number}/locations/{location}/documents/{source_document_id}/documentLinks/{document_link_id}. */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1DeleteDocumentLinkRequest): Request<{}>;
        }
        interface ReferenceIdResource {
            /** Deletes a document. Returns NOT_FOUND if the document does not exist. */
            delete(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /**
                 * Required. The name of the document to delete. Format: projects/{project_number}/locations/{location}/documents/{document_id} or
                 * projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
                 */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1DeleteDocumentRequest;
            }): Request<{}>;
            delete(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /**
                 * Required. The name of the document to delete. Format: projects/{project_number}/locations/{location}/documents/{document_id} or
                 * projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
                 */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1DeleteDocumentRequest): Request<{}>;
            /** Gets a document. Returns NOT_FOUND if the document does not exist. */
            get(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /**
                 * Required. The name of the document to retrieve. Format: projects/{project_number}/locations/{location}/documents/{document_id} or
                 * projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
                 */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1GetDocumentRequest;
            }): Request<GoogleCloudContentwarehouseV1Document>;
            get(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /**
                 * Required. The name of the document to retrieve. Format: projects/{project_number}/locations/{location}/documents/{document_id} or
                 * projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
                 */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1GetDocumentRequest): Request<GoogleCloudContentwarehouseV1Document>;
            /** Updates a document. Returns INVALID_ARGUMENT if the name of the document is non-empty and does not equal the existing name. */
            patch(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /**
                 * Required. The name of the document to update. Format: projects/{project_number}/locations/{location}/documents/{document_id} or
                 * projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
                 */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1UpdateDocumentRequest;
            }): Request<GoogleCloudContentwarehouseV1UpdateDocumentResponse>;
            patch(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /**
                 * Required. The name of the document to update. Format: projects/{project_number}/locations/{location}/documents/{document_id} or
                 * projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
                 */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1UpdateDocumentRequest): Request<GoogleCloudContentwarehouseV1UpdateDocumentResponse>;
        }
        interface DocumentsResource {
            /** Creates a document. */
            create(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Required. The parent name. Format: projects/{project_number}/locations/{location}. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1CreateDocumentRequest;
            }): Request<GoogleCloudContentwarehouseV1CreateDocumentResponse>;
            create(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Required. The parent name. Format: projects/{project_number}/locations/{location}. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1CreateDocumentRequest): Request<GoogleCloudContentwarehouseV1CreateDocumentResponse>;
            /** Deletes a document. Returns NOT_FOUND if the document does not exist. */
            delete(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /**
                 * Required. The name of the document to delete. Format: projects/{project_number}/locations/{location}/documents/{document_id} or
                 * projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
                 */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1DeleteDocumentRequest;
            }): Request<{}>;
            delete(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /**
                 * Required. The name of the document to delete. Format: projects/{project_number}/locations/{location}/documents/{document_id} or
                 * projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
                 */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1DeleteDocumentRequest): Request<{}>;
            /** Gets the access control policy for a resource. Returns NOT_FOUND error if the resource does not exist. Returns an empty policy if the resource exists but does not have a policy set. */
            fetchAcl(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /**
                 * Required. REQUIRED: The resource for which the policy is being requested. Format for document: projects/{project_number}/locations/{location}/documents/{document_id}. Format for
                 * project: projects/{project_number}.
                 */
                resource: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1FetchAclRequest): Request<GoogleCloudContentwarehouseV1FetchAclResponse>;
            /** Gets a document. Returns NOT_FOUND if the document does not exist. */
            get(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /**
                 * Required. The name of the document to retrieve. Format: projects/{project_number}/locations/{location}/documents/{document_id} or
                 * projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
                 */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1GetDocumentRequest;
            }): Request<GoogleCloudContentwarehouseV1Document>;
            get(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /**
                 * Required. The name of the document to retrieve. Format: projects/{project_number}/locations/{location}/documents/{document_id} or
                 * projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
                 */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1GetDocumentRequest): Request<GoogleCloudContentwarehouseV1Document>;
            /** Return all source document-links from the document. */
            linkedSources(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Required. The name of the document, for which all source links are returned. Format: projects/{project_number}/locations/{location}/documents/{source_document_id}. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1ListLinkedSourcesRequest;
            }): Request<GoogleCloudContentwarehouseV1ListLinkedSourcesResponse>;
            linkedSources(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Required. The name of the document, for which all source links are returned. Format: projects/{project_number}/locations/{location}/documents/{source_document_id}. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1ListLinkedSourcesRequest): Request<GoogleCloudContentwarehouseV1ListLinkedSourcesResponse>;
            /** Return all target document-links from the document. */
            linkedTargets(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Required. The name of the document, for which all target links are returned. Format: projects/{project_number}/locations/{location}/documents/{target_document_id}. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1ListLinkedTargetsRequest;
            }): Request<GoogleCloudContentwarehouseV1ListLinkedTargetsResponse>;
            linkedTargets(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Required. The name of the document, for which all target links are returned. Format: projects/{project_number}/locations/{location}/documents/{target_document_id}. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1ListLinkedTargetsRequest): Request<GoogleCloudContentwarehouseV1ListLinkedTargetsResponse>;
            /** Updates a document. Returns INVALID_ARGUMENT if the name of the document is non-empty and does not equal the existing name. */
            patch(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /**
                 * Required. The name of the document to update. Format: projects/{project_number}/locations/{location}/documents/{document_id} or
                 * projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
                 */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1UpdateDocumentRequest;
            }): Request<GoogleCloudContentwarehouseV1UpdateDocumentResponse>;
            patch(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /**
                 * Required. The name of the document to update. Format: projects/{project_number}/locations/{location}/documents/{document_id} or
                 * projects/{project_number}/locations/{location}/documents/referenceId/{reference_id}.
                 */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1UpdateDocumentRequest): Request<GoogleCloudContentwarehouseV1UpdateDocumentResponse>;
            /** Searches for documents using provided SearchDocumentsRequest. This call only returns documents that the caller has permission to search against. */
            search(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Required. The parent, which owns this collection of documents. Format: projects/{project_number}/locations/{location}. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1SearchDocumentsRequest;
            }): Request<GoogleCloudContentwarehouseV1SearchDocumentsResponse>;
            search(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Required. The parent, which owns this collection of documents. Format: projects/{project_number}/locations/{location}. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1SearchDocumentsRequest): Request<GoogleCloudContentwarehouseV1SearchDocumentsResponse>;
            /** Sets the access control policy for a resource. Replaces any existing policy. */
            setAcl(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /**
                 * Required. REQUIRED: The resource for which the policy is being requested. Format for document: projects/{project_number}/locations/{location}/documents/{document_id}. Format for
                 * project: projects/{project_number}.
                 */
                resource: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1SetAclRequest): Request<GoogleCloudContentwarehouseV1SetAclResponse>;
            documentLinks: DocumentLinksResource;
            referenceId: ReferenceIdResource;
        }
        interface DocumentSchemasResource {
            /** Creates a document schema. */
            create(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Required. The parent name. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1DocumentSchema;
            }): Request<GoogleCloudContentwarehouseV1DocumentSchema>;
            create(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Required. The parent name. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1DocumentSchema): Request<GoogleCloudContentwarehouseV1DocumentSchema>;
            /** Deletes a document schema. Returns NOT_FOUND if the document schema does not exist. Returns BAD_REQUEST if the document schema has documents depending on it. */
            delete(request?: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** Required. The name of the document schema to delete. */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            }): Request<{}>;
            /** Gets a document schema. Returns NOT_FOUND if the document schema does not exist. */
            get(request?: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** Required. The name of the document schema to retrieve. */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            }): Request<GoogleCloudContentwarehouseV1DocumentSchema>;
            /** Lists document schemas. */
            list(request?: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /**
                 * The maximum number of document schemas to return. The service may return fewer than this value. If unspecified, at most 50 document schemas will be returned. The maximum value
                 * is 1000; values above 1000 will be coerced to 1000.
                 */
                pageSize?: number;
                /**
                 * A page token, received from a previous `ListDocumentSchemas` call. Provide this to retrieve the subsequent page. When paginating, all other parameters provided to
                 * `ListDocumentSchemas` must match the call that provided the page token.
                 */
                pageToken?: string;
                /** Required. The parent, which owns this collection of document schemas. Format: projects/{project_number}/locations/{location}. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            }): Request<GoogleCloudContentwarehouseV1ListDocumentSchemasResponse>;
            /**
             * Updates a Document Schema. Returns INVALID_ARGUMENT if the name of the Document Schema is non-empty and does not equal the existing name. Supports only appending new properties,
             * adding new ENUM possible values, and updating the EnumTypeOptions.validation_check_disabled flag for ENUM possible values. Updating existing properties will result into
             * INVALID_ARGUMENT.
             */
            patch(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** Required. The name of the document schema to update. Format: projects/{project_number}/locations/{location}/documentSchemas/{document_schema_id}. */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1UpdateDocumentSchemaRequest;
            }): Request<GoogleCloudContentwarehouseV1DocumentSchema>;
            patch(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** Required. The name of the document schema to update. Format: projects/{project_number}/locations/{location}/documentSchemas/{document_schema_id}. */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1UpdateDocumentSchemaRequest): Request<GoogleCloudContentwarehouseV1DocumentSchema>;
        }
        interface OperationsResource {
            /** Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service. */
            get(request?: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** The name of the operation resource. */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            }): Request<GoogleLongrunningOperation>;
        }
        interface RuleSetsResource {
            /** Creates a ruleset. */
            create(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Required. The parent name. Format: projects/{project_number}/locations/{location}. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1RuleSet;
            }): Request<GoogleCloudContentwarehouseV1RuleSet>;
            create(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Required. The parent name. Format: projects/{project_number}/locations/{location}. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1RuleSet): Request<GoogleCloudContentwarehouseV1RuleSet>;
            /** Deletes a ruleset. Returns NOT_FOUND if the document does not exist. */
            delete(request?: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** Required. The name of the rule set to delete. Format: projects/{project_number}/locations/{location}/ruleSets/{rule_set_id}. */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            }): Request<{}>;
            /** Gets a ruleset. Returns NOT_FOUND if the ruleset does not exist. */
            get(request?: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** Required. The name of the rule set to retrieve. Format: projects/{project_number}/locations/{location}/ruleSets/{rule_set_id}. */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            }): Request<GoogleCloudContentwarehouseV1RuleSet>;
            /** Lists rulesets. */
            list(request?: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /**
                 * The maximum number of rule sets to return. The service may return fewer than this value. If unspecified, at most 50 rule sets will be returned. The maximum value is 1000; values
                 * above 1000 will be coerced to 1000.
                 */
                pageSize?: number;
                /**
                 * A page token, received from a previous `ListRuleSets` call. Provide this to retrieve the subsequent page. When paginating, all other parameters provided to `ListRuleSets` must
                 * match the call that provided the page token.
                 */
                pageToken?: string;
                /** Required. The parent, which owns this collection of document. Format: projects/{project_number}/locations/{location}. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            }): Request<GoogleCloudContentwarehouseV1ListRuleSetsResponse>;
            /** Updates a ruleset. Returns INVALID_ARGUMENT if the name of the ruleset is non-empty and does not equal the existing name. */
            patch(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** Required. The name of the rule set to update. Format: projects/{project_number}/locations/{location}/ruleSets/{rule_set_id}. */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1UpdateRuleSetRequest;
            }): Request<GoogleCloudContentwarehouseV1RuleSet>;
            patch(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** Required. The name of the rule set to update. Format: projects/{project_number}/locations/{location}/ruleSets/{rule_set_id}. */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1UpdateRuleSetRequest): Request<GoogleCloudContentwarehouseV1RuleSet>;
        }
        interface SynonymSetsResource {
            /** Creates a SynonymSet for a single context. Throws an ALREADY_EXISTS exception if a synonymset already exists for the context. */
            create(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Required. The parent name. Format: projects/{project_number}/locations/{location}. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1SynonymSet;
            }): Request<GoogleCloudContentwarehouseV1SynonymSet>;
            create(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Required. The parent name. Format: projects/{project_number}/locations/{location}. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1SynonymSet): Request<GoogleCloudContentwarehouseV1SynonymSet>;
            /** Deletes a SynonymSet for a given context. Throws a NOT_FOUND exception if the SynonymSet is not found. */
            delete(request?: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** Required. The name of the synonymSet to delete Format: projects/{project_number}/locations/{location}/synonymSets/{context}. */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            }): Request<{}>;
            /** Gets a SynonymSet for a particular context. Throws a NOT_FOUND exception if the Synonymset does not exist */
            get(request?: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** Required. The name of the synonymSet to retrieve Format: projects/{project_number}/locations/{location}/synonymSets/{context}. */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            }): Request<GoogleCloudContentwarehouseV1SynonymSet>;
            /** Returns all SynonymSets (for all contexts) for the specified location. */
            list(request?: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /**
                 * The maximum number of synonymSets to return. The service may return fewer than this value. If unspecified, at most 50 rule sets will be returned. The maximum value is 1000;
                 * values above 1000 will be coerced to 1000.
                 */
                pageSize?: number;
                /**
                 * A page token, received from a previous `ListSynonymSets` call. Provide this to retrieve the subsequent page. When paginating, all other parameters provided to `ListSynonymSets`
                 * must match the call that provided the page token.
                 */
                pageToken?: string;
                /** Required. The parent name. Format: projects/{project_number}/locations/{location}. */
                parent: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            }): Request<GoogleCloudContentwarehouseV1ListSynonymSetsResponse>;
            /** Remove the existing SynonymSet for the context and replaces it with a new one. Throws a NOT_FOUND exception if the SynonymSet is not found. */
            patch(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** Required. The name of the synonymSet to update Format: projects/{project_number}/locations/{location}/synonymSets/{context}. */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1SynonymSet;
            }): Request<GoogleCloudContentwarehouseV1SynonymSet>;
            patch(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** Required. The name of the synonymSet to update Format: projects/{project_number}/locations/{location}/synonymSets/{context}. */
                name: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1SynonymSet): Request<GoogleCloudContentwarehouseV1SynonymSet>;
        }
        interface LocationsResource {
            /** Provisions resources for given tenant project. Returns a long running operation. */
            initialize(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** Required. The location to be initialized Format: projects/{project_number}/locations/{location}. */
                location: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
                /** Request body */
                resource: GoogleCloudContentwarehouseV1InitializeProjectRequest;
            }): Request<GoogleLongrunningOperation>;
            initialize(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** Required. The location to be initialized Format: projects/{project_number}/locations/{location}. */
                location: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1InitializeProjectRequest): Request<GoogleLongrunningOperation>;
            documents: DocumentsResource;
            documentSchemas: DocumentSchemasResource;
            operations: OperationsResource;
            ruleSets: RuleSetsResource;
            synonymSets: SynonymSetsResource;
        }
        interface ProjectsResource {
            /** Gets the access control policy for a resource. Returns NOT_FOUND error if the resource does not exist. Returns an empty policy if the resource exists but does not have a policy set. */
            fetchAcl(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /**
                 * Required. REQUIRED: The resource for which the policy is being requested. Format for document: projects/{project_number}/locations/{location}/documents/{document_id}. Format for
                 * project: projects/{project_number}.
                 */
                resource: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1FetchAclRequest): Request<GoogleCloudContentwarehouseV1FetchAclResponse>;
            /** Sets the access control policy for a resource. Replaces any existing policy. */
            setAcl(request: {
                /** V1 error format. */
                "$.xgafv"?: string;
                /** OAuth access token. */
                access_token?: string;
                /** Data format for response. */
                alt?: string;
                /** JSONP */
                callback?: string;
                /** Selector specifying which fields to include in a partial response. */
                fields?: string;
                /** API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. */
                key?: string;
                /** OAuth 2.0 token for the current user. */
                oauth_token?: string;
                /** Returns response with indentations and line breaks. */
                prettyPrint?: boolean;
                /** Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. */
                quotaUser?: string;
                /**
                 * Required. REQUIRED: The resource for which the policy is being requested. Format for document: projects/{project_number}/locations/{location}/documents/{document_id}. Format for
                 * project: projects/{project_number}.
                 */
                resource: string;
                /** Upload protocol for media (e.g. "raw", "multipart"). */
                upload_protocol?: string;
                /** Legacy upload protocol for media (e.g. "media", "multipart"). */
                uploadType?: string;
            },
            body: GoogleCloudContentwarehouseV1SetAclRequest): Request<GoogleCloudContentwarehouseV1SetAclResponse>;
            locations: LocationsResource;
        }

        const projects: ProjectsResource;
    }
}
