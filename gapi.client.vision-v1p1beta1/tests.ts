/* This is stub file for gapi.client.vision-v1p1beta1 definition tests */
// IMPORTANT
// This file was generated by https://github.com/Maxim-Mazurok/google-api-typings-generator. Please do not edit it manually.
// In case of any problems please post issue to https://github.com/Maxim-Mazurok/google-api-typings-generator

// Revision: 20241213

gapi.load('client', async () => {
  /** now we can use gapi.client */

  await gapi.client.load(
    'https://vision.googleapis.com/$discovery/rest?version=v1p1beta1'
  );
  /** now we can use gapi.client.vision */

  /** don't forget to authenticate your client before sending any request to resources: */
  /** declare client_id registered in Google Developers Console */
  const client_id = '<<PUT YOUR CLIENT ID HERE>>';
  const scope = [
    /** See, edit, configure, and delete your Google Cloud data and see the email address for your Google Account. */
    'https://www.googleapis.com/auth/cloud-platform',
    /** Apply machine learning models to understand and label images */
    'https://www.googleapis.com/auth/cloud-vision',
  ];
  const immediate = false;
  gapi.auth.authorize({client_id, scope, immediate}, authResult => {
    if (authResult && !authResult.error) {
      /** handle successful authorization */
      void run();
    } else {
      /** handle authorization error */
    }
  });

  async function run() {
    /** Service that performs image detection and annotation for a batch of files. Now only "application/pdf", "image/tiff" and "image/gif" are supported. This service will extract at most 5 (customers can specify which 5 in AnnotateFileRequest.pages) frames (gif) or pages (pdf or tiff) from each file provided and perform detection and annotation for each image extracted. */
    await gapi.client.vision.files.annotate(
      {},
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
            inputConfig: {
              content: 'Test string',
              gcsSource: {
                uri: 'Test string',
              },
              mimeType: 'Test string',
            },
            pages: [42],
          },
        ],
      }
    );
    /** Run asynchronous image detection and annotation for a list of generic files, such as PDF files, which may contain multiple pages and multiple images per page. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateFilesResponse` (results). */
    await gapi.client.vision.files.asyncBatchAnnotate(
      {},
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
            inputConfig: {
              content: 'Test string',
              gcsSource: {
                uri: 'Test string',
              },
              mimeType: 'Test string',
            },
            outputConfig: {
              batchSize: 42,
              gcsDestination: {
                uri: 'Test string',
              },
            },
          },
        ],
      }
    );
    /** Run image detection and annotation for a batch of images. */
    await gapi.client.vision.images.annotate(
      {},
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            image: {
              content: 'Test string',
              source: {
                gcsImageUri: 'Test string',
                imageUri: 'Test string',
              },
            },
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
          },
        ],
      }
    );
    /** Run asynchronous image detection and annotation for a list of images. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateImagesResponse` (results). This service will write image annotation outputs to json files in customer GCS bucket, each json file containing BatchAnnotateImagesResponse proto. */
    await gapi.client.vision.images.asyncBatchAnnotate(
      {},
      {
        labels: {
          A: 'Test string',
        },
        outputConfig: {
          batchSize: 42,
          gcsDestination: {
            uri: 'Test string',
          },
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            image: {
              content: 'Test string',
              source: {
                gcsImageUri: 'Test string',
                imageUri: 'Test string',
              },
            },
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
          },
        ],
      }
    );
    /** Service that performs image detection and annotation for a batch of files. Now only "application/pdf", "image/tiff" and "image/gif" are supported. This service will extract at most 5 (customers can specify which 5 in AnnotateFileRequest.pages) frames (gif) or pages (pdf or tiff) from each file provided and perform detection and annotation for each image extracted. */
    await gapi.client.vision.projects.files.annotate(
      {
        parent: 'Test string',
      },
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
            inputConfig: {
              content: 'Test string',
              gcsSource: {
                uri: 'Test string',
              },
              mimeType: 'Test string',
            },
            pages: [42],
          },
        ],
      }
    );
    /** Run asynchronous image detection and annotation for a list of generic files, such as PDF files, which may contain multiple pages and multiple images per page. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateFilesResponse` (results). */
    await gapi.client.vision.projects.files.asyncBatchAnnotate(
      {
        parent: 'Test string',
      },
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
            inputConfig: {
              content: 'Test string',
              gcsSource: {
                uri: 'Test string',
              },
              mimeType: 'Test string',
            },
            outputConfig: {
              batchSize: 42,
              gcsDestination: {
                uri: 'Test string',
              },
            },
          },
        ],
      }
    );
    /** Run image detection and annotation for a batch of images. */
    await gapi.client.vision.projects.images.annotate(
      {
        parent: 'Test string',
      },
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            image: {
              content: 'Test string',
              source: {
                gcsImageUri: 'Test string',
                imageUri: 'Test string',
              },
            },
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
          },
        ],
      }
    );
    /** Run asynchronous image detection and annotation for a list of images. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateImagesResponse` (results). This service will write image annotation outputs to json files in customer GCS bucket, each json file containing BatchAnnotateImagesResponse proto. */
    await gapi.client.vision.projects.images.asyncBatchAnnotate(
      {
        parent: 'Test string',
      },
      {
        labels: {
          A: 'Test string',
        },
        outputConfig: {
          batchSize: 42,
          gcsDestination: {
            uri: 'Test string',
          },
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            image: {
              content: 'Test string',
              source: {
                gcsImageUri: 'Test string',
                imageUri: 'Test string',
              },
            },
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
          },
        ],
      }
    );
    /** Service that performs image detection and annotation for a batch of files. Now only "application/pdf", "image/tiff" and "image/gif" are supported. This service will extract at most 5 (customers can specify which 5 in AnnotateFileRequest.pages) frames (gif) or pages (pdf or tiff) from each file provided and perform detection and annotation for each image extracted. */
    await gapi.client.vision.projects.locations.files.annotate(
      {
        parent: 'Test string',
      },
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
            inputConfig: {
              content: 'Test string',
              gcsSource: {
                uri: 'Test string',
              },
              mimeType: 'Test string',
            },
            pages: [42],
          },
        ],
      }
    );
    /** Run asynchronous image detection and annotation for a list of generic files, such as PDF files, which may contain multiple pages and multiple images per page. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateFilesResponse` (results). */
    await gapi.client.vision.projects.locations.files.asyncBatchAnnotate(
      {
        parent: 'Test string',
      },
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
            inputConfig: {
              content: 'Test string',
              gcsSource: {
                uri: 'Test string',
              },
              mimeType: 'Test string',
            },
            outputConfig: {
              batchSize: 42,
              gcsDestination: {
                uri: 'Test string',
              },
            },
          },
        ],
      }
    );
    /** Run image detection and annotation for a batch of images. */
    await gapi.client.vision.projects.locations.images.annotate(
      {
        parent: 'Test string',
      },
      {
        labels: {
          A: 'Test string',
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            image: {
              content: 'Test string',
              source: {
                gcsImageUri: 'Test string',
                imageUri: 'Test string',
              },
            },
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
          },
        ],
      }
    );
    /** Run asynchronous image detection and annotation for a list of images. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `OperationMetadata` (metadata). `Operation.response` contains `AsyncBatchAnnotateImagesResponse` (results). This service will write image annotation outputs to json files in customer GCS bucket, each json file containing BatchAnnotateImagesResponse proto. */
    await gapi.client.vision.projects.locations.images.asyncBatchAnnotate(
      {
        parent: 'Test string',
      },
      {
        labels: {
          A: 'Test string',
        },
        outputConfig: {
          batchSize: 42,
          gcsDestination: {
            uri: 'Test string',
          },
        },
        parent: 'Test string',
        requests: [
          {
            features: [
              {
                maxResults: 42,
                model: 'Test string',
                type: 'Test string',
              },
            ],
            image: {
              content: 'Test string',
              source: {
                gcsImageUri: 'Test string',
                imageUri: 'Test string',
              },
            },
            imageContext: {
              cropHintsParams: {
                aspectRatios: [42],
              },
              languageHints: ['Test string'],
              latLongRect: {
                maxLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
                minLatLng: {
                  latitude: 42,
                  longitude: 42,
                },
              },
              productSearchParams: {
                boundingPoly: {
                  normalizedVertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                  vertices: [
                    {
                      x: 42,
                      y: 42,
                    },
                  ],
                },
                filter: 'Test string',
                productCategories: ['Test string'],
                productSet: 'Test string',
              },
              textDetectionParams: {
                advancedOcrOptions: ['Test string'],
                enableTextDetectionConfidenceScore: true,
              },
              webDetectionParams: {
                includeGeoResults: true,
              },
            },
          },
        ],
      }
    );
  }
});
