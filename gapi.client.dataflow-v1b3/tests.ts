/* This is stub file for gapi.client.dataflow-v1b3 definition tests */
// IMPORTANT
// This file was generated by https://github.com/Maxim-Mazurok/google-api-typings-generator. Please do not edit it manually.
// In case of any problems please post issue to https://github.com/Maxim-Mazurok/google-api-typings-generator

// Revision: 20240723

gapi.load('client', async () => {
  /** now we can use gapi.client */

  await gapi.client.load(
    'https://dataflow.googleapis.com/$discovery/rest?version=v1b3'
  );
  /** now we can use gapi.client.dataflow */

  /** don't forget to authenticate your client before sending any request to resources: */
  /** declare client_id registered in Google Developers Console */
  const client_id = '<<PUT YOUR CLIENT ID HERE>>';
  const scope = [
    /** See, edit, configure, and delete your Google Cloud data and see the email address for your Google Account. */
    'https://www.googleapis.com/auth/cloud-platform',
    /** View and manage your Google Compute Engine resources */
    'https://www.googleapis.com/auth/compute',
  ];
  const immediate = false;
  gapi.auth.authorize({client_id, scope, immediate}, authResult => {
    if (authResult && !authResult.error) {
      /** handle successful authorization */
      void run();
    } else {
      /** handle authorization error */
    }
  });

  async function run() {
    /** Deletes a snapshot. */
    await gapi.client.dataflow.projects.deleteSnapshots({
      location: 'Test string',
      projectId: 'Test string',
      snapshotId: 'Test string',
    });
    /** Send a worker_message to the service. */
    await gapi.client.dataflow.projects.workerMessages(
      {
        projectId: 'Test string',
      },
      {
        location: 'Test string',
        workerMessages: [
          {
            dataSamplingReport: {
              bytesWrittenDelta: 'Test string',
              elementsSampledBytes: 'Test string',
              elementsSampledCount: 'Test string',
              exceptionsSampledCount: 'Test string',
              pcollectionsSampledCount: 'Test string',
              persistenceErrorsCount: 'Test string',
              translationErrorsCount: 'Test string',
            },
            labels: {
              A: 'Test string',
            },
            perWorkerMetrics: {
              perStepNamespaceMetrics: [
                {
                  metricsNamespace: 'Test string',
                  metricValues: [
                    {
                      metric: 'Test string',
                      metricLabels: {
                        A: 'Test string',
                      },
                      valueHistogram: {
                        bucketCounts: ['Test string'],
                        bucketOptions: {
                          exponential: {
                            numberOfBuckets: 42,
                            scale: 42,
                          },
                          linear: {
                            numberOfBuckets: 42,
                            start: 42,
                            width: 42,
                          },
                        },
                        count: 'Test string',
                        outlierStats: {
                          overflowCount: 'Test string',
                          overflowMean: 42,
                          underflowCount: 'Test string',
                          underflowMean: 42,
                        },
                      },
                      valueInt64: 'Test string',
                    },
                  ],
                  originalStep: 'Test string',
                },
              ],
            },
            streamingScalingReport: {
              activeBundleCount: 42,
              activeThreadCount: 42,
              maximumBundleCount: 42,
              maximumBytes: 'Test string',
              maximumBytesCount: 42,
              maximumThreadCount: 42,
              outstandingBundleCount: 42,
              outstandingBytes: 'Test string',
              outstandingBytesCount: 42,
            },
            time: 'Test string',
            workerHealthReport: {
              msg: 'Test string',
              pods: [
                {
                  A: 42,
                },
              ],
              reportInterval: 'Test string',
              vmBrokenCode: 'Test string',
              vmIsBroken: true,
              vmIsHealthy: true,
              vmStartupTime: 'Test string',
            },
            workerLifecycleEvent: {
              containerStartTime: 'Test string',
              event: 'Test string',
              metadata: {
                A: 'Test string',
              },
            },
            workerMessageCode: {
              code: 'Test string',
              parameters: {
                A: 42,
              },
            },
            workerMetrics: {
              containers: undefined,
              cpuTime: [
                {
                  rate: 42,
                  timestamp: 'Test string',
                  totalMs: 'Test string',
                },
              ],
              memoryInfo: [
                {
                  currentLimitBytes: 'Test string',
                  currentOoms: 'Test string',
                  currentRssBytes: 'Test string',
                  timestamp: 'Test string',
                  totalGbMs: 'Test string',
                },
              ],
            },
            workerShutdownNotice: {
              reason: 'Test string',
            },
            workerThreadScalingReport: {
              currentThreadCount: 42,
            },
          },
        ],
      }
    );
    /** List the jobs of a project across all regions. **Note:** This method doesn't support filtering the list of jobs by name. */
    await gapi.client.dataflow.projects.jobs.aggregated({
      filter: 'Test string',
      location: 'Test string',
      name: 'Test string',
      pageSize: 42,
      pageToken: 'Test string',
      projectId: 'Test string',
      view: 'Test string',
    });
    /** Creates a Cloud Dataflow job. To create a job, we recommend using `projects.locations.jobs.create` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using `projects.jobs.create` is not recommended, as your job will always start in `us-central1`. Do not enter confidential information when you supply string values using the API. */
    await gapi.client.dataflow.projects.jobs.create(
      {
        location: 'Test string',
        projectId: 'Test string',
        replaceJobId: 'Test string',
        view: 'Test string',
      },
      {
        clientRequestId: 'Test string',
        createdFromSnapshotId: 'Test string',
        createTime: 'Test string',
        currentState: 'Test string',
        currentStateTime: 'Test string',
        environment: {
          clusterManagerApiService: 'Test string',
          dataset: 'Test string',
          debugOptions: {
            dataSampling: {
              behaviors: ['Test string'],
            },
            enableHotKeyLogging: true,
          },
          experiments: ['Test string'],
          flexResourceSchedulingGoal: 'Test string',
          internalExperiments: {
            A: 42,
          },
          sdkPipelineOptions: {
            A: 42,
          },
          serviceAccountEmail: 'Test string',
          serviceKmsKeyName: 'Test string',
          serviceOptions: ['Test string'],
          shuffleMode: 'Test string',
          streamingMode: 'Test string',
          tempStoragePrefix: 'Test string',
          userAgent: {
            A: 42,
          },
          useStreamingEngineResourceBasedBilling: true,
          version: {
            A: 42,
          },
          workerPools: [
            {
              autoscalingSettings: {
                algorithm: 'Test string',
                maxNumWorkers: 42,
              },
              dataDisks: [
                {
                  diskType: 'Test string',
                  mountPoint: 'Test string',
                  sizeGb: 42,
                },
              ],
              defaultPackageSet: 'Test string',
              diskSizeGb: 42,
              diskSourceImage: 'Test string',
              diskType: 'Test string',
              ipConfiguration: 'Test string',
              kind: 'Test string',
              machineType: 'Test string',
              metadata: {
                A: 'Test string',
              },
              network: 'Test string',
              numThreadsPerWorker: 42,
              numWorkers: 42,
              onHostMaintenance: 'Test string',
              packages: [
                {
                  location: 'Test string',
                  name: 'Test string',
                },
              ],
              poolArgs: {
                A: 42,
              },
              sdkHarnessContainerImages: [
                {
                  capabilities: ['Test string'],
                  containerImage: 'Test string',
                  environmentId: 'Test string',
                  useSingleCorePerContainer: true,
                },
              ],
              subnetwork: 'Test string',
              taskrunnerSettings: {
                alsologtostderr: true,
                baseTaskDir: 'Test string',
                baseUrl: 'Test string',
                commandlinesFileName: 'Test string',
                continueOnException: true,
                dataflowApiVersion: 'Test string',
                harnessCommand: 'Test string',
                languageHint: 'Test string',
                logDir: 'Test string',
                logToSerialconsole: true,
                logUploadLocation: 'Test string',
                oauthScopes: ['Test string'],
                parallelWorkerSettings: {
                  baseUrl: 'Test string',
                  reportingEnabled: true,
                  servicePath: 'Test string',
                  shuffleServicePath: 'Test string',
                  tempStoragePrefix: 'Test string',
                  workerId: 'Test string',
                },
                streamingWorkerMainClass: 'Test string',
                taskGroup: 'Test string',
                taskUser: 'Test string',
                tempStoragePrefix: 'Test string',
                vmId: 'Test string',
                workflowFileName: 'Test string',
              },
              teardownPolicy: 'Test string',
              workerHarnessContainerImage: 'Test string',
              zone: 'Test string',
            },
          ],
          workerRegion: 'Test string',
          workerZone: 'Test string',
        },
        executionInfo: {
          stages: {
            A: {
              stepName: ['Test string'],
            },
          },
        },
        id: 'Test string',
        jobMetadata: {
          bigqueryDetails: [
            {
              dataset: 'Test string',
              projectId: 'Test string',
              query: 'Test string',
              table: 'Test string',
            },
          ],
          bigTableDetails: [
            {
              instanceId: 'Test string',
              projectId: 'Test string',
              tableId: 'Test string',
            },
          ],
          datastoreDetails: [
            {
              namespace: 'Test string',
              projectId: 'Test string',
            },
          ],
          fileDetails: [
            {
              filePattern: 'Test string',
            },
          ],
          pubsubDetails: [
            {
              subscription: 'Test string',
              topic: 'Test string',
            },
          ],
          sdkVersion: {
            bugs: [
              {
                severity: 'Test string',
                type: 'Test string',
                uri: 'Test string',
              },
            ],
            sdkSupportStatus: 'Test string',
            version: 'Test string',
            versionDisplayName: 'Test string',
          },
          spannerDetails: [
            {
              databaseId: 'Test string',
              instanceId: 'Test string',
              projectId: 'Test string',
            },
          ],
          userDisplayProperties: {
            A: 'Test string',
          },
        },
        labels: {
          A: 'Test string',
        },
        location: 'Test string',
        name: 'Test string',
        pipelineDescription: {
          displayData: [
            {
              boolValue: true,
              durationValue: 'Test string',
              floatValue: 42,
              int64Value: 'Test string',
              javaClassValue: 'Test string',
              key: 'Test string',
              label: 'Test string',
              namespace: 'Test string',
              shortStrValue: 'Test string',
              strValue: 'Test string',
              timestampValue: 'Test string',
              url: 'Test string',
            },
          ],
          executionPipelineStage: [
            {
              componentSource: [
                {
                  name: 'Test string',
                  originalTransformOrCollection: 'Test string',
                  userName: 'Test string',
                },
              ],
              componentTransform: [
                {
                  name: 'Test string',
                  originalTransform: 'Test string',
                  userName: 'Test string',
                },
              ],
              id: 'Test string',
              inputSource: [
                {
                  name: 'Test string',
                  originalTransformOrCollection: 'Test string',
                  sizeBytes: 'Test string',
                  userName: 'Test string',
                },
              ],
              kind: 'Test string',
              name: 'Test string',
              outputSource: [
                {
                  name: 'Test string',
                  originalTransformOrCollection: 'Test string',
                  sizeBytes: 'Test string',
                  userName: 'Test string',
                },
              ],
              prerequisiteStage: ['Test string'],
            },
          ],
          originalPipelineTransform: [
            {
              displayData: [
                {
                  boolValue: true,
                  durationValue: 'Test string',
                  floatValue: 42,
                  int64Value: 'Test string',
                  javaClassValue: 'Test string',
                  key: 'Test string',
                  label: 'Test string',
                  namespace: 'Test string',
                  shortStrValue: 'Test string',
                  strValue: 'Test string',
                  timestampValue: 'Test string',
                  url: 'Test string',
                },
              ],
              id: 'Test string',
              inputCollectionName: ['Test string'],
              kind: 'Test string',
              name: 'Test string',
              outputCollectionName: ['Test string'],
            },
          ],
          stepNamesHash: 'Test string',
        },
        projectId: 'Test string',
        replacedByJobId: 'Test string',
        replaceJobId: 'Test string',
        requestedState: 'Test string',
        runtimeUpdatableParams: {
          maxNumWorkers: 42,
          minNumWorkers: 42,
          workerUtilizationHint: 42,
        },
        satisfiesPzi: true,
        satisfiesPzs: true,
        serviceResources: {
          zones: ['Test string'],
        },
        stageStates: [
          {
            currentStateTime: 'Test string',
            executionStageName: 'Test string',
            executionStageState: 'Test string',
          },
        ],
        startTime: 'Test string',
        steps: [
          {
            kind: 'Test string',
            name: 'Test string',
            properties: {
              A: 42,
            },
          },
        ],
        stepsLocation: 'Test string',
        tempFiles: ['Test string'],
        transformNameMapping: {
          A: 'Test string',
        },
        type: 'Test string',
      }
    );
    /** Gets the state of the specified Cloud Dataflow job. To get the state of a job, we recommend using `projects.locations.jobs.get` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using `projects.jobs.get` is not recommended, as you can only get the state of jobs that are running in `us-central1`. */
    await gapi.client.dataflow.projects.jobs.get({
      jobId: 'Test string',
      location: 'Test string',
      projectId: 'Test string',
      view: 'Test string',
    });
    /** Request the job status. To request the status of a job, we recommend using `projects.locations.jobs.getMetrics` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using `projects.jobs.getMetrics` is not recommended, as you can only request the status of jobs that are running in `us-central1`. */
    await gapi.client.dataflow.projects.jobs.getMetrics({
      jobId: 'Test string',
      location: 'Test string',
      projectId: 'Test string',
      startTime: 'Test string',
    });
    /** List the jobs of a project. To list the jobs of a project in a region, we recommend using `projects.locations.jobs.list` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). To list the all jobs across all regions, use `projects.jobs.aggregated`. Using `projects.jobs.list` is not recommended, because you can only get the list of jobs that are running in `us-central1`. `projects.locations.jobs.list` and `projects.jobs.list` support filtering the list of jobs by name. Filtering by name isn't supported by `projects.jobs.aggregated`. */
    await gapi.client.dataflow.projects.jobs.list({
      filter: 'Test string',
      location: 'Test string',
      name: 'Test string',
      pageSize: 42,
      pageToken: 'Test string',
      projectId: 'Test string',
      view: 'Test string',
    });
    /** Snapshot the state of a streaming job. */
    await gapi.client.dataflow.projects.jobs.snapshot(
      {
        jobId: 'Test string',
        projectId: 'Test string',
      },
      {
        description: 'Test string',
        location: 'Test string',
        snapshotSources: true,
        ttl: 'Test string',
      }
    );
    /** Updates the state of an existing Cloud Dataflow job. To update the state of an existing job, we recommend using `projects.locations.jobs.update` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using `projects.jobs.update` is not recommended, as you can only update the state of jobs that are running in `us-central1`. */
    await gapi.client.dataflow.projects.jobs.update(
      {
        jobId: 'Test string',
        location: 'Test string',
        projectId: 'Test string',
        updateMask: 'Test string',
      },
      {
        clientRequestId: 'Test string',
        createdFromSnapshotId: 'Test string',
        createTime: 'Test string',
        currentState: 'Test string',
        currentStateTime: 'Test string',
        environment: {
          clusterManagerApiService: 'Test string',
          dataset: 'Test string',
          debugOptions: {
            dataSampling: {
              behaviors: ['Test string'],
            },
            enableHotKeyLogging: true,
          },
          experiments: ['Test string'],
          flexResourceSchedulingGoal: 'Test string',
          internalExperiments: {
            A: 42,
          },
          sdkPipelineOptions: {
            A: 42,
          },
          serviceAccountEmail: 'Test string',
          serviceKmsKeyName: 'Test string',
          serviceOptions: ['Test string'],
          shuffleMode: 'Test string',
          streamingMode: 'Test string',
          tempStoragePrefix: 'Test string',
          userAgent: {
            A: 42,
          },
          useStreamingEngineResourceBasedBilling: true,
          version: {
            A: 42,
          },
          workerPools: [
            {
              autoscalingSettings: {
                algorithm: 'Test string',
                maxNumWorkers: 42,
              },
              dataDisks: [
                {
                  diskType: 'Test string',
                  mountPoint: 'Test string',
                  sizeGb: 42,
                },
              ],
              defaultPackageSet: 'Test string',
              diskSizeGb: 42,
              diskSourceImage: 'Test string',
              diskType: 'Test string',
              ipConfiguration: 'Test string',
              kind: 'Test string',
              machineType: 'Test string',
              metadata: {
                A: 'Test string',
              },
              network: 'Test string',
              numThreadsPerWorker: 42,
              numWorkers: 42,
              onHostMaintenance: 'Test string',
              packages: [
                {
                  location: 'Test string',
                  name: 'Test string',
                },
              ],
              poolArgs: {
                A: 42,
              },
              sdkHarnessContainerImages: [
                {
                  capabilities: ['Test string'],
                  containerImage: 'Test string',
                  environmentId: 'Test string',
                  useSingleCorePerContainer: true,
                },
              ],
              subnetwork: 'Test string',
              taskrunnerSettings: {
                alsologtostderr: true,
                baseTaskDir: 'Test string',
                baseUrl: 'Test string',
                commandlinesFileName: 'Test string',
                continueOnException: true,
                dataflowApiVersion: 'Test string',
                harnessCommand: 'Test string',
                languageHint: 'Test string',
                logDir: 'Test string',
                logToSerialconsole: true,
                logUploadLocation: 'Test string',
                oauthScopes: ['Test string'],
                parallelWorkerSettings: {
                  baseUrl: 'Test string',
                  reportingEnabled: true,
                  servicePath: 'Test string',
                  shuffleServicePath: 'Test string',
                  tempStoragePrefix: 'Test string',
                  workerId: 'Test string',
                },
                streamingWorkerMainClass: 'Test string',
                taskGroup: 'Test string',
                taskUser: 'Test string',
                tempStoragePrefix: 'Test string',
                vmId: 'Test string',
                workflowFileName: 'Test string',
              },
              teardownPolicy: 'Test string',
              workerHarnessContainerImage: 'Test string',
              zone: 'Test string',
            },
          ],
          workerRegion: 'Test string',
          workerZone: 'Test string',
        },
        executionInfo: {
          stages: {
            A: {
              stepName: ['Test string'],
            },
          },
        },
        id: 'Test string',
        jobMetadata: {
          bigqueryDetails: [
            {
              dataset: 'Test string',
              projectId: 'Test string',
              query: 'Test string',
              table: 'Test string',
            },
          ],
          bigTableDetails: [
            {
              instanceId: 'Test string',
              projectId: 'Test string',
              tableId: 'Test string',
            },
          ],
          datastoreDetails: [
            {
              namespace: 'Test string',
              projectId: 'Test string',
            },
          ],
          fileDetails: [
            {
              filePattern: 'Test string',
            },
          ],
          pubsubDetails: [
            {
              subscription: 'Test string',
              topic: 'Test string',
            },
          ],
          sdkVersion: {
            bugs: [
              {
                severity: 'Test string',
                type: 'Test string',
                uri: 'Test string',
              },
            ],
            sdkSupportStatus: 'Test string',
            version: 'Test string',
            versionDisplayName: 'Test string',
          },
          spannerDetails: [
            {
              databaseId: 'Test string',
              instanceId: 'Test string',
              projectId: 'Test string',
            },
          ],
          userDisplayProperties: {
            A: 'Test string',
          },
        },
        labels: {
          A: 'Test string',
        },
        location: 'Test string',
        name: 'Test string',
        pipelineDescription: {
          displayData: [
            {
              boolValue: true,
              durationValue: 'Test string',
              floatValue: 42,
              int64Value: 'Test string',
              javaClassValue: 'Test string',
              key: 'Test string',
              label: 'Test string',
              namespace: 'Test string',
              shortStrValue: 'Test string',
              strValue: 'Test string',
              timestampValue: 'Test string',
              url: 'Test string',
            },
          ],
          executionPipelineStage: [
            {
              componentSource: [
                {
                  name: 'Test string',
                  originalTransformOrCollection: 'Test string',
                  userName: 'Test string',
                },
              ],
              componentTransform: [
                {
                  name: 'Test string',
                  originalTransform: 'Test string',
                  userName: 'Test string',
                },
              ],
              id: 'Test string',
              inputSource: [
                {
                  name: 'Test string',
                  originalTransformOrCollection: 'Test string',
                  sizeBytes: 'Test string',
                  userName: 'Test string',
                },
              ],
              kind: 'Test string',
              name: 'Test string',
              outputSource: [
                {
                  name: 'Test string',
                  originalTransformOrCollection: 'Test string',
                  sizeBytes: 'Test string',
                  userName: 'Test string',
                },
              ],
              prerequisiteStage: ['Test string'],
            },
          ],
          originalPipelineTransform: [
            {
              displayData: [
                {
                  boolValue: true,
                  durationValue: 'Test string',
                  floatValue: 42,
                  int64Value: 'Test string',
                  javaClassValue: 'Test string',
                  key: 'Test string',
                  label: 'Test string',
                  namespace: 'Test string',
                  shortStrValue: 'Test string',
                  strValue: 'Test string',
                  timestampValue: 'Test string',
                  url: 'Test string',
                },
              ],
              id: 'Test string',
              inputCollectionName: ['Test string'],
              kind: 'Test string',
              name: 'Test string',
              outputCollectionName: ['Test string'],
            },
          ],
          stepNamesHash: 'Test string',
        },
        projectId: 'Test string',
        replacedByJobId: 'Test string',
        replaceJobId: 'Test string',
        requestedState: 'Test string',
        runtimeUpdatableParams: {
          maxNumWorkers: 42,
          minNumWorkers: 42,
          workerUtilizationHint: 42,
        },
        satisfiesPzi: true,
        satisfiesPzs: true,
        serviceResources: {
          zones: ['Test string'],
        },
        stageStates: [
          {
            currentStateTime: 'Test string',
            executionStageName: 'Test string',
            executionStageState: 'Test string',
          },
        ],
        startTime: 'Test string',
        steps: [
          {
            kind: 'Test string',
            name: 'Test string',
            properties: {
              A: 42,
            },
          },
        ],
        stepsLocation: 'Test string',
        tempFiles: ['Test string'],
        transformNameMapping: {
          A: 'Test string',
        },
        type: 'Test string',
      }
    );
    /** Get encoded debug configuration for component. Not cacheable. */
    await gapi.client.dataflow.projects.jobs.debug.getConfig(
      {
        jobId: 'Test string',
        projectId: 'Test string',
      },
      {
        componentId: 'Test string',
        location: 'Test string',
        workerId: 'Test string',
      }
    );
    /** Send encoded debug capture data for component. */
    await gapi.client.dataflow.projects.jobs.debug.sendCapture(
      {
        jobId: 'Test string',
        projectId: 'Test string',
      },
      {
        componentId: 'Test string',
        data: 'Test string',
        dataFormat: 'Test string',
        location: 'Test string',
        workerId: 'Test string',
      }
    );
    /** Request the job status. To request the status of a job, we recommend using `projects.locations.jobs.messages.list` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using `projects.jobs.messages.list` is not recommended, as you can only request the status of jobs that are running in `us-central1`. */
    await gapi.client.dataflow.projects.jobs.messages.list({
      endTime: 'Test string',
      jobId: 'Test string',
      location: 'Test string',
      minimumImportance: 'Test string',
      pageSize: 42,
      pageToken: 'Test string',
      projectId: 'Test string',
      startTime: 'Test string',
    });
    /** Leases a dataflow WorkItem to run. */
    await gapi.client.dataflow.projects.jobs.workItems.lease(
      {
        jobId: 'Test string',
        projectId: 'Test string',
      },
      {
        currentWorkerTime: 'Test string',
        location: 'Test string',
        requestedLeaseDuration: 'Test string',
        unifiedWorkerRequest: {
          A: 42,
        },
        workerCapabilities: ['Test string'],
        workerId: 'Test string',
        workItemTypes: ['Test string'],
      }
    );
    /** Reports the status of dataflow WorkItems leased by a worker. */
    await gapi.client.dataflow.projects.jobs.workItems.reportStatus(
      {
        jobId: 'Test string',
        projectId: 'Test string',
      },
      {
        currentWorkerTime: 'Test string',
        location: 'Test string',
        unifiedWorkerRequest: {
          A: 42,
        },
        workerId: 'Test string',
        workItemStatuses: [
          {
            completed: true,
            counterUpdates: [
              {
                boolean: true,
                cumulative: true,
                distribution: {
                  count: {
                    highBits: 42,
                    lowBits: 42,
                  },
                  histogram: {
                    bucketCounts: ['Test string'],
                    firstBucketOffset: 42,
                  },
                  max: {
                    highBits: 42,
                    lowBits: 42,
                  },
                  min: {
                    highBits: 42,
                    lowBits: 42,
                  },
                  sum: {
                    highBits: 42,
                    lowBits: 42,
                  },
                  sumOfSquares: 42,
                },
                floatingPoint: 42,
                floatingPointList: {
                  elements: [42],
                },
                floatingPointMean: {
                  count: {
                    highBits: 42,
                    lowBits: 42,
                  },
                  sum: 42,
                },
                integer: {
                  highBits: 42,
                  lowBits: 42,
                },
                integerGauge: {
                  timestamp: 'Test string',
                  value: {
                    highBits: 42,
                    lowBits: 42,
                  },
                },
                integerList: {
                  elements: [
                    {
                      highBits: 42,
                      lowBits: 42,
                    },
                  ],
                },
                integerMean: {
                  count: {
                    highBits: 42,
                    lowBits: 42,
                  },
                  sum: {
                    highBits: 42,
                    lowBits: 42,
                  },
                },
                internal: 42,
                nameAndKind: {
                  kind: 'Test string',
                  name: 'Test string',
                },
                shortId: 'Test string',
                stringList: {
                  elements: ['Test string'],
                },
                structuredNameAndMetadata: {
                  metadata: {
                    description: 'Test string',
                    kind: 'Test string',
                    otherUnits: 'Test string',
                    standardUnits: 'Test string',
                  },
                  name: {
                    componentStepName: 'Test string',
                    executionStepName: 'Test string',
                    inputIndex: 42,
                    name: 'Test string',
                    origin: 'Test string',
                    originalRequestingStepName: 'Test string',
                    originalStepName: 'Test string',
                    originNamespace: 'Test string',
                    portion: 'Test string',
                    workerId: 'Test string',
                  },
                },
              },
            ],
            dynamicSourceSplit: {
              primary: {
                derivationMode: 'Test string',
                source: {
                  baseSpecs: [
                    {
                      A: 42,
                    },
                  ],
                  codec: {
                    A: 42,
                  },
                  doesNotNeedSplitting: true,
                  metadata: {
                    estimatedSizeBytes: 'Test string',
                    infinite: true,
                    producesSortedKeys: true,
                  },
                  spec: {
                    A: 42,
                  },
                },
              },
              residual: {
                derivationMode: 'Test string',
                source: {
                  baseSpecs: [
                    {
                      A: 42,
                    },
                  ],
                  codec: {
                    A: 42,
                  },
                  doesNotNeedSplitting: true,
                  metadata: {
                    estimatedSizeBytes: 'Test string',
                    infinite: true,
                    producesSortedKeys: true,
                  },
                  spec: {
                    A: 42,
                  },
                },
              },
            },
            errors: [
              {
                code: 42,
                details: [
                  {
                    A: 42,
                  },
                ],
                message: 'Test string',
              },
            ],
            metricUpdates: [
              {
                cumulative: true,
                distribution: 42,
                gauge: 42,
                internal: 42,
                kind: 'Test string',
                meanCount: 42,
                meanSum: 42,
                name: {
                  context: {
                    A: 'Test string',
                  },
                  name: 'Test string',
                  origin: 'Test string',
                },
                scalar: 42,
                set: 42,
                updateTime: 'Test string',
              },
            ],
            progress: {
              percentComplete: 42,
              position: {
                byteOffset: 'Test string',
                concatPosition: {
                  index: 42,
                  position: undefined,
                },
                end: true,
                key: 'Test string',
                recordIndex: 'Test string',
                shufflePosition: 'Test string',
              },
              remainingTime: 'Test string',
            },
            reportedProgress: {
              consumedParallelism: {
                isInfinite: true,
                value: 42,
              },
              fractionConsumed: 42,
              position: {
                byteOffset: 'Test string',
                concatPosition: {
                  index: 42,
                  position: undefined,
                },
                end: true,
                key: 'Test string',
                recordIndex: 'Test string',
                shufflePosition: 'Test string',
              },
              remainingParallelism: {
                isInfinite: true,
                value: 42,
              },
            },
            reportIndex: 'Test string',
            requestedLeaseDuration: 'Test string',
            sourceFork: {
              primary: {
                derivationMode: 'Test string',
                source: {
                  baseSpecs: [
                    {
                      A: 42,
                    },
                  ],
                  codec: {
                    A: 42,
                  },
                  doesNotNeedSplitting: true,
                  metadata: {
                    estimatedSizeBytes: 'Test string',
                    infinite: true,
                    producesSortedKeys: true,
                  },
                  spec: {
                    A: 42,
                  },
                },
              },
              primarySource: {
                derivationMode: 'Test string',
                source: {
                  baseSpecs: [
                    {
                      A: 42,
                    },
                  ],
                  codec: {
                    A: 42,
                  },
                  doesNotNeedSplitting: true,
                  metadata: {
                    estimatedSizeBytes: 'Test string',
                    infinite: true,
                    producesSortedKeys: true,
                  },
                  spec: {
                    A: 42,
                  },
                },
              },
              residual: {
                derivationMode: 'Test string',
                source: {
                  baseSpecs: [
                    {
                      A: 42,
                    },
                  ],
                  codec: {
                    A: 42,
                  },
                  doesNotNeedSplitting: true,
                  metadata: {
                    estimatedSizeBytes: 'Test string',
                    infinite: true,
                    producesSortedKeys: true,
                  },
                  spec: {
                    A: 42,
                  },
                },
              },
              residualSource: {
                derivationMode: 'Test string',
                source: {
                  baseSpecs: [
                    {
                      A: 42,
                    },
                  ],
                  codec: {
                    A: 42,
                  },
                  doesNotNeedSplitting: true,
                  metadata: {
                    estimatedSizeBytes: 'Test string',
                    infinite: true,
                    producesSortedKeys: true,
                  },
                  spec: {
                    A: 42,
                  },
                },
              },
            },
            sourceOperationResponse: {
              getMetadata: {
                metadata: {
                  estimatedSizeBytes: 'Test string',
                  infinite: true,
                  producesSortedKeys: true,
                },
              },
              split: {
                bundles: [
                  {
                    derivationMode: 'Test string',
                    source: {
                      baseSpecs: [
                        {
                          A: 42,
                        },
                      ],
                      codec: {
                        A: 42,
                      },
                      doesNotNeedSplitting: true,
                      metadata: {
                        estimatedSizeBytes: 'Test string',
                        infinite: true,
                        producesSortedKeys: true,
                      },
                      spec: {
                        A: 42,
                      },
                    },
                  },
                ],
                outcome: 'Test string',
                shards: [
                  {
                    derivationMode: 'Test string',
                    source: {
                      baseSpecs: [
                        {
                          A: 42,
                        },
                      ],
                      codec: {
                        A: 42,
                      },
                      doesNotNeedSplitting: true,
                      metadata: {
                        estimatedSizeBytes: 'Test string',
                        infinite: true,
                        producesSortedKeys: true,
                      },
                      spec: {
                        A: 42,
                      },
                    },
                  },
                ],
              },
            },
            stopPosition: {
              byteOffset: 'Test string',
              concatPosition: {
                index: 42,
                position: undefined,
              },
              end: true,
              key: 'Test string',
              recordIndex: 'Test string',
              shufflePosition: 'Test string',
            },
            totalThrottlerWaitTimeSeconds: 42,
            workItemId: 'Test string',
          },
        ],
      }
    );
    /** Send a worker_message to the service. */
    await gapi.client.dataflow.projects.locations.workerMessages(
      {
        location: 'Test string',
        projectId: 'Test string',
      },
      {
        location: 'Test string',
        workerMessages: [
          {
            dataSamplingReport: {
              bytesWrittenDelta: 'Test string',
              elementsSampledBytes: 'Test string',
              elementsSampledCount: 'Test string',
              exceptionsSampledCount: 'Test string',
              pcollectionsSampledCount: 'Test string',
              persistenceErrorsCount: 'Test string',
              translationErrorsCount: 'Test string',
            },
            labels: {
              A: 'Test string',
            },
            perWorkerMetrics: {
              perStepNamespaceMetrics: [
                {
                  metricsNamespace: 'Test string',
                  metricValues: [
                    {
                      metric: 'Test string',
                      metricLabels: {
                        A: 'Test string',
                      },
                      valueHistogram: {
                        bucketCounts: ['Test string'],
                        bucketOptions: {
                          exponential: {
                            numberOfBuckets: 42,
                            scale: 42,
                          },
                          linear: {
                            numberOfBuckets: 42,
                            start: 42,
                            width: 42,
                          },
                        },
                        count: 'Test string',
                        outlierStats: {
                          overflowCount: 'Test string',
                          overflowMean: 42,
                          underflowCount: 'Test string',
                          underflowMean: 42,
                        },
                      },
                      valueInt64: 'Test string',
                    },
                  ],
                  originalStep: 'Test string',
                },
              ],
            },
            streamingScalingReport: {
              activeBundleCount: 42,
              activeThreadCount: 42,
              maximumBundleCount: 42,
              maximumBytes: 'Test string',
              maximumBytesCount: 42,
              maximumThreadCount: 42,
              outstandingBundleCount: 42,
              outstandingBytes: 'Test string',
              outstandingBytesCount: 42,
            },
            time: 'Test string',
            workerHealthReport: {
              msg: 'Test string',
              pods: [
                {
                  A: 42,
                },
              ],
              reportInterval: 'Test string',
              vmBrokenCode: 'Test string',
              vmIsBroken: true,
              vmIsHealthy: true,
              vmStartupTime: 'Test string',
            },
            workerLifecycleEvent: {
              containerStartTime: 'Test string',
              event: 'Test string',
              metadata: {
                A: 'Test string',
              },
            },
            workerMessageCode: {
              code: 'Test string',
              parameters: {
                A: 42,
              },
            },
            workerMetrics: {
              containers: undefined,
              cpuTime: [
                {
                  rate: 42,
                  timestamp: 'Test string',
                  totalMs: 'Test string',
                },
              ],
              memoryInfo: [
                {
                  currentLimitBytes: 'Test string',
                  currentOoms: 'Test string',
                  currentRssBytes: 'Test string',
                  timestamp: 'Test string',
                  totalGbMs: 'Test string',
                },
              ],
            },
            workerShutdownNotice: {
              reason: 'Test string',
            },
            workerThreadScalingReport: {
              currentThreadCount: 42,
            },
          },
        ],
      }
    );
    /** Launch a job with a FlexTemplate. */
    await gapi.client.dataflow.projects.locations.flexTemplates.launch(
      {
        location: 'Test string',
        projectId: 'Test string',
      },
      {
        launchParameter: {
          containerSpec: {
            defaultEnvironment: {
              additionalExperiments: ['Test string'],
              additionalUserLabels: {
                A: 'Test string',
              },
              autoscalingAlgorithm: 'Test string',
              diskSizeGb: 42,
              dumpHeapOnOom: true,
              enableLauncherVmSerialPortLogging: true,
              enableStreamingEngine: true,
              flexrsGoal: 'Test string',
              ipConfiguration: 'Test string',
              kmsKeyName: 'Test string',
              launcherMachineType: 'Test string',
              machineType: 'Test string',
              maxWorkers: 42,
              network: 'Test string',
              numWorkers: 42,
              saveHeapDumpsToGcsPath: 'Test string',
              sdkContainerImage: 'Test string',
              serviceAccountEmail: 'Test string',
              stagingLocation: 'Test string',
              streamingMode: 'Test string',
              subnetwork: 'Test string',
              tempLocation: 'Test string',
              workerRegion: 'Test string',
              workerZone: 'Test string',
              zone: 'Test string',
            },
            image: 'Test string',
            imageRepositoryCertPath: 'Test string',
            imageRepositoryPasswordSecretId: 'Test string',
            imageRepositoryUsernameSecretId: 'Test string',
            metadata: {
              defaultStreamingMode: 'Test string',
              description: 'Test string',
              name: 'Test string',
              parameters: [
                {
                  customMetadata: {
                    A: 'Test string',
                  },
                  defaultValue: 'Test string',
                  enumOptions: [
                    {
                      description: 'Test string',
                      label: 'Test string',
                      value: 'Test string',
                    },
                  ],
                  groupName: 'Test string',
                  helpText: 'Test string',
                  hiddenUi: true,
                  isOptional: true,
                  label: 'Test string',
                  name: 'Test string',
                  paramType: 'Test string',
                  parentName: 'Test string',
                  parentTriggerValues: ['Test string'],
                  regexes: ['Test string'],
                },
              ],
              streaming: true,
              supportsAtLeastOnce: true,
              supportsExactlyOnce: true,
            },
            sdkInfo: {
              language: 'Test string',
              version: 'Test string',
            },
          },
          containerSpecGcsPath: 'Test string',
          environment: {
            additionalExperiments: ['Test string'],
            additionalUserLabels: {
              A: 'Test string',
            },
            autoscalingAlgorithm: 'Test string',
            diskSizeGb: 42,
            dumpHeapOnOom: true,
            enableLauncherVmSerialPortLogging: true,
            enableStreamingEngine: true,
            flexrsGoal: 'Test string',
            ipConfiguration: 'Test string',
            kmsKeyName: 'Test string',
            launcherMachineType: 'Test string',
            machineType: 'Test string',
            maxWorkers: 42,
            network: 'Test string',
            numWorkers: 42,
            saveHeapDumpsToGcsPath: 'Test string',
            sdkContainerImage: 'Test string',
            serviceAccountEmail: 'Test string',
            stagingLocation: 'Test string',
            streamingMode: 'Test string',
            subnetwork: 'Test string',
            tempLocation: 'Test string',
            workerRegion: 'Test string',
            workerZone: 'Test string',
            zone: 'Test string',
          },
          jobName: 'Test string',
          launchOptions: {
            A: 'Test string',
          },
          parameters: {
            A: 'Test string',
          },
          transformNameMappings: {
            A: 'Test string',
          },
          update: true,
        },
        validateOnly: true,
      }
    );
    /** Creates a Cloud Dataflow job. To create a job, we recommend using `projects.locations.jobs.create` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using `projects.jobs.create` is not recommended, as your job will always start in `us-central1`. Do not enter confidential information when you supply string values using the API. */
    await gapi.client.dataflow.projects.locations.jobs.create(
      {
        location: 'Test string',
        projectId: 'Test string',
        replaceJobId: 'Test string',
        view: 'Test string',
      },
      {
        clientRequestId: 'Test string',
        createdFromSnapshotId: 'Test string',
        createTime: 'Test string',
        currentState: 'Test string',
        currentStateTime: 'Test string',
        environment: {
          clusterManagerApiService: 'Test string',
          dataset: 'Test string',
          debugOptions: {
            dataSampling: {
              behaviors: ['Test string'],
            },
            enableHotKeyLogging: true,
          },
          experiments: ['Test string'],
          flexResourceSchedulingGoal: 'Test string',
          internalExperiments: {
            A: 42,
          },
          sdkPipelineOptions: {
            A: 42,
          },
          serviceAccountEmail: 'Test string',
          serviceKmsKeyName: 'Test string',
          serviceOptions: ['Test string'],
          shuffleMode: 'Test string',
          streamingMode: 'Test string',
          tempStoragePrefix: 'Test string',
          userAgent: {
            A: 42,
          },
          useStreamingEngineResourceBasedBilling: true,
          version: {
            A: 42,
          },
          workerPools: [
            {
              autoscalingSettings: {
                algorithm: 'Test string',
                maxNumWorkers: 42,
              },
              dataDisks: [
                {
                  diskType: 'Test string',
                  mountPoint: 'Test string',
                  sizeGb: 42,
                },
              ],
              defaultPackageSet: 'Test string',
              diskSizeGb: 42,
              diskSourceImage: 'Test string',
              diskType: 'Test string',
              ipConfiguration: 'Test string',
              kind: 'Test string',
              machineType: 'Test string',
              metadata: {
                A: 'Test string',
              },
              network: 'Test string',
              numThreadsPerWorker: 42,
              numWorkers: 42,
              onHostMaintenance: 'Test string',
              packages: [
                {
                  location: 'Test string',
                  name: 'Test string',
                },
              ],
              poolArgs: {
                A: 42,
              },
              sdkHarnessContainerImages: [
                {
                  capabilities: ['Test string'],
                  containerImage: 'Test string',
                  environmentId: 'Test string',
                  useSingleCorePerContainer: true,
                },
              ],
              subnetwork: 'Test string',
              taskrunnerSettings: {
                alsologtostderr: true,
                baseTaskDir: 'Test string',
                baseUrl: 'Test string',
                commandlinesFileName: 'Test string',
                continueOnException: true,
                dataflowApiVersion: 'Test string',
                harnessCommand: 'Test string',
                languageHint: 'Test string',
                logDir: 'Test string',
                logToSerialconsole: true,
                logUploadLocation: 'Test string',
                oauthScopes: ['Test string'],
                parallelWorkerSettings: {
                  baseUrl: 'Test string',
                  reportingEnabled: true,
                  servicePath: 'Test string',
                  shuffleServicePath: 'Test string',
                  tempStoragePrefix: 'Test string',
                  workerId: 'Test string',
                },
                streamingWorkerMainClass: 'Test string',
                taskGroup: 'Test string',
                taskUser: 'Test string',
                tempStoragePrefix: 'Test string',
                vmId: 'Test string',
                workflowFileName: 'Test string',
              },
              teardownPolicy: 'Test string',
              workerHarnessContainerImage: 'Test string',
              zone: 'Test string',
            },
          ],
          workerRegion: 'Test string',
          workerZone: 'Test string',
        },
        executionInfo: {
          stages: {
            A: {
              stepName: ['Test string'],
            },
          },
        },
        id: 'Test string',
        jobMetadata: {
          bigqueryDetails: [
            {
              dataset: 'Test string',
              projectId: 'Test string',
              query: 'Test string',
              table: 'Test string',
            },
          ],
          bigTableDetails: [
            {
              instanceId: 'Test string',
              projectId: 'Test string',
              tableId: 'Test string',
            },
          ],
          datastoreDetails: [
            {
              namespace: 'Test string',
              projectId: 'Test string',
            },
          ],
          fileDetails: [
            {
              filePattern: 'Test string',
            },
          ],
          pubsubDetails: [
            {
              subscription: 'Test string',
              topic: 'Test string',
            },
          ],
          sdkVersion: {
            bugs: [
              {
                severity: 'Test string',
                type: 'Test string',
                uri: 'Test string',
              },
            ],
            sdkSupportStatus: 'Test string',
            version: 'Test string',
            versionDisplayName: 'Test string',
          },
          spannerDetails: [
            {
              databaseId: 'Test string',
              instanceId: 'Test string',
              projectId: 'Test string',
            },
          ],
          userDisplayProperties: {
            A: 'Test string',
          },
        },
        labels: {
          A: 'Test string',
        },
        location: 'Test string',
        name: 'Test string',
        pipelineDescription: {
          displayData: [
            {
              boolValue: true,
              durationValue: 'Test string',
              floatValue: 42,
              int64Value: 'Test string',
              javaClassValue: 'Test string',
              key: 'Test string',
              label: 'Test string',
              namespace: 'Test string',
              shortStrValue: 'Test string',
              strValue: 'Test string',
              timestampValue: 'Test string',
              url: 'Test string',
            },
          ],
          executionPipelineStage: [
            {
              componentSource: [
                {
                  name: 'Test string',
                  originalTransformOrCollection: 'Test string',
                  userName: 'Test string',
                },
              ],
              componentTransform: [
                {
                  name: 'Test string',
                  originalTransform: 'Test string',
                  userName: 'Test string',
                },
              ],
              id: 'Test string',
              inputSource: [
                {
                  name: 'Test string',
                  originalTransformOrCollection: 'Test string',
                  sizeBytes: 'Test string',
                  userName: 'Test string',
                },
              ],
              kind: 'Test string',
              name: 'Test string',
              outputSource: [
                {
                  name: 'Test string',
                  originalTransformOrCollection: 'Test string',
                  sizeBytes: 'Test string',
                  userName: 'Test string',
                },
              ],
              prerequisiteStage: ['Test string'],
            },
          ],
          originalPipelineTransform: [
            {
              displayData: [
                {
                  boolValue: true,
                  durationValue: 'Test string',
                  floatValue: 42,
                  int64Value: 'Test string',
                  javaClassValue: 'Test string',
                  key: 'Test string',
                  label: 'Test string',
                  namespace: 'Test string',
                  shortStrValue: 'Test string',
                  strValue: 'Test string',
                  timestampValue: 'Test string',
                  url: 'Test string',
                },
              ],
              id: 'Test string',
              inputCollectionName: ['Test string'],
              kind: 'Test string',
              name: 'Test string',
              outputCollectionName: ['Test string'],
            },
          ],
          stepNamesHash: 'Test string',
        },
        projectId: 'Test string',
        replacedByJobId: 'Test string',
        replaceJobId: 'Test string',
        requestedState: 'Test string',
        runtimeUpdatableParams: {
          maxNumWorkers: 42,
          minNumWorkers: 42,
          workerUtilizationHint: 42,
        },
        satisfiesPzi: true,
        satisfiesPzs: true,
        serviceResources: {
          zones: ['Test string'],
        },
        stageStates: [
          {
            currentStateTime: 'Test string',
            executionStageName: 'Test string',
            executionStageState: 'Test string',
          },
        ],
        startTime: 'Test string',
        steps: [
          {
            kind: 'Test string',
            name: 'Test string',
            properties: {
              A: 42,
            },
          },
        ],
        stepsLocation: 'Test string',
        tempFiles: ['Test string'],
        transformNameMapping: {
          A: 'Test string',
        },
        type: 'Test string',
      }
    );
    /** Gets the state of the specified Cloud Dataflow job. To get the state of a job, we recommend using `projects.locations.jobs.get` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using `projects.jobs.get` is not recommended, as you can only get the state of jobs that are running in `us-central1`. */
    await gapi.client.dataflow.projects.locations.jobs.get({
      jobId: 'Test string',
      location: 'Test string',
      projectId: 'Test string',
      view: 'Test string',
    });
    /** Request detailed information about the execution status of the job. EXPERIMENTAL. This API is subject to change or removal without notice. */
    await gapi.client.dataflow.projects.locations.jobs.getExecutionDetails({
      jobId: 'Test string',
      location: 'Test string',
      pageSize: 42,
      pageToken: 'Test string',
      projectId: 'Test string',
    });
    /** Request the job status. To request the status of a job, we recommend using `projects.locations.jobs.getMetrics` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using `projects.jobs.getMetrics` is not recommended, as you can only request the status of jobs that are running in `us-central1`. */
    await gapi.client.dataflow.projects.locations.jobs.getMetrics({
      jobId: 'Test string',
      location: 'Test string',
      projectId: 'Test string',
      startTime: 'Test string',
    });
    /** List the jobs of a project. To list the jobs of a project in a region, we recommend using `projects.locations.jobs.list` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). To list the all jobs across all regions, use `projects.jobs.aggregated`. Using `projects.jobs.list` is not recommended, because you can only get the list of jobs that are running in `us-central1`. `projects.locations.jobs.list` and `projects.jobs.list` support filtering the list of jobs by name. Filtering by name isn't supported by `projects.jobs.aggregated`. */
    await gapi.client.dataflow.projects.locations.jobs.list({
      filter: 'Test string',
      location: 'Test string',
      name: 'Test string',
      pageSize: 42,
      pageToken: 'Test string',
      projectId: 'Test string',
      view: 'Test string',
    });
    /** Snapshot the state of a streaming job. */
    await gapi.client.dataflow.projects.locations.jobs.snapshot(
      {
        jobId: 'Test string',
        location: 'Test string',
        projectId: 'Test string',
      },
      {
        description: 'Test string',
        location: 'Test string',
        snapshotSources: true,
        ttl: 'Test string',
      }
    );
    /** Updates the state of an existing Cloud Dataflow job. To update the state of an existing job, we recommend using `projects.locations.jobs.update` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using `projects.jobs.update` is not recommended, as you can only update the state of jobs that are running in `us-central1`. */
    await gapi.client.dataflow.projects.locations.jobs.update(
      {
        jobId: 'Test string',
        location: 'Test string',
        projectId: 'Test string',
        updateMask: 'Test string',
      },
      {
        clientRequestId: 'Test string',
        createdFromSnapshotId: 'Test string',
        createTime: 'Test string',
        currentState: 'Test string',
        currentStateTime: 'Test string',
        environment: {
          clusterManagerApiService: 'Test string',
          dataset: 'Test string',
          debugOptions: {
            dataSampling: {
              behaviors: ['Test string'],
            },
            enableHotKeyLogging: true,
          },
          experiments: ['Test string'],
          flexResourceSchedulingGoal: 'Test string',
          internalExperiments: {
            A: 42,
          },
          sdkPipelineOptions: {
            A: 42,
          },
          serviceAccountEmail: 'Test string',
          serviceKmsKeyName: 'Test string',
          serviceOptions: ['Test string'],
          shuffleMode: 'Test string',
          streamingMode: 'Test string',
          tempStoragePrefix: 'Test string',
          userAgent: {
            A: 42,
          },
          useStreamingEngineResourceBasedBilling: true,
          version: {
            A: 42,
          },
          workerPools: [
            {
              autoscalingSettings: {
                algorithm: 'Test string',
                maxNumWorkers: 42,
              },
              dataDisks: [
                {
                  diskType: 'Test string',
                  mountPoint: 'Test string',
                  sizeGb: 42,
                },
              ],
              defaultPackageSet: 'Test string',
              diskSizeGb: 42,
              diskSourceImage: 'Test string',
              diskType: 'Test string',
              ipConfiguration: 'Test string',
              kind: 'Test string',
              machineType: 'Test string',
              metadata: {
                A: 'Test string',
              },
              network: 'Test string',
              numThreadsPerWorker: 42,
              numWorkers: 42,
              onHostMaintenance: 'Test string',
              packages: [
                {
                  location: 'Test string',
                  name: 'Test string',
                },
              ],
              poolArgs: {
                A: 42,
              },
              sdkHarnessContainerImages: [
                {
                  capabilities: ['Test string'],
                  containerImage: 'Test string',
                  environmentId: 'Test string',
                  useSingleCorePerContainer: true,
                },
              ],
              subnetwork: 'Test string',
              taskrunnerSettings: {
                alsologtostderr: true,
                baseTaskDir: 'Test string',
                baseUrl: 'Test string',
                commandlinesFileName: 'Test string',
                continueOnException: true,
                dataflowApiVersion: 'Test string',
                harnessCommand: 'Test string',
                languageHint: 'Test string',
                logDir: 'Test string',
                logToSerialconsole: true,
                logUploadLocation: 'Test string',
                oauthScopes: ['Test string'],
                parallelWorkerSettings: {
                  baseUrl: 'Test string',
                  reportingEnabled: true,
                  servicePath: 'Test string',
                  shuffleServicePath: 'Test string',
                  tempStoragePrefix: 'Test string',
                  workerId: 'Test string',
                },
                streamingWorkerMainClass: 'Test string',
                taskGroup: 'Test string',
                taskUser: 'Test string',
                tempStoragePrefix: 'Test string',
                vmId: 'Test string',
                workflowFileName: 'Test string',
              },
              teardownPolicy: 'Test string',
              workerHarnessContainerImage: 'Test string',
              zone: 'Test string',
            },
          ],
          workerRegion: 'Test string',
          workerZone: 'Test string',
        },
        executionInfo: {
          stages: {
            A: {
              stepName: ['Test string'],
            },
          },
        },
        id: 'Test string',
        jobMetadata: {
          bigqueryDetails: [
            {
              dataset: 'Test string',
              projectId: 'Test string',
              query: 'Test string',
              table: 'Test string',
            },
          ],
          bigTableDetails: [
            {
              instanceId: 'Test string',
              projectId: 'Test string',
              tableId: 'Test string',
            },
          ],
          datastoreDetails: [
            {
              namespace: 'Test string',
              projectId: 'Test string',
            },
          ],
          fileDetails: [
            {
              filePattern: 'Test string',
            },
          ],
          pubsubDetails: [
            {
              subscription: 'Test string',
              topic: 'Test string',
            },
          ],
          sdkVersion: {
            bugs: [
              {
                severity: 'Test string',
                type: 'Test string',
                uri: 'Test string',
              },
            ],
            sdkSupportStatus: 'Test string',
            version: 'Test string',
            versionDisplayName: 'Test string',
          },
          spannerDetails: [
            {
              databaseId: 'Test string',
              instanceId: 'Test string',
              projectId: 'Test string',
            },
          ],
          userDisplayProperties: {
            A: 'Test string',
          },
        },
        labels: {
          A: 'Test string',
        },
        location: 'Test string',
        name: 'Test string',
        pipelineDescription: {
          displayData: [
            {
              boolValue: true,
              durationValue: 'Test string',
              floatValue: 42,
              int64Value: 'Test string',
              javaClassValue: 'Test string',
              key: 'Test string',
              label: 'Test string',
              namespace: 'Test string',
              shortStrValue: 'Test string',
              strValue: 'Test string',
              timestampValue: 'Test string',
              url: 'Test string',
            },
          ],
          executionPipelineStage: [
            {
              componentSource: [
                {
                  name: 'Test string',
                  originalTransformOrCollection: 'Test string',
                  userName: 'Test string',
                },
              ],
              componentTransform: [
                {
                  name: 'Test string',
                  originalTransform: 'Test string',
                  userName: 'Test string',
                },
              ],
              id: 'Test string',
              inputSource: [
                {
                  name: 'Test string',
                  originalTransformOrCollection: 'Test string',
                  sizeBytes: 'Test string',
                  userName: 'Test string',
                },
              ],
              kind: 'Test string',
              name: 'Test string',
              outputSource: [
                {
                  name: 'Test string',
                  originalTransformOrCollection: 'Test string',
                  sizeBytes: 'Test string',
                  userName: 'Test string',
                },
              ],
              prerequisiteStage: ['Test string'],
            },
          ],
          originalPipelineTransform: [
            {
              displayData: [
                {
                  boolValue: true,
                  durationValue: 'Test string',
                  floatValue: 42,
                  int64Value: 'Test string',
                  javaClassValue: 'Test string',
                  key: 'Test string',
                  label: 'Test string',
                  namespace: 'Test string',
                  shortStrValue: 'Test string',
                  strValue: 'Test string',
                  timestampValue: 'Test string',
                  url: 'Test string',
                },
              ],
              id: 'Test string',
              inputCollectionName: ['Test string'],
              kind: 'Test string',
              name: 'Test string',
              outputCollectionName: ['Test string'],
            },
          ],
          stepNamesHash: 'Test string',
        },
        projectId: 'Test string',
        replacedByJobId: 'Test string',
        replaceJobId: 'Test string',
        requestedState: 'Test string',
        runtimeUpdatableParams: {
          maxNumWorkers: 42,
          minNumWorkers: 42,
          workerUtilizationHint: 42,
        },
        satisfiesPzi: true,
        satisfiesPzs: true,
        serviceResources: {
          zones: ['Test string'],
        },
        stageStates: [
          {
            currentStateTime: 'Test string',
            executionStageName: 'Test string',
            executionStageState: 'Test string',
          },
        ],
        startTime: 'Test string',
        steps: [
          {
            kind: 'Test string',
            name: 'Test string',
            properties: {
              A: 42,
            },
          },
        ],
        stepsLocation: 'Test string',
        tempFiles: ['Test string'],
        transformNameMapping: {
          A: 'Test string',
        },
        type: 'Test string',
      }
    );
    /** Get encoded debug configuration for component. Not cacheable. */
    await gapi.client.dataflow.projects.locations.jobs.debug.getConfig(
      {
        jobId: 'Test string',
        location: 'Test string',
        projectId: 'Test string',
      },
      {
        componentId: 'Test string',
        location: 'Test string',
        workerId: 'Test string',
      }
    );
    /** Send encoded debug capture data for component. */
    await gapi.client.dataflow.projects.locations.jobs.debug.sendCapture(
      {
        jobId: 'Test string',
        location: 'Test string',
        projectId: 'Test string',
      },
      {
        componentId: 'Test string',
        data: 'Test string',
        dataFormat: 'Test string',
        location: 'Test string',
        workerId: 'Test string',
      }
    );
    /** Request the job status. To request the status of a job, we recommend using `projects.locations.jobs.messages.list` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using `projects.jobs.messages.list` is not recommended, as you can only request the status of jobs that are running in `us-central1`. */
    await gapi.client.dataflow.projects.locations.jobs.messages.list({
      endTime: 'Test string',
      jobId: 'Test string',
      location: 'Test string',
      minimumImportance: 'Test string',
      pageSize: 42,
      pageToken: 'Test string',
      projectId: 'Test string',
      startTime: 'Test string',
    });
    /** Lists snapshots. */
    await gapi.client.dataflow.projects.locations.jobs.snapshots.list({
      jobId: 'Test string',
      location: 'Test string',
      projectId: 'Test string',
    });
    /** Request detailed information about the execution status of a stage of the job. EXPERIMENTAL. This API is subject to change or removal without notice. */
    await gapi.client.dataflow.projects.locations.jobs.stages.getExecutionDetails(
      {
        endTime: 'Test string',
        jobId: 'Test string',
        location: 'Test string',
        pageSize: 42,
        pageToken: 'Test string',
        projectId: 'Test string',
        stageId: 'Test string',
        startTime: 'Test string',
      }
    );
    /** Leases a dataflow WorkItem to run. */
    await gapi.client.dataflow.projects.locations.jobs.workItems.lease(
      {
        jobId: 'Test string',
        location: 'Test string',
        projectId: 'Test string',
      },
      {
        currentWorkerTime: 'Test string',
        location: 'Test string',
        requestedLeaseDuration: 'Test string',
        unifiedWorkerRequest: {
          A: 42,
        },
        workerCapabilities: ['Test string'],
        workerId: 'Test string',
        workItemTypes: ['Test string'],
      }
    );
    /** Reports the status of dataflow WorkItems leased by a worker. */
    await gapi.client.dataflow.projects.locations.jobs.workItems.reportStatus(
      {
        jobId: 'Test string',
        location: 'Test string',
        projectId: 'Test string',
      },
      {
        currentWorkerTime: 'Test string',
        location: 'Test string',
        unifiedWorkerRequest: {
          A: 42,
        },
        workerId: 'Test string',
        workItemStatuses: [
          {
            completed: true,
            counterUpdates: [
              {
                boolean: true,
                cumulative: true,
                distribution: {
                  count: {
                    highBits: 42,
                    lowBits: 42,
                  },
                  histogram: {
                    bucketCounts: ['Test string'],
                    firstBucketOffset: 42,
                  },
                  max: {
                    highBits: 42,
                    lowBits: 42,
                  },
                  min: {
                    highBits: 42,
                    lowBits: 42,
                  },
                  sum: {
                    highBits: 42,
                    lowBits: 42,
                  },
                  sumOfSquares: 42,
                },
                floatingPoint: 42,
                floatingPointList: {
                  elements: [42],
                },
                floatingPointMean: {
                  count: {
                    highBits: 42,
                    lowBits: 42,
                  },
                  sum: 42,
                },
                integer: {
                  highBits: 42,
                  lowBits: 42,
                },
                integerGauge: {
                  timestamp: 'Test string',
                  value: {
                    highBits: 42,
                    lowBits: 42,
                  },
                },
                integerList: {
                  elements: [
                    {
                      highBits: 42,
                      lowBits: 42,
                    },
                  ],
                },
                integerMean: {
                  count: {
                    highBits: 42,
                    lowBits: 42,
                  },
                  sum: {
                    highBits: 42,
                    lowBits: 42,
                  },
                },
                internal: 42,
                nameAndKind: {
                  kind: 'Test string',
                  name: 'Test string',
                },
                shortId: 'Test string',
                stringList: {
                  elements: ['Test string'],
                },
                structuredNameAndMetadata: {
                  metadata: {
                    description: 'Test string',
                    kind: 'Test string',
                    otherUnits: 'Test string',
                    standardUnits: 'Test string',
                  },
                  name: {
                    componentStepName: 'Test string',
                    executionStepName: 'Test string',
                    inputIndex: 42,
                    name: 'Test string',
                    origin: 'Test string',
                    originalRequestingStepName: 'Test string',
                    originalStepName: 'Test string',
                    originNamespace: 'Test string',
                    portion: 'Test string',
                    workerId: 'Test string',
                  },
                },
              },
            ],
            dynamicSourceSplit: {
              primary: {
                derivationMode: 'Test string',
                source: {
                  baseSpecs: [
                    {
                      A: 42,
                    },
                  ],
                  codec: {
                    A: 42,
                  },
                  doesNotNeedSplitting: true,
                  metadata: {
                    estimatedSizeBytes: 'Test string',
                    infinite: true,
                    producesSortedKeys: true,
                  },
                  spec: {
                    A: 42,
                  },
                },
              },
              residual: {
                derivationMode: 'Test string',
                source: {
                  baseSpecs: [
                    {
                      A: 42,
                    },
                  ],
                  codec: {
                    A: 42,
                  },
                  doesNotNeedSplitting: true,
                  metadata: {
                    estimatedSizeBytes: 'Test string',
                    infinite: true,
                    producesSortedKeys: true,
                  },
                  spec: {
                    A: 42,
                  },
                },
              },
            },
            errors: [
              {
                code: 42,
                details: [
                  {
                    A: 42,
                  },
                ],
                message: 'Test string',
              },
            ],
            metricUpdates: [
              {
                cumulative: true,
                distribution: 42,
                gauge: 42,
                internal: 42,
                kind: 'Test string',
                meanCount: 42,
                meanSum: 42,
                name: {
                  context: {
                    A: 'Test string',
                  },
                  name: 'Test string',
                  origin: 'Test string',
                },
                scalar: 42,
                set: 42,
                updateTime: 'Test string',
              },
            ],
            progress: {
              percentComplete: 42,
              position: {
                byteOffset: 'Test string',
                concatPosition: {
                  index: 42,
                  position: undefined,
                },
                end: true,
                key: 'Test string',
                recordIndex: 'Test string',
                shufflePosition: 'Test string',
              },
              remainingTime: 'Test string',
            },
            reportedProgress: {
              consumedParallelism: {
                isInfinite: true,
                value: 42,
              },
              fractionConsumed: 42,
              position: {
                byteOffset: 'Test string',
                concatPosition: {
                  index: 42,
                  position: undefined,
                },
                end: true,
                key: 'Test string',
                recordIndex: 'Test string',
                shufflePosition: 'Test string',
              },
              remainingParallelism: {
                isInfinite: true,
                value: 42,
              },
            },
            reportIndex: 'Test string',
            requestedLeaseDuration: 'Test string',
            sourceFork: {
              primary: {
                derivationMode: 'Test string',
                source: {
                  baseSpecs: [
                    {
                      A: 42,
                    },
                  ],
                  codec: {
                    A: 42,
                  },
                  doesNotNeedSplitting: true,
                  metadata: {
                    estimatedSizeBytes: 'Test string',
                    infinite: true,
                    producesSortedKeys: true,
                  },
                  spec: {
                    A: 42,
                  },
                },
              },
              primarySource: {
                derivationMode: 'Test string',
                source: {
                  baseSpecs: [
                    {
                      A: 42,
                    },
                  ],
                  codec: {
                    A: 42,
                  },
                  doesNotNeedSplitting: true,
                  metadata: {
                    estimatedSizeBytes: 'Test string',
                    infinite: true,
                    producesSortedKeys: true,
                  },
                  spec: {
                    A: 42,
                  },
                },
              },
              residual: {
                derivationMode: 'Test string',
                source: {
                  baseSpecs: [
                    {
                      A: 42,
                    },
                  ],
                  codec: {
                    A: 42,
                  },
                  doesNotNeedSplitting: true,
                  metadata: {
                    estimatedSizeBytes: 'Test string',
                    infinite: true,
                    producesSortedKeys: true,
                  },
                  spec: {
                    A: 42,
                  },
                },
              },
              residualSource: {
                derivationMode: 'Test string',
                source: {
                  baseSpecs: [
                    {
                      A: 42,
                    },
                  ],
                  codec: {
                    A: 42,
                  },
                  doesNotNeedSplitting: true,
                  metadata: {
                    estimatedSizeBytes: 'Test string',
                    infinite: true,
                    producesSortedKeys: true,
                  },
                  spec: {
                    A: 42,
                  },
                },
              },
            },
            sourceOperationResponse: {
              getMetadata: {
                metadata: {
                  estimatedSizeBytes: 'Test string',
                  infinite: true,
                  producesSortedKeys: true,
                },
              },
              split: {
                bundles: [
                  {
                    derivationMode: 'Test string',
                    source: {
                      baseSpecs: [
                        {
                          A: 42,
                        },
                      ],
                      codec: {
                        A: 42,
                      },
                      doesNotNeedSplitting: true,
                      metadata: {
                        estimatedSizeBytes: 'Test string',
                        infinite: true,
                        producesSortedKeys: true,
                      },
                      spec: {
                        A: 42,
                      },
                    },
                  },
                ],
                outcome: 'Test string',
                shards: [
                  {
                    derivationMode: 'Test string',
                    source: {
                      baseSpecs: [
                        {
                          A: 42,
                        },
                      ],
                      codec: {
                        A: 42,
                      },
                      doesNotNeedSplitting: true,
                      metadata: {
                        estimatedSizeBytes: 'Test string',
                        infinite: true,
                        producesSortedKeys: true,
                      },
                      spec: {
                        A: 42,
                      },
                    },
                  },
                ],
              },
            },
            stopPosition: {
              byteOffset: 'Test string',
              concatPosition: {
                index: 42,
                position: undefined,
              },
              end: true,
              key: 'Test string',
              recordIndex: 'Test string',
              shufflePosition: 'Test string',
            },
            totalThrottlerWaitTimeSeconds: 42,
            workItemId: 'Test string',
          },
        ],
      }
    );
    /** Deletes a snapshot. */
    await gapi.client.dataflow.projects.locations.snapshots.delete({
      location: 'Test string',
      projectId: 'Test string',
      snapshotId: 'Test string',
    });
    /** Gets information about a snapshot. */
    await gapi.client.dataflow.projects.locations.snapshots.get({
      location: 'Test string',
      projectId: 'Test string',
      snapshotId: 'Test string',
    });
    /** Lists snapshots. */
    await gapi.client.dataflow.projects.locations.snapshots.list({
      jobId: 'Test string',
      location: 'Test string',
      projectId: 'Test string',
    });
    /** Creates a Cloud Dataflow job from a template. Do not enter confidential information when you supply string values using the API. To create a job, we recommend using `projects.locations.templates.create` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using `projects.templates.create` is not recommended, because your job will always start in `us-central1`. */
    await gapi.client.dataflow.projects.locations.templates.create(
      {
        location: 'Test string',
        projectId: 'Test string',
      },
      {
        environment: {
          additionalExperiments: ['Test string'],
          additionalUserLabels: {
            A: 'Test string',
          },
          bypassTempDirValidation: true,
          diskSizeGb: 42,
          enableStreamingEngine: true,
          ipConfiguration: 'Test string',
          kmsKeyName: 'Test string',
          machineType: 'Test string',
          maxWorkers: 42,
          network: 'Test string',
          numWorkers: 42,
          serviceAccountEmail: 'Test string',
          streamingMode: 'Test string',
          subnetwork: 'Test string',
          tempLocation: 'Test string',
          workerRegion: 'Test string',
          workerZone: 'Test string',
          zone: 'Test string',
        },
        gcsPath: 'Test string',
        jobName: 'Test string',
        location: 'Test string',
        parameters: {
          A: 'Test string',
        },
      }
    );
    /** Get the template associated with a template. To get the template, we recommend using `projects.locations.templates.get` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using `projects.templates.get` is not recommended, because only templates that are running in `us-central1` are retrieved. */
    await gapi.client.dataflow.projects.locations.templates.get({
      gcsPath: 'Test string',
      location: 'Test string',
      projectId: 'Test string',
      view: 'Test string',
    });
    /** Launches a template. To launch a template, we recommend using `projects.locations.templates.launch` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using `projects.templates.launch` is not recommended, because jobs launched from the template will always start in `us-central1`. */
    await gapi.client.dataflow.projects.locations.templates.launch(
      {
        'dynamicTemplate.gcsPath': 'Test string',
        'dynamicTemplate.stagingLocation': 'Test string',
        gcsPath: 'Test string',
        location: 'Test string',
        projectId: 'Test string',
        validateOnly: true,
      },
      {
        environment: {
          additionalExperiments: ['Test string'],
          additionalUserLabels: {
            A: 'Test string',
          },
          bypassTempDirValidation: true,
          diskSizeGb: 42,
          enableStreamingEngine: true,
          ipConfiguration: 'Test string',
          kmsKeyName: 'Test string',
          machineType: 'Test string',
          maxWorkers: 42,
          network: 'Test string',
          numWorkers: 42,
          serviceAccountEmail: 'Test string',
          streamingMode: 'Test string',
          subnetwork: 'Test string',
          tempLocation: 'Test string',
          workerRegion: 'Test string',
          workerZone: 'Test string',
          zone: 'Test string',
        },
        jobName: 'Test string',
        parameters: {
          A: 'Test string',
        },
        transformNameMapping: {
          A: 'Test string',
        },
        update: true,
      }
    );
    /** Gets information about a snapshot. */
    await gapi.client.dataflow.projects.snapshots.get({
      location: 'Test string',
      projectId: 'Test string',
      snapshotId: 'Test string',
    });
    /** Lists snapshots. */
    await gapi.client.dataflow.projects.snapshots.list({
      jobId: 'Test string',
      location: 'Test string',
      projectId: 'Test string',
    });
    /** Creates a Cloud Dataflow job from a template. Do not enter confidential information when you supply string values using the API. To create a job, we recommend using `projects.locations.templates.create` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using `projects.templates.create` is not recommended, because your job will always start in `us-central1`. */
    await gapi.client.dataflow.projects.templates.create(
      {
        projectId: 'Test string',
      },
      {
        environment: {
          additionalExperiments: ['Test string'],
          additionalUserLabels: {
            A: 'Test string',
          },
          bypassTempDirValidation: true,
          diskSizeGb: 42,
          enableStreamingEngine: true,
          ipConfiguration: 'Test string',
          kmsKeyName: 'Test string',
          machineType: 'Test string',
          maxWorkers: 42,
          network: 'Test string',
          numWorkers: 42,
          serviceAccountEmail: 'Test string',
          streamingMode: 'Test string',
          subnetwork: 'Test string',
          tempLocation: 'Test string',
          workerRegion: 'Test string',
          workerZone: 'Test string',
          zone: 'Test string',
        },
        gcsPath: 'Test string',
        jobName: 'Test string',
        location: 'Test string',
        parameters: {
          A: 'Test string',
        },
      }
    );
    /** Get the template associated with a template. To get the template, we recommend using `projects.locations.templates.get` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using `projects.templates.get` is not recommended, because only templates that are running in `us-central1` are retrieved. */
    await gapi.client.dataflow.projects.templates.get({
      gcsPath: 'Test string',
      location: 'Test string',
      projectId: 'Test string',
      view: 'Test string',
    });
    /** Launches a template. To launch a template, we recommend using `projects.locations.templates.launch` with a [regional endpoint] (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints). Using `projects.templates.launch` is not recommended, because jobs launched from the template will always start in `us-central1`. */
    await gapi.client.dataflow.projects.templates.launch(
      {
        'dynamicTemplate.gcsPath': 'Test string',
        'dynamicTemplate.stagingLocation': 'Test string',
        gcsPath: 'Test string',
        location: 'Test string',
        projectId: 'Test string',
        validateOnly: true,
      },
      {
        environment: {
          additionalExperiments: ['Test string'],
          additionalUserLabels: {
            A: 'Test string',
          },
          bypassTempDirValidation: true,
          diskSizeGb: 42,
          enableStreamingEngine: true,
          ipConfiguration: 'Test string',
          kmsKeyName: 'Test string',
          machineType: 'Test string',
          maxWorkers: 42,
          network: 'Test string',
          numWorkers: 42,
          serviceAccountEmail: 'Test string',
          streamingMode: 'Test string',
          subnetwork: 'Test string',
          tempLocation: 'Test string',
          workerRegion: 'Test string',
          workerZone: 'Test string',
          zone: 'Test string',
        },
        jobName: 'Test string',
        parameters: {
          A: 'Test string',
        },
        transformNameMapping: {
          A: 'Test string',
        },
        update: true,
      }
    );
  }
});
